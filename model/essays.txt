April 2016  <br/>  <br/> _(This is a talk I gave at an event called Opt412 in Pittsburgh. Much of it<br/>will apply to other towns. But not all, because as I say in the talk,<br/>Pittsburgh has some important advantages over most would-be startup hubs.)_  <br/>  <br/>What would it take to make Pittsburgh into a startup hub, like Silicon Valley?<br/>I understand Pittsburgh pretty well, because I grew up here, in Monroeville.<br/>And I understand Silicon Valley pretty well because that's where I live now.<br/>Could you get that kind of startup ecosystem going here?  <br/>  <br/>When I agreed to speak here, I didn't think I'd be able to give a very<br/>optimistic talk. I thought I'd be talking about what Pittsburgh could do to<br/>become a startup hub, very much in the subjunctive. Instead I'm going to talk<br/>about what Pittsburgh can do.  <br/>  <br/>What changed my mind was an article I read in, of all places, the _New York<br/>Times_ food section. The title was " _Pittsburgh's Youth-Driven Food Boom_."<br/>To most people that might not even sound interesting, let alone something<br/>related to startups. But it was electrifying to me to read that title. I don't<br/>think I could pick a more promising one if I tried. And when I read the<br/>article I got even more excited. It said "people ages 25 to 29 now make up 7.6<br/>percent of all residents, up from 7 percent about a decade ago." Wow, I<br/>thought, Pittsburgh could be the next Portland. It could become the cool place<br/>all the people in their twenties want to go live.  <br/>  <br/>When I got here a couple days ago, I could feel the difference. I lived here<br/>from 1968 to 1984. I didn't realize it at the time, but during that whole<br/>period the city was in free fall. On top of the flight to the suburbs that<br/>happened everywhere, the steel and nuclear businesses were both dying. Boy are<br/>things different now. It's not just that downtown seems a lot more prosperous.<br/>There is an energy here that was not here when I was a kid.  <br/>  <br/>When I was a kid, this was a place young people left. Now it's a place that<br/>attracts them.  <br/>  <br/>What does that have to do with startups? Startups are made of people, and the<br/>average age of the people in a typical startup is right in that 25 to 29<br/>bracket.  <br/>  <br/>I've seen how powerful it is for a city to have those people. Five years ago<br/>they shifted the center of gravity of Silicon Valley from the peninsula to San<br/>Francisco. Google and Facebook are on the peninsula, but the next generation<br/>of big winners are all in SF. The reason the center of gravity shifted was the<br/>talent war, for programmers especially. Most 25 to 29 year olds want to live<br/>in the city, not down in the boring suburbs. So whether they like it or not,<br/>founders know they have to be in the city. I know multiple founders who would<br/>have preferred to live down in the Valley proper, but who made themselves move<br/>to SF because they knew otherwise they'd lose the talent war.  <br/>  <br/>So being a magnet for people in their twenties is a very promising thing to<br/>be. It's hard to imagine a place becoming a startup hub without also being<br/>that. When I read that statistic about the increasing percentage of 25 to 29<br/>year olds, I had exactly the same feeling of excitement I get when I see a<br/>startup's graphs start to creep upward off the x axis.  <br/>  <br/>Nationally the percentage of 25 to 29 year olds is 6.8%. That means you're .8%<br/>ahead. The population is 306,000, so we're talking about a surplus of about<br/>2500 people. That's the population of a small town, and that's just the<br/>surplus. So you have a toehold. Now you just have to expand it.  <br/>  <br/>And though "youth-driven food boom" may sound frivolous, it is anything but.<br/>Restaurants and cafes are a big part of the personality of a city. Imagine<br/>walking down a street in Paris. What are you walking past? Little restaurants<br/>and cafes. Imagine driving through some depressing random exurb. What are you<br/>driving past? Starbucks and McDonalds and Pizza Hut. As Gertrude Stein said,<br/>there is no there there. You could be anywhere.  <br/>  <br/>These independent restaurants and cafes are not just feeding people. They're<br/>making there be a there here.  <br/>  <br/>So here is my first concrete recommendation for turning Pittsburgh into the<br/>next Silicon Valley: do everything you can to encourage this youth-driven food<br/>boom. What could the city do? Treat the people starting these little<br/>restaurants and cafes as your users, and go ask them what they want. I can<br/>guess at least one thing they might want: a fast permit process. San Francisco<br/>has left you a huge amount of room to beat them in that department.  <br/>  <br/>I know restaurants aren't the prime mover though. The prime mover, as the<br/>Times article said, is cheap housing. That's a big advantage. But that phrase<br/>"cheap housing" is a bit misleading. There are plenty of places that are<br/>cheaper. What's special about Pittsburgh is not that it's cheap, but that it's<br/>a cheap place you'd actually want to live.  <br/>  <br/>Part of that is the buildings themselves. I realized a long time ago, back<br/>when I was a poor twenty-something myself, that the best deals were places<br/>that had once been rich, and then became poor. If a place has always been<br/>rich, it's nice but too expensive. If a place has always been poor, it's cheap<br/>but grim. But if a place was once rich and then got poor, you can find palaces<br/>for cheap. And that's what's bringing people here. When Pittsburgh was rich, a<br/>hundred years ago, the people who lived here built big solid buildings. Not<br/>always in the best taste, but definitely solid. So here is another piece of<br/>advice for becoming a startup hub: don't destroy the buildings that are<br/>bringing people here. When cities are on the way back up, like Pittsburgh is<br/>now, developers race to tear down the old buildings. Don't let that happen.<br/>Focus on historic preservation. Big real estate development projects are not<br/>what's bringing the twenty-somethings here. They're the opposite of the new<br/>restaurants and cafes; they subtract personality from the city.  <br/>  <br/>The empirical evidence suggests you cannot be too strict about historic<br/>preservation. The tougher cities are about it, the better they seem to do.  <br/>  <br/>But the appeal of Pittsburgh is not just the buildings themselves. It's the<br/>neighborhoods they're in. Like San Francisco and New York, Pittsburgh is<br/>fortunate in being a pre-car city. It's not too spread out. Because those 25<br/>to 29 year olds do not like driving. They prefer walking, or bicycling, or<br/>taking public transport. If you've been to San Francisco recently you can't<br/>help noticing the huge number of bicyclists. And this is not just a fad that<br/>the twenty-somethings have adopted. In this respect they have discovered a<br/>better way to live. The beards will go, but not the bikes. Cities where you<br/>can get around without driving are just better period. So I would suggest you<br/>do everything you can to capitalize on this. As with historic preservation, it<br/>seems impossible to go too far.  <br/>  <br/>Why not make Pittsburgh the most bicycle and pedestrian friendly city in the<br/>country? See if you can go so far that you make San Francisco seem backward by<br/>comparison. If you do, it's very unlikely you'll regret it. The city will seem<br/>like a paradise to the young people you want to attract. If they do leave to<br/>get jobs elsewhere, it will be with regret at leaving behind such a place. And<br/>what's the downside? Can you imagine a headline "City ruined by becoming too<br/>bicycle-friendly?" It just doesn't happen.  <br/>  <br/>So suppose cool old neighborhoods and cool little restaurants make this the<br/>next Portland. Will that be enough? It will put you in a way better position<br/>than Portland itself, because Pittsburgh has something Portland lacks: a<br/>first-rate research university. CMU plus little cafes means you have more than<br/>hipsters drinking lattes. It means you have hipsters drinking lattes while<br/>talking about distributed systems. Now you're getting really close to San<br/>Francisco.  <br/>  <br/>In fact you're better off than San Francisco in one way, because CMU is<br/>downtown, but Stanford and Berkeley are out in the suburbs.  <br/>  <br/>What can CMU do to help Pittsburgh become a startup hub? Be an even better<br/>research university. CMU is one of the best universities in the world, but<br/>imagine what things would be like if it were the very best, and everyone knew<br/>it. There are a lot of ambitious people who must go to the best place,<br/>wherever it is. If CMU were it, they would all come here. There would be kids<br/>in Kazakhstan dreaming of one day living in Pittsburgh.  <br/>  <br/>Being that kind of talent magnet is the most important contribution<br/>universities can make toward making their city a startup hub. In fact it is<br/>practically the only contribution they can make.  <br/>  <br/>But wait, shouldn't universities be setting up programs with words like<br/>"innovation" and "entrepreneurship" in their names? No, they should not. These<br/>kind of things almost always turn out to be disappointments. They're pursuing<br/>the wrong targets. The way to get innovation is not to aim for innovation but<br/>to aim for something more specific, like better batteries or better 3D<br/>printing. And the way to learn about entrepreneurship is to do it, which you<br/>_can't in school_.  <br/>  <br/>I know it may disappoint some administrators to hear that the best thing a<br/>university can do to encourage startups is to be a great university. It's like<br/>telling people who want to lose weight that the way to do it is to eat less.  <br/>  <br/>But if you want to know where startups come from, look at the empirical<br/>evidence. Look at the histories of the most successful startups, and you'll<br/>find they grow organically out of a couple of founders building something that<br/>starts as an interesting side project. Universities are great at bringing<br/>together founders, but beyond that the best thing they can do is get out of<br/>the way. For example, by not claiming ownership of "intellectual property"<br/>that students and faculty develop, and by having liberal rules about deferred<br/>admission and leaves of absence.  <br/>  <br/>In fact, one of the most effective things a university could do to encourage<br/>startups is an elaborate form of getting out of the way invented by Harvard.<br/>Harvard used to have exams for the fall semester after Christmas. At the<br/>beginning of January they had something called "Reading Period" when you were<br/>supposed to be studying for exams. And Microsoft and Facebook have something<br/>in common that few people realize: they were both started during Reading<br/>Period. It's the perfect situation for producing the sort of side projects<br/>that turn into startups. The students are all on campus, but they don't have<br/>to do anything because they're supposed to be studying for exams.  <br/>  <br/>Harvard may have closed this window, because a few years ago they moved exams<br/>before Christmas and shortened reading period from 11 days to 7. But if a<br/>university really wanted to help its students start startups, the empirical<br/>evidence, weighted by market cap, suggests the best thing they can do is<br/>literally nothing.  <br/>  <br/>The culture of Pittsburgh is another of its strengths. It seems like a city<br/>has to be socially liberal to be a startup hub, and it's pretty clear why. A<br/>city has to tolerate strangeness to be a home for startups, because startups<br/>are so strange. And you can't choose to allow just the forms of strangeness<br/>that will turn into big startups, because they're all intermingled. You have<br/>to tolerate all strangeness.  <br/>  <br/>That immediately rules out _big chunks of the US_. I'm optimistic it doesn't<br/>rule out Pittsburgh. One of the things I remember from growing up here, though<br/>I didn't realize at the time that there was anything unusual about it, is how<br/>well people got along. I'm still not sure why. Maybe one reason was that<br/>everyone felt like an immigrant. When I was a kid in Monroeville, people<br/>didn't call themselves American. They called themselves Italian or Serbian or<br/>Ukranian. Just imagine what it must have been like here a hundred years ago,<br/>when people were pouring in from twenty different countries. Tolerance was the<br/>only option.  <br/>  <br/>What I remember about the culture of Pittsburgh is that it was both tolerant<br/>and pragmatic. That's how I'd describe the culture of Silicon Valley too. And<br/>it's not a coincidence, because Pittsburgh was the Silicon Valley of its time.<br/>This was a city where people built new things. And while the things people<br/>build have changed, the spirit you need to do that kind of work is the same.  <br/>  <br/>So although an influx of latte-swilling hipsters may be annoying in some ways,<br/>I would go out of my way to encourage them. And more generally to tolerate<br/>strangeness, even unto the degree wacko Californians do. For Pittsburgh that<br/>is a conservative choice: it's a return to the city's roots.  <br/>  <br/>Unfortunately I saved the toughest part for last. There is one more thing you<br/>need to be a startup hub, and Pittsburgh hasn't got it: investors. Silicon<br/>Valley has a big investor community because it's had 50 years to grow one. New<br/>York has a big investor community because it's full of people who like money a<br/>lot and are quick to notice new ways to get it. But Pittsburgh has neither of<br/>these. And the cheap housing that draws other people here has no effect on<br/>investors.  <br/>  <br/>If an investor community grows up here, it will happen the same way it did in<br/>Silicon Valley: slowly and organically. So I would not bet on having a big<br/>investor community in the short term. But fortunately there are three trends<br/>that make that less necessary than it used to be. One is that startups are<br/>increasingly cheap to start, so you just don't need as much outside money as<br/>you used to. The second is that thanks to things like Kickstarter, a startup<br/>can get to revenue faster. You can put something on Kickstarter from anywhere.<br/>The third is programs like Y Combinator. A startup from anywhere in the world<br/>can go to YC for 3 months, pick up funding, and then return home if they want.  <br/>  <br/>My advice is to make Pittsburgh a great place for startups, and gradually more<br/>of them will stick. Some of those will succeed; some of their founders will<br/>become investors; and still more startups will stick.  <br/>  <br/>This is not a fast path to becoming a startup hub. But it is at least a path,<br/>which is something few other cities have. And it's not as if you have to make<br/>painful sacrifices in the meantime. Think about what I've suggested you should<br/>do. Encourage local restaurants, save old buildings, take advantage of<br/>density, make CMU the best, promote tolerance. These are the things that make<br/>Pittsburgh good to live in now. All I'm saying is that you should do even more<br/>of them.  <br/>  <br/>And that's an encouraging thought. If Pittsburgh's path to becoming a startup<br/>hub is to be even more itself, then it has a good chance of succeeding. In<br/>fact it probably has the best chance of any city its size. It will take some<br/>effort, and a lot of time, but if any city can do it, Pittsburgh can.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Thanks** to Charlie Cheever and Jessica Livingston for reading drafts of<br/>this, and to Meg Cheever for organizing Opt412 and inviting me to speak.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>November 2012  <br/>  <br/>The way to get startup ideas is not to try to think of startup ideas. It's to<br/>look for problems, preferably problems you have yourself.  <br/>  <br/>The very best startup ideas tend to have three things in common: they're<br/>something the founders themselves want, that they themselves can build, and<br/>that few others realize are worth doing. Microsoft, Apple, Yahoo, Google, and<br/>Facebook all began this way.  <br/>  <br/>**Problems**  <br/>  <br/>Why is it so important to work on a problem you have? Among other things, it<br/>ensures the problem really exists. It sounds obvious to say you should only<br/>work on problems that exist. And yet by far the most common mistake startups<br/>make is to solve problems no one has.  <br/>  <br/>I made it myself. In 1995 I started a company to put art galleries online. But<br/>galleries didn't want to be online. It's not how the art business works. So<br/>why did I spend 6 months working on this stupid idea? Because I didn't pay<br/>attention to users. I invented a model of the world that didn't correspond to<br/>reality, and worked from that. I didn't notice my model was wrong until I<br/>tried to convince users to pay for what we'd built. Even then I took<br/>embarrassingly long to catch on. I was attached to my model of the world, and<br/>I'd spent a lot of time on the software. They had to want it!  <br/>  <br/>Why do so many founders build things no one wants? Because they begin by<br/>trying to think of startup ideas. That m.o. is doubly dangerous: it doesn't<br/>merely yield few good ideas; it yields bad ideas that sound plausible enough<br/>to fool you into working on them.  <br/>  <br/>At YC we call these "made-up" or "sitcom" startup ideas. Imagine one of the<br/>characters on a TV show was starting a startup. The writers would have to<br/>invent something for it to do. But coming up with good startup ideas is hard.<br/>It's not something you can do for the asking. So (unless they got amazingly<br/>lucky) the writers would come up with an idea that sounded plausible, but was<br/>actually bad.  <br/>  <br/>For example, a social network for pet owners. It doesn't sound obviously<br/>mistaken. Millions of people have pets. Often they care a lot about their pets<br/>and spend a lot of money on them. Surely many of these people would like a<br/>site where they could talk to other pet owners. Not all of them perhaps, but<br/>if just 2 or 3 percent were regular visitors, you could have millions of<br/>users. You could serve them targeted offers, and maybe charge for premium<br/>features. [1]  <br/>  <br/>The danger of an idea like this is that when you run it by your friends with<br/>pets, they don't say "I would _never_ use this." They say "Yeah, maybe I could<br/>see using something like that." Even when the startup launches, it will sound<br/>plausible to a lot of people. They don't want to use it themselves, at least<br/>not right now, but they could imagine other people wanting it. Sum that<br/>reaction across the entire population, and you have zero users. [2]  <br/>  <br/>**Well**  <br/>  <br/>When a startup launches, there have to be at least some users who really need<br/>what they're making — not just people who could see themselves using it one<br/>day, but who want it urgently. Usually this initial group of users is small,<br/>for the simple reason that if there were something that large numbers of<br/>people urgently needed and that could be built with the amount of effort a<br/>startup usually puts into a version one, it would probably already exist.<br/>Which means you have to compromise on one dimension: you can either build<br/>something a large number of people want a small amount, or something a small<br/>number of people want a large amount. Choose the latter. Not all ideas of that<br/>type are good startup ideas, but nearly all good startup ideas are of that<br/>type.  <br/>  <br/>Imagine a graph whose x axis represents all the people who might want what<br/>you're making and whose y axis represents how much they want it. If you invert<br/>the scale on the y axis, you can envision companies as holes. Google is an<br/>immense crater: hundreds of millions of people use it, and they need it a lot.<br/>A startup just starting out can't expect to excavate that much volume. So you<br/>have two choices about the shape of hole you start with. You can either dig a<br/>hole that's broad but shallow, or one that's narrow and deep, like a well.  <br/>  <br/>Made-up startup ideas are usually of the first type. Lots of people are mildly<br/>interested in a social network for pet owners.  <br/>  <br/>Nearly all good startup ideas are of the second type. Microsoft was a well<br/>when they made Altair Basic. There were only a couple thousand Altair owners,<br/>but without this software they were programming in machine language. Thirty<br/>years later Facebook had the same shape. Their first site was exclusively for<br/>Harvard students, of which there are only a few thousand, but those few<br/>thousand users wanted it a lot.  <br/>  <br/>When you have an idea for a startup, ask yourself: who wants this right now?<br/>Who wants this so much that they'll use it even when it's a crappy version one<br/>made by a two-person startup they've never heard of? If you can't answer that,<br/>the idea is probably bad. [3]  <br/>  <br/>You don't need the narrowness of the well per se. It's depth you need; you get<br/>narrowness as a byproduct of optimizing for depth (and speed). But you almost<br/>always do get it. In practice the link between depth and narrowness is so<br/>strong that it's a good sign when you know that an idea will appeal strongly<br/>to a specific group or type of user.  <br/>  <br/>But while demand shaped like a well is almost a necessary condition for a good<br/>startup idea, it's not a sufficient one. If Mark Zuckerberg had built<br/>something that could only ever have appealed to Harvard students, it would not<br/>have been a good startup idea. Facebook was a good idea because it started<br/>with a small market there was a fast path out of. Colleges are similar enough<br/>that if you build a facebook that works at Harvard, it will work at any<br/>college. So you spread rapidly through all the colleges. Once you have all the<br/>college students, you get everyone else simply by letting them in.  <br/>  <br/>Similarly for Microsoft: Basic for the Altair; Basic for other machines; other<br/>languages besides Basic; operating systems; applications; IPO.  <br/>  <br/>**Self**  <br/>  <br/>How do you tell whether there's a path out of an idea? How do you tell whether<br/>something is the germ of a giant company, or just a niche product? Often you<br/>can't. The founders of Airbnb didn't realize at first how big a market they<br/>were tapping. Initially they had a much narrower idea. They were going to let<br/>hosts rent out space on their floors during conventions. They didn't foresee<br/>the expansion of this idea; it forced itself upon them gradually. All they<br/>knew at first is that they were onto something. That's probably as much as<br/>Bill Gates or Mark Zuckerberg knew at first.  <br/>  <br/>Occasionally it's obvious from the beginning when there's a path out of the<br/>initial niche. And sometimes I can see a path that's not immediately obvious;<br/>that's one of our specialties at YC. But there are limits to how well this can<br/>be done, no matter how much experience you have. The most important thing to<br/>understand about paths out of the initial idea is the meta-fact that these are<br/>hard to see.  <br/>  <br/>So if you can't predict whether there's a path out of an idea, how do you<br/>choose between ideas? The truth is disappointing but interesting: if you're<br/>the right sort of person, you have the right sort of hunches. If you're at the<br/>leading edge of a field that's changing fast, when you have a hunch that<br/>something is worth doing, you're more likely to be right.  <br/>  <br/>In _Zen and the Art of Motorcycle Maintenance_ , Robert Pirsig says:<br/><br/>> You want to know how to paint a perfect painting? It's easy. Make yourself<br/>> perfect and then just paint naturally.<br/><br/>I've wondered about that passage since I read it in high school. I'm not sure<br/>how useful his advice is for painting specifically, but it fits this situation<br/>well. Empirically, the way to have good startup ideas is to become the sort of<br/>person who has them.  <br/>  <br/>Being at the leading edge of a field doesn't mean you have to be one of the<br/>people pushing it forward. You can also be at the leading edge as a user. It<br/>was not so much because he was a programmer that Facebook seemed a good idea<br/>to Mark Zuckerberg as because he used computers so much. If you'd asked most<br/>40 year olds in 2004 whether they'd like to publish their lives semi-publicly<br/>on the Internet, they'd have been horrified at the idea. But Mark already<br/>lived online; to him it seemed natural.  <br/>  <br/>Paul Buchheit says that people at the leading edge of a rapidly changing field<br/>"live in the future." Combine that with Pirsig and you get:<br/><br/>> Live in the future, then build what's missing.<br/><br/>That describes the way many if not most of the biggest startups got started.<br/>Neither Apple nor Yahoo nor Google nor Facebook were even supposed to be<br/>companies at first. They grew out of things their founders built because there<br/>seemed a gap in the world.  <br/>  <br/>If you look at the way successful founders have had their ideas, it's<br/>generally the result of some external stimulus hitting a prepared mind. Bill<br/>Gates and Paul Allen hear about the Altair and think "I bet we could write a<br/>Basic interpreter for it." Drew Houston realizes he's forgotten his USB stick<br/>and thinks "I really need to make my files live online." Lots of people heard<br/>about the Altair. Lots forgot USB sticks. The reason those stimuli caused<br/>those founders to start companies was that their experiences had prepared them<br/>to notice the opportunities they represented.  <br/>  <br/>The verb you want to be using with respect to startup ideas is not "think up"<br/>but "notice." At YC we call ideas that grow naturally out of the founders' own<br/>experiences "organic" startup ideas. The most successful startups almost all<br/>begin this way.  <br/>  <br/>That may not have been what you wanted to hear. You may have expected recipes<br/>for coming up with startup ideas, and instead I'm telling you that the key is<br/>to have a mind that's prepared in the right way. But disappointing though it<br/>may be, this is the truth. And it is a recipe of a sort, just one that in the<br/>worst case takes a year rather than a weekend.  <br/>  <br/>If you're not at the leading edge of some rapidly changing field, you can get<br/>to one. For example, anyone reasonably smart can probably get to an edge of<br/>programming (e.g. building mobile apps) in a year. Since a successful startup<br/>will consume at least 3-5 years of your life, a year's preparation would be a<br/>reasonable investment. Especially if you're also looking for a cofounder. [4]  <br/>  <br/>You don't have to learn programming to be at the leading edge of a domain<br/>that's changing fast. Other domains change fast. But while learning to hack is<br/>not necessary, it is for the forseeable future sufficient. As Marc Andreessen<br/>put it, software is eating the world, and this trend has decades left to run.  <br/>  <br/>Knowing how to hack also means that when you have ideas, you'll be able to<br/>implement them. That's not absolutely necessary (Jeff Bezos couldn't) but it's<br/>an advantage. It's a big advantage, when you're considering an idea like<br/>putting a college facebook online, if instead of merely thinking "That's an<br/>interesting idea," you can think instead "That's an interesting idea. I'll try<br/>building an initial version tonight." It's even better when you're both a<br/>programmer and the target user, because then the cycle of generating new<br/>versions and testing them on users can happen inside one head.  <br/>  <br/>**Noticing**  <br/>  <br/>Once you're living in the future in some respect, the way to notice startup<br/>ideas is to look for things that seem to be missing. If you're really at the<br/>leading edge of a rapidly changing field, there will be things that are<br/>obviously missing. What won't be obvious is that they're startup ideas. So if<br/>you want to find startup ideas, don't merely turn on the filter "What's<br/>missing?" Also turn off every other filter, particularly "Could this be a big<br/>company?" There's plenty of time to apply that test later. But if you're<br/>thinking about that initially, it may not only filter out lots of good ideas,<br/>but also cause you to focus on bad ones.  <br/>  <br/>Most things that are missing will take some time to see. You almost have to<br/>trick yourself into seeing the ideas around you.  <br/>  <br/>But you _know_ the ideas are out there. This is not one of those problems<br/>where there might not be an answer. It's impossibly unlikely that this is the<br/>exact moment when technological progress stops. You can be sure people are<br/>going to build things in the next few years that will make you think "What did<br/>I do before x?"  <br/>  <br/>And when these problems get solved, they will probably seem flamingly obvious<br/>in retrospect. What you need to do is turn off the filters that usually<br/>prevent you from seeing them. The most powerful is simply taking the current<br/>state of the world for granted. Even the most radically open-minded of us<br/>mostly do that. You couldn't get from your bed to the front door if you<br/>stopped to question everything.  <br/>  <br/>But if you're looking for startup ideas you can sacrifice some of the<br/>efficiency of taking the status quo for granted and start to question things.<br/>Why is your inbox overflowing? Because you get a lot of email, or because it's<br/>hard to get email out of your inbox? Why do you get so much email? What<br/>problems are people trying to solve by sending you email? Are there better<br/>ways to solve them? And why is it hard to get emails out of your inbox? Why do<br/>you keep emails around after you've read them? Is an inbox the optimal tool<br/>for that?  <br/>  <br/>Pay particular attention to things that chafe you. The advantage of taking the<br/>status quo for granted is not just that it makes life (locally) more<br/>efficient, but also that it makes life more tolerable. If you knew about all<br/>the things we'll get in the next 50 years but don't have yet, you'd find<br/>present day life pretty constraining, just as someone from the present would<br/>if they were sent back 50 years in a time machine. When something annoys you,<br/>it could be because you're living in the future.  <br/>  <br/>When you find the right sort of problem, you should probably be able to<br/>describe it as _obvious_ , at least to you. When we started Viaweb, all the<br/>online stores were built by hand, by web designers making individual HTML<br/>pages. It was obvious to us as programmers that these sites would have to be<br/>generated by software. [5]  <br/>  <br/>Which means, strangely enough, that coming up with startup ideas is a question<br/>of seeing the obvious. That suggests how weird this process is: you're trying<br/>to see things that are obvious, and yet that you hadn't seen.  <br/>  <br/>Since what you need to do here is loosen up your own mind, it may be best not<br/>to make too much of a direct frontal attack on the problem — i.e. to sit down<br/>and try to think of ideas. The best plan may be just to keep a background<br/>process running, looking for things that seem to be missing. Work on hard<br/>problems, driven mainly by curiosity, but have a second self watching over<br/>your shoulder, taking note of gaps and anomalies. [6]  <br/>  <br/>Give yourself some time. You have a lot of control over the rate at which you<br/>turn yours into a prepared mind, but you have less control over the stimuli<br/>that spark ideas when they hit it. If Bill Gates and Paul Allen had<br/>constrained themselves to come up with a startup idea in one month, what if<br/>they'd chosen a month before the Altair appeared? They probably would have<br/>worked on a less promising idea. Drew Houston did work on a less promising<br/>idea before Dropbox: an SAT prep startup. But Dropbox was a much better idea,<br/>both in the absolute sense and also as a match for his skills. [7]  <br/>  <br/>A good way to trick yourself into noticing ideas is to work on projects that<br/>seem like they'd be cool. If you do that, you'll naturally tend to build<br/>things that are missing. It wouldn't seem as interesting to build something<br/>that already existed.  <br/>  <br/>Just as trying to think up startup ideas tends to produce bad ones, working on<br/>things that could be dismissed as "toys" often produces good ones. When<br/>something is described as a toy, that means it has everything an idea needs<br/>except being important. It's cool; users love it; it just doesn't matter. But<br/>if you're living in the future and you build something cool that users love,<br/>it may matter more than outsiders think. Microcomputers seemed like toys when<br/>Apple and Microsoft started working on them. I'm old enough to remember that<br/>era; the usual term for people with their own microcomputers was "hobbyists."<br/>BackRub seemed like an inconsequential science project. The Facebook was just<br/>a way for undergrads to stalk one another.  <br/>  <br/>At YC we're excited when we meet startups working on things that we could<br/>imagine know-it-alls on forums dismissing as toys. To us that's positive<br/>evidence an idea is good.  <br/>  <br/>If you can afford to take a long view (and arguably you can't afford not to),<br/>you can turn "Live in the future and build what's missing" into something even<br/>better:<br/><br/>> Live in the future and build what seems interesting.<br/><br/>  <br/>  <br/>**School**  <br/>  <br/>That's what I'd advise college students to do, rather than trying to learn<br/>about "entrepreneurship." "Entrepreneurship" is something you learn best by<br/>doing it. The examples of the most successful founders make that clear. What<br/>you should be spending your time on in college is ratcheting yourself into the<br/>future. College is an incomparable opportunity to do that. What a waste to<br/>sacrifice an opportunity to solve the hard part of starting a startup —<br/>becoming the sort of person who can have organic startup ideas — by spending<br/>time learning about the easy part. Especially since you won't even really<br/>learn about it, any more than you'd learn about sex in a class. All you'll<br/>learn is the words for things.  <br/>  <br/>The clash of domains is a particularly fruitful source of ideas. If you know a<br/>lot about programming and you start learning about some other field, you'll<br/>probably see problems that software could solve. In fact, you're doubly likely<br/>to find good problems in another domain: (a) the inhabitants of that domain<br/>are not as likely as software people to have already solved their problems<br/>with software, and (b) since you come into the new domain totally ignorant,<br/>you don't even know what the status quo is to take it for granted.  <br/>  <br/>So if you're a CS major and you want to start a startup, instead of taking a<br/>class on entrepreneurship you're better off taking a class on, say, genetics.<br/>Or better still, go work for a biotech company. CS majors normally get summer<br/>jobs at computer hardware or software companies. But if you want to find<br/>startup ideas, you might do better to get a summer job in some unrelated<br/>field. [8]  <br/>  <br/>Or don't take any extra classes, and just build things. It's no coincidence<br/>that Microsoft and Facebook both got started in January. At Harvard that is<br/>(or was) Reading Period, when students have no classes to attend because<br/>they're supposed to be studying for finals. [9]  <br/>  <br/>But don't feel like you have to build things that will become startups. That's<br/>premature optimization. Just build things. Preferably with other students.<br/>It's not just the classes that make a university such a good place to crank<br/>oneself into the future. You're also surrounded by other people trying to do<br/>the same thing. If you work together with them on projects, you'll end up<br/>producing not just organic ideas, but organic ideas with organic founding<br/>teams — and that, empirically, is the best combination.  <br/>  <br/>Beware of research. If an undergrad writes something all his friends start<br/>using, it's quite likely to represent a good startup idea. Whereas a PhD<br/>dissertation is extremely unlikely to. For some reason, the more a project has<br/>to count as research, the less likely it is to be something that could be<br/>turned into a startup. [10] I think the reason is that the subset of ideas<br/>that count as research is so narrow that it's unlikely that a project that<br/>satisfied that constraint would also satisfy the orthogonal constraint of<br/>solving users' problems. Whereas when students (or professors) build something<br/>as a side-project, they automatically gravitate toward solving users' problems<br/>— perhaps even with an additional energy that comes from being freed from the<br/>constraints of research.  <br/>  <br/>**Competition**  <br/>  <br/>Because a good idea should seem obvious, when you have one you'll tend to feel<br/>that you're late. Don't let that deter you. Worrying that you're late is one<br/>of the signs of a good idea. Ten minutes of searching the web will usually<br/>settle the question. Even if you find someone else working on the same thing,<br/>you're probably not too late. It's exceptionally rare for startups to be<br/>killed by competitors — so rare that you can almost discount the possibility.<br/>So unless you discover a competitor with the sort of lock-in that would<br/>prevent users from choosing you, don't discard the idea.  <br/>  <br/>If you're uncertain, ask users. The question of whether you're too late is<br/>subsumed by the question of whether anyone urgently needs what you plan to<br/>make. If you have something that no competitor does and that some subset of<br/>users urgently need, you have a beachhead. [11]  <br/>  <br/>The question then is whether that beachhead is big enough. Or more<br/>importantly, who's in it: if the beachhead consists of people doing something<br/>lots more people will be doing in the future, then it's probably big enough no<br/>matter how small it is. For example, if you're building something<br/>differentiated from competitors by the fact that it works on phones, but it<br/>only works on the newest phones, that's probably a big enough beachhead.  <br/>  <br/>Err on the side of doing things where you'll face competitors. Inexperienced<br/>founders usually give competitors more credit than they deserve. Whether you<br/>succeed depends far more on you than on your competitors. So better a good<br/>idea with competitors than a bad one without.  <br/>  <br/>You don't need to worry about entering a "crowded market" so long as you have<br/>a thesis about what everyone else in it is overlooking. In fact that's a very<br/>promising starting point. Google was that type of idea. Your thesis has to be<br/>more precise than "we're going to make an x that doesn't suck" though. You<br/>have to be able to phrase it in terms of something the incumbents are<br/>overlooking. Best of all is when you can say that they didn't have the courage<br/>of their convictions, and that your plan is what they'd have done if they'd<br/>followed through on their own insights. Google was that type of idea too. The<br/>search engines that preceded them shied away from the most radical<br/>implications of what they were doing — particularly that the better a job they<br/>did, the faster users would leave.  <br/>  <br/>A crowded market is actually a good sign, because it means both that there's<br/>demand and that none of the existing solutions are good enough. A startup<br/>can't hope to enter a market that's obviously big and yet in which they have<br/>no competitors. So any startup that succeeds is either going to be entering a<br/>market with existing competitors, but armed with some secret weapon that will<br/>get them all the users (like Google), or entering a market that looks small<br/>but which will turn out to be big (like Microsoft). [12]  <br/>  <br/>**Filters**  <br/>  <br/>There are two more filters you'll need to turn off if you want to notice<br/>startup ideas: the unsexy filter and the schlep filter.  <br/>  <br/>Most programmers wish they could start a startup by just writing some<br/>brilliant code, pushing it to a server, and having users pay them lots of<br/>money. They'd prefer not to deal with tedious problems or get involved in<br/>messy ways with the real world. Which is a reasonable preference, because such<br/>things slow you down. But this preference is so widespread that the space of<br/>convenient startup ideas has been stripped pretty clean. If you let your mind<br/>wander a few blocks down the street to the messy, tedious ideas, you'll find<br/>valuable ones just sitting there waiting to be implemented.  <br/>  <br/>The schlep filter is so dangerous that I wrote a separate essay about the<br/>condition it induces, which I called schlep blindness. I gave Stripe as an<br/>example of a startup that benefited from turning off this filter, and a pretty<br/>striking example it is. Thousands of programmers were in a position to see<br/>this idea; thousands of programmers knew how painful it was to process<br/>payments before Stripe. But when they looked for startup ideas they didn't see<br/>this one, because unconsciously they shrank from having to deal with payments.<br/>And dealing with payments is a schlep for Stripe, but not an intolerable one.<br/>In fact they might have had net less pain; because the fear of dealing with<br/>payments kept most people away from this idea, Stripe has had comparatively<br/>smooth sailing in other areas that are sometimes painful, like user<br/>acquisition. They didn't have to try very hard to make themselves heard by<br/>users, because users were desperately waiting for what they were building.  <br/>  <br/>The unsexy filter is similar to the schlep filter, except it keeps you from<br/>working on problems you despise rather than ones you fear. We overcame this<br/>one to work on Viaweb. There were interesting things about the architecture of<br/>our software, but we weren't interested in ecommerce per se. We could see the<br/>problem was one that needed to be solved though.  <br/>  <br/>Turning off the schlep filter is more important than turning off the unsexy<br/>filter, because the schlep filter is more likely to be an illusion. And even<br/>to the degree it isn't, it's a worse form of self-indulgence. Starting a<br/>successful startup is going to be fairly laborious no matter what. Even if the<br/>product doesn't entail a lot of schleps, you'll still have plenty dealing with<br/>investors, hiring and firing people, and so on. So if there's some idea you<br/>think would be cool but you're kept away from by fear of the schleps involved,<br/>don't worry: any sufficiently good idea will have as many.  <br/>  <br/>The unsexy filter, while still a source of error, is not as entirely useless<br/>as the schlep filter. If you're at the leading edge of a field that's changing<br/>rapidly, your ideas about what's sexy will be somewhat correlated with what's<br/>valuable in practice. Particularly as you get older and more experienced. Plus<br/>if you find an idea sexy, you'll work on it more enthusiastically. [13]  <br/>  <br/>**Recipes**  <br/>  <br/>While the best way to discover startup ideas is to become the sort of person<br/>who has them and then build whatever interests you, sometimes you don't have<br/>that luxury. Sometimes you need an idea now. For example, if you're working on<br/>a startup and your initial idea turns out to be bad.  <br/>  <br/>For the rest of this essay I'll talk about tricks for coming up with startup<br/>ideas on demand. Although empirically you're better off using the organic<br/>strategy, you could succeed this way. You just have to be more disciplined.<br/>When you use the organic method, you don't even notice an idea unless it's<br/>evidence that something is truly missing. But when you make a conscious effort<br/>to think of startup ideas, you have to replace this natural constraint with<br/>self-discipline. You'll see a lot more ideas, most of them bad, so you need to<br/>be able to filter them.  <br/>  <br/>One of the biggest dangers of not using the organic method is the example of<br/>the organic method. Organic ideas feel like inspirations. There are a lot of<br/>stories about successful startups that began when the founders had what seemed<br/>a crazy idea but "just knew" it was promising. When you feel that about an<br/>idea you've had while trying to come up with startup ideas, you're probably<br/>mistaken.  <br/>  <br/>When searching for ideas, look in areas where you have some expertise. If<br/>you're a database expert, don't build a chat app for teenagers (unless you're<br/>also a teenager). Maybe it's a good idea, but you can't trust your judgment<br/>about that, so ignore it. There have to be other ideas that involve databases,<br/>and whose quality you can judge. Do you find it hard to come up with good<br/>ideas involving databases? That's because your expertise raises your<br/>standards. Your ideas about chat apps are just as bad, but you're giving<br/>yourself a Dunning-Kruger pass in that domain.  <br/>  <br/>The place to start looking for ideas is things you need. There _must_ be<br/>things you need. [14]  <br/>  <br/>One good trick is to ask yourself whether in your previous job you ever found<br/>yourself saying "Why doesn't someone make x? If someone made x we'd buy it in<br/>a second." If you can think of any x people said that about, you probably have<br/>an idea. You know there's demand, and people don't say that about things that<br/>are impossible to build.  <br/>  <br/>More generally, try asking yourself whether there's something unusual about<br/>you that makes your needs different from most other people's. You're probably<br/>not the only one. It's especially good if you're different in a way people<br/>will increasingly be.  <br/>  <br/>If you're changing ideas, one unusual thing about you is the idea you'd<br/>previously been working on. Did you discover any needs while working on it?<br/>Several well-known startups began this way. Hotmail began as something its<br/>founders wrote to talk about their previous startup idea while they were<br/>working at their day jobs. [15]  <br/>  <br/>A particularly promising way to be unusual is to be young. Some of the most<br/>valuable new ideas take root first among people in their teens and early<br/>twenties. And while young founders are at a disadvantage in some respects,<br/>they're the only ones who really understand their peers. It would have been<br/>very hard for someone who wasn't a college student to start Facebook. So if<br/>you're a young founder (under 23 say), are there things you and your friends<br/>would like to do that current technology won't let you?  <br/>  <br/>The next best thing to an unmet need of your own is an unmet need of someone<br/>else. Try talking to everyone you can about the gaps they find in the world.<br/>What's missing? What would they like to do that they can't? What's tedious or<br/>annoying, particularly in their work? Let the conversation get general; don't<br/>be trying too hard to find startup ideas. You're just looking for something to<br/>spark a thought. Maybe you'll notice a problem they didn't consciously realize<br/>they had, because you know how to solve it.  <br/>  <br/>When you find an unmet need that isn't your own, it may be somewhat blurry at<br/>first. The person who needs something may not know exactly what they need. In<br/>that case I often recommend that founders act like consultants — that they do<br/>what they'd do if they'd been retained to solve the problems of this one user.<br/>People's problems are similar enough that nearly all the code you write this<br/>way will be reusable, and whatever isn't will be a small price to start out<br/>certain that you've reached the bottom of the well. [16]  <br/>  <br/>One way to ensure you do a good job solving other people's problems is to make<br/>them your own. When Rajat Suri of E la Carte decided to write software for<br/>restaurants, he got a job as a waiter to learn how restaurants worked. That<br/>may seem like taking things to extremes, but startups are extreme. We love it<br/>when founders do such things.  <br/>  <br/>In fact, one strategy I recommend to people who need a new idea is not merely<br/>to turn off their schlep and unsexy filters, but to seek out ideas that are<br/>unsexy or involve schleps. Don't try to start Twitter. Those ideas are so rare<br/>that you can't find them by looking for them. Make something unsexy that<br/>people will pay you for.  <br/>  <br/>A good trick for bypassing the schlep and to some extent the unsexy filter is<br/>to ask what you wish someone else would build, so that you could use it. What<br/>would you pay for right now?  <br/>  <br/>Since startups often garbage-collect broken companies and industries, it can<br/>be a good trick to look for those that are dying, or deserve to, and try to<br/>imagine what kind of company would profit from their demise. For example,<br/>journalism is in free fall at the moment. But there may still be money to be<br/>made from something like journalism. What sort of company might cause people<br/>in the future to say "this replaced journalism" on some axis?  <br/>  <br/>But imagine asking that in the future, not now. When one company or industry<br/>replaces another, it usually comes in from the side. So don't look for a<br/>replacement for x; look for something that people will later say turned out to<br/>be a replacement for x. And be imaginative about the axis along which the<br/>replacement occurs. Traditional journalism, for example, is a way for readers<br/>to get information and to kill time, a way for writers to make money and to<br/>get attention, and a vehicle for several different types of advertising. It<br/>could be replaced on any of these axes (it has already started to be on most).  <br/>  <br/>When startups consume incumbents, they usually start by serving some small but<br/>important market that the big players ignore. It's particularly good if<br/>there's an admixture of disdain in the big players' attitude, because that<br/>often misleads them. For example, after Steve Wozniak built the computer that<br/>became the Apple I, he felt obliged to give his then-employer Hewlett-Packard<br/>the option to produce it. Fortunately for him, they turned it down, and one of<br/>the reasons they did was that it used a TV for a monitor, which seemed<br/>intolerably déclassé to a high-end hardware company like HP was at the time.<br/>[17]  <br/>  <br/>Are there groups of scruffy but sophisticated users like the early<br/>microcomputer "hobbyists" that are currently being ignored by the big players?<br/>A startup with its sights set on bigger things can often capture a small<br/>market easily by expending an effort that wouldn't be justified by that market<br/>alone.  <br/>  <br/>Similarly, since the most successful startups generally ride some wave bigger<br/>than themselves, it could be a good trick to look for waves and ask how one<br/>could benefit from them. The prices of gene sequencing and 3D printing are<br/>both experiencing Moore's Law-like declines. What new things will we be able<br/>to do in the new world we'll have in a few years? What are we unconsciously<br/>ruling out as impossible that will soon be possible?  <br/>  <br/>**Organic**  <br/>  <br/>But talking about looking explicitly for waves makes it clear that such<br/>recipes are plan B for getting startup ideas. Looking for waves is essentially<br/>a way to simulate the organic method. If you're at the leading edge of some<br/>rapidly changing field, you don't have to look for waves; you are the wave.  <br/>  <br/>Finding startup ideas is a subtle business, and that's why most people who try<br/>fail so miserably. It doesn't work well simply to try to think of startup<br/>ideas. If you do that, you get bad ones that sound dangerously plausible. The<br/>best approach is more indirect: if you have the right sort of background, good<br/>startup ideas will seem obvious to you. But even then, not immediately. It<br/>takes time to come across situations where you notice something missing. And<br/>often these gaps won't seem to be ideas for companies, just things that would<br/>be interesting to build. Which is why it's good to have the time and the<br/>inclination to build things just because they're interesting.  <br/>  <br/>Live in the future and build what seems interesting. Strange as it sounds,<br/>that's the real recipe.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] This form of bad idea has been around as long as the web. It was common in<br/>the 1990s, except then people who had it used to say they were going to create<br/>a portal for x instead of a social network for x. Structurally the idea is<br/>stone soup: you post a sign saying "this is the place for people interested in<br/>x," and all those people show up and you make money from them. What lures<br/>founders into this sort of idea are statistics about the millions of people<br/>who might be interested in each type of x. What they forget is that any given<br/>person might have 20 affinities by this standard, and no one is going to visit<br/>20 different communities regularly.  <br/>  <br/>[2] I'm not saying, incidentally, that I know for sure a social network for<br/>pet owners is a bad idea. I know it's a bad idea the way I know randomly<br/>generated DNA would not produce a viable organism. The set of plausible<br/>sounding startup ideas is many times larger than the set of good ones, and<br/>many of the good ones don't even sound that plausible. So if all you know<br/>about a startup idea is that it sounds plausible, you have to assume it's bad.  <br/>  <br/>[3] More precisely, the users' need has to give them sufficient activation<br/>energy to start using whatever you make, which can vary a lot. For example,<br/>the activation energy for enterprise software sold through traditional<br/>channels is very high, so you'd have to be a _lot_ better to get users to<br/>switch. Whereas the activation energy required to switch to a new search<br/>engine is low. Which in turn is why search engines are so much better than<br/>enterprise software.  <br/>  <br/>[4] This gets harder as you get older. While the space of ideas doesn't have<br/>dangerous local maxima, the space of careers does. There are fairly high walls<br/>between most of the paths people take through life, and the older you get, the<br/>higher the walls become.  <br/>  <br/>[5] It was also obvious to us that the web was going to be a big deal. Few<br/>non-programmers grasped that in 1995, but the programmers had seen what GUIs<br/>had done for desktop computers.  <br/>  <br/>[6] Maybe it would work to have this second self keep a journal, and each<br/>night to make a brief entry listing the gaps and anomalies you'd noticed that<br/>day. Not startup ideas, just the raw gaps and anomalies.  <br/>  <br/>[7] Sam Altman points out that taking time to come up with an idea is not<br/>merely a better strategy in an absolute sense, but also like an undervalued<br/>stock in that so few founders do it.  <br/>  <br/>There's comparatively little competition for the best ideas, because few<br/>founders are willing to put in the time required to notice them. Whereas there<br/>is a great deal of competition for mediocre ideas, because when people make up<br/>startup ideas, they tend to make up the same ones.  <br/>  <br/>[8] For the computer hardware and software companies, summer jobs are the<br/>first phase of the recruiting funnel. But if you're good you can skip the<br/>first phase. If you're good you'll have no trouble getting hired by these<br/>companies when you graduate, regardless of how you spent your summers.  <br/>  <br/>[9] The empirical evidence suggests that if colleges want to help their<br/>students start startups, the best thing they can do is leave them alone in the<br/>right way.  <br/>  <br/>[10] I'm speaking here of IT startups; in biotech things are different.  <br/>  <br/>[11] This is an instance of a more general rule: focus on users, not<br/>competitors. The most important information about competitors is what you<br/>learn via users anyway.  <br/>  <br/>[12] In practice most successful startups have elements of both. And you can<br/>describe each strategy in terms of the other by adjusting the boundaries of<br/>what you call the market. But it's useful to consider these two ideas<br/>separately.  <br/>  <br/>[13] I almost hesitate to raise that point though. Startups are businesses;<br/>the point of a business is to make money; and with that additional constraint,<br/>you can't expect you'll be able to spend all your time working on what<br/>interests you most.  <br/>  <br/>[14] The need has to be a strong one. You can retroactively describe any made-<br/>up idea as something you need. But do you really need that recipe site or<br/>local event aggregator as much as Drew Houston needed Dropbox, or Brian Chesky<br/>and Joe Gebbia needed Airbnb?  <br/>  <br/>Quite often at YC I find myself asking founders "Would you use this thing<br/>yourself, if you hadn't written it?" and you'd be surprised how often the<br/>answer is no.  <br/>  <br/>[15] Paul Buchheit points out that trying to sell something bad can be a<br/>source of better ideas:  <br/>  <br/>"The best technique I've found for dealing with YC companies that have bad<br/>ideas is to tell them to go sell the product ASAP (before wasting time<br/>building it). Not only do they learn that nobody wants what they are building,<br/>they very often come back with a real idea that they discovered in the process<br/>of trying to sell the bad idea."  <br/>  <br/>[16] Here's a recipe that might produce the next Facebook, if you're college<br/>students. If you have a connection to one of the more powerful sororities at<br/>your school, approach the queen bees thereof and offer to be their personal IT<br/>consultants, building anything they could imagine needing in their social<br/>lives that didn't already exist. Anything that got built this way would be<br/>very promising, because such users are not just the most demanding but also<br/>the perfect point to spread from.  <br/>  <br/>I have no idea whether this would work.  <br/>  <br/>[17] And the reason it used a TV for a monitor is that Steve Wozniak started<br/>out by solving his own problems. He, like most of his peers, couldn't afford a<br/>monitor.  <br/>  <br/>  <br/>  <br/> **Thanks** to Sam Altman, Mike Arrington, Paul Buchheit, John Collison,<br/>Patrick Collison, Garry Tan, and Harj Taggar for reading drafts of this, and<br/>Marc Andreessen, Joe Gebbia, Reid Hoffman, Shel Kaphan, Mike Moritz and Kevin<br/>Systrom for answering my questions about startup history.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>March 2008  <br/>  <br/>The web is turning writing into a conversation. Twenty years ago, writers<br/>wrote and readers read. The web lets readers respond, and increasingly they<br/>do—in comment threads, on forums, and in their own blog posts.  <br/>  <br/>Many who respond to something disagree with it. That's to be expected.<br/>Agreeing tends to motivate people less than disagreeing. And when you agree<br/>there's less to say. You could expand on something the author said, but he has<br/>probably already explored the most interesting implications. When you disagree<br/>you're entering territory he may not have explored.  <br/>  <br/>The result is there's a lot more disagreeing going on, especially measured by<br/>the word. That doesn't mean people are getting angrier. The structural change<br/>in the way we communicate is enough to account for it. But though it's not<br/>anger that's driving the increase in disagreement, there's a danger that the<br/>increase in disagreement will make people angrier. Particularly online, where<br/>it's easy to say things you'd never say face to face.  <br/>  <br/>If we're all going to be disagreeing more, we should be careful to do it well.<br/>What does it mean to disagree well? Most readers can tell the difference<br/>between mere name-calling and a carefully reasoned refutation, but I think it<br/>would help to put names on the intermediate stages. So here's an attempt at a<br/>disagreement hierarchy:  <br/>  <br/>**DH0. Name-calling.**  <br/>  <br/>This is the lowest form of disagreement, and probably also the most common.<br/>We've all seen comments like this:<br/><br/>> u r a fag!!!!!!!!!!<br/><br/>But it's important to realize that more articulate name-calling has just as<br/>little weight. A comment like<br/><br/>> The author is a self-important dilettante.<br/><br/>is really nothing more than a pretentious version of "u r a fag."  <br/>  <br/>**DH1. Ad Hominem.**  <br/>  <br/>An ad hominem attack is not quite as weak as mere name-calling. It might<br/>actually carry some weight. For example, if a senator wrote an article saying<br/>senators' salaries should be increased, one could respond:<br/><br/>> Of course he would say that. He's a senator.<br/><br/>This wouldn't refute the author's argument, but it may at least be relevant to<br/>the case. It's still a very weak form of disagreement, though. If there's<br/>something wrong with the senator's argument, you should say what it is; and if<br/>there isn't, what difference does it make that he's a senator?  <br/>  <br/>Saying that an author lacks the authority to write about a topic is a variant<br/>of ad hominem—and a particularly useless sort, because good ideas often come<br/>from outsiders. The question is whether the author is correct or not. If his<br/>lack of authority caused him to make mistakes, point those out. And if it<br/>didn't, it's not a problem.  <br/>  <br/>**DH2. Responding to Tone.**  <br/>  <br/>The next level up we start to see responses to the writing, rather than the<br/>writer. The lowest form of these is to disagree with the author's tone. E.g.<br/><br/>> I can't believe the author dismisses intelligent design in such a cavalier<br/>> fashion.<br/><br/>Though better than attacking the author, this is still a weak form of<br/>disagreement. It matters much more whether the author is wrong or right than<br/>what his tone is. Especially since tone is so hard to judge. Someone who has a<br/>chip on their shoulder about some topic might be offended by a tone that to<br/>other readers seemed neutral.  <br/>  <br/>So if the worst thing you can say about something is to criticize its tone,<br/>you're not saying much. Is the author flippant, but correct? Better that than<br/>grave and wrong. And if the author is incorrect somewhere, say where.  <br/>  <br/> **DH3. Contradiction.**  <br/>  <br/>In this stage we finally get responses to what was said, rather than how or by<br/>whom. The lowest form of response to an argument is simply to state the<br/>opposing case, with little or no supporting evidence.  <br/>  <br/>This is often combined with DH2 statements, as in:<br/><br/>> I can't believe the author dismisses intelligent design in such a cavalier<br/>> fashion. Intelligent design is a legitimate scientific theory.<br/><br/>Contradiction can sometimes have some weight. Sometimes merely seeing the<br/>opposing case stated explicitly is enough to see that it's right. But usually<br/>evidence will help.  <br/>  <br/> **DH4. Counterargument.**  <br/>  <br/>At level 4 we reach the first form of convincing disagreement:<br/>counterargument. Forms up to this point can usually be ignored as proving<br/>nothing. Counterargument might prove something. The problem is, it's hard to<br/>say exactly what.  <br/>  <br/>Counterargument is contradiction plus reasoning and/or evidence. When aimed<br/>squarely at the original argument, it can be convincing. But unfortunately<br/>it's common for counterarguments to be aimed at something slightly different.<br/>More often than not, two people arguing passionately about something are<br/>actually arguing about two different things. Sometimes they even agree with<br/>one another, but are so caught up in their squabble they don't realize it.  <br/>  <br/>There could be a legitimate reason for arguing against something slightly<br/>different from what the original author said: when you feel they missed the<br/>heart of the matter. But when you do that, you should say explicitly you're<br/>doing it.  <br/>  <br/> **DH5. Refutation.**  <br/>  <br/>The most convincing form of disagreement is refutation. It's also the rarest,<br/>because it's the most work. Indeed, the disagreement hierarchy forms a kind of<br/>pyramid, in the sense that the higher you go the fewer instances you find.  <br/>  <br/>To refute someone you probably have to quote them. You have to find a "smoking<br/>gun," a passage in whatever you disagree with that you feel is mistaken, and<br/>then explain why it's mistaken. If you can't find an actual quote to disagree<br/>with, you may be arguing with a straw man.  <br/>  <br/>While refutation generally entails quoting, quoting doesn't necessarily imply<br/>refutation. Some writers quote parts of things they disagree with to give the<br/>appearance of legitimate refutation, then follow with a response as low as DH3<br/>or even DH0.  <br/>  <br/> **DH6. Refuting the Central Point.**  <br/>  <br/>The force of a refutation depends on what you refute. The most powerful form<br/>of disagreement is to refute someone's central point.  <br/>  <br/>Even as high as DH5 we still sometimes see deliberate dishonesty, as when<br/>someone picks out minor points of an argument and refutes those. Sometimes the<br/>spirit in which this is done makes it more of a sophisticated form of ad<br/>hominem than actual refutation. For example, correcting someone's grammar, or<br/>harping on minor mistakes in names or numbers. Unless the opposing argument<br/>actually depends on such things, the only purpose of correcting them is to<br/>discredit one's opponent.  <br/>  <br/>Truly refuting something requires one to refute its central point, or at least<br/>one of them. And that means one has to commit explicitly to what the central<br/>point is. So a truly effective refutation would look like:<br/><br/>> The author's main point seems to be x. As he says:<br/>><br/><br/>>> <quotation><br/><br/>><br/>> But this is wrong for the following reasons...<br/><br/>The quotation you point out as mistaken need not be the actual statement of<br/>the author's main point. It's enough to refute something it depends upon.  <br/>  <br/>**What It Means**  <br/>  <br/>Now we have a way of classifying forms of disagreement. What good is it? One<br/>thing the disagreement hierarchy _doesn't_ give us is a way of picking a<br/>winner. DH levels merely describe the form of a statement, not whether it's<br/>correct. A DH6 response could still be completely mistaken.  <br/>  <br/>But while DH levels don't set a lower bound on the convincingness of a reply,<br/>they do set an upper bound. A DH6 response might be unconvincing, but a DH2 or<br/>lower response is always unconvincing.  <br/>  <br/>The most obvious advantage of classifying the forms of disagreement is that it<br/>will help people to evaluate what they read. In particular, it will help them<br/>to see through intellectually dishonest arguments. An eloquent speaker or<br/>writer can give the impression of vanquishing an opponent merely by using<br/>forceful words. In fact that is probably the defining quality of a demagogue.<br/>By giving names to the different forms of disagreement, we give critical<br/>readers a pin for popping such balloons.  <br/>  <br/>Such labels may help writers too. Most intellectual dishonesty is<br/>unintentional. Someone arguing against the tone of something he disagrees with<br/>may believe he's really saying something. Zooming out and seeing his current<br/>position on the disagreement hierarchy may inspire him to try moving up to<br/>counterargument or refutation.  <br/>  <br/>But the greatest benefit of disagreeing well is not just that it will make<br/>conversations better, but that it will make the people who have them happier.<br/>If you study conversations, you find there is a lot more meanness down in DH1<br/>than up in DH6. You don't have to be mean when you have a real point to make.<br/>In fact, you don't want to. If you have something real to say, being mean just<br/>gets in the way.  <br/>  <br/>If moving up the disagreement hierarchy makes people less mean, that will make<br/>most of them happier. Most people don't really enjoy being mean; they do it<br/>because they can't help it.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Thanks** to Trevor Blackwell and Jessica Livingston for reading drafts of<br/>this.  <br/>  <br/>  <br/>  <br/> **Related:**  <br/>  <br/><br/>What You Can't Say  <br/><br/>The Age of the Essay  <br/><br/>Italian Translation  <br/><br/>Russian Translation  <br/><br/>Swedish Translation  <br/><br/>Spanish Translation  <br/><br/>German Translation  <br/><br/>French Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>May 2005  <br/>  <br/> _(This essay is derived from a talk at the Berkeley CSUA.)_  <br/>  <br/>The three big powers on the Internet now are Yahoo, Google, and Microsoft.<br/>Average age of their founders: 24. So it is pretty well established now that<br/>grad students can start successful companies. And if grad students can do it,<br/>why not undergrads?  <br/>  <br/>Like everything else in technology, the cost of starting a startup has<br/>decreased dramatically. Now it's so low that it has disappeared into the<br/>noise. The main cost of starting a Web-based startup is food and rent. Which<br/>means it doesn't cost much more to start a company than to be a total slacker.<br/>You can probably start a startup on ten thousand dollars of seed funding, if<br/>you're prepared to live on ramen.  <br/>  <br/>The less it costs to start a company, the less you need the permission of<br/>investors to do it. So a lot of people will be able to start companies now who<br/>never could have before.  <br/>  <br/>The most interesting subset may be those in their early twenties. I'm not so<br/>excited about founders who have everything investors want except intelligence,<br/>or everything except energy. The most promising group to be liberated by the<br/>new, lower threshold are those who have everything investors want except<br/>experience.  <br/>  <br/> **Market Rate**  <br/>  <br/>I once claimed that nerds were unpopular in secondary school mainly because<br/>they had better things to do than work full-time at being popular. Some said I<br/>was just telling people what they wanted to hear. Well, I'm now about to do<br/>that in a spectacular way: I think undergraduates are undervalued.  <br/>  <br/>Or more precisely, I think few realize the huge spread in the value of 20 year<br/>olds. Some, it's true, are not very capable. But others are more capable than<br/>all but a handful of 30 year olds. [1]  <br/>  <br/>Till now the problem has always been that it's difficult to pick them out.<br/>Every VC in the world, if they could go back in time, would try to invest in<br/>Microsoft. But which would have then? How many would have understood that this<br/>particular 19 year old was Bill Gates?  <br/>  <br/>It's hard to judge the young because (a) they change rapidly, (b) there is<br/>great variation between them, and (c) they're individually inconsistent. That<br/>last one is a big problem. When you're young, you occasionally say and do<br/>stupid things even when you're smart. So if the algorithm is to filter out<br/>people who say stupid things, as many investors and employers unconsciously<br/>do, you're going to get a lot of false positives.  <br/>  <br/>Most organizations who hire people right out of college are only aware of the<br/>average value of 22 year olds, which is not that high. And so the idea for<br/>most of the twentieth century was that everyone had to begin as a trainee in<br/>some entry-level job. Organizations realized there was a lot of variation in<br/>the incoming stream, but instead of pursuing this thought they tended to<br/>suppress it, in the belief that it was good for even the most promising kids<br/>to start at the bottom, so they didn't get swelled heads.  <br/>  <br/>The most productive young people will _always_ be undervalued by large<br/>organizations, because the young have no performance to measure yet, and any<br/>error in guessing their ability will tend toward the mean.  <br/>  <br/>What's an especially productive 22 year old to do? One thing you can do is go<br/>over the heads of organizations, directly to the users. Any company that hires<br/>you is, economically, acting as a proxy for the customer. The rate at which<br/>they value you (though they may not consciously realize it) is an attempt to<br/>guess your value to the user. But there's a way to appeal their judgement. If<br/>you want, you can opt to be valued directly by users, by starting your own<br/>company.  <br/>  <br/>The market is a lot more discerning than any employer. And it is completely<br/>non-discriminatory. On the Internet, nobody knows you're a dog. And more to<br/>the point, nobody knows you're 22. All users care about is whether your site<br/>or software gives them what they want. They don't care if the person behind it<br/>is a high school kid.  <br/>  <br/>If you're really productive, why not make employers pay market rate for you?<br/>Why go work as an ordinary employee for a big company, when you could start a<br/>startup and make them buy it to get you?  <br/>  <br/>When most people hear the word "startup," they think of the famous ones that<br/>have gone public. But most startups that succeed do it by getting bought. And<br/>usually the acquirer doesn't just want the technology, but the people who<br/>created it as well.  <br/>  <br/>Often big companies buy startups before they're profitable. Obviously in such<br/>cases they're not after revenues. What they want is the development team and<br/>the software they've built so far. When a startup gets bought for 2 or 3<br/>million six months in, it's really more of a hiring bonus than an acquisition.  <br/>  <br/>I think this sort of thing will happen more and more, and that it will be<br/>better for everyone. It's obviously better for the people who start the<br/>startup, because they get a big chunk of money up front. But I think it will<br/>be better for the acquirers too. The central problem in big companies, and the<br/>main reason they're so much less productive than small companies, is the<br/>difficulty of valuing each person's work. Buying larval startups solves that<br/>problem for them: the acquirer doesn't pay till the developers have proven<br/>themselves. Acquirers are protected on the downside, but still get most of the<br/>upside.  <br/>  <br/> **Product Development**  <br/>  <br/>Buying startups also solves another problem afflicting big companies: they<br/>can't do product development. Big companies are good at extracting the value<br/>from existing products, but bad at creating new ones.  <br/>  <br/>Why? It's worth studying this phenomenon in detail, because this is the raison<br/>d'etre of startups.  <br/>  <br/>To start with, most big companies have some kind of turf to protect, and this<br/>tends to warp their development decisions. For example, Web-based applications<br/>are hot now, but within Microsoft there must be a lot of ambivalence about<br/>them, because the very idea of Web-based software threatens the desktop. So<br/>any Web-based application that Microsoft ends up with, will probably, like<br/>Hotmail, be something developed outside the company.  <br/>  <br/>Another reason big companies are bad at developing new products is that the<br/>kind of people who do that tend not to have much power in big companies<br/>(unless they happen to be the CEO). Disruptive technologies are developed by<br/>disruptive people. And they either don't work for the big company, or have<br/>been outmaneuvered by yes-men and have comparatively little influence.  <br/>  <br/>Big companies also lose because they usually only build one of each thing.<br/>When you only have one Web browser, you can't do anything really risky with<br/>it. If ten different startups design ten different Web browsers and you take<br/>the best, you'll probably get something better.  <br/>  <br/>The more general version of this problem is that there are too many new ideas<br/>for companies to explore them all. There might be 500 startups right now who<br/>think they're making something Microsoft might buy. Even Microsoft probably<br/>couldn't manage 500 development projects in-house.  <br/>  <br/>Big companies also don't pay people the right way. People developing a new<br/>product at a big company get paid roughly the same whether it succeeds or<br/>fails. People at a startup expect to get rich if the product succeeds, and get<br/>nothing if it fails. [2] So naturally the people at the startup work a lot<br/>harder.  <br/>  <br/>The mere bigness of big companies is an obstacle. In startups, developers are<br/>often forced to talk directly to users, whether they want to or not, because<br/>there is no one else to do sales and support. It's painful doing sales, but<br/>you learn much more from trying to sell people something than reading what<br/>they said in focus groups.  <br/>  <br/>And then of course, big companies are bad at product development because<br/>they're bad at everything. Everything happens slower in big companies than<br/>small ones, and product development is something that has to happen fast,<br/>because you have to go through a lot of iterations to get something good.  <br/>  <br/> **Trend**  <br/>  <br/>I think the trend of big companies buying startups will only accelerate. One<br/>of the biggest remaining obstacles is pride. Most companies, at least<br/>unconsciously, feel they ought to be able to develop stuff in house, and that<br/>buying startups is to some degree an admission of failure. And so, as people<br/>generally do with admissions of failure, they put it off for as long as<br/>possible. That makes the acquisition very expensive when it finally happens.  <br/>  <br/>What companies should do is go out and discover startups when they're young,<br/>before VCs have puffed them up into something that costs hundreds of millions<br/>to acquire. Much of what VCs add, the acquirer doesn't need anyway.  <br/>  <br/>Why don't acquirers try to predict the companies they're going to have to buy<br/>for hundreds of millions, and grab them early for a tenth or a twentieth of<br/>that? Because they can't predict the winners in advance? If they're only<br/>paying a twentieth as much, they only have to predict a twentieth as well.<br/>Surely they can manage that.  <br/>  <br/>I think companies that acquire technology will gradually learn to go after<br/>earlier stage startups. They won't necessarily buy them outright. The solution<br/>may be some hybrid of investment and acquisition: for example, to buy a chunk<br/>of the company and get an option to buy the rest later.  <br/>  <br/>When companies buy startups, they're effectively fusing recruiting and product<br/>development. And I think that's more efficient than doing the two separately,<br/>because you always get people who are really committed to what they're working<br/>on.  <br/>  <br/>Plus this method yields teams of developers who already work well together.<br/>Any conflicts between them have been ironed out under the very hot iron of<br/>running a startup. By the time the acquirer gets them, they're finishing one<br/>another's sentences. That's valuable in software, because so many bugs occur<br/>at the boundaries between different people's code.  <br/>  <br/> **Investors**  <br/>  <br/>The increasing cheapness of starting a company doesn't just give hackers more<br/>power relative to employers. It also gives them more power relative to<br/>investors.  <br/>  <br/>The conventional wisdom among VCs is that hackers shouldn't be allowed to run<br/>their own companies. The founders are supposed to accept MBAs as their bosses,<br/>and themselves take on some title like Chief Technical Officer. There may be<br/>cases where this is a good idea. But I think founders will increasingly be<br/>able to push back in the matter of control, because they just don't need the<br/>investors' money as much as they used to.  <br/>  <br/>Startups are a comparatively new phenomenon. Fairchild Semiconductor is<br/>considered the first VC-backed startup, and they were founded in 1959, less<br/>than fifty years ago. Measured on the time scale of social change, what we<br/>have now is pre-beta. So we shouldn't assume the way startups work now is the<br/>way they have to work.  <br/>  <br/>Fairchild needed a lot of money to get started. They had to build actual<br/>factories. What does the first round of venture funding for a Web-based<br/>startup get spent on today? More money can't get software written faster; it<br/>isn't needed for facilities, because those can now be quite cheap; all money<br/>can really buy you is sales and marketing. A sales force is worth something,<br/>I'll admit. But marketing is increasingly irrelevant. On the Internet,<br/>anything genuinely good will spread by word of mouth.  <br/>  <br/>Investors' power comes from money. When startups need less money, investors<br/>have less power over them. So future founders may not have to accept new CEOs<br/>if they don't want them. The VCs will have to be dragged kicking and screaming<br/>down this road, but like many things people have to be dragged kicking and<br/>screaming toward, it may actually be good for them.  <br/>  <br/>Google is a sign of the way things are going. As a condition of funding, their<br/>investors insisted they hire someone old and experienced as CEO. But from what<br/>I've heard the founders didn't just give in and take whoever the VCs wanted.<br/>They delayed for an entire year, and when they did finally take a CEO, they<br/>chose a guy with a PhD in computer science.  <br/>  <br/>It sounds to me as if the founders are still the most powerful people in the<br/>company, and judging by Google's performance, their youth and inexperience<br/>doesn't seem to have hurt them. Indeed, I suspect Google has done better than<br/>they would have if the founders had given the VCs what they wanted, when they<br/>wanted it, and let some MBA take over as soon as they got their first round of<br/>funding.  <br/>  <br/>I'm not claiming the business guys installed by VCs have no value. Certainly<br/>they have. But they don't need to become the founders' bosses, which is what<br/>that title CEO means. I predict that in the future the executives installed by<br/>VCs will increasingly be COOs rather than CEOs. The founders will run<br/>engineering directly, and the rest of the company through the COO.  <br/>  <br/> **The Open Cage**  <br/>  <br/>With both employers and investors, the balance of power is slowly shifting<br/>towards the young. And yet they seem the last to realize it. Only the most<br/>ambitious undergrads even consider starting their own company when they<br/>graduate. Most just want to get a job.  <br/>  <br/>Maybe this is as it should be. Maybe if the idea of starting a startup is<br/>intimidating, you filter out the uncommitted. But I suspect the filter is set<br/>a little too high. I think there are people who could, if they tried, start<br/>successful startups, and who instead let themselves be swept into the intake<br/>ducts of big companies.  <br/>  <br/>Have you ever noticed that when animals are let out of cages, they don't<br/>always realize at first that the door's open? Often they have to be poked with<br/>a stick to get them out. Something similar happened with blogs. People could<br/>have been publishing online in 1995, and yet blogging has only really taken<br/>off in the last couple years. In 1995 we thought only professional writers<br/>were entitled to publish their ideas, and that anyone else who did was a<br/>crank. Now publishing online is becoming so popular that everyone wants to do<br/>it, even print journalists. But blogging has not taken off recently because of<br/>any technical innovation; it just took eight years for everyone to realize the<br/>cage was open.  <br/>  <br/>I think most undergrads don't realize yet that the economic cage is open. A<br/>lot have been told by their parents that the route to success is to get a good<br/>job. This was true when their parents were in college, but it's less true now.<br/>The route to success is to build something valuable, and you don't have to be<br/>working for an existing company to do that. Indeed, you can often do it better<br/>if you're not.  <br/>  <br/>When I talk to undergrads, what surprises me most about them is how<br/>conservative they are. Not politically, of course. I mean they don't seem to<br/>want to take risks. This is a mistake, because the younger you are, the more<br/>risk you can take.  <br/>  <br/> **Risk**  <br/>  <br/>Risk and reward are always proportionate. For example, stocks are riskier than<br/>bonds, and over time always have greater returns. So why does anyone invest in<br/>bonds? The catch is that phrase "over time." Stocks will generate greater<br/>returns over thirty years, but they might lose value from year to year. So<br/>what you should invest in depends on how soon you need the money. If you're<br/>young, you should take the riskiest investments you can find.  <br/>  <br/>All this talk about investing may seem very theoretical. Most undergrads<br/>probably have more debts than assets. They may feel they have nothing to<br/>invest. But that's not true: they have their time to invest, and the same rule<br/>about risk applies there. Your early twenties are exactly the time to take<br/>insane career risks.  <br/>  <br/>The reason risk is always proportionate to reward is that market forces make<br/>it so. People will pay extra for stability. So if you choose stability-- by<br/>buying bonds, or by going to work for a big company-- it's going to cost you.  <br/>  <br/>Riskier career moves pay better on average, because there is less demand for<br/>them. Extreme choices like starting a startup are so frightening that most<br/>people won't even try. So you don't end up having as much competition as you<br/>might expect, considering the prizes at stake.  <br/>  <br/>The math is brutal. While perhaps 9 out of 10 startups fail, the one that<br/>succeeds will pay the founders more than 10 times what they would have made in<br/>an ordinary job. [3] That's the sense in which startups pay better "on<br/>average."  <br/>  <br/>Remember that. If you start a startup, you'll probably fail. Most startups<br/>fail. It's the nature of the business. But it's not necessarily a mistake to<br/>try something that has a 90% chance of failing, if you can afford the risk.<br/>Failing at 40, when you have a family to support, could be serious. But if you<br/>fail at 22, so what? If you try to start a startup right out of college and it<br/>tanks, you'll end up at 23 broke and a lot smarter. Which, if you think about<br/>it, is roughly what you hope to get from a graduate program.  <br/>  <br/>Even if your startup does tank, you won't harm your prospects with employers.<br/>To make sure I asked some friends who work for big companies. I asked managers<br/>at Yahoo, Google, Amazon, Cisco and Microsoft how they'd feel about two<br/>candidates, both 24, with equal ability, one who'd tried to start a startup<br/>that tanked, and another who'd spent the two years since college working as a<br/>developer at a big company. Every one responded that they'd prefer the guy<br/>who'd tried to start his own company. Zod Nazem, who's in charge of<br/>engineering at Yahoo, said:<br/><br/>> I actually put more value on the guy with the failed startup. And you can<br/>> quote me!<br/><br/>So there you have it. Want to get hired by Yahoo? Start your own company.  <br/>  <br/> **The Man is the Customer**  <br/>  <br/>If even big employers think highly of young hackers who start companies, why<br/>don't more do it? Why are undergrads so conservative? I think it's because<br/>they've spent so much time in institutions.  <br/>  <br/>The first twenty years of everyone's life consists of being piped from one<br/>institution to another. You probably didn't have much choice about the<br/>secondary schools you went to. And after high school it was probably<br/>understood that you were supposed to go to college. You may have had a few<br/>different colleges to choose between, but they were probably pretty similar.<br/>So by this point you've been riding on a subway line for twenty years, and the<br/>next stop seems to be a job.  <br/>  <br/>Actually college is where the line ends. Superficially, going to work for a<br/>company may feel like just the next in a series of institutions, but<br/>underneath, everything is different. The end of school is the fulcrum of your<br/>life, the point where you go from net consumer to net producer.  <br/>  <br/>The other big change is that now, you're steering. You can go anywhere you<br/>want. So it may be worth standing back and understanding what's going on,<br/>instead of just doing the default thing.  <br/>  <br/>All through college, and probably long before that, most undergrads have been<br/>thinking about what employers want. But what really matters is what customers<br/>want, because they're the ones who give employers the money to pay you.  <br/>  <br/>So instead of thinking about what employers want, you're probably better off<br/>thinking directly about what users want. To the extent there's any difference<br/>between the two, you can even use that to your advantage if you start a<br/>company of your own. For example, big companies like docile conformists. But<br/>this is merely an artifact of their bigness, not something customers need.  <br/>  <br/> **Grad School**  <br/>  <br/>I didn't consciously realize all this when I was graduating from college--<br/>partly because I went straight to grad school. Grad school can be a pretty<br/>good deal, even if you think of one day starting a startup. You can start one<br/>when you're done, or even pull the ripcord part way through, like the founders<br/>of Yahoo and Google.  <br/>  <br/>Grad school makes a good launch pad for startups, because you're collected<br/>together with a lot of smart people, and you have bigger chunks of time to<br/>work on your own projects than an undergrad or corporate employee would. As<br/>long as you have a fairly tolerant advisor, you can take your time developing<br/>an idea before turning it into a company. David Filo and Jerry Yang started<br/>the Yahoo directory in February 1994 and were getting a million hits a day by<br/>the fall, but they didn't actually drop out of grad school and start a company<br/>till March 1995.  <br/>  <br/>You could also try the startup first, and if it doesn't work, then go to grad<br/>school. When startups tank they usually do it fairly quickly. Within a year<br/>you'll know if you're wasting your time.  <br/>  <br/>If it fails, that is. If it succeeds, you may have to delay grad school a<br/>little longer. But you'll have a much more enjoyable life once there than you<br/>would on a regular grad student stipend.  <br/>  <br/> **Experience**  <br/>  <br/>Another reason people in their early twenties don't start startups is that<br/>they feel they don't have enough experience. Most investors feel the same.  <br/>  <br/>I remember hearing a lot of that word "experience" when I was in college. What<br/>do people really mean by it? Obviously it's not the experience itself that's<br/>valuable, but something it changes in your brain. What's different about your<br/>brain after you have "experience," and can you make that change happen faster?  <br/>  <br/>I now have some data on this, and I can tell you what tends to be missing when<br/>people lack experience. I've said that every startup needs three things: to<br/>start with good people, to make something users want, and not to spend too<br/>much money. It's the middle one you get wrong when you're inexperienced. There<br/>are plenty of undergrads with enough technical skill to write good software,<br/>and undergrads are not especially prone to waste money. If they get something<br/>wrong, it's usually not realizing they have to make something people want.  <br/>  <br/>This is not exclusively a failing of the young. It's common for startup<br/>founders of all ages to build things no one wants.  <br/>  <br/>Fortunately, this flaw should be easy to fix. If undergrads were all bad<br/>programmers, the problem would be a lot harder. It can take years to learn how<br/>to program. But I don't think it takes years to learn how to make things<br/>people want. My hypothesis is that all you have to do is smack hackers on the<br/>side of the head and tell them: Wake up. Don't sit here making up a priori<br/>theories about what users need. Go find some users and see what they need.  <br/>  <br/>Most successful startups not only do something very specific, but solve a<br/>problem people already know they have.  <br/>  <br/>The big change that "experience" causes in your brain is learning that you<br/>need to solve people's problems. Once you grasp that, you advance quickly to<br/>the next step, which is figuring out what those problems are. And that takes<br/>some effort, because the way software actually gets used, especially by the<br/>people who pay the most for it, is not at all what you might expect. For<br/>example, the stated purpose of Powerpoint is to present ideas. Its real role<br/>is to overcome people's fear of public speaking. It allows you to give an<br/>impressive-looking talk about nothing, and it causes the audience to sit in a<br/>dark room looking at slides, instead of a bright one looking at you.  <br/>  <br/>This kind of thing is out there for anyone to see. The key is to know to look<br/>for it-- to realize that having an idea for a startup is not like having an<br/>idea for a class project. The goal in a startup is not to write a cool piece<br/>of software. It's to make something people want. And to do that you have to<br/>look at users-- forget about hacking, and just look at users. This can be<br/>quite a mental adjustment, because little if any of the software you write in<br/>school even has users.  <br/>  <br/>A few steps before a Rubik's Cube is solved, it still looks like a mess. I<br/>think there are a lot of undergrads whose brains are in a similar position:<br/>they're only a few steps away from being able to start successful startups, if<br/>they wanted to, but they don't realize it. They have more than enough<br/>technical skill. They just haven't realized yet that the way to create wealth<br/>is to make what users want, and that employers are just proxies for users in<br/>which risk is pooled.  <br/>  <br/>If you're young and smart, you don't need either of those. You don't need<br/>someone else to tell you what users want, because you can figure it out<br/>yourself. And you don't want to pool risk, because the younger you are, the<br/>more risk you should take.  <br/>  <br/> **A Public Service Message**  <br/>  <br/>I'd like to conclude with a joint message from me and your parents. Don't drop<br/>out of college to start a startup. There's no rush. There will be plenty of<br/>time to start companies after you graduate. In fact, it may be just as well to<br/>go work for an existing company for a couple years after you graduate, to<br/>learn how companies work.  <br/>  <br/>And yet, when I think about it, I can't imagine telling Bill Gates at 19 that<br/>he should wait till he graduated to start a company. He'd have told me to get<br/>lost. And could I have honestly claimed that he was harming his future-- that<br/>he was learning less by working at ground zero of the microcomputer revolution<br/>than he would have if he'd been taking classes back at Harvard? No, probably<br/>not.  <br/>  <br/>And yes, while it is probably true that you'll learn some valuable things by<br/>going to work for an existing company for a couple years before starting your<br/>own, you'd learn a thing or two running your own company during that time too.  <br/>  <br/>The advice about going to work for someone else would get an even colder<br/>reception from the 19 year old Bill Gates. So I'm supposed to finish college,<br/>then go work for another company for two years, and then I can start my own? I<br/>have to wait till I'm 23? That's _four years_. That's more than twenty percent<br/>of my life so far. Plus in four years it will be way too late to make money<br/>writing a Basic interpreter for the Altair.  <br/>  <br/>And he'd be right. The Apple II was launched just two years later. In fact, if<br/>Bill had finished college and gone to work for another company as we're<br/>suggesting, he might well have gone to work for Apple. And while that would<br/>probably have been better for all of us, it wouldn't have been better for him.  <br/>  <br/>So while I stand by our responsible advice to finish college and then go work<br/>for a while before starting a startup, I have to admit it's one of those<br/>things the old tell the young, but don't expect them to listen to. We say this<br/>sort of thing mainly so we can claim we warned you. So don't say I didn't warn<br/>you.  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] The average B-17 pilot in World War II was in his early twenties. (Thanks<br/>to Tad Marko for pointing this out.)  <br/>  <br/>[2] If a company tried to pay employees this way, they'd be called unfair. And<br/>yet when they buy some startups and not others, no one thinks of calling that<br/>unfair.  <br/>  <br/>[3] The 1/10 success rate for startups is a bit of an urban legend. It's<br/>suspiciously neat. My guess is the odds are slightly worse.  <br/>  <br/> **Thanks** to Jessica Livingston for reading drafts of this, to the friends I<br/>promised anonymity to for their opinions about hiring, and to Karen Nguyen and<br/>the Berkeley CSUA for organizing this talk.  <br/>  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Romanian Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>February 2009  <br/>  <br/>A lot of cities look at Silicon Valley and ask "How could we make something<br/>like that happen here?" The organic way to do it is to establish a first-rate<br/>university in a place where rich people want to live. That's how Silicon<br/>Valley happened. But could you shortcut the process by funding startups?  <br/>  <br/>Possibly. Let's consider what it would take.  <br/>  <br/>The first thing to understand is that encouraging startups is a different<br/>problem from encouraging startups in a particular city. The latter is much<br/>more expensive.  <br/>  <br/>People sometimes think they could improve the startup scene in their town by<br/>starting something like Y Combinator there, but in fact it will have near zero<br/>effect. I know because Y Combinator itself had near zero effect on Boston when<br/>we were based there half the year. The people we funded came from all over the<br/>country (indeed, the world) and afterward they went wherever they could get<br/>more funding—which generally meant Silicon Valley.  <br/>  <br/>The seed funding business is not a regional business, because at that stage<br/>startups are mobile. They're just a couple founders with laptops. [1]  <br/>  <br/>If you want to encourage startups in a particular city, you have to fund<br/>startups that won't leave. There are two ways to do that: have rules<br/>preventing them from leaving, or fund them at the point in their life when<br/>they naturally take root. The first approach is a mistake, because it becomes<br/>a filter for selecting bad startups. If your terms force startups to do things<br/>they don't want to, only the desperate ones will take your money.  <br/>  <br/>Good startups will move to another city as a condition of funding. What they<br/>won't do is agree not to move the next time they need funding. So the only way<br/>to get them to stay is to give them enough that they never need to leave.  <br/>  <br/>___  <br/>  <br/>How much would that take? If you want to keep startups from leaving your town,<br/>you have to give them enough that they're not tempted by an offer from Silicon<br/>Valley VCs that requires them to move. A startup would be able to refuse such<br/>an offer if they had grown to the point where they were (a) rooted in your<br/>town and/or (b) so successful that VCs would fund them even if they didn't<br/>move.  <br/>  <br/>How much would it cost to grow a startup to that point? A minimum of several<br/>hundred thousand dollars. Wufoo seem to have rooted themselves in Tampa on<br/>$118k, but they're an extreme case. On average it would take at least half a<br/>million.  <br/>  <br/>So if it seems too good to be true to think you could grow a local silicon<br/>valley by giving startups $15-20k each like Y Combinator, that's because it<br/>is. To make them stick around you'd have to give them at least 20 times that<br/>much.  <br/>  <br/>However, even that is an interesting prospect. Suppose to be on the safe side<br/>it would cost a million dollars per startup. If you could get startups to<br/>stick to your town for a million apiece, then for a billion dollars you could<br/>bring in a thousand startups. That probably wouldn't push you past Silicon<br/>Valley itself, but it might get you second place.  <br/>  <br/>For the price of a football stadium, any town that was decent to live in could<br/>make itself one of the biggest startup hubs in the world.  <br/>  <br/>What's more, it wouldn't take very long. You could probably do it in five<br/>years. During the term of one mayor. And it would get easier over time,<br/>because the more startups you had in town, the less it would take to get new<br/>ones to move there. By the time you had a thousand startups in town, the VCs<br/>wouldn't be trying so hard to get them to move to Silicon Valley; instead<br/>they'd be opening local offices. Then you'd really be in good shape. You'd<br/>have started a self-sustaining chain reaction like the one that drives the<br/>Valley.  <br/>  <br/>___  <br/>  <br/>But now comes the hard part. You have to pick the startups. How do you do<br/>that? Picking startups is a rare and valuable skill, and the handful of people<br/>who have it are not readily hireable. And this skill is so hard to measure<br/>that if a government did try to hire people with it, they'd almost certainly<br/>get the wrong ones.  <br/>  <br/>For example, a city could give money to a VC fund to establish a local branch,<br/>and let them make the choices. But only a bad VC fund would take that deal.<br/>They wouldn't _seem_ bad to the city officials. They'd seem very impressive.<br/>But they'd be bad at picking startups. That's the characteristic failure mode<br/>of VCs. All VCs look impressive to limited partners. The difference between<br/>the good ones and the bad ones only becomes visible in the other half of their<br/>jobs: choosing and advising startups. [2]  <br/>  <br/>What you really want is a pool of local angel investors—people investing money<br/>they made from their own startups. But unfortunately you run into a chicken<br/>and egg problem here. If your city isn't already a startup hub, there won't be<br/>people there who got rich from startups. And there is no way I can think of<br/>that a city could attract angels from outside. By definition they're rich.<br/>There's no incentive that would make them move. [3]  <br/>  <br/>However, a city could select startups by piggybacking on the expertise of<br/>investors who weren't local. It would be pretty straightforward to make a list<br/>of the most eminent Silicon Valley angels and from that to generate a list of<br/>all the startups they'd invested in. If a city offered these companies a<br/>million dollars each to move, a lot of the earlier stage ones would probably<br/>take it.  <br/>  <br/>Preposterous as this plan sounds, it's probably the most efficient way a city<br/>could select good startups.  <br/>  <br/>It would hurt the startups somewhat to be separated from their original<br/>investors. On the other hand, the extra million dollars would give them a lot<br/>more runway.  <br/>  <br/>___  <br/>  <br/>Would the transplanted startups survive? Quite possibly. The only way to find<br/>out would be to try it. It would be a pretty cheap experiment, as civil<br/>expenditures go. Pick 30 startups that eminent angels have recently invested<br/>in, give them each a million dollars if they'll relocate to your city, and see<br/>what happens after a year. If they seem to be thriving, you can try importing<br/>startups on a larger scale.  <br/>  <br/>Don't be too legalistic about the conditions under which they're allowed to<br/>leave. Just have a gentlemen's agreement.  <br/>  <br/>Don't try to do it on the cheap and pick only 10 for the initial experiment.<br/>If you do this on too small a scale you'll just guarantee failure. Startups<br/>need to be around other startups. 30 would be enough to feel like a community.  <br/>  <br/>Don't try to make them all work in some renovated warehouse you've made into<br/>an "incubator." Real startups prefer to work in their own spaces.  <br/>  <br/>In fact, don't impose any restrictions on the startups at all. Startup<br/>founders are mostly hackers, and hackers are much more constrained by<br/>gentlemen's agreements than regulations. If they shake your hand on a promise,<br/>they'll keep it. But show them a lock and their first thought is how to pick<br/>it.  <br/>  <br/>Interestingly, the 30-startup experiment could be done by any sufficiently<br/>rich private citizen. And what pressure it would put on the city if it worked.<br/>[4]  <br/>  <br/>___  <br/>  <br/>Should the city take stock in return for the money? In principle they're<br/>entitled to, but how would they choose valuations for the startups? You<br/>couldn't just give them all the same valuation: that would be too low for some<br/>(who'd turn you down) and too high for others (because it might make their<br/>next round a "down round"). And since we're assuming we're doing this without<br/>being able to pick startups, we also have to assume we can't value them, since<br/>that's practically the same thing.  <br/>  <br/>Another reason not to take stock in the startups is that startups are often<br/>involved in disreputable things. So are established companies, but they don't<br/>get blamed for it. If someone gets murdered by someone they met on Facebook,<br/>the press will treat the story as if it were about Facebook. If someone gets<br/>murdered by someone they met at a supermarket, the press will just treat it as<br/>a story about a murder. So understand that if you invest in startups, they<br/>might build things that get used for pornography, or file-sharing, or the<br/>expression of unfashionable opinions. You should probably sponsor this project<br/>jointly with your political opponents, so they can't use whatever the startups<br/>do as a club to beat you with.  <br/>  <br/>It would be too much of a political liability just to give the startups the<br/>money, though. So the best plan would be to make it convertible debt, but<br/>which didn't convert except in a really big round, like $20 million.  <br/>  <br/>___  <br/>  <br/>How well this scheme worked would depend on the city. There are some towns,<br/>like Portland, that would be easy to turn into startup hubs, and others, like<br/>Detroit, where it would really be an uphill battle. So be honest with yourself<br/>about the sort of town you have before you try this.  <br/>  <br/>It will be easier in proportion to how much your town resembles San Francisco.<br/>Do you have good weather? Do people live downtown, or have they abandoned the<br/>center for the suburbs? Would the city be described as "hip" and "tolerant,"<br/>or as reflecting "traditional values?" Are there good universities nearby? Are<br/>there walkable neighborhoods? Would nerds feel at home? If you answered yes to<br/>all these questions, you might be able not only to pull off this scheme, but<br/>to do it for less than a million per startup.  <br/>  <br/>I realize the chance of any city having the political will to carry out this<br/>plan is microscopically small. I just wanted to explore what it would take if<br/>one did. How hard would it be to jumpstart a silicon valley? It's fascinating<br/>to think this prize might be within the reach of so many cities. So even<br/>though they'll all still spend the money on the stadium, at least now someone<br/>can ask them: why did you choose to do that instead of becoming a serious<br/>rival to Silicon Valley?  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] What people who start these supposedly local seed firms always find is<br/>that (a) their applicants come from all over, not just the local area, and (b)<br/>the local startups also apply to the other seed firms. So what ends up<br/>happening is that the applicant pool gets partitioned by quality rather than<br/>geography.  <br/>  <br/>[2] Interestingly, the bad VCs fail by choosing startups run by people like<br/>them—people who are good presenters, but have no real substance. It's a case<br/>of the fake leading the fake. And since everyone involved is so plausible, the<br/>LPs who invest in these funds have no idea what's happening till they measure<br/>their returns.  <br/>  <br/>[3] Not even being a tax haven, I suspect. That makes some rich people move,<br/>but not the type who would make good angel investors in startups.  <br/>  <br/>[4] Thanks to Michael Keenan for pointing this out.  <br/>  <br/> **Thanks** to Trevor Blackwell, Jessica Livingston, Robert Morris, and Fred<br/>Wilson for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>January 2005  <br/>  <br/> _(I wrote this talk for a high school. I never actually gave it, because the<br/>school authorities vetoed the plan to invite me.)_  <br/>  <br/>When I said I was speaking at a high school, my friends were curious. What<br/>will you say to high school students? So I asked them, what do you wish<br/>someone had told you in high school? Their answers were remarkably similar. So<br/>I'm going to tell you what we all wish someone had told us.  <br/>  <br/>I'll start by telling you something you don't have to know in high school:<br/>what you want to do with your life. People are always asking you this, so you<br/>think you're supposed to have an answer. But adults ask this mainly as a<br/>conversation starter. They want to know what sort of person you are, and this<br/>question is just to get you talking. They ask it the way you might poke a<br/>hermit crab in a tide pool, to see what it does.  <br/>  <br/>If I were back in high school and someone asked about my plans, I'd say that<br/>my first priority was to learn what the options were. You don't need to be in<br/>a rush to choose your life's work. What you need to do is discover what you<br/>like. You have to work on stuff you like if you want to be good at what you<br/>do.  <br/>  <br/>It might seem that nothing would be easier than deciding what you like, but it<br/>turns out to be hard, partly because it's hard to get an accurate picture of<br/>most jobs. Being a doctor is not the way it's portrayed on TV. Fortunately you<br/>can also watch real doctors, by volunteering in hospitals. [1]  <br/>  <br/>But there are other jobs you can't learn about, because no one is doing them<br/>yet. Most of the work I've done in the last ten years didn't exist when I was<br/>in high school. The world changes fast, and the rate at which it changes is<br/>itself speeding up. In such a world it's not a good idea to have fixed plans.  <br/>  <br/>And yet every May, speakers all over the country fire up the Standard<br/>Graduation Speech, the theme of which is: don't give up on your dreams. I know<br/>what they mean, but this is a bad way to put it, because it implies you're<br/>supposed to be bound by some plan you made early on. The computer world has a<br/>name for this: premature optimization. And it is synonymous with disaster.<br/>These speakers would do better to say simply, don't give up.  <br/>  <br/>What they really mean is, don't get demoralized. Don't think that you can't do<br/>what other people can. And I agree you shouldn't underestimate your potential.<br/>People who've done great things tend to seem as if they were a race apart. And<br/>most biographies only exaggerate this illusion, partly due to the worshipful<br/>attitude biographers inevitably sink into, and partly because, knowing how the<br/>story ends, they can't help streamlining the plot till it seems like the<br/>subject's life was a matter of destiny, the mere unfolding of some innate<br/>genius. In fact I suspect if you had the sixteen year old Shakespeare or<br/>Einstein in school with you, they'd seem impressive, but not totally unlike<br/>your other friends.  <br/>  <br/>Which is an uncomfortable thought. If they were just like us, then they had to<br/>work very hard to do what they did. And that's one reason we like to believe<br/>in genius. It gives us an excuse for being lazy. If these guys were able to do<br/>what they did only because of some magic Shakespeareness or Einsteinness, then<br/>it's not our fault if we can't do something as good.  <br/>  <br/>I'm not saying there's no such thing as genius. But if you're trying to choose<br/>between two theories and one gives you an excuse for being lazy, the other one<br/>is probably right.  <br/>  <br/>So far we've cut the Standard Graduation Speech down from "don't give up on<br/>your dreams" to "what someone else can do, you can do." But it needs to be cut<br/>still further. There is _some_ variation in natural ability. Most people<br/>overestimate its role, but it does exist. If I were talking to a guy four feet<br/>tall whose ambition was to play in the NBA, I'd feel pretty stupid saying, you<br/>can do anything if you really try. [2]  <br/>  <br/>We need to cut the Standard Graduation Speech down to, "what someone else with<br/>your abilities can do, you can do; and don't underestimate your abilities."<br/>But as so often happens, the closer you get to the truth, the messier your<br/>sentence gets. We've taken a nice, neat (but wrong) slogan, and churned it up<br/>like a mud puddle. It doesn't make a very good speech anymore. But worse<br/>still, it doesn't tell you what to do anymore. Someone with your abilities?<br/>What are your abilities?  <br/>  <br/> **Upwind**  <br/>  <br/>I think the solution is to work in the other direction. Instead of working<br/>back from a goal, work forward from promising situations. This is what most<br/>successful people actually do anyway.  <br/>  <br/>In the graduation-speech approach, you decide where you want to be in twenty<br/>years, and then ask: what should I do now to get there? I propose instead that<br/>you don't commit to anything in the future, but just look at the options<br/>available now, and choose those that will give you the most promising range of<br/>options afterward.  <br/>  <br/>It's not so important what you work on, so long as you're not wasting your<br/>time. Work on things that interest you and increase your options, and worry<br/>later about which you'll take.  <br/>  <br/>Suppose you're a college freshman deciding whether to major in math or<br/>economics. Well, math will give you more options: you can go into almost any<br/>field from math. If you major in math it will be easy to get into grad school<br/>in economics, but if you major in economics it will be hard to get into grad<br/>school in math.  <br/>  <br/>Flying a glider is a good metaphor here. Because a glider doesn't have an<br/>engine, you can't fly into the wind without losing a lot of altitude. If you<br/>let yourself get far downwind of good places to land, your options narrow<br/>uncomfortably. As a rule you want to stay upwind. So I propose that as a<br/>replacement for "don't give up on your dreams." Stay upwind.  <br/>  <br/>How do you do that, though? Even if math is upwind of economics, how are you<br/>supposed to know that as a high school student?  <br/>  <br/>Well, you don't, and that's what you need to find out.  Look for smart people<br/>and hard problems. Smart people tend to clump together, and if you can find<br/>such a clump, it's probably worthwhile to join it. But it's not<br/>straightforward to find these, because there is a lot of faking going on.  <br/>  <br/>To a newly arrived undergraduate, all university departments look much the<br/>same. The professors all seem forbiddingly intellectual and publish papers<br/>unintelligible to outsiders. But while in some fields the papers are<br/>unintelligible because they're full of hard ideas, in others they're<br/>deliberately written in an obscure way to seem as if they're saying something<br/>important. This may seem a scandalous proposition, but it has been<br/>experimentally verified, in the famous _Social Text_ affair. Suspecting that<br/>the papers published by literary theorists were often just intellectual-<br/>sounding nonsense, a physicist deliberately wrote a paper full of<br/>intellectual-sounding nonsense, and submitted it to a literary theory journal,<br/>which published it.  <br/>  <br/>The best protection is always to be working on hard problems. Writing novels<br/>is hard. Reading novels isn't. Hard means worry: if you're not worrying that<br/>something you're making will come out badly, or that you won't be able to<br/>understand something you're studying, then it isn't hard enough. There has to<br/>be suspense.  <br/>  <br/>Well, this seems a grim view of the world, you may think. What I'm telling you<br/>is that you should worry? Yes, but it's not as bad as it sounds. It's<br/>exhilarating to overcome worries. You don't see faces much happier than people<br/>winning gold medals. And you know why they're so happy? Relief.  <br/>  <br/>I'm not saying this is the only way to be happy. Just that some kinds of worry<br/>are not as bad as they sound.  <br/>  <br/> **Ambition**  <br/>  <br/>In practice, "stay upwind" reduces to "work on hard problems." And you can<br/>start today. I wish I'd grasped that in high school.  <br/>  <br/>Most people like to be good at what they do. In the so-called real world this<br/>need is a powerful force. But high school students rarely benefit from it,<br/>because they're given a fake thing to do. When I was in high school, I let<br/>myself believe that my job was to be a high school student. And so I let my<br/>need to be good at what I did be satisfied by merely doing well in school.  <br/>  <br/>If you'd asked me in high school what the difference was between high school<br/>kids and adults, I'd have said it was that adults had to earn a living. Wrong.<br/>It's that adults take responsibility for themselves. Making a living is only a<br/>small part of it. Far more important is to take intellectual responsibility<br/>for oneself.  <br/>  <br/>If I had to go through high school again, I'd treat it like a day job. I don't<br/>mean that I'd slack in school. Working at something as a day job doesn't mean<br/>doing it badly. It means not being defined by it. I mean I wouldn't think of<br/>myself as a high school student, just as a musician with a day job as a waiter<br/>doesn't think of himself as a waiter. [3] And when I wasn't working at my day<br/>job I'd start trying to do real work.  <br/>  <br/>When I ask people what they regret most about high school, they nearly all say<br/>the same thing: that they wasted so much time. If you're wondering what you're<br/>doing now that you'll regret most later, that's probably it. [4]  <br/>  <br/>Some people say this is inevitable-- that high school students aren't capable<br/>of getting anything done yet. But I don't think this is true. And the proof is<br/>that you're bored. You probably weren't bored when you were eight. When you're<br/>eight it's called "playing" instead of "hanging out," but it's the same thing.<br/>And when I was eight, I was rarely bored. Give me a back yard and a few other<br/>kids and I could play all day.  <br/>  <br/>The reason this got stale in middle school and high school, I now realize, is<br/>that I was ready for something else. Childhood was getting old.  <br/>  <br/>I'm not saying you shouldn't hang out with your friends-- that you should all<br/>become humorless little robots who do nothing but work. Hanging out with<br/>friends is like chocolate cake. You enjoy it more if you eat it occasionally<br/>than if you eat nothing but chocolate cake for every meal. No matter how much<br/>you like chocolate cake, you'll be pretty queasy after the third meal of it.<br/>And that's what the malaise one feels in high school is: mental queasiness.<br/>[5]  <br/>  <br/>You may be thinking, we have to do more than get good grades. We have to have<br/>_extracurricular activities._ But you know perfectly well how bogus most of<br/>these are. Collecting donations for a charity is an admirable thing to do, but<br/>it's not _hard._ It's not getting something done. What I mean by getting<br/>something done is learning how to write well, or how to program computers, or<br/>what life was really like in preindustrial societies, or how to draw the human<br/>face from life. This sort of thing rarely translates into a line item on a<br/>college application.  <br/>  <br/> **Corruption**  <br/>  <br/>It's dangerous to design your life around getting into college, because the<br/>people you have to impress to get into college are not a very discerning<br/>audience. At most colleges, it's not the professors who decide whether you get<br/>in, but admissions officers, and they are nowhere near as smart. They're the<br/>NCOs of the intellectual world. They can't tell how smart you are. The mere<br/>existence of prep schools is proof of that.  <br/>  <br/>Few parents would pay so much for their kids to go to a school that didn't<br/>improve their admissions prospects. Prep schools openly say this is one of<br/>their aims. But what that means, if you stop to think about it, is that they<br/>can hack the admissions process: that they can take the very same kid and make<br/>him seem a more appealing candidate than he would if he went to the local<br/>public school. [6]  <br/>  <br/>Right now most of you feel your job in life is to be a promising college<br/>applicant. But that means you're designing your life to satisfy a process so<br/>mindless that there's a whole industry devoted to subverting it. No wonder you<br/>become cynical. The malaise you feel is the same that a producer of reality TV<br/>shows or a tobacco industry executive feels. And you don't even get paid a<br/>lot.  <br/>  <br/>So what do you do? What you should not do is rebel. That's what I did, and it<br/>was a mistake. I didn't realize exactly what was happening to us, but I<br/>smelled a major rat. And so I just gave up. Obviously the world sucked, so why<br/>bother?  <br/>  <br/>When I discovered that one of our teachers was herself using Cliff's Notes, it<br/>seemed par for the course. Surely it meant nothing to get a good grade in such<br/>a class.  <br/>  <br/>In retrospect this was stupid. It was like someone getting fouled in a soccer<br/>game and saying, hey, you fouled me, that's against the rules, and walking off<br/>the field in indignation. Fouls happen. The thing to do when you get fouled is<br/>not to lose your cool. Just keep playing.  <br/>  <br/>By putting you in this situation, society has fouled you. Yes, as you suspect,<br/>a lot of the stuff you learn in your classes is crap. And yes, as you suspect,<br/>the college admissions process is largely a charade. But like many fouls, this<br/>one was unintentional. [7] So just keep playing.  <br/>  <br/>Rebellion is almost as stupid as obedience. In either case you let yourself be<br/>defined by what they tell you to do. The best plan, I think, is to step onto<br/>an orthogonal vector. Don't just do what they tell you, and don't just refuse<br/>to. Instead treat school as a day job. As day jobs go, it's pretty sweet.<br/>You're done at 3 o'clock, and you can even work on your own stuff while you're<br/>there.  <br/>  <br/> **Curiosity**  <br/>  <br/>And what's your real job supposed to be? Unless you're Mozart, your first task<br/>is to figure that out. What are the great things to work on? Where are the<br/>imaginative people? And most importantly, what are you interested in? The word<br/>"aptitude" is misleading, because it implies something innate. The most<br/>powerful sort of aptitude is a consuming interest in some question, and such<br/>interests are often acquired tastes.  <br/>  <br/>A distorted version of this idea has filtered into popular culture under the<br/>name "passion." I recently saw an ad for waiters saying they wanted people<br/>with a "passion for service." The real thing is not something one could have<br/>for waiting on tables. And passion is a bad word for it. A better name would<br/>be curiosity.  <br/>  <br/>Kids are curious, but the curiosity I mean has a different shape from kid<br/>curiosity. Kid curiosity is broad and shallow; they ask why at random about<br/>everything. In most adults this curiosity dries up entirely. It has to: you<br/>can't get anything done if you're always asking why about everything. But in<br/>ambitious adults, instead of drying up, curiosity becomes narrow and deep. The<br/>mud flat morphs into a well.  <br/>  <br/>Curiosity turns work into play. For Einstein, relativity wasn't a book full of<br/>hard stuff he had to learn for an exam. It was a mystery he was trying to<br/>solve. So it probably felt like less work to him to invent it than it would<br/>seem to someone now to learn it in a class.  <br/>  <br/>One of the most dangerous illusions you get from school is the idea that doing<br/>great things requires a lot of discipline. Most subjects are taught in such a<br/>boring way that it's only by discipline that you can flog yourself through<br/>them. So I was surprised when, early in college, I read a quote by<br/>Wittgenstein saying that he had no self-discipline and had never been able to<br/>deny himself anything, not even a cup of coffee.  <br/>  <br/>Now I know a number of people who do great work, and it's the same with all of<br/>them. They have little discipline. They're all terrible procrastinators and<br/>find it almost impossible to make themselves do anything they're not<br/>interested in. One still hasn't sent out his half of the thank-you notes from<br/>his wedding, four years ago. Another has 26,000 emails in her inbox.  <br/>  <br/>I'm not saying you can get away with zero self-discipline. You probably need<br/>about the amount you need to go running. I'm often reluctant to go running,<br/>but once I do, I enjoy it. And if I don't run for several days, I feel ill.<br/>It's the same with people who do great things. They know they'll feel bad if<br/>they don't work, and they have enough discipline to get themselves to their<br/>desks to start working. But once they get started, interest takes over, and<br/>discipline is no longer necessary.  <br/>  <br/>Do you think Shakespeare was gritting his teeth and diligently trying to write<br/>Great Literature? Of course not. He was having fun. That's why he's so good.  <br/>  <br/>If you want to do good work, what you need is a great curiosity about a<br/>promising question. The critical moment for Einstein was when he looked at<br/>Maxwell's equations and said, what the hell is going on here?  <br/>  <br/>It can take years to zero in on a productive question, because it can take<br/>years to figure out what a subject is really about. To take an extreme<br/>example, consider math. Most people think they hate math, but the boring stuff<br/>you do in school under the name "mathematics" is not at all like what<br/>mathematicians do.  <br/>  <br/>The great mathematician G. H. Hardy said he didn't like math in high school<br/>either. He only took it up because he was better at it than the other<br/>students. Only later did he realize math was interesting-- only later did he<br/>start to ask questions instead of merely answering them correctly.  <br/>  <br/>When a friend of mine used to grumble because he had to write a paper for<br/>school, his mother would tell him: find a way to make it interesting. That's<br/>what you need to do: find a question that makes the world interesting. People<br/>who do great things look at the same world everyone else does, but notice some<br/>odd detail that's compellingly mysterious.  <br/>  <br/>And not only in intellectual matters. Henry Ford's great question was, why do<br/>cars have to be a luxury item? What would happen if you treated them as a<br/>commodity? Franz Beckenbauer's was, in effect, why does everyone have to stay<br/>in his position? Why can't defenders score goals too?  <br/>  <br/> **Now**  <br/>  <br/>If it takes years to articulate great questions, what do you do now, at<br/>sixteen? Work toward finding one. Great questions don't appear suddenly. They<br/>gradually congeal in your head. And what makes them congeal is experience. So<br/>the way to find great questions is not to search for them-- not to wander<br/>about thinking, what great discovery shall I make? You can't answer that; if<br/>you could, you'd have made it.  <br/>  <br/>The way to get a big idea to appear in your head is not to hunt for big ideas,<br/>but to put in a lot of time on work that interests you, and in the process<br/>keep your mind open enough that a big idea can take roost. Einstein, Ford, and<br/>Beckenbauer all used this recipe. They all knew their work like a piano player<br/>knows the keys. So when something seemed amiss to them, they had the<br/>confidence to notice it.  <br/>  <br/>Put in time how and on what? Just pick a project that seems interesting: to<br/>master some chunk of material, or to make something, or to answer some<br/>question. Choose a project that will take less than a month, and make it<br/>something you have the means to finish. Do something hard enough to stretch<br/>you, but only just, especially at first. If you're deciding between two<br/>projects, choose whichever seems most fun. If one blows up in your face, start<br/>another. Repeat till, like an internal combustion engine, the process becomes<br/>self-sustaining, and each project generates the next one. (This could take<br/>years.)  <br/>  <br/>It may be just as well not to do a project "for school," if that will restrict<br/>you or make it seem like work. Involve your friends if you want, but not too<br/>many, and only if they're not flakes. Friends offer moral support (few<br/>startups are started by one person), but secrecy also has its advantages.<br/>There's something pleasing about a secret project. And you can take more<br/>risks, because no one will know if you fail.  <br/>  <br/>Don't worry if a project doesn't seem to be on the path to some goal you're<br/>supposed to have. Paths can bend a lot more than you think. So let the path<br/>grow out the project. The most important thing is to be excited about it,<br/>because it's by doing that you learn.  <br/>  <br/>Don't disregard unseemly motivations. One of the most powerful is the desire<br/>to be better than other people at something. Hardy said that's what got him<br/>started, and I think the only unusual thing about him is that he admitted it.<br/>Another powerful motivator is the desire to do, or know, things you're not<br/>supposed to. Closely related is the desire to do something audacious. Sixteen<br/>year olds aren't supposed to write novels. So if you try, anything you achieve<br/>is on the plus side of the ledger; if you fail utterly, you're doing no worse<br/>than expectations. [8]  <br/>  <br/>Beware of bad models. Especially when they excuse laziness. When I was in high<br/>school I used to write "existentialist" short stories like ones I'd seen by<br/>famous writers. My stories didn't have a lot of plot, but they were very deep.<br/>And they were less work to write than entertaining ones would have been. I<br/>should have known that was a danger sign. And in fact I found my stories<br/>pretty boring; what excited me was the idea of writing serious, intellectual<br/>stuff like the famous writers.  <br/>  <br/>Now I have enough experience to realize that those famous writers actually<br/>sucked. Plenty of famous people do; in the short term, the quality of one's<br/>work is only a small component of fame. I should have been less worried about<br/>doing something that seemed cool, and just done something I liked. That's the<br/>actual road to coolness anyway.  <br/>  <br/>A key ingredient in many projects, almost a project on its own, is to find<br/>good books. Most books are bad. Nearly all textbooks are bad. [9] So don't<br/>assume a subject is to be learned from whatever book on it happens to be<br/>closest. You have to search actively for the tiny number of good books.  <br/>  <br/>The important thing is to get out there and do stuff. Instead of waiting to be<br/>taught, go out and learn.  <br/>  <br/>Your life doesn't have to be shaped by admissions officers. It could be shaped<br/>by your own curiosity. It is for all ambitious adults. And you don't have to<br/>wait to start. In fact, you don't have to wait to be an adult. There's no<br/>switch inside you that magically flips when you turn a certain age or graduate<br/>from some institution. You start being an adult when you decide to take<br/>responsibility for your life. You can do that at any age. [10]  <br/>  <br/>This may sound like bullshit. I'm just a minor, you may think, I have no<br/>money, I have to live at home, I have to do what adults tell me all day long.<br/>Well, most adults labor under restrictions just as cumbersome, and they manage<br/>to get things done. If you think it's restrictive being a kid, imagine having<br/>kids.  <br/>  <br/>The only real difference between adults and high school kids is that adults<br/>realize they need to get things done, and high school kids don't. That<br/>realization hits most people around 23. But I'm letting you in on the secret<br/>early. So get to work. Maybe you can be the first generation whose greatest<br/>regret from high school isn't how much time you wasted.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] A doctor friend warns that even this can give an inaccurate picture. "Who<br/>knew how much time it would take up, how little autonomy one would have for<br/>endless years of training, and how unbelievably annoying it is to carry a<br/>beeper?"  <br/>  <br/>[2] His best bet would probably be to become dictator and intimidate the NBA<br/>into letting him play. So far the closest anyone has come is Secretary of<br/>Labor.  <br/>  <br/>[3] A day job is one you take to pay the bills so you can do what you really<br/>want, like play in a band, or invent relativity.  <br/>  <br/>Treating high school as a day job might actually make it easier for some<br/>students to get good grades. If you treat your classes as a game, you won't be<br/>demoralized if they seem pointless.  <br/>  <br/>However bad your classes, you need to get good grades in them to get into a<br/>decent college. And that _is_ worth doing, because universities are where a<br/>lot of the clumps of smart people are these days.  <br/>  <br/>[4] The second biggest regret was caring so much about unimportant things. And<br/>especially about what other people thought of them.  <br/>  <br/>I think what they really mean, in the latter case, is caring what random<br/>people thought of them. Adults care just as much what other people think, but<br/>they get to be more selective about the other people.  <br/>  <br/>I have about thirty friends whose opinions I care about, and the opinion of<br/>the rest of the world barely affects me. The problem in high school is that<br/>your peers are chosen for you by accidents of age and geography, rather than<br/>by you based on respect for their judgement.  <br/>  <br/>[5] The key to wasting time is distraction. Without distractions it's too<br/>obvious to your brain that you're not doing anything with it, and you start to<br/>feel uncomfortable. If you want to measure how dependent you've become on<br/>distractions, try this experiment: set aside a chunk of time on a weekend and<br/>sit alone and think. You can have a notebook to write your thoughts down in,<br/>but nothing else: no friends, TV, music, phone, IM, email, Web, games, books,<br/>newspapers, or magazines. Within an hour most people will feel a strong<br/>craving for distraction.  <br/>  <br/>[6] I don't mean to imply that the only function of prep schools is to trick<br/>admissions officers. They also generally provide a better education. But try<br/>this thought experiment: suppose prep schools supplied the same superior<br/>education but had a tiny (.001) negative effect on college admissions. How<br/>many parents would still send their kids to them?  <br/>  <br/>It might also be argued that kids who went to prep schools, because they've<br/>learned more, _are_ better college candidates. But this seems empirically<br/>false. What you learn in even the best high school is rounding error compared<br/>to what you learn in college. Public school kids arrive at college with a<br/>slight disadvantage, but they start to pull ahead in the sophomore year.  <br/>  <br/>(I'm not saying public school kids are smarter than preppies, just that they<br/>are within any given college. That follows necessarily if you agree prep<br/>schools improve kids' admissions prospects.)  <br/>  <br/>[7] Why does society foul you? Indifference, mainly. There are simply no<br/>outside forces pushing high school to be good. The air traffic control system<br/>works because planes would crash otherwise. Businesses have to deliver because<br/>otherwise competitors would take their customers. But no planes crash if your<br/>school sucks, and it has no competitors. High school isn't evil; it's random;<br/>but random is pretty bad.  <br/>  <br/>[8] And then of course there is money. It's not a big factor in high school,<br/>because you can't do much that anyone wants. But a lot of great things were<br/>created mainly to make money. Samuel Johnson said "no man but a blockhead ever<br/>wrote except for money." (Many hope he was exaggerating.)  <br/>  <br/>[9] Even college textbooks are bad. When you get to college, you'll find that<br/>(with a few stellar exceptions) the textbooks are not written by the leading<br/>scholars in the field they describe. Writing college textbooks is unpleasant<br/>work, done mostly by people who need the money. It's unpleasant because the<br/>publishers exert so much control, and there are few things worse than close<br/>supervision by someone who doesn't understand what you're doing. This<br/>phenomenon is apparently even worse in the production of high school<br/>textbooks.  <br/>  <br/>[10] Your teachers are always telling you to behave like adults. I wonder if<br/>they'd like it if you did. You may be loud and disorganized, but you're very<br/>docile compared to adults. If you actually started acting like adults, it<br/>would be just as if a bunch of adults had been transposed into your bodies.<br/>Imagine the reaction of an FBI agent or taxi driver or reporter to being told<br/>they had to ask permission to go the bathroom, and only one person could go at<br/>a time. To say nothing of the things you're taught. If a bunch of actual<br/>adults suddenly found themselves trapped in high school, the first thing<br/>they'd do is form a union and renegotiate all the rules with the<br/>administration.  <br/>  <br/> **Thanks** to Ingrid Bassett, Trevor Blackwell, Rich Draves, Dan Giffin,<br/>Sarah Harlin, Jessica Livingston, Jackie McDonough, Robert Morris, Mark<br/>Nitzberg, Lisa Randall, and Aaron Swartz for reading drafts of this, and to<br/>many others for talking to me about high school.  <br/>  <br/><br/>Why Nerds are Unpopular  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>October 2015  <br/>  <br/>Here's a simple trick for getting more people to read what you write: write in<br/>spoken language.  <br/>  <br/>Something comes over most people when they start writing. They write in a<br/>different language than they'd use if they were talking to a friend. The<br/>sentence structure and even the words are different. No one uses "pen" as a<br/>verb in spoken English. You'd feel like an idiot using "pen" instead of<br/>"write" in a conversation with a friend.  <br/>  <br/>The last straw for me was a sentence I read a couple days ago:<br/><br/>> The mercurial Spaniard himself declared: "After Altamira, all is decadence."<br/><br/>It's from Neil Oliver's _A History of Ancient Britain_. I feel bad making an<br/>example of this book, because it's no worse than lots of others. But just<br/>imagine calling Picasso "the mercurial Spaniard" when talking to a friend.<br/>Even one sentence of this would raise eyebrows in conversation. And yet people<br/>write whole books of it.  <br/>  <br/>Ok, so written and spoken language are different. Does that make written<br/>language worse?  <br/>  <br/>If you want people to read and understand what you write, yes. Written<br/>language is more complex, which makes it more work to read. It's also more<br/>formal and distant, which gives the reader's attention permission to drift.<br/>But perhaps worst of all, the complex sentences and fancy words give you, the<br/>writer, the false impression that you're saying more than you actually are.  <br/>  <br/>You don't need complex sentences to express complex ideas. When specialists in<br/>some abstruse topic talk to one another about ideas in their field, they don't<br/>use sentences any more complex than they do when talking about what to have<br/>for lunch. They use different words, certainly. But even those they use no<br/>more than necessary. And in my experience, the harder the subject, the more<br/>informally experts speak. Partly, I think, because they have less to prove,<br/>and partly because the harder the ideas you're talking about, the less you can<br/>afford to let language get in the way.  <br/>  <br/>Informal language is the athletic clothing of ideas.  <br/>  <br/>I'm not saying spoken language always works best. Poetry is as much music as<br/>text, so you can say things you wouldn't say in conversation. And there are a<br/>handful of writers who can get away with using fancy language in prose. And<br/>then of course there are cases where writers don't want to make it easy to<br/>understand what they're saying—in corporate announcements of bad news, for<br/>example, or at the more _bogus_ end of the humanities. But for nearly everyone<br/>else, spoken language is better.  <br/>  <br/>It seems to be hard for most people to write in spoken language. So perhaps<br/>the best solution is to write your first draft the way you usually would, then<br/>afterward look at each sentence and ask "Is this the way I'd say this if I<br/>were talking to a friend?" If it isn't, imagine what you would say, and use<br/>that instead. After a while this filter will start to operate as you write.<br/>When you write something you wouldn't say, you'll hear the clank as it hits<br/>the page.  <br/>  <br/>Before I publish a new essay, I read it out loud and fix everything that<br/>doesn't sound like conversation. I even fix bits that are phonetically<br/>awkward; I don't know if that's necessary, but it doesn't cost much.  <br/>  <br/>This trick may not always be enough. I've seen writing so far removed from<br/>spoken language that it couldn't be fixed sentence by sentence. For cases like<br/>that there's a more drastic solution. After writing the first draft, try<br/>explaining to a friend what you just wrote. Then replace the draft with what<br/>you said to your friend.  <br/>  <br/>People often tell me how much my essays sound like me talking. The fact that<br/>this seems worthy of comment shows how rarely people manage to write in spoken<br/>language. Otherwise everyone's writing would sound like them talking.  <br/>  <br/>If you simply manage to write in spoken language, you'll be ahead of 95% of<br/>writers. And it's so easy to do: just don't let a sentence through unless it's<br/>the way you'd say it to a friend.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Thanks** to Patrick Collison and Jessica Livingston for reading drafts of<br/>this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>May 2001<br/><br/>_(I wrote this article to help myself understand exactly what McCarthy<br/>discovered. You don't need to know this stuff to program in Lisp, but it<br/>should be helpful to anyone who wants to understand the essence of Lisp  both<br/>in the sense of its origins and its semantic core. The fact that it has such a<br/>core is one of Lisp's distinguishing features, and the reason why, unlike<br/>other languages, Lisp has dialects.)_  <br/>  <br/>In 1960, John McCarthy published a remarkable paper in which he did for<br/>programming something like what Euclid did for geometry. He showed how, given<br/>a handful of simple operators and a notation for functions, you can build a<br/>whole programming language. He called this language Lisp, for "List<br/>Processing," because one of his key ideas was to use a simple data structure<br/>called a _list_ for both code and data.  <br/>  <br/>It's worth understanding what McCarthy discovered, not just as a landmark in<br/>the history of computers, but as a model for what programming is tending to<br/>become in our own time. It seems to me that there have been two really clean,<br/>consistent models of programming so far: the C model and the Lisp model. These<br/>two seem points of high ground, with swampy lowlands between them. As<br/>computers have grown more powerful, the new languages being developed have<br/>been moving steadily toward the Lisp model. A popular recipe for new<br/>programming languages in the past 20 years has been to take the C model of<br/>computing and add to it, piecemeal, parts taken from the Lisp model, like<br/>runtime typing and garbage collection.  <br/>  <br/>In this article I'm going to try to explain in the simplest possible terms<br/>what McCarthy discovered. The point is not just to learn about an interesting<br/>theoretical result someone figured out forty years ago, but to show where<br/>languages are heading. The unusual thing about Lisp  in fact, the defining<br/>quality of Lisp  is that it can be written in itself. To understand what<br/>McCarthy meant by this, we're going to retrace his steps, with his<br/>mathematical notation translated into running Common Lisp code.  <br/>  <br/>  <br/><br/>Complete Article (Postscript)  <br/><br/>What Made Lisp Different  <br/><br/>The Code  <br/><br/>Chinese Translation  <br/><br/>Japanese Translation  <br/><br/>Portuguese Translation  <br/><br/>Korean Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>After a link to Beating the Averages was posted on slashdot, some readers<br/>wanted to hear in more detail about the specific technical advantages we got<br/>from using Lisp in Viaweb. For those who are interested, here are some<br/>excerpts from a talk I gave in April 2001 at BBN Labs in Cambridge, MA.  <br/>  <br/><br/>BBN Talk Excerpts (ASCII)  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>March 2009  <br/>  <br/> _(This essay is derived from a talk atAngelConf.)_  <br/>  <br/>When we sold our startup in 1998 I thought one day I'd do some angel<br/>investing. Seven years later I still hadn't started. I put it off because it<br/>seemed mysterious and complicated. It turns out to be easier than I expected,<br/>and also more interesting.  <br/>  <br/>The part I thought was hard, the mechanics of investing, really isn't. You<br/>give a startup money and they give you stock. You'll probably get either<br/>preferred stock, which means stock with extra rights like getting your money<br/>back first in a sale, or convertible debt, which means (on paper) you're<br/>lending the company money, and the debt converts to stock at the next<br/>sufficiently big funding round. [1]  <br/>  <br/>There are sometimes minor tactical advantages to using one or the other. The<br/>paperwork for convertible debt is simpler. But really it doesn't matter much<br/>which you use. Don't spend much time worrying about the details of deal terms,<br/>especially when you first start angel investing. That's not how you win at<br/>this game. When you hear people talking about a successful angel investor,<br/>they're not saying "He got a 4x liquidation preference." They're saying "He<br/>invested in Google."  <br/>  <br/>That's how you win: by investing in the right startups. That is so much more<br/>important than anything else that I worry I'm misleading you by even talking<br/>about other things.  <br/>  <br/> **Mechanics**  <br/>  <br/>Angel investors often syndicate deals, which means they join together to<br/>invest on the same terms. In a syndicate there is usually a "lead" investor<br/>who negotiates the terms with the startup. But not always: sometimes the<br/>startup cobbles together a syndicate of investors who approach them<br/>independently, and the startup's lawyer supplies the paperwork.  <br/>  <br/>The easiest way to get started in angel investing is to find a friend who<br/>already does it, and try to get included in his syndicates. Then all you have<br/>to do is write checks.  <br/>  <br/>Don't feel like you have to join a syndicate, though. It's not that hard to do<br/>it yourself. You can just use the standard series AA documents Wilson Sonsini<br/>and Y Combinator published online. You should of course have your lawyer<br/>review everything. Both you and the startup should have lawyers. But the<br/>lawyers don't have to create the agreement from scratch. [2]  <br/>  <br/>When you negotiate terms with a startup, there are two numbers you care about:<br/>how much money you're putting in, and the valuation of the company. The<br/>valuation determines how much stock you get. If you put $50,000 into a company<br/>at a pre-money valuation of $1 million, then the post-money valuation is $1.05<br/>million, and you get .05/1.05, or 4.76% of the company's stock.  <br/>  <br/>If the company raises more money later, the new investor will take a chunk of<br/>the company away from all the existing shareholders just as you did. If in the<br/>next round they sell 10% of the company to a new investor, your 4.76% will be<br/>reduced to 4.28%.  <br/>  <br/>That's ok. Dilution is normal. What saves you from being mistreated in future<br/>rounds, usually, is that you're in the same boat as the founders. They can't<br/>dilute you without diluting themselves just as much. And they won't dilute<br/>themselves unless they end up net ahead. So in theory, each further round of<br/>investment leaves you with a smaller share of an even more valuable company,<br/>till after several more rounds you end up with .5% of the company at the point<br/>where it IPOs, and you are very happy because your $50,000 has become $5<br/>million. [3]  <br/>  <br/>The agreement by which you invest should have provisions that let you<br/>contribute to future rounds to maintain your percentage. So it's your choice<br/>whether you get diluted. [4] If the company does really well, you eventually<br/>will, because eventually the valuations will get so high it's not worth it for<br/>you.  <br/>  <br/>How much does an angel invest? That varies enormously, from $10,000 to<br/>hundreds of thousands or in rare cases even millions. The upper bound is<br/>obviously the total amount the founders want to raise. The lower bound is<br/>5-10% of the total or $10,000, whichever is greater. A typical angel round<br/>these days might be $150,000 raised from 5 people.  <br/>  <br/>Valuations don't vary as much. For angel rounds it's rare to see a valuation<br/>lower than half a million or higher than 4 or 5 million. 4 million is starting<br/>to be VC territory.  <br/>  <br/>How do you decide what valuation to offer? If you're part of a round led by<br/>someone else, that problem is solved for you. But what if you're investing by<br/>yourself? There's no real answer. There is no rational way to value an early<br/>stage startup. The valuation reflects nothing more than the strength of the<br/>company's bargaining position. If they really want you, either because they<br/>desperately need money, or you're someone who can help them a lot, they'll let<br/>you invest at a low valuation. If they don't need you, it will be higher. So<br/>guess. The startup may not have any more idea what the number should be than<br/>you do. [5]  <br/>  <br/>Ultimately it doesn't matter much. When angels make a lot of money from a<br/>deal, it's not because they invested at a valuation of $1.5 million instead of<br/>$3 million. It's because the company was really successful.  <br/>  <br/>I can't emphasize that too much. Don't get hung up on mechanics or deal terms.<br/>What you should spend your time thinking about is whether the company is good.  <br/>  <br/>(Similarly, founders also should not get hung up on deal terms, but should<br/>spend their time thinking about how to make the company good.)  <br/>  <br/>There's a second less obvious component of an angel investment: how much<br/>you're expected to help the startup. Like the amount you invest, this can vary<br/>a lot. You don't have to do anything if you don't want to; you could simply be<br/>a source of money. Or you can become a de facto employee of the company. Just<br/>make sure that you and the startup agree in advance about roughly how much<br/>you'll do for them.  <br/>  <br/>Really hot companies sometimes have high standards for angels. The ones<br/>everyone wants to invest in practically audition investors, and only take<br/>money from people who are famous and/or will work hard for them. But don't<br/>feel like you have to put in a lot of time or you won't get to invest in any<br/>good startups. There is a surprising lack of correlation between how hot a<br/>deal a startup is and how well it ends up doing. Lots of hot startups will end<br/>up failing, and lots of startups no one likes will end up succeeding. And the<br/>latter are so desperate for money that they'll take it from anyone at a low<br/>valuation. [6]  <br/>  <br/> **Picking Winners**  <br/>  <br/>It would be nice to be able to pick those out, wouldn't it? The part of angel<br/>investing that has most effect on your returns, picking the right companies,<br/>is also the hardest. So you should practically ignore (or more precisely,<br/>archive, in the Gmail sense) everything I've told you so far. You may need to<br/>refer to it at some point, but it is not the central issue.  <br/>  <br/>The central issue is picking the right startups. What "Make something people<br/>want" is for startups, "Pick the right startups" is for investors. Combined<br/>they yield "Pick the startups that will make something people want."  <br/>  <br/>How do you do that? It's not as simple as picking startups that are already<br/>making something wildly popular. By then it's too late for angels. VCs will<br/>already be onto them. As an angel, you have to pick startups before they've<br/>got a hit—either because they've made something great but users don't realize<br/>it yet, like Google early on, or because they're still an iteration or two<br/>away from the big hit, like Paypal when they were making software for<br/>transferring money between PDAs.  <br/>  <br/>To be a good angel investor, you have to be a good judge of potential. That's<br/>what it comes down to. VCs can be fast followers. Most of them don't try to<br/>predict what will win. They just try to notice quickly when something already<br/>is winning. But angels have to be able to predict. [7]  <br/>  <br/>One interesting consequence of this fact is that there are a lot of people out<br/>there who have never even made an angel investment and yet are already better<br/>angel investors than they realize. Someone who doesn't know the first thing<br/>about the mechanics of venture funding but knows what a successful startup<br/>founder looks like is actually far ahead of someone who knows termsheets<br/>inside out, but thinks "hacker" means someone who breaks into computers. If<br/>you can recognize good startup founders by empathizing with them—if you both<br/>resonate at the same frequency—then you may already be a better startup picker<br/>than the median professional VC. [8]  <br/>  <br/>Paul Buchheit, for example, started angel investing about a year after me, and<br/>he was pretty much immediately as good as me at picking startups. My extra<br/>year of experience was rounding error compared to our ability to empathize<br/>with founders.  <br/>  <br/>What makes a good founder? If there were a word that meant the opposite of<br/>hapless, that would be the one. Bad founders seem hapless. They may be smart,<br/>or not, but somehow events overwhelm them and they get discouraged and give<br/>up. Good founders make things happen the way they want. Which is not to say<br/>they force things to happen in a predefined way. Good founders have a healthy<br/>respect for reality. But they are relentlessly resourceful. That's the closest<br/>I can get to the opposite of hapless. You want to fund people who are<br/>relentlessly resourceful.  <br/>  <br/>Notice we started out talking about things, and now we're talking about<br/>people. There is an ongoing debate between investors which is more important,<br/>the people, or the idea—or more precisely, the market. Some, like Ron Conway,<br/>say it's the people—that the idea will change, but the people are the<br/>foundation of the company. Whereas Marc Andreessen says he'd back ok founders<br/>in a hot market over great founders in a bad one. [9]  <br/>  <br/>These two positions are not so far apart as they seem, because good people<br/>find good markets. Bill Gates would probably have ended up pretty rich even if<br/>IBM hadn't happened to drop the PC standard in his lap.  <br/>  <br/>I've thought a lot about the disagreement between the investors who prefer to<br/>bet on people and those who prefer to bet on markets. It's kind of surprising<br/>that it even exists. You'd expect opinions to have converged more.  <br/>  <br/>But I think I've figured out what's going on. The three most prominent people<br/>I know who favor markets are Marc, Jawed Karim, and Joe Kraus. And all three<br/>of them, in their own startups, basically flew into a thermal: they hit a<br/>market growing so fast that it was all they could do to keep up with it. That<br/>kind of experience is hard to ignore. Plus I think they underestimate<br/>themselves: they think back to how easy it felt to ride that huge thermal<br/>upward, and they think "anyone could have done it." But that isn't true; they<br/>are not ordinary people.  <br/>  <br/>So as an angel investor I think you want to go with Ron Conway and bet on<br/>people. Thermals happen, yes, but no one can predict them—not even the<br/>founders, and certainly not you as an investor. And only good people can ride<br/>the thermals if they hit them anyway.  <br/>  <br/> **Deal Flow**  <br/>  <br/>Of course the question of how to choose startups presumes you have startups to<br/>choose between. How do you find them? This is yet another problem that gets<br/>solved for you by syndicates. If you tag along on a friend's investments, you<br/>don't have to find startups.  <br/>  <br/>The problem is not finding startups, exactly, but finding a stream of<br/>reasonably high quality ones. The traditional way to do this is through<br/>contacts. If you're friends with a lot of investors and founders, they'll send<br/>deals your way. The Valley basically runs on referrals. And once you start to<br/>become known as reliable, useful investor, people will refer lots of deals to<br/>you. I certainly will.  <br/>  <br/>There's also a newer way to find startups, which is to come to events like Y<br/>Combinator's Demo Day, where a batch of newly created startups presents to<br/>investors all at once. We have two Demo Days a year, one in March and one in<br/>August. These are basically mass referrals.  <br/>  <br/>But events like Demo Day only account for a fraction of matches between<br/>startups and investors. The personal referral is still the most common route.<br/>So if you want to hear about new startups, the best way to do it is to get<br/>lots of referrals.  <br/>  <br/>The best way to get lots of referrals is to invest in startups. No matter how<br/>smart and nice you seem, insiders will be reluctant to send you referrals<br/>until you've proven yourself by doing a couple investments. Some smart, nice<br/>guys turn out to be flaky, high-maintenance investors. But once you prove<br/>yourself as a good investor, the deal flow, as they call it, will increase<br/>rapidly in both quality and quantity. At the extreme, for someone like Ron<br/>Conway, it is basically identical with the deal flow of the whole Valley.  <br/>  <br/>So if you want to invest seriously, the way to get started is to bootstrap<br/>yourself off your existing connections, be a good investor in the startups you<br/>meet that way, and eventually you'll start a chain reaction. Good investors<br/>are rare, even in Silicon Valley. There probably aren't more than a couple<br/>hundred serious angels in the whole Valley, and yet they're probably the<br/>single most important ingredient in making the Valley what it is. Angels are<br/>the limiting reagent in startup formation.  <br/>  <br/>If there are only a couple hundred serious angels in the Valley, then by<br/>deciding to become one you could single-handedly make the pipeline for<br/>startups in Silicon Valley significantly wider. That is kind of mind-blowing.  <br/>  <br/> **Being Good**  <br/>  <br/>How do you be a good angel investor? The first thing you need is to be<br/>decisive. When we talk to founders about good and bad investors, one of the<br/>ways we describe the good ones is to say "he writes checks." That doesn't mean<br/>the investor says yes to everyone. Far from it. It means he makes up his mind<br/>quickly, and follows through. You may be thinking, how hard could that be?<br/>You'll see when you try it. It follows from the nature of angel investing that<br/>the decisions are hard. You have to guess early, at the stage when the most<br/>promising ideas still seem counterintuitive, because if they were obviously<br/>good, VCs would already have funded them.  <br/>  <br/>Suppose it's 1998. You come across a startup founded by a couple grad<br/>students. They say they're going to work on Internet search. There are already<br/>a bunch of big public companies doing search. How can these grad students<br/>possibly compete with them? And does search even matter anyway? All the search<br/>engines are trying to get people to start calling them "portals" instead. Why<br/>would you want to invest in a startup run by a couple of nobodies who are<br/>trying to compete with large, aggressive companies in an area they themselves<br/>have declared passe? And yet the grad students seem pretty smart. What do you<br/>do?  <br/>  <br/>There's a hack for being decisive when you're inexperienced: ratchet down the<br/>size of your investment till it's an amount you wouldn't care too much about<br/>losing. For every rich person (you probably shouldn't try angel investing<br/>unless you think of yourself as rich) there's some amount that would be<br/>painless, though annoying, to lose. Till you feel comfortable investing, don't<br/>invest more than that per startup.  <br/>  <br/>For example, if you have $5 million in investable assets, it would probably be<br/>painless (though annoying) to lose $15,000. That's less than .3% of your net<br/>worth. So start by making 3 or 4 $15,000 investments. Nothing will teach you<br/>about angel investing like experience. Treat the first few as an educational<br/>expense. $60,000 is less than a lot of graduate programs. Plus you get equity.  <br/>  <br/>What's really uncool is to be strategically indecisive: to string founders<br/>along while trying to gather more information about the startup's trajectory.<br/>[10] There's always a temptation to do that, because you just have so little<br/>to go on, but you have to consciously resist it. In the long term it's to your<br/>advantage to be good.  <br/>  <br/>The other component of being a good angel investor is simply to be a good<br/>person. Angel investing is not a business where you make money by screwing<br/>people over. Startups create wealth, and creating wealth is not a zero sum<br/>game. No one has to lose for you to win. In fact, if you mistreat the founders<br/>you invest in, they'll just get demoralized and the company will do worse.<br/>Plus your referrals will dry up. So I recommend being good.  <br/>  <br/>The most successful angel investors I know are all basically good people. Once<br/>they invest in a company, all they want to do is help it. And they'll help<br/>people they haven't invested in too. When they do favors they don't seem to<br/>keep track of them. It's too much overhead. They just try to help everyone,<br/>and assume good things will flow back to them somehow. Empirically that seems<br/>to work.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] Convertible debt can be either capped at a particular valuation, or can be<br/>done at a discount to whatever the valuation turns out to be when it converts.<br/>E.g. convertible debt at a discount of 30% means when it converts you get<br/>stock as if you'd invested at a 30% lower valuation. That can be useful in<br/>cases where you can't or don't want to figure out what the valuation should<br/>be. You leave it to the next investor. On the other hand, a lot of investors<br/>want to know exactly what they're getting, so they will only do convertible<br/>debt with a cap.  <br/>  <br/>[2] The expensive part of creating an agreement from scratch is not writing<br/>the agreement, but bickering at several hundred dollars an hour over the<br/>details. That's why the series AA paperwork aims at a middle ground. You can<br/>just start from the compromise you'd have reached after lots of back and<br/>forth.  <br/>  <br/>When you fund a startup, both your lawyers should be specialists in startups.<br/>Do not use ordinary corporate lawyers for this. Their inexperience makes them<br/>overbuild: they'll create huge, overcomplicated agreements, and spend hours<br/>arguing over irrelevant things.  <br/>  <br/>In the Valley, the top startup law firms are Wilson Sonsini, Orrick, Fenwick &<br/>West, Gunderson Dettmer, and Cooley Godward. In Boston the best are Goodwin<br/>Procter, Wilmer Hale, and Foley Hoag.  <br/>  <br/>[3] Your mileage may vary.  <br/>  <br/>[4] These anti-dilution provisions also protect you against tricks like a<br/>later investor trying to steal the company by doing another round that values<br/>the company at $1. If you have a competent startup lawyer handle the deal for<br/>you, you should be protected against such tricks initially. But it could<br/>become a problem later. If a big VC firm wants to invest in the startup after<br/>you, they may try to make you take out your anti-dilution protections. And if<br/>they do the startup will be pressuring you to agree. They'll tell you that if<br/>you don't, you're going to kill their deal with the VC. I recommend you solve<br/>this problem by having a gentlemen's agreement with the founders: agree with<br/>them in advance that you're not going to give up your anti-dilution<br/>protections. Then it's up to them to tell VCs early on.  <br/>  <br/>The reason you don't want to give them up is the following scenario. The VCs<br/>recapitalize the company, meaning they give it additional funding at a pre-<br/>money valuation of zero. This wipes out the existing shareholders, including<br/>both you and the founders. They then grant the founders lots of options,<br/>because they need them to stay around, but you get nothing.  <br/>  <br/>Obviously this is not a nice thing to do. It doesn't happen often. Brand-name<br/>VCs wouldn't recapitalize a company just to steal a few percent from an angel.<br/>But there's a continuum here. A less upstanding, lower-tier VC might be<br/>tempted to do it to steal a big chunk of stock.  <br/>  <br/>I'm not saying you should always absolutely refuse to give up your anti-<br/>dilution protections. Everything is a negotiation. If you're part of a<br/>powerful syndicate, you might be able to give up legal protections and rely on<br/>social ones. If you invest in a deal led by a big angel like Ron Conway, for<br/>example, you're pretty well protected against being mistreated, because any VC<br/>would think twice before crossing him. This kind of protection is one of the<br/>reasons angels like to invest in syndicates.  <br/>  <br/>[5] Don't invest so much, or at such a low valuation, that you end up with an<br/>excessively large share of a startup, unless you're sure your money will be<br/>the last they ever need. Later stage investors won't invest in a company if<br/>the founders don't have enough equity left to motivate them. I talked to a VC<br/>recently who said he'd met with a company he really liked, but he turned them<br/>down because investors already owned more than half of it. Those investors<br/>probably thought they'd been pretty clever by getting such a large chunk of<br/>this desirable company, but in fact they were shooting themselves in the foot.  <br/>  <br/>[6] At any given time I know of at least 3 or 4 YC alumni who I believe will<br/>be big successes but who are running on vapor, financially, because investors<br/>don't yet get what they're doing. (And no, unfortunately, I can't tell you who<br/>they are. I can't refer a startup to an investor I don't know.)  <br/>  <br/>[7] There are some VCs who can predict instead of reacting. Not surprisingly,<br/>these are the most successful ones.  <br/>  <br/>[8] It's somewhat sneaky of me to put it this way, because the median VC loses<br/>money. That's one of the most surprising things I've learned about VC while<br/>working on Y Combinator. Only a fraction of VCs even have positive returns.<br/>The rest exist to satisfy demand among fund managers for venture capital as an<br/>asset class. Learning this explained a lot about some of the VCs I encountered<br/>when we were working on Viaweb.  <br/>  <br/>[9] VCs also generally say they prefer great markets to great people. But what<br/>they're really saying is they want both. They're so selective that they only<br/>even consider great people. So when they say they care above all about big<br/>markets, they mean that's how they choose between great people.  <br/>  <br/>[10] Founders rightly dislike the sort of investor who says he's interested in<br/>investing but doesn't want to lead. There are circumstances where this is an<br/>acceptable excuse, but more often than not what it means is "No, but if you<br/>turn out to be a hot deal, I want to be able to claim retroactively I said<br/>yes."  <br/>  <br/>If you like a startup enough to invest in it, then invest in it. Just use the<br/>standard series AA terms and write them a check.  <br/>  <br/>**Thanks** to Sam Altman, Paul Buchheit, Jessica Livingston, Robert Morris,<br/>and Fred Wilson for reading drafts of this.  <br/>  <br/>Comment on this essay.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>February 2008  <br/>  <br/>A user on Hacker News recently posted a comment that set me thinking:<br/><br/>> Something about hacker culture that never really set well with me was this <br/>> the nastiness. ... I just don't understand why people troll like they do.<br/><br/>I've thought a lot over the last couple years about the problem of trolls.<br/>It's an old one, as old as forums, but we're still just learning what the<br/>causes are and how to address them.  <br/>  <br/>There are two senses of the word "troll." In the original sense it meant<br/>someone, usually an outsider, who deliberately stirred up fights in a forum by<br/>saying controversial things. [1] For example, someone who didn't use a certain<br/>programming language might go to a forum for users of that language and make<br/>disparaging remarks about it, then sit back and watch as people rose to the<br/>bait. This sort of trolling was in the nature of a practical joke, like<br/>letting a bat loose in a room full of people.  <br/>  <br/>The definition then spread to people who behaved like assholes in forums,<br/>whether intentionally or not. Now when people talk about trolls they usually<br/>mean this broader sense of the word. Though in a sense this is historically<br/>inaccurate, it is in other ways more accurate, because when someone is being<br/>an asshole it's usually uncertain even in their own mind how much is<br/>deliberate. That is arguably one of the defining qualities of an asshole.  <br/>  <br/>I think trolling in the broader sense has four causes. The most important is<br/>distance. People will say things in anonymous forums that they'd never dare<br/>say to someone's face, just as they'll do things in cars that they'd never do<br/>as pedestrians  like tailgate people, or honk at them, or cut them off.  <br/>  <br/>Trolling tends to be particularly bad in forums related to computers, and I<br/>think that's due to the kind of people you find there. Most of them (myself<br/>included) are more comfortable dealing with abstract ideas than with people.<br/>Hackers can be abrupt even in person. Put them on an anonymous forum, and the<br/>problem gets worse.  <br/>  <br/>The third cause of trolling is incompetence. If you disagree with something,<br/>it's easier to say "you suck" than to figure out and explain exactly what you<br/>disagree with. You're also safe that way from refutation. In this respect<br/>trolling is a lot like graffiti. Graffiti happens at the intersection of<br/>ambition and incompetence: people want to make their mark on the world, but<br/>have no other way to do it than literally making a mark on the world. [2]  <br/>  <br/>The final contributing factor is the culture of the forum. Trolls are like<br/>children (many _are_ children) in that they're capable of a wide range of<br/>behavior depending on what they think will be tolerated. In a place where<br/>rudeness isn't tolerated, most can be polite. But vice versa as well.  <br/>  <br/>There's a sort of Gresham's Law of trolls: trolls are willing to use a forum<br/>with a lot of thoughtful people in it, but thoughtful people aren't willing to<br/>use a forum with a lot of trolls in it. Which means that once trolling takes<br/>hold, it tends to become the dominant culture. That had already happened to<br/>Slashdot and Digg by the time I paid attention to comment threads there, but I<br/>watched it happen to Reddit.  <br/>  <br/>News.YC<br/><br/>Russian Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/> _Note: The strategy described at the end of this essay didn't work. It would<br/>work for a while, and then I'd gradually find myself using the Internet on my<br/>work computer. I'm trying other strategies now, but I think this time I'll<br/>wait till I'm sure they work before writing about them._  <br/>  <br/>May 2008  <br/>  <br/>Procrastination feeds on distractions. Most people find it uncomfortable just<br/>to sit and do nothing; you avoid work by doing something else.  <br/>  <br/>So one way to beat procrastination is to starve it of distractions. But that's<br/>not as straightforward as it sounds, because there are people working hard to<br/>distract you. Distraction is not a static obstacle that you avoid like you<br/>might avoid a rock in the road. Distraction seeks you out.  <br/>  <br/>Chesterfield described dirt as matter out of place. Distracting is, similarly,<br/>desirable at the wrong time. And technology is continually being refined to<br/>produce more and more desirable things. Which means that as we learn to avoid<br/>one class of distractions, new ones constantly appear, like drug-resistant<br/>bacteria.  <br/>  <br/>Television, for example, has after 50 years of refinement reached the point<br/>where it's like visual crack. I realized when I was 13 that TV was addictive,<br/>so I stopped watching it. But I read recently that the average American<br/>watches 4 hours of TV a day. A quarter of their life.  <br/>  <br/>TV is in decline now, but only because people have found even more addictive<br/>ways of wasting time. And what's especially dangerous is that many happen at<br/>your computer. This is no accident. An ever larger percentage of office<br/>workers sit in front of computers connected to the Internet, and distractions<br/>always evolve toward the procrastinators.  <br/>  <br/>I remember when computers were, for me at least, exclusively for work. I might<br/>occasionally dial up a server to get mail or ftp files, but most of the time I<br/>was offline. All I could do was write and program. Now I feel as if someone<br/>snuck a television onto my desk. Terribly addictive things are just a click<br/>away. Run into an obstacle in what you're working on? Hmm, I wonder what's new<br/>online. Better check.  <br/>  <br/>After years of carefully avoiding classic time sinks like TV, games, and<br/>Usenet, I still managed to fall prey to distraction, because I didn't realize<br/>that it evolves. Something that used to be safe, using the Internet, gradually<br/>became more and more dangerous. Some days I'd wake up, get a cup of tea and<br/>check the news, then check email, then check the news again, then answer a few<br/>emails, then suddenly notice it was almost lunchtime and I hadn't gotten any<br/>real work done. And this started to happen more and more often.  <br/>  <br/>It took me surprisingly long to realize how distracting the Internet had<br/>become, because the problem was intermittent. I ignored it the way you let<br/>yourself ignore a bug that only appears intermittently. When I was in the<br/>middle of a project, distractions weren't really a problem. It was when I'd<br/>finished one project and was deciding what to do next that they always bit me.  <br/>  <br/>Another reason it was hard to notice the danger of this new type of<br/>distraction was that social customs hadn't yet caught up with it. If I'd spent<br/>a whole morning sitting on a sofa watching TV, I'd have noticed very quickly.<br/>That's a known danger sign, like drinking alone. But using the Internet still<br/>looked and felt a lot like work.  <br/>  <br/>Eventually, though, it became clear that the Internet had become so much more<br/>distracting that I had to start treating it differently. Basically, I had to<br/>add a new application to my list of known time sinks: Firefox.  <br/>  <br/>* * *  <br/>  <br/>The problem is a hard one to solve because most people still need the Internet<br/>for some things. If you drink too much, you can solve that problem by stopping<br/>entirely. But you can't solve the problem of overeating by stopping eating. I<br/>couldn't simply avoid the Internet entirely, as I'd done with previous time<br/>sinks.  <br/>  <br/>At first I tried rules. For example, I'd tell myself I was only going to use<br/>the Internet twice a day. But these schemes never worked for long. Eventually<br/>something would come up that required me to use it more than that. And then<br/>I'd gradually slip back into my old ways.  <br/>  <br/>Addictive things have to be treated as if they were sentient adversaries—as if<br/>there were a little man in your head always cooking up the most plausible<br/>arguments for doing whatever you're trying to stop doing. If you leave a path<br/>to it, he'll find it.  <br/>  <br/>The key seems to be visibility. The biggest ingredient in most bad habits is<br/>denial. So you have to make it so that you can't merely _slip_ into doing the<br/>thing you're trying to avoid. It has to set off alarms.  <br/>  <br/>Maybe in the long term the right answer for dealing with Internet distractions<br/>will be software that watches and controls them. But in the meantime I've<br/>found a more drastic solution that definitely works: to set up a separate<br/>computer for using the Internet.  <br/>  <br/>I now leave wifi turned off on my main computer except when I need to transfer<br/>a file or edit a web page, and I have a separate laptop on the other side of<br/>the room that I use to check mail or browse the web. (Irony of ironies, it's<br/>the computer Steve Huffman wrote Reddit on. When Steve and Alexis auctioned<br/>off their old laptops for charity, I bought them for the Y Combinator museum.)  <br/>  <br/>My rule is that I can spend as much time online as I want, as long as I do it<br/>on that computer. And this turns out to be enough. When I have to sit on the<br/>other side of the room to check email or browse the web, I become much more<br/>aware of it. Sufficiently aware, in my case at least, that it's hard to spend<br/>more than about an hour a day online.  <br/>  <br/>And my main computer is now freed for work. If you try this trick, you'll<br/>probably be struck by how different it feels when your computer is<br/>disconnected from the Internet. It was alarming to me how foreign it felt to<br/>sit in front of a computer that could only be used for work, because that<br/>showed how much time I must have been wasting.  <br/>  <br/> _Wow. All I can do at this computer is work. Ok, I better work then._  <br/>  <br/>That's the good part. Your old bad habits now help you to work. You're used to<br/>sitting in front of that computer for hours at a time. But you can't browse<br/>the web or check email now. What are you going to do? You can't just sit<br/>there. So you start working.  <br/>  <br/><br/>Good and Bad Procrastination  <br/><br/>Spanish Translation  <br/><br/>Arabic Translation  <br/><br/>Catalan Translation  <br/><br/>Russian Translation  <br/><br/>Spanish Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>July 2006  <br/>  <br/>I've discovered a handy test for figuring out what you're addicted to. Imagine<br/>you were going to spend the weekend at a friend's house on a little island off<br/>the coast of Maine. There are no shops on the island and you won't be able to<br/>leave while you're there. Also, you've never been to this house before, so you<br/>can't assume it will have more than any house might.  <br/>  <br/>What, besides clothes and toiletries, do you make a point of packing? That's<br/>what you're addicted to. For example, if you find yourself packing a bottle of<br/>vodka (just in case), you may want to stop and think about that.  <br/>  <br/>For me the list is four things: books, earplugs, a notebook, and a pen.  <br/>  <br/>There are other things I might bring if I thought of it, like music, or tea,<br/>but I can live without them. I'm not so addicted to caffeine that I wouldn't<br/>risk the house not having any tea, just for a weekend.  <br/>  <br/>Quiet is another matter. I realize it seems a bit eccentric to take earplugs<br/>on a trip to an island off the coast of Maine. If anywhere should be quiet,<br/>that should. But what if the person in the next room snored? What if there was<br/>a kid playing basketball? (Thump, thump, thump... thump.) Why risk it?<br/>Earplugs are small.  <br/>  <br/>Sometimes I can think with noise. If I already have momentum on some project,<br/>I can work in noisy places. I can edit an essay or debug code in an airport.<br/>But airports are not so bad: most of the noise is whitish. I couldn't work<br/>with the sound of a sitcom coming through the wall, or a car in the street<br/>playing thump-thump music.  <br/>  <br/>And of course there's another kind of thinking, when you're starting something<br/>new, that requires complete quiet. You never know when this will strike. It's<br/>just as well to carry plugs.  <br/>  <br/>The notebook and pen are professional equipment, as it were. Though actually<br/>there is something druglike about them, in the sense that their main purpose<br/>is to make me feel better. I hardly ever go back and read stuff I write down<br/>in notebooks. It's just that if I can't write things down, worrying about<br/>remembering one idea gets in the way of having the next. Pen and paper wick<br/>ideas.  <br/>  <br/>The best notebooks I've found are made by a company called Miquelrius. I use<br/>their smallest size, which is about 2.5 x 4 in. The secret to writing on such<br/>narrow pages is to break words only when you run out of space, like a Latin<br/>inscription. I use the cheapest plastic Bic ballpoints, partly because their<br/>gluey ink doesn't seep through pages, and partly so I don't worry about losing<br/>them.  <br/>  <br/>I only started carrying a notebook about three years ago. Before that I used<br/>whatever scraps of paper I could find. But the problem with scraps of paper is<br/>that they're not ordered. In a notebook you can guess what a scribble means by<br/>looking at the pages around it. In the scrap era I was constantly finding<br/>notes I'd written years before that might say something I needed to remember,<br/>if I could only figure out what.  <br/>  <br/>As for books, I know the house would probably have something to read. On the<br/>average trip I bring four books and only read one of them, because I find new<br/>books to read en route. Really bringing books is insurance.  <br/>  <br/>I realize this dependence on books is not entirely good—that what I need them<br/>for is distraction. The books I bring on trips are often quite virtuous, the<br/>sort of stuff that might be assigned reading in a college class. But I know my<br/>motives aren't virtuous. I bring books because if the world gets boring I need<br/>to be able to slip into another distilled by some writer. It's like eating jam<br/>when you know you should be eating fruit.  <br/>  <br/>There is a point where I'll do without books. I was walking in some steep<br/>mountains once, and decided I'd rather just think, if I was bored, rather than<br/>carry a single unnecessary ounce. It wasn't so bad. I found I could entertain<br/>myself by having ideas instead of reading other people's. If you stop eating<br/>jam, fruit starts to taste better.  <br/>  <br/>So maybe I'll try not bringing books on some future trip. They're going to<br/>have to pry the plugs out of my cold, dead ears, however.  <br/>  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>April 2005  <br/>  <br/>This summer, as an experiment, some friends and I are giving seed funding to a<br/>bunch of new startups. It's an experiment because we're prepared to fund<br/>younger founders than most investors would. That's why we're doing it during<br/>the summer—so even college students can participate.  <br/>  <br/>We know from Google and Yahoo that grad students can start successful<br/>startups. And we know from experience that some undergrads are as capable as<br/>most grad students. The accepted age for startup founders has been creeping<br/>downward. We're trying to find the lower bound.  <br/>  <br/>The deadline has now passed, and we're sifting through 227 applications.  We<br/>expected to divide them into two categories, promising and unpromising. But we<br/>soon saw we needed a third: promising people with unpromising ideas. [1]  <br/>  <br/> **The Artix Phase**  <br/>  <br/>We should have expected this. It's very common for a group of founders to go<br/>through one lame idea before realizing that a startup has to make something<br/>people will pay for. In fact, we ourselves did.  <br/>  <br/>Viaweb wasn't the first startup Robert Morris and I started. In January 1995,<br/>we and a couple friends started a company called Artix. The plan was to put<br/>art galleries on the Web. In retrospect, I wonder how we could have wasted our<br/>time on anything so stupid. Galleries are not especially excited about being<br/>on the Web even now, ten years later. They don't want to have their stock<br/>visible to any random visitor, like an antique store. [2]  <br/>  <br/>Besides which, art dealers are the most technophobic people on earth. They<br/>didn't become art dealers after a difficult choice between that and a career<br/>in the hard sciences. Most of them had never seen the Web before we came to<br/>tell them why they should be on it. Some didn't even have computers. It<br/>doesn't do justice to the situation to describe it as a hard _sell_ ; we soon<br/>sank to building sites for free, and it was hard to convince galleries even to<br/>do that.  <br/>  <br/>Gradually it dawned on us that instead of trying to make Web sites for people<br/>who didn't want them, we could make sites for people who did. In fact,<br/>software that would let people who wanted sites make their own. So we ditched<br/>Artix and started a new company, Viaweb, to make software for building online<br/>stores. That one succeeded.  <br/>  <br/>We're in good company here. Microsoft was not the first company Paul Allen and<br/>Bill Gates started either. The first was called Traf-o-data. It does not seem<br/>to have done as well as Micro-soft.  <br/>  <br/>In Robert's defense, he was skeptical about Artix. I dragged him into it. [3]<br/>But there were moments when he was optimistic. And if we, who were 29 and 30<br/>at the time, could get excited about such a thoroughly boneheaded idea, we<br/>should not be surprised that hackers aged 21 or 22 are pitching us ideas with<br/>little hope of making money.  <br/>  <br/> **The Still Life Effect**  <br/>  <br/>Why does this happen? Why do good hackers have bad business ideas?  <br/>  <br/>Let's look at our case. One reason we had such a lame idea was that it was the<br/>first thing we thought of. I was in New York trying to be a starving artist at<br/>the time (the starving part is actually quite easy), so I was haunting<br/>galleries anyway. When I learned about the Web, it seemed natural to mix the<br/>two. Make Web sites for galleries—that's the ticket!  <br/>  <br/>If you're going to spend years working on something, you'd think it might be<br/>wise to spend at least a couple days considering different ideas, instead of<br/>going with the first that comes into your head. You'd think. But people don't.<br/>In fact, this is a constant problem when you're painting still lifes. You<br/>plonk down a bunch of stuff on a table, and maybe spend five or ten minutes<br/>rearranging it to look interesting. But you're so impatient to get started<br/>painting that ten minutes of rearranging feels very long. So you start<br/>painting. Three days later, having spent twenty hours staring at it, you're<br/>kicking yourself for having set up such an awkward and boring composition, but<br/>by then it's too late.  <br/>  <br/>Part of the problem is that big projects tend to grow out of small ones. You<br/>set up a still life to make a quick sketch when you have a spare hour, and<br/>days later you're still working on it. I once spent a month painting three<br/>versions of a still life I set up in about four minutes. At each point (a day,<br/>a week, a month) I thought I'd already put in so much time that it was too<br/>late to change.  <br/>  <br/>So the biggest cause of bad ideas is the still life effect: you come up with a<br/>random idea, plunge into it, and then at each point (a day, a week, a month)<br/>feel you've put so much time into it that this must be _the_ idea.  <br/>  <br/>How do we fix that? I don't think we should discard plunging. Plunging into an<br/>idea is a good thing. The solution is at the other end: to realize that having<br/>invested time in something doesn't make it good.  <br/>  <br/>This is clearest in the case of names. Viaweb was originally called Webgen,<br/>but we discovered someone else had a product called that. We were so attached<br/>to our name that we offered him _5% of the company_ if he'd let us have it.<br/>But he wouldn't, so we had to think of another. [4] The best we could do was<br/>Viaweb, which we disliked at first. It was like having a new mother. But<br/>within three days we loved it, and Webgen sounded lame and old-fashioned.  <br/>  <br/>If it's hard to change something so simple as a name, imagine how hard it is<br/>to garbage-collect an idea. A name only has one point of attachment into your<br/>head. An idea for a company gets woven into your thoughts. So you must<br/>consciously discount for that. Plunge in, by all means, but remember later to<br/>look at your idea in the harsh light of morning and ask: is this something<br/>people will pay for? Is this, of all the things we could make, the thing<br/>people will pay most for?  <br/>  <br/> **Muck**  <br/>  <br/>The second mistake we made with Artix is also very common. Putting galleries<br/>on the Web seemed cool.  <br/>  <br/>One of the most valuable things my father taught me is an old Yorkshire<br/>saying: where there's muck, there's brass. Meaning that unpleasant work pays.<br/>And more to the point here, vice versa. Work people like doesn't pay well, for<br/>reasons of supply and demand. The most extreme case is developing programming<br/>languages, which doesn't pay at all, because people like it so much they do it<br/>for free.  <br/>  <br/>When we started Artix, I was still ambivalent about business. I wanted to keep<br/>one foot in the art world. Big, big, mistake. Going into business is like a<br/>hang-glider launch: you'd better do it wholeheartedly, or not at all. The<br/>purpose of a company, and a startup especially, is to make money. You can't<br/>have divided loyalties.  <br/>  <br/>Which is not to say that you have to do the most disgusting sort of work, like<br/>spamming, or starting a company whose only purpose is patent litigation. What<br/>I mean is, if you're starting a company that will do something cool, the aim<br/>had better be to make money and maybe be cool, not to be cool and maybe make<br/>money.  <br/>  <br/>It's hard enough to make money that you can't do it by accident. Unless it's<br/>your first priority, it's unlikely to happen at all.  <br/>  <br/> **Hyenas**  <br/>  <br/>When I probe our motives with Artix, I see a third mistake: timidity. If you'd<br/>proposed at the time that we go into the e-commerce business, we'd have found<br/>the idea terrifying. Surely a field like that would be dominated by fearsome<br/>startups with five million dollars of VC money each. Whereas we felt pretty<br/>sure that we could hold our own in the slightly less competitive business of<br/>generating Web sites for art galleries.  <br/>  <br/>We erred ridiculously far on the side of safety. As it turns out, VC-backed<br/>startups are not that fearsome. They're too busy trying to spend all that<br/>money to get software written. In 1995, the e-commerce business was very<br/>competitive as measured in press releases, but not as measured in software.<br/>And really it never was. The big fish like Open Market (rest their souls) were<br/>just consulting companies pretending to be product companies [5], and the<br/>offerings at our end of the market were a couple hundred lines of Perl<br/>scripts. Or could have been implemented as a couple hundred lines of Perl; in<br/>fact they were probably tens of thousands of lines of C++ or Java. Once we<br/>actually took the plunge into e-commerce, it turned out to be surprisingly<br/>easy to compete.  <br/>  <br/>So why were we afraid? We felt we were good at programming, but we lacked<br/>confidence in our ability to do a mysterious, undifferentiated thing we called<br/>"business." In fact there is no such thing as "business." There's selling,<br/>promotion, figuring out what people want, deciding how much to charge,<br/>customer support, paying your bills, getting customers to pay you, getting<br/>incorporated, raising money, and so on. And the combination is not as hard as<br/>it seems, because some tasks (like raising money and getting incorporated) are<br/>an O(1) pain in the ass, whether you're big or small, and others (like selling<br/>and promotion) depend more on energy and imagination than any kind of special<br/>training.  <br/>  <br/>Artix was like a hyena, content to survive on carrion because we were afraid<br/>of the lions. Except the lions turned out not to have any teeth, and the<br/>business of putting galleries online barely qualified as carrion.  <br/>  <br/> **A Familiar Problem**  <br/>  <br/>Sum up all these sources of error, and it's no wonder we had such a bad idea<br/>for a company. We did the first thing we thought of; we were ambivalent about<br/>being in business at all; and we deliberately chose an impoverished market to<br/>avoid competition.  <br/>  <br/>Looking at the applications for the Summer Founders Program, I see signs of<br/>all three. But the first is by far the biggest problem. Most of the groups<br/>applying have not stopped to ask: of all the things we could do, is _this_ the<br/>one with the best chance of making money?  <br/>  <br/>If they'd already been through their Artix phase, they'd have learned to ask<br/>that. After the reception we got from art dealers, we were ready to. This<br/>time, we thought, let's make something people want.  <br/>  <br/>Reading the _Wall Street Journal_ for a week should give anyone ideas for two<br/>or three new startups. The articles are full of descriptions of problems that<br/>need to be solved. But most of the applicants don't seem to have looked far<br/>for ideas.  <br/>  <br/>We expected the most common proposal to be for multiplayer games. We were not<br/>far off: this was the second most common. The most common was some combination<br/>of a blog, a calendar, a dating site, and Friendster. Maybe there is some new<br/>killer app to be discovered here, but it seems perverse to go poking around in<br/>this fog when there are valuable, unsolved problems lying about in the open<br/>for anyone to see. Why did no one propose a new scheme for micropayments? An<br/>ambitious project, perhaps, but I can't believe we've considered every<br/>alternative. And newspapers and magazines are (literally) dying for a<br/>solution.  <br/>  <br/>Why did so few applicants really think about what customers want? I think the<br/>problem with many, as with people in their early twenties generally, is that<br/>they've been trained their whole lives to jump through predefined hoops.<br/>They've spent 15-20 years solving problems other people have set for them. And<br/>how much time deciding what problems would be good to solve? Two or three<br/>course projects?  They're good at solving problems, but bad at choosing them.  <br/>  <br/>But that, I'm convinced, is just the effect of training. Or more precisely,<br/>the effect of grading. To make grading efficient, everyone has to solve the<br/>same problem, and that means it has to be decided in advance. It would be<br/>great if schools taught students how to choose problems as well as how to<br/>solve them, but I don't know how you'd run such a class in practice.  <br/>  <br/> **Copper and Tin**  <br/>  <br/>The good news is, choosing problems is something that can be learned. I know<br/>that from experience. Hackers can learn to make things customers want. [6]  <br/>  <br/>This is a controversial view. One expert on "entrepreneurship" told me that<br/>any startup had to include business people, because only they could focus on<br/>what customers wanted. I'll probably alienate this guy forever by quoting him,<br/>but I have to risk it, because his email was such a perfect example of this<br/>view:<br/><br/>> 80% of MIT spinoffs succeed _provided_ they have at least one management<br/>> person in the team at the start. The business person represents the "voice<br/>> of the customer" and that's what keeps the engineers and product development<br/>> on track.<br/><br/>This is, in my opinion, a crock. Hackers are perfectly capable of hearing the<br/>voice of the customer without a business person to amplify the signal for<br/>them. Larry Page and Sergey Brin were grad students in computer science, which<br/>presumably makes them "engineers." Do you suppose Google is only good because<br/>they had some business guy whispering in their ears what customers wanted? It<br/>seems to me the business guys who did the most for Google were the ones who<br/>obligingly flew Altavista into a hillside just as Google was getting started.  <br/>  <br/>The hard part about figuring out what customers want is figuring out that you<br/>need to figure it out. But that's something you can learn quickly. It's like<br/>seeing the other interpretation of an ambiguous picture. As soon as someone<br/>tells you there's a rabbit as well as a duck, it's hard not to see it.  <br/>  <br/>And compared to the sort of problems hackers are used to solving, giving<br/>customers what they want is easy. Anyone who can write an optimizing compiler<br/>can design a UI that doesn't confuse users, once they _choose_ to focus on<br/>that problem. And once you apply that kind of brain power to petty but<br/>profitable questions, you can create wealth very rapidly.  <br/>  <br/>That's the essence of a startup: having brilliant people do work that's<br/>beneath them. Big companies try to hire the right person for the job. Startups<br/>win because they don't—because they take people so smart that they would in a<br/>big company be doing "research," and set them to work instead on problems of<br/>the most immediate and mundane sort. Think Einstein designing refrigerators.<br/>[7]  <br/>  <br/>If you want to learn what people want, read Dale Carnegie's _How to Win<br/>Friends and Influence People._ [8] When a friend recommended this book, I<br/>couldn't believe he was serious. But he insisted it was good, so I read it,<br/>and he was right. It deals with the most difficult problem in human<br/>experience: how to see things from other people's point of view, instead of<br/>thinking only of yourself.  <br/>  <br/>Most smart people don't do that very well. But adding this ability to raw<br/>brainpower is like adding tin to copper. The result is bronze, which is so<br/>much harder that it seems a different metal.  <br/>  <br/>A hacker who has learned what to make, and not just how to make, is<br/>extraordinarily powerful. And not just at making money: look what a small<br/>group of volunteers has achieved with Firefox.  <br/>  <br/>Doing an Artix teaches you to make something people want in the same way that<br/>not drinking anything would teach you how much you depend on water. But it<br/>would be more convenient for all involved if the Summer Founders didn't learn<br/>this on our dime—if they could skip the Artix phase and go right on to make<br/>something customers wanted. That, I think, is going to be the real experiment<br/>this summer. How long will it take them to grasp this?  <br/>  <br/>We decided we ought to have T-Shirts for the SFP, and we'd been thinking about<br/>what to print on the back. Till now we'd been planning to use<br/><br/>> If you can read this, I should be working.<br/><br/>but now we've decided it's going to be<br/><br/>> Make something people want.<br/><br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] SFP applicants: please don't assume that not being accepted means we think<br/>your idea is bad. Because we want to keep the number of startups small this<br/>first summer, we're going to have to turn down some good proposals too.  <br/>  <br/>[2] Dealers try to give each customer the impression that the stuff they're<br/>showing him is something special that only a few people have seen, when in<br/>fact it may have been sitting in their racks for years while they tried to<br/>unload it on buyer after buyer.  <br/>  <br/>[3] On the other hand, he was skeptical about Viaweb too. I have a precise<br/>measure of that, because at one point in the first couple months we made a<br/>bet: if he ever made a million dollars out of Viaweb, he'd get his ear<br/>pierced. We didn't let him off, either.  <br/>  <br/>[4] I wrote a program to generate all the combinations of "Web" plus a three<br/>letter word. I learned from this that most three letter words are bad: Webpig,<br/>Webdog, Webfat, Webzit, Webfug. But one of them was Webvia; I swapped them to<br/>make Viaweb.  <br/>  <br/>[5] It's much easier to sell services than a product, just as it's easier to<br/>make a living playing at weddings than by selling recordings. But the margins<br/>are greater on products. So during the Bubble a lot of companies used<br/>consulting to generate revenues they could attribute to the sale of products,<br/>because it made a better story for an IPO.  <br/>  <br/>[6] Trevor Blackwell presents the following recipe for a startup: "Watch<br/>people who have money to spend, see what they're wasting their time on, cook<br/>up a solution, and try selling it to them. It's surprising how small a problem<br/>can be and still provide a profitable market for a solution."  <br/>  <br/>[7] You need to offer especially large rewards to get great people to do<br/>tedious work. That's why startups always pay equity rather than just salary.  <br/>  <br/>[8] Buy an old copy from the 1940s or 50s instead of the current edition,<br/>which has been rewritten to suit present fashions. The original edition<br/>contained a few unPC ideas, but it's always better to read an original book,<br/>bearing in mind that it's a book from a past era, than to read a new version<br/>sanitized for your protection.  <br/>  <br/> **Thanks** to Bill Birch, Trevor Blackwell, Jessica Livingston, and Robert<br/>Morris for reading drafts of this.  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Italian Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>August 2008  <br/>  <br/>Raising money is the second hardest part of starting a startup. The hardest<br/>part is making something people want: most startups that die, die because they<br/>didn't do that. But the second biggest cause of death is probably the<br/>difficulty of raising money. Fundraising is brutal.  <br/>  <br/>One reason it's so brutal is simply the brutality of markets. People who've<br/>spent most of their lives in schools or big companies may not have been<br/>exposed to that. Professors and bosses usually feel some sense of<br/>responsibility toward you; if you make a valiant effort and fail, they'll cut<br/>you a break. Markets are less forgiving. Customers don't care how hard you<br/>worked, only whether you solved their problems.  <br/>  <br/>Investors evaluate startups the way customers evaluate products, not the way<br/>bosses evaluate employees. If you're making a valiant effort and failing,<br/>maybe they'll invest in your next startup, but not this one.  <br/>  <br/>But raising money from investors is harder than selling to customers, because<br/>there are so few of them. There's nothing like an efficient market. You're<br/>unlikely to have more than 10 who are interested; it's difficult to talk to<br/>more. So the randomness of any one investor's behavior can really affect you.  <br/>  <br/>Problem number 3: investors are very random. All investors, including us, are<br/>by ordinary standards incompetent. We constantly have to make decisions about<br/>things we don't understand, and more often than not we're wrong.  <br/>  <br/>And yet a lot is at stake. The amounts invested by different types of<br/>investors vary from five thousand dollars to fifty million, but the amount<br/>usually seems large for whatever type of investor it is. Investment decisions<br/>are big decisions.  <br/>  <br/>That combination—making big decisions about things they don't understand—tends<br/>to make investors very skittish. VCs are notorious for leading founders on.<br/>Some of the more unscrupulous do it deliberately. But even the most well-<br/>intentioned investors can behave in a way that would seem crazy in everyday<br/>life. One day they're full of enthusiasm and seem ready to write you a check<br/>on the spot; the next they won't return your phone calls. They're not playing<br/>games with you. They just can't make up their minds. [1]  <br/>  <br/>If that weren't bad enough, these wildly fluctuating nodes are all linked<br/>together. Startup investors all know one another, and (though they hate to<br/>admit it) the biggest factor in their opinion of you is the opinion of other<br/>investors. [2] Talk about a recipe for an unstable system. You get the<br/>opposite of the damping that the fear/greed balance usually produces in<br/>markets. No one is interested in a startup that's a "bargain" because everyone<br/>else hates it.  <br/>  <br/>So the inefficient market you get because there are so few players is<br/>exacerbated by the fact that they act less than independently. The result is a<br/>system like some kind of primitive, multi-celled sea creature, where you<br/>irritate one extremity and the whole thing contracts violently.  <br/>  <br/>Y Combinator is working to fix this. We're trying to increase the number of<br/>investors just as we're increasing the number of startups. We hope that as the<br/>number of both increases we'll get something more like an efficient market. As<br/>t approaches infinity, Demo Day approaches an auction.  <br/>  <br/>Unfortunately, t is still very far from infinity. What does a startup do now,<br/>in the imperfect world we currently inhabit? The most important thing is not<br/>to let fundraising get you down. Startups live or die on morale. If you let<br/>the difficulty of raising money destroy your morale, it will become a self-<br/>fulfilling prophecy.  <br/>  <br/>**Bootstrapping (= Consulting)**  <br/>  <br/>Some would-be founders may by now be thinking, why deal with investors at all?<br/>If raising money is so painful, why do it?  <br/>  <br/>One answer to that is obvious: because you need money to live on. It's a fine<br/>idea in principle to finance your startup with its own revenues, but you can't<br/>create instant customers. Whatever you make, you have to sell a certain amount<br/>to break even. It will take time to grow your sales to that point, and it's<br/>hard to predict, till you try, how long it will take.  <br/>  <br/>We could not have bootstrapped Viaweb, for example. We charged quite a lot for<br/>our software—about $140 per user per month—but it was at least a year before<br/>our revenues would have covered even our paltry costs. We didn't have enough<br/>saved to live on for a year.  <br/>  <br/>If you factor out the "bootstrapped" companies that were actually funded by<br/>their founders through savings or a day job, the remainder either (a) got<br/>really lucky, which is hard to do on demand, or (b) began life as consulting<br/>companies and gradually transformed themselves into product companies.  <br/>  <br/>Consulting is the only option you can count on. But consulting is far from<br/>free money. It's not as painful as raising money from investors, perhaps, but<br/>the pain is spread over a longer period. Years, probably. And for many types<br/>of startup, that delay could be fatal. If you're working on something so<br/>unusual that no one else is likely to think of it, you can take your time.<br/>Joshua Schachter gradually built Delicious on the side while working on Wall<br/>Street. He got away with it because no one else realized it was a good idea.<br/>But if you were building something as obviously necessary as online store<br/>software at about the same time as Viaweb, and you were working on it on the<br/>side while spending most of your time on client work, you were not in a good<br/>position.  <br/>  <br/>Bootstrapping sounds great in principle, but this apparently verdant territory<br/>is one from which few startups emerge alive. The mere fact that bootstrapped<br/>startups tend to be famous on that account should set off alarm bells. If it<br/>worked so well, it would be the norm. [3]  <br/>  <br/>Bootstrapping may get easier, because starting a company is getting cheaper.<br/>But I don't think we'll ever reach the point where most startups can do<br/>without outside funding. Technology tends to get dramatically cheaper, but<br/>living expenses don't.  <br/>  <br/>The upshot is, you can choose your pain: either the short, sharp pain of<br/>raising money, or the chronic ache of consulting. For a given total amount of<br/>pain, raising money is the better choice, because new technology is usually<br/>more valuable now than later.  <br/>  <br/>But although for most startups raising money will be the lesser evil, it's<br/>still a pretty big evil—so big that it can easily kill you. Not merely in the<br/>obvious sense that if you fail to raise money you might have to shut the<br/>company down, but because the _process_ of raising money itself can kill you.  <br/>  <br/>To survive it you need a set of techniques mostly orthogonal to the ones used<br/>in convincing investors, just as mountain climbers need to know survival<br/>techniques that are mostly orthogonal to those used in physically getting up<br/>and down mountains.  <br/>  <br/>**1\. Have low expectations.**  <br/>  <br/>The reason raising money destroys so many startups' morale is not simply that<br/>it's hard, but that it's so much harder than they expected. What kills you is<br/>the disappointment. And the lower your expectations, the harder it is to be<br/>disappointed.  <br/>  <br/>Startup founders tend to be optimistic. This can work well in technology, at<br/>least some of the time, but it's the wrong way to approach raising money.<br/>Better to assume investors will always let you down. Acquirers too, while<br/>we're at it. At YC one of our secondary mantras is "Deals fall through." No<br/>matter what deal you have going on, assume it will fall through. The<br/>predictive power of this simple rule is amazing.  <br/>  <br/>There will be a tendency, as a deal progresses, to start to believe it will<br/>happen, and then to depend on it happening. You must resist this. Tie yourself<br/>to the mast. This is what kills you. Deals do not have a trajectory like most<br/>other human interactions, where shared plans solidify linearly over time.<br/>Deals often fall through at the last moment. Often the other party doesn't<br/>really think about what they want till the last moment. So you can't use your<br/>everyday intuitions about shared plans as a guide. When it comes to deals, you<br/>have to consciously turn them off and become pathologically cynical.  <br/>  <br/>This is harder to do than it sounds. It's very flattering when eminent<br/>investors seem interested in funding you. It's easy to start to believe that<br/>raising money will be quick and straightforward. But it hardly ever is.  <br/>  <br/>**2\. Keep working on your startup.**  <br/>  <br/>It sounds obvious to say that you should keep working on your startup while<br/>raising money. Actually this is hard to do. Most startups don't manage to.  <br/>  <br/>Raising money has a mysterious capacity to suck up all your attention. Even if<br/>you only have one meeting a day with investors, somehow that one meeting will<br/>burn up your whole day. It costs not just the time of the actual meeting, but<br/>the time getting there and back, and the time preparing for it beforehand and<br/>thinking about it afterward.  <br/>  <br/>The best way to survive the distraction of meeting with investors is probably<br/>to partition the company: to pick one founder to deal with investors while the<br/>others keep the company going. This works better when a startup has 3 founders<br/>than 2, and better when the leader of the company is not also the lead<br/>developer. In the best case, the company keeps moving forward at about half<br/>speed.  <br/>  <br/>That's the best case, though. More often than not the company comes to a<br/>standstill while raising money. And that is dangerous for so many reasons.<br/>Raising money always takes longer than you expect. What seems like it's going<br/>to be a 2 week interruption turns into a 4 month interruption. That can be<br/>very demoralizing. And worse still, it can make you less attractive to<br/>investors. They want to invest in companies that are dynamic. A company that<br/>hasn't done anything new in 4 months doesn't seem dynamic, so they start to<br/>lose interest. Investors rarely grasp this, but much of what they're<br/>responding to when they lose interest in a startup is the damage done by their<br/>own indecision.  <br/>  <br/>The solution: put the startup first. Fit meetings with investors into the<br/>spare moments in your development schedule, rather than doing development in<br/>the spare moments between meetings with investors. If you keep the company<br/>moving forward—releasing new features, increasing traffic, doing deals,<br/>getting written about—those investor meetings are more likely to be<br/>productive. Not just because your startup will seem more alive, but also<br/>because it will be better for your own morale, which is one of the main ways<br/>investors judge you.  <br/>  <br/>**3\. Be conservative.**  <br/>  <br/>As conditions get worse, the optimal strategy becomes more conservative. When<br/>things go well you can take risks; when things are bad you want to play it<br/>safe.  <br/>  <br/>I advise approaching fundraising as if it were always going badly. The reason<br/>is that between your ability to delude yourself and the wildly unstable nature<br/>of the system you're dealing with, things probably either already are or could<br/>easily become much worse than they seem.  <br/>  <br/>What I tell most startups we fund is that if someone reputable offers you<br/>funding on reasonable terms, take it. There have been startups that ignored<br/>this advice and got away with it—startups that ignored a good offer in the<br/>hope of getting a better one, and actually did. But in the same position I'd<br/>give the same advice again. Who knows how many bullets were in the gun they<br/>were playing Russian roulette with?  <br/>  <br/>Corollary: if an investor seems interested, don't just let them sit. You can't<br/>assume someone interested in investing will stay interested. In fact, you<br/>can't even tell ( _they_ can't even tell) if they're really interested till<br/>you try to convert that interest into money. So if you have hot prospect,<br/>either close them now or write them off. And unless you already have enough<br/>funding, that reduces to: close them now.  <br/>  <br/>Startups don't win by getting great funding rounds, but by making great<br/>products. So finish raising money and get back to work.  <br/>  <br/>**4\. Be flexible.**  <br/>  <br/>There are two questions VCs ask that you shouldn't answer: "Who else are you<br/>talking to?" and "How much are you trying to raise?"  <br/>  <br/>VCs don't expect you to answer the first question. They ask it just in case.<br/>[4] They do seem to expect an answer to the second. But I don't think you<br/>should just tell them a number. Not as a way to play games with them, but<br/>because you shouldn't _have_ a fixed amount you need to raise.  <br/>  <br/>The custom of a startup needing a fixed amount of funding is an obsolete one<br/>left over from the days when startups were more expensive. A company that<br/>needed to build a factory or hire 50 people obviously needed to raise a<br/>certain minimum amount. But few technology startups are in that position<br/>today.  <br/>  <br/>We advise startups to tell investors there are several different routes they<br/>could take depending on how much they raised. As little as $50k could pay for<br/>food and rent for the founders for a year. A couple hundred thousand would let<br/>them get office space and hire some smart people they know from school. A<br/>couple million would let them really blow this thing out. The message (and not<br/>just the message, but the fact) should be: we're going to succeed no matter<br/>what. Raising more money just lets us do it faster.  <br/>  <br/>If you're raising an angel round, the size of the round can even change on the<br/>fly. In fact, it's just as well to make the round small initially, then expand<br/>as needed, rather than trying to raise a large round and risk losing the<br/>investors you already have if you can't raise the full amount. You may even<br/>want to do a "rolling close," where the round has no predetermined size, but<br/>instead you sell stock to investors one at a time as they say yes. That helps<br/>break deadlocks, because you can start as soon as the first one is ready to<br/>buy. [5]  <br/>  <br/>**5\. Be independent.**  <br/>  <br/>A startup with a couple founders in their early twenties can have expenses so<br/>low that they could be profitable on as little as $2000 per month. That's<br/>negligible as corporate revenues go, but the effect on your morale and your<br/>bargaining position is anything but. At YC we use the phrase "ramen<br/>profitable" to describe the situation where you're making just enough to pay<br/>your living expenses. Once you cross into ramen profitable, everything<br/>changes. You may still need investment to make it big, but you don't need it<br/>this month.  <br/>  <br/>You can't plan when you start a startup how long it will take to become<br/>profitable. But if you find yourself in a position where a little more effort<br/>expended on sales would carry you over the threshold of ramen profitable, do<br/>it.  <br/>  <br/>Investors like it when you're ramen profitable. It shows you've thought about<br/>making money, instead of just working on amusing technical problems; it shows<br/>you have the discipline to keep your expenses low; but above all, it means you<br/>don't need them.  <br/>  <br/>There is nothing investors like more than a startup that seems like it's going<br/>to succeed even without them. Investors like it when they can help a startup,<br/>but they don't like startups that would die without that help.  <br/>  <br/>At YC we spend a lot of time trying to predict how the startups we've funded<br/>will do, because we're trying to learn how to pick winners. We've now watched<br/>the trajectories of so many startups that we're getting better at predicting<br/>them. And when we're talking about startups we think are likely to succeed,<br/>what we find ourselves saying is things like "Oh, those guys can take care of<br/>themselves. They'll be fine." Not "those guys are really smart" or "those guys<br/>are working on a great idea." [6] When we predict good outcomes for startups,<br/>the qualities that come up in the supporting arguments are toughness,<br/>adaptability, determination. Which means to the extent we're correct, those<br/>are the qualities you need to win.  <br/>  <br/>Investors know this, at least unconsciously. The reason they like it when you<br/>don't need them is not simply that they like what they can't have, but because<br/>that quality is what makes founders succeed.  <br/>  <br/>Sam Altman has it. You could parachute him into an island full of cannibals<br/>and come back in 5 years and he'd be the king. If you're Sam Altman, you don't<br/>have to be profitable to convey to investors that you'll succeed with or<br/>without them. (He wasn't, and he did.) Not everyone has Sam's deal-making<br/>ability. I myself don't. But if you don't, you can let the numbers speak for<br/>you.  <br/>  <br/>**6\. Don't take rejection personally.**  <br/>  <br/>Getting rejected by investors can make you start to doubt yourself. After all,<br/>they're more experienced than you. If they think your startup is lame, aren't<br/>they probably right?  <br/>  <br/>Maybe, maybe not. The way to handle rejection is with precision. You shouldn't<br/>simply ignore rejection. It might mean something. But you shouldn't<br/>automatically get demoralized either.  <br/>  <br/>To understand what rejection means, you have to understand first of all how<br/>common it is. Statistically, the average VC is a rejection machine. David<br/>Hornik, a partner at August, told me:<br/><br/>> The numbers for me ended up being something like 500 to 800 plans received<br/>> and read, somewhere between 50 and 100 initial 1 hour meetings held, about<br/>> 20 companies that I got interested in, about 5 that I got serious about and<br/>> did a bunch of work, 1 to 2 deals done in a year. So the odds are against<br/>> you. You may be a great entrepreneur, working on interesting stuff, etc. but<br/>> it is still incredibly unlikely that you get funded.<br/><br/>This is less true with angels, but VCs reject practically everyone. The<br/>structure of their business means a partner does at most 2 new investments a<br/>year, no matter how many good startups approach him.  <br/>  <br/>In addition to the odds being terrible, the average investor is, as I<br/>mentioned, a pretty bad judge of startups. It's harder to judge startups than<br/>most other things, because great startup ideas tend to seem wrong. A good<br/>startup idea has to be not just good but novel. And to be both good and novel,<br/>an idea probably has to seem bad to most people, or someone would already be<br/>doing it and it wouldn't be novel.  <br/>  <br/>That makes judging startups harder than most other things one judges. You have<br/>to be an intellectual contrarian to be a good startup investor. That's a<br/>problem for VCs, most of whom are not particularly imaginative. VCs are mostly<br/>money guys, not people who make things. [7] Angels are better at appreciating<br/>novel ideas, because most were founders themselves.  <br/>  <br/>So when you get a rejection, use the data that's in it, and not what's not. If<br/>an investor gives you specific reasons for not investing, look at your startup<br/>and ask if they're right. If they're real problems, fix them. But don't just<br/>take their word for it. You're supposed to be the domain expert; you have to<br/>decide.  <br/>  <br/>Though a rejection doesn't necessarily tell you anything about your startup,<br/>it does suggest your pitch could be improved. Figure out what's not working<br/>and change it. Don't just think "investors are stupid." Often they are, but<br/>figure out precisely where you lose them.  <br/>  <br/>Don't let rejections pile up as a depressing, undifferentiated heap. Sort them<br/>and analyze them, and then instead of thinking "no one likes us," you'll know<br/>precisely how big a problem you have, and what to do about it.  <br/>  <br/>**7\. Be able to downshift into consulting (if appropriate).**  <br/>  <br/>Consulting, as I mentioned, is a dangerous way to finance a startup. But it's<br/>better than dying. It's a bit like anaerobic respiration: not the optimum<br/>solution for the long term, but it can save you from an immediate threat. If<br/>you're having trouble raising money from investors at all, it could save you<br/>to be able to shift toward consulting.  <br/>  <br/>This works better for some startups than others. It wouldn't have been a<br/>natural fit for, say, Google, but if your company was making software for<br/>building web sites, you could degrade fairly gracefully into consulting by<br/>building sites for clients with it.  <br/>  <br/>So long as you were careful not to get sucked permanently into consulting,<br/>this could even have advantages. You'd understand your users well if you were<br/>using the software for them. Plus as a consulting company you might be able to<br/>get big-name users using your software that you wouldn't have gotten as a<br/>product company.  <br/>  <br/>At Viaweb we were forced to operate like a consulting company initially,<br/>because we were so desperate for users that we'd offer to build merchants'<br/>sites for them if they'd sign up. But we never charged for such work, because<br/>we didn't want them to start treating us like actual consultants, and calling<br/>us every time they wanted something changed on their site. We knew we had to<br/>stay a product company, because only that scales.  <br/>  <br/>**8\. Avoid inexperienced investors.**  <br/>  <br/>Though novice investors seem unthreatening they can be the most dangerous<br/>sort, because they're so nervous. Especially in proportion to the amount they<br/>invest. Raising $20,000 from a first-time angel investor can be as much work<br/>as raising $2 million from a VC fund.  <br/>  <br/>Their lawyers are generally inexperienced too. But while the investors can<br/>admit they don't know what they're doing, their lawyers can't. One YC startup<br/>negotiated terms for a tiny round with an angel, only to receive a 70-page<br/>agreement from his lawyer. And since the lawyer could never admit, in front of<br/>his client, that he'd screwed up, he instead had to insist on retaining all<br/>the draconian terms in it, so the deal fell through.  <br/>  <br/>Of course, someone has to take money from novice investors, or there would<br/>never be any experienced ones. But if you do, either (a) drive the process<br/>yourself, including supplying the paperwork, or (b) use them only to fill up a<br/>larger round led by someone else.  <br/>  <br/>**9\. Know where you stand.**  <br/>  <br/>The most dangerous thing about investors is their indecisiveness. The worst<br/>case scenario is the long no, the no that comes after months of meetings.<br/>Rejections from investors are like design flaws: inevitable, but much less<br/>costly if you discover them early.  <br/>  <br/>So while you're talking to investors, constantly look for signs of where you<br/>stand. How likely are they to offer you a term sheet? What do they have to be<br/>convinced of first? You shouldn't necessarily always be asking these questions<br/>outright—that could get annoying—but you should always be collecting data<br/>about them.  <br/>  <br/>Investors tend to resist committing except to the extent you push them to.<br/>It's in their interest to collect the maximum amount of information while<br/>making the minimum number of decisions. The best way to force them to act is,<br/>of course, competing investors. But you can also apply some force by focusing<br/>the discussion: by asking what specific questions they need answered to make<br/>up their minds, and then answering them. If you get through several obstacles<br/>and they keep raising new ones, assume that ultimately they're going to flake.  <br/>  <br/>You have to be disciplined when collecting data about investors' intentions.<br/>Otherwise their desire to lead you on will combine with your own desire to be<br/>led on to produce completely inaccurate impressions.  <br/>  <br/>Use the data to weight your strategy. You'll probably be talking to several<br/>investors. Focus on the ones that are most likely to say yes. The value of a<br/>potential investor is a combination of how good it would be if they said yes,<br/>and how likely they are to say it. Put the most weight on the second factor.<br/>Partly because the most important quality in an investor is simply investing.<br/>But also because, as I mentioned, the biggest factor in investors' opinion of<br/>you is other investors' opinion of you. If you're talking to several investors<br/>and you manage to get one over the threshold of saying yes, it will make the<br/>others much more interested. So you're not sacrificing the lukewarm investors<br/>if you focus on the hot ones; convincing the hot investors is the best way to<br/>convince the lukewarm ones.  <br/>  <br/>**Future**  <br/>  <br/>I'm hopeful things won't always be so awkward. I hope that as startups get<br/>cheaper and the number of investors increases, raising money will become, if<br/>not easy, at least straightforward.  <br/>  <br/>In the meantime, the brokenness of the funding process offers a big<br/>opportunity. Most investors have no idea how dangerous they are. They'd be<br/>surprised to hear that raising money from them is something that has to be<br/>treated as a threat to a company's survival. They just think they need a<br/>little more information to make up their minds. They don't get that there are<br/>10 other investors who also want a little more information, and that the<br/>process of talking to them all can bring a startup to a standstill for months.  <br/>  <br/>Because investors don't understand the cost of dealing with them, they don't<br/>realize how much room there is for a potential competitor to undercut them. I<br/>know from my own experience how much faster investors could decide, because<br/>we've brought our own time down to 20 minutes (5 minutes of reading an<br/>application plus a 10 minute interview plus 5 minutes of discussion). If you<br/>were investing more money you'd want to take longer, of course. But if we can<br/>decide in 20 minutes, should it take anyone longer than a couple days?  <br/>  <br/>Opportunities like this don't sit unexploited forever, even in an industry as<br/>conservative as venture capital. So either existing investors will start to<br/>make up their minds faster, or new investors will emerge who do.  <br/>  <br/>In the meantime founders have to treat raising money as a dangerous process.<br/>Fortunately, I can fix the biggest danger right here. The biggest danger is<br/>surprise. It's that startups will underestimate the difficulty of raising<br/>money—that they'll cruise through all the initial steps, but when they turn to<br/>raising money they'll find it surprisingly hard, get demoralized, and give up.<br/>So I'm telling you in advance: raising money is hard.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] When investors can't make up their minds, they sometimes describe it as if<br/>it were a property of the startup. "You're too early for us," they sometimes<br/>say. But which of them, if they were taken back in a time machine to the hour<br/>Google was founded, wouldn't offer to invest at any valuation the founders<br/>chose? An hour old is not too early if it's the right startup. What "you're<br/>too early" really means is "we can't figure out yet whether you'll succeed."  <br/>  <br/>[2] Investors influence one another both directly and indirectly. They<br/>influence one another directly through the "buzz" that surrounds a hot<br/>startup. But they also influence one another indirectly _through the<br/>founders._ When a lot of investors are interested in you, it increases your<br/>confidence in a way that makes you much more attractive to investors.  <br/>  <br/>No VC will admit they're influenced by buzz. Some genuinely aren't. But there<br/>are few who can say they're not influenced by confidence.  <br/>  <br/>[3] One VC who read this essay wrote:  <br/>  <br/>"We try to avoid companies that got bootstrapped with consulting. It creates<br/>very bad behaviors/instincts that are hard to erase from a company's culture."  <br/>  <br/>[4] The optimal way to answer the first question is to say that it would be<br/>improper to name names, while simultaneously implying that you're talking to a<br/>bunch of other VCs who are all about to give you term sheets. If you're the<br/>sort of person who understands how to do that, go ahead. If not, don't even<br/>try. Nothing annoys VCs more than clumsy efforts to manipulate them.  <br/>  <br/>[5] The disadvantage of expanding a round on the fly is that the valuation is<br/>fixed at the start, so if you get a sudden rush of interest, you may have to<br/>decide between turning some investors away and selling more of the company<br/>than you meant to. That's a good problem to have, however.  <br/>  <br/>[6] I wouldn't say that intelligence doesn't matter in startups. We're only<br/>comparing YC startups, who've already made it over a certain threshold.  <br/>  <br/>[7] But not all are. Though most VCs are suits at heart, the most successful<br/>ones tend not to be. Oddly enough, the best VCs tend to be the least VC-like.  <br/>  <br/>**Thanks** to Trevor Blackwell, David Hornik, Jessica Livingston, Robert<br/>Morris, and Fred Wilson for reading drafts of this.  <br/>  <br/><br/>Russian Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>August 2003  <br/>  <br/>We may be able to improve the accuracy of Bayesian spam filters by having them<br/>follow links to see what's waiting at the other end. Richard Jowsey of<br/>death2spam now does this in borderline cases, and reports that it works well.  <br/>  <br/>Why only do it in borderline cases? And why only do it once?  <br/>  <br/>As I mentioned in Will Filters Kill Spam?, following all the urls in a spam<br/>would have an amusing side-effect. If popular email clients did this in order<br/>to filter spam, the spammer's servers would take a serious pounding. The more<br/>I think about this, the better an idea it seems. This isn't just amusing; it<br/>would be hard to imagine a more perfectly targeted counterattack on spammers.  <br/>  <br/>So I'd like to suggest an additional feature to those working on spam filters:<br/>a "punish" mode which, if turned on, would spider every url in a suspected<br/>spam n times, where n could be set by the user. [1]  <br/>  <br/>As many people have noted, one of the problems with the current email system<br/>is that it's too passive. It does whatever you tell it. So far all the<br/>suggestions for fixing the problem seem to involve new protocols. This one<br/>wouldn't.  <br/>  <br/>If widely used, auto-retrieving spam filters would make the email system<br/>_rebound._ The huge volume of the spam, which has so far worked in the<br/>spammer's favor, would now work against him, like a branch snapping back in<br/>his face. Auto-retrieving spam filters would drive the spammer's costs up, and<br/>his sales down: his bandwidth usage would go through the roof, and his servers<br/>would grind to a halt under the load, which would make them unavailable to the<br/>people who would have responded to the spam.  <br/>  <br/>Pump out a million emails an hour, get a million hits an hour on your servers.  <br/>  <br/>We would want to ensure that this is only done to suspected spams. As a rule,<br/>any url sent to millions of people is likely to be a spam url, so submitting<br/>every http request in every email would work fine nearly all the time. But<br/>there are a few cases where this isn't true: the urls at the bottom of mails<br/>sent from free email services like Yahoo Mail and Hotmail, for example.  <br/>  <br/>To protect such sites, and to prevent abuse, auto-retrieval should be combined<br/>with blacklists of spamvertised sites. Only sites on a blacklist would get<br/>crawled, and sites would be blacklisted only after being inspected by humans.<br/>The lifetime of a spam must be several hours at least, so it should be easy to<br/>update such a list in time to interfere with a spam promoting a new site. [2]  <br/>  <br/>High-volume auto-retrieval would only be practical for users on high-bandwidth<br/>connections, but there are enough of those to cause spammers serious trouble.<br/>Indeed, this solution neatly mirrors the problem. The problem with spam is<br/>that in order to reach a few gullible people the spammer sends mail to<br/>everyone. The non-gullible recipients are merely collateral damage. But the<br/>non-gullible majority won't stop getting spam until they can stop (or threaten<br/>to stop) the gullible from responding to it. Auto-retrieving spam filters<br/>offer them a way to do this.  <br/>  <br/>Would that kill spam? Not quite. The biggest spammers could probably protect<br/>their servers against auto-retrieving filters. However, the easiest and<br/>cheapest way for them to do it would be to include working unsubscribe links<br/>in their mails. And this would be a necessity for smaller fry, and for<br/>"legitimate" sites that hired spammers to promote them. So if auto-retrieving<br/>filters became widespread, they'd become auto-unsubscribing filters.  <br/>  <br/>In this scenario, spam would, like OS crashes, viruses, and popups, become one<br/>of those plagues that only afflict people who don't bother to use the right<br/>software.  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] Auto-retrieving filters will have to follow redirects, and should in some<br/>cases (e.g. a page that just says "click here") follow more than one level of<br/>links. Make sure too that the http requests are indistinguishable from those<br/>of popular Web browsers, including the order and referrer.  <br/>  <br/>If the response doesn't come back within x amount of time, default to some<br/>fairly high spam probability.  <br/>  <br/>Instead of making n constant, it might be a good idea to make it a function of<br/>the number of spams that have been seen mentioning the site. This would add a<br/>further level of protection against abuse and accidents.  <br/>  <br/>[2] The original version of this article used the term "whitelist" instead of<br/>"blacklist". Though they were to work like blacklists, I preferred to call<br/>them whitelists because it might make them less vulnerable to legal attack.<br/>This just seems to have confused readers, though.  <br/>  <br/>There should probably be multiple blacklists. A single point of failure would<br/>be vulnerable both to attack and abuse.  <br/>  <br/>  <br/>  <br/>**Thanks** to Brian Burton, Bill Yerazunis, Dan Giffin, Eric Raymond, and<br/>Richard Jowsey for reading drafts of this.  <br/>  <br/><br/>FFB FAQ  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>A Perl FFB  <br/>  <br/><br/>Lycos DDoS@Home  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>April 2006, rev August 2009  <br/>  <br/>Plato quotes Socrates as saying "the unexamined life is not worth living."<br/>Part of what he meant was that the proper role of humans is to think, just as<br/>the proper role of anteaters is to poke their noses into anthills.  <br/>  <br/>A lot of ancient philosophy had the quality — and I don't mean this in an<br/>insulting way — of the kind of conversations freshmen have late at night in<br/>common rooms:<br/><br/>> What is our purpose? Well, we humans are as conspicuously different from<br/>> other animals as the anteater. In our case the distinguishing feature is the<br/>> ability to reason. So obviously that is what we should be doing, and a human<br/>> who doesn't is doing a bad job of being human — is no better than an animal.<br/><br/>Now we'd give a different answer. At least, someone Socrates's age would. We'd<br/>ask why we even suppose we have a "purpose" in life. We may be better adapted<br/>for some things than others; we may be happier doing things we're adapted for;<br/>but why assume purpose?  <br/>  <br/>The history of ideas is a history of gradually discarding the assumption that<br/>it's all about us. No, it turns out, the earth is not the center of the<br/>universe — not even the center of the solar system. No, it turns out, humans<br/>are not created by God in his own image; they're just one species among many,<br/>descended not merely from apes, but from microorganisms. Even the concept of<br/>"me" turns out to be fuzzy around the edges if you examine it closely.  <br/>  <br/>The idea that we're the center of things is difficult to discard. So difficult<br/>that there's probably room to discard more. Richard Dawkins made another step<br/>in that direction only in the last several decades, with the idea of the<br/>selfish gene. No, it turns out, we're not even the protagonists: we're just<br/>the latest model vehicle our genes have constructed to travel around in. And<br/>having kids is our genes heading for the lifeboats. Reading that book snapped<br/>my brain out of its previous way of thinking the way Darwin's must have when<br/>it first appeared.  <br/>  <br/>(Few people can experience now what Darwin's contemporaries did when _The<br/>Origin of Species_ was first published, because everyone now is raised either<br/>to take evolution for granted, or to regard it as a heresy. No one encounters<br/>the idea of natural selection for the first time as an adult.)  <br/>  <br/>So if you want to discover things that have been overlooked till now, one<br/>really good place to look is in our blind spot: in our natural, naive belief<br/>that it's all about us. And expect to encounter ferocious opposition if you<br/>do.  <br/>  <br/>Conversely, if you have to choose between two theories, prefer the one that<br/>doesn't center on you.  <br/>  <br/>This principle isn't only for big ideas. It works in everyday life, too. For<br/>example, suppose you're saving a piece of cake in the fridge, and you come<br/>home one day to find your housemate has eaten it. Two possible theories:<br/><br/>> a) Your housemate did it deliberately to upset you. He _knew_ you were<br/>> saving that piece of cake.  <br/>>  <br/>> b) Your housemate was hungry.<br/><br/>I say pick b. No one knows who said "never attribute to malice what can be<br/>explained by incompetence," but it is a powerful idea. Its more general<br/>version is our answer to the Greeks:<br/><br/>> Don't see purpose where there isn't.<br/><br/>Or better still, the positive version:<br/><br/>> See randomness.<br/><br/>  <br/>  <br/><br/>Korean Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>November 2009  <br/>  <br/>I don't think Apple realizes how badly the App Store approval process is<br/>broken. Or rather, I don't think they realize how much it matters that it's<br/>broken.  <br/>  <br/>The way Apple runs the App Store has harmed their reputation with programmers<br/>more than anything else they've ever done. Their reputation with programmers<br/>used to be great. It used to be the most common complaint you heard about<br/>Apple was that their fans admired them too uncritically. The App Store has<br/>changed that. Now a lot of programmers have started to see Apple as evil.  <br/>  <br/>How much of the goodwill Apple once had with programmers have they lost over<br/>the App Store? A third? Half? And that's just so far. The App Store is an<br/>ongoing karma leak.  <br/>  <br/>* * *  <br/>  <br/>How did Apple get into this mess? Their fundamental problem is that they don't<br/>understand software.  <br/>  <br/>They treat iPhone apps the way they treat the music they sell through iTunes.<br/>Apple is the channel; they own the user; if you want to reach users, you do it<br/>on their terms. The record labels agreed, reluctantly. But this model doesn't<br/>work for software. It doesn't work for an intermediary to own the user. The<br/>software business learned that in the early 1980s, when companies like<br/>VisiCorp showed that although the words "software" and "publisher" fit<br/>together, the underlying concepts don't. Software isn't like music or books.<br/>It's too complicated for a third party to act as an intermediary between<br/>developer and user. And yet that's what Apple is trying to be with the App<br/>Store: a software publisher. And a particularly overreaching one at that, with<br/>fussy tastes and a rigidly enforced house style.  <br/>  <br/>If software publishing didn't work in 1980, it works even less now that<br/>software development has evolved from a small number of big releases to a<br/>constant stream of small ones. But Apple doesn't understand that either. Their<br/>model of product development derives from hardware. They work on something<br/>till they think it's finished, then they release it. You have to do that with<br/>hardware, but because software is so easy to change, its design can benefit<br/>from evolution. The standard way to develop applications now is to launch fast<br/>and iterate. Which means it's a disaster to have long, random delays each time<br/>you release a new version.  <br/>  <br/>Apparently Apple's attitude is that developers should be more careful when<br/>they submit a new version to the App Store. They would say that. But powerful<br/>as they are, they're not powerful enough to turn back the evolution of<br/>technology. Programmers don't use launch-fast-and-iterate out of laziness.<br/>They use it because it yields the best results. By obstructing that process,<br/>Apple is making them do bad work, and programmers hate that as much as Apple<br/>would.  <br/>  <br/>How would Apple like it if when they discovered a serious bug in OS X, instead<br/>of releasing a software update immediately, they had to submit their code to<br/>an intermediary who sat on it for a month and then rejected it because it<br/>contained an icon they didn't like?  <br/>  <br/>By breaking software development, Apple gets the opposite of what they<br/>intended: the version of an app currently available in the App Store tends to<br/>be an old and buggy one. One developer told me:<br/><br/>> As a result of their process, the App Store is full of half-baked<br/>> applications. I make a new version almost every day that I release to beta<br/>> users. The version on the App Store feels old and crappy. I'm sure that a<br/>> lot of developers feel this way: One emotion is "I'm not really proud about<br/>> what's in the App Store", and it's combined with the emotion "Really, it's<br/>> Apple's fault."<br/><br/>Another wrote:<br/><br/>> I believe that they think their approval process helps users by ensuring<br/>> quality. In reality, bugs like ours get through all the time and then it can<br/>> take 4-8 weeks to get that bug fix approved, leaving users to think that<br/>> iPhone apps sometimes just don't work. Worse for Apple, these apps work just<br/>> fine on other platforms that have immediate approval processes.<br/><br/>Actually I suppose Apple has a third misconception: that all the complaints<br/>about App Store approvals are not a serious problem. They must hear developers<br/>complaining. But partners and suppliers are always complaining. It would be a<br/>bad sign if they weren't; it would mean you were being too easy on them.<br/>Meanwhile the iPhone is selling better than ever. So why do they need to fix<br/>anything?  <br/>  <br/>They get away with maltreating developers, in the short term, because they<br/>make such great hardware. I just bought a new 27" iMac a couple days ago. It's<br/>fabulous. The screen's too shiny, and the disk is surprisingly loud, but it's<br/>so beautiful that you can't make yourself care.  <br/>  <br/>So I bought it, but I bought it, for the first time, with misgivings. I felt<br/>the way I'd feel buying something made in a country with a bad human rights<br/>record. That was new. In the past when I bought things from Apple it was an<br/>unalloyed pleasure. Oh boy! They make such great stuff. This time it felt like<br/>a Faustian bargain. They make such great stuff, but they're such assholes. Do<br/>I really want to support this company?  <br/>  <br/>* * *  <br/>  <br/>Should Apple care what people like me think? What difference does it make if<br/>they alienate a small minority of their users?  <br/>  <br/>There are a couple reasons they should care. One is that these users are the<br/>people they want as employees. If your company seems evil, the best<br/>programmers won't work for you. That hurt Microsoft a lot starting in the 90s.<br/>Programmers started to feel sheepish about working there. It seemed like<br/>selling out. When people from Microsoft were talking to other programmers and<br/>they mentioned where they worked, there were a lot of self-deprecating jokes<br/>about having gone over to the dark side. But the real problem for Microsoft<br/>wasn't the embarrassment of the people they hired. It was the people they<br/>never got. And you know who got them? Google and Apple. If Microsoft was the<br/>Empire, they were the Rebel Alliance. And it's largely because they got more<br/>of the best people that Google and Apple are doing so much better than<br/>Microsoft today.  <br/>  <br/>Why are programmers so fussy about their employers' morals? Partly because<br/>they can afford to be. The best programmers can work wherever they want. They<br/>don't have to work for a company they have qualms about.  <br/>  <br/>But the other reason programmers are fussy, I think, is that evil begets<br/>stupidity. An organization that wins by exercising power starts to lose the<br/>ability to win by doing better work. And it's not fun for a smart person to<br/>work in a place where the best ideas aren't the ones that win. I think the<br/>reason Google embraced "Don't be evil" so eagerly was not so much to impress<br/>the outside world as to inoculate themselves against arrogance. [1]  <br/>  <br/>That has worked for Google so far. They've become more bureaucratic, but<br/>otherwise they seem to have held true to their original principles. With Apple<br/>that seems less the case. When you look at the famous 1984 ad now, it's easier<br/>to imagine Apple as the dictator on the screen than the woman with the hammer.<br/>[2] In fact, if you read the dictator's speech it sounds uncannily like a<br/>prophecy of the App Store.<br/><br/>> We have triumphed over the unprincipled dissemination of facts.  <br/>>  <br/>> We have created, for the first time in all history, a garden of pure<br/>> ideology, where each worker may bloom secure from the pests of contradictory<br/>> and confusing truths.<br/><br/>The other reason Apple should care what programmers think of them is that when<br/>you sell a platform, developers make or break you. If anyone should know this,<br/>Apple should. VisiCalc made the Apple II.  <br/>  <br/>And programmers build applications for the platforms they use. Most<br/>applications—most startups, probably—grow out of personal projects. Apple<br/>itself did. Apple made microcomputers because that's what Steve Wozniak wanted<br/>for himself. He couldn't have afforded a minicomputer. [3] Microsoft likewise<br/>started out making interpreters for little microcomputers because Bill Gates<br/>and Paul Allen were interested in using them. It's a rare startup that doesn't<br/>build something the founders use.  <br/>  <br/>The main reason there are so many iPhone apps is that so many programmers have<br/>iPhones. They may know, because they read it in an article, that Blackberry<br/>has such and such market share. But in practice it's as if RIM didn't exist.<br/>If they're going to build something, they want to be able to use it<br/>themselves, and that means building an iPhone app.  <br/>  <br/>So programmers continue to develop iPhone apps, even though Apple continues to<br/>maltreat them. They're like someone stuck in an abusive relationship. They're<br/>so attracted to the iPhone that they can't leave. But they're looking for a<br/>way out. One wrote:<br/><br/>> While I did enjoy developing for the iPhone, the control they place on the<br/>> App Store does not give me the drive to develop applications as I would<br/>> like. In fact I don't intend to make any more iPhone applications unless<br/>> absolutely necessary. [4]<br/><br/>Can anything break this cycle? No device I've seen so far could. Palm and RIM<br/>haven't a hope. The only credible contender is Android. But Android is an<br/>orphan; Google doesn't really care about it, not the way Apple cares about the<br/>iPhone. Apple cares about the iPhone the way Google cares about search.  <br/>  <br/>* * *  <br/>  <br/>Is the future of handheld devices one locked down by Apple? It's a worrying<br/>prospect. It would be a bummer to have another grim monoculture like we had in<br/>the 1990s. In 1995, writing software for end users was effectively identical<br/>with writing Windows applications. Our horror at that prospect was the single<br/>biggest thing that drove us to start building web apps.  <br/>  <br/>At least we know now what it would take to break Apple's lock. You'd have to<br/>get iPhones out of programmers' hands. If programmers used some other device<br/>for mobile web access, they'd start to develop apps for that instead.  <br/>  <br/>How could you make a device programmers liked better than the iPhone? It's<br/>unlikely you could make something better designed. Apple leaves no room there.<br/>So this alternative device probably couldn't win on general appeal. It would<br/>have to win by virtue of some appeal it had to programmers specifically.  <br/>  <br/>One way to appeal to programmers is with software. If you could think of an<br/>application programmers had to have, but that would be impossible in the<br/>circumscribed world of the iPhone, you could presumably get them to switch.  <br/>  <br/>That would definitely happen if programmers started to use handhelds as<br/>development machines—if handhelds displaced laptops the way laptops displaced<br/>desktops. You need more control of a development machine than Apple will let<br/>you have over an iPhone.  <br/>  <br/>Could anyone make a device that you'd carry around in your pocket like a<br/>phone, and yet would also work as a development machine? It's hard to imagine<br/>what it would look like. But I've learned never to say never about technology.<br/>A phone-sized device that would work as a development machine is no more<br/>miraculous by present standards than the iPhone itself would have seemed by<br/>the standards of 1995.  <br/>  <br/>My current development machine is a MacBook Air, which I use with an external<br/>monitor and keyboard in my office, and by itself when traveling. If there was<br/>a version half the size I'd prefer it. That still wouldn't be small enough to<br/>carry around everywhere like a phone, but we're within a factor of 4 or so.<br/>Surely that gap is bridgeable. In fact, let's make it an RFS. Wanted: Woman<br/>with hammer.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] When Google adopted "Don't be evil," they were still so small that no one<br/>would have expected them to be, yet.  <br/>  <br/>[2] The dictator in the 1984 ad isn't Microsoft, incidentally; it's IBM. IBM<br/>seemed a lot more frightening in those days, but they were friendlier to<br/>developers than Apple is now.  <br/>  <br/>[3] He couldn't even afford a _monitor_. That's why the Apple I used a TV as a<br/>monitor.  <br/>  <br/>[4] Several people I talked to mentioned how much they liked the iPhone SDK.<br/>The problem is not Apple's products but their policies. Fortunately policies<br/>are software; Apple can change them instantly if they want to. Handy that,<br/>isn't it?  <br/>  <br/> **Thanks** to Sam Altman, Trevor Blackwell, Ross Boucher, James Bracy, Gabor<br/>Cselle, Patrick Collison, Jason Freedman, John Gruber, Joe Hewitt, Jessica<br/>Livingston, Robert Morris, Teng Siong Ong, Nikhil Pandit, Savraj Singh, and<br/>Jared Tame for reading drafts of this.  <br/>  <br/><br/>Russian Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>November 2014  <br/>  <br/>It struck me recently how few of the most successful people I know are mean.<br/>There are exceptions, but remarkably few.  <br/>  <br/>Meanness isn't rare. In fact, one of the things the internet has shown us is<br/>how mean people can be. A few decades ago, only famous people and professional<br/>writers got to publish their opinions. Now everyone can, and we can all see<br/>the long tail of meanness<br/><br/>Portuguese Translation  <br/><br/>Japanese Translation  <br/><br/>Arabic Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>August 2009  <br/>  <br/>Kate Courteau is the architect who designed Y Combinator's office. Recently we<br/>managed to recruit her to help us run YC when she's not busy with<br/>architectural projects. Though she'd heard a lot about YC since the beginning,<br/>the last 9 months have been a total immersion.  <br/>  <br/>I've been around the startup world for so long that it seems normal to me, so<br/>I was curious to hear what had surprised her most about it. This was her list:  <br/>  <br/>  <br/>  <br/> **1\. How many startups fail.** Kate knew in principle that startups were<br/>very risky, but she was surprised to see how constant the threat of failure<br/>was—not just for the minnows, but even for the famous startups whose founders<br/>came to speak at YC dinners.  <br/>  <br/>**2\. How much startups' ideas change.** As usual, by Demo Day about half the<br/>startups were doing something significantly different than they started with.<br/>We encourage that. Starting a startup is like science in that you have to<br/>follow the truth wherever it leads. In the rest of the world, people don't<br/>start things till they're sure what they want to do, and once started they<br/>tend continue on their initial path even if it's mistaken.  <br/>  <br/>**3\. How little money it can take to start a startup.** In Kate's world,<br/>everything is still physical and expensive. You can barely renovate a bathroom<br/>for the cost of starting a startup.  <br/>  <br/>**4\. How scrappy founders are.** That was her actual word. I agree with her,<br/>but till she mentioned this it never occurred to me how little this quality is<br/>appreciated in most of the rest of the world. It wouldn't be a compliment in<br/>most organizations to call someone scrappy.  <br/>  <br/>What does it mean, exactly? It's basically the diminutive form of belligerent.<br/>Someone who's scrappy manages to be both threatening and undignified at the<br/>same time. Which seems to me exactly what one would want to be, in any kind of<br/>work. If you're not threatening, you're probably not doing anything new, and<br/>dignity is merely a sort of plaque.  <br/>  <br/>**5\. How tech-saturated Silicon Valley is.** "It seems like everybody here is<br/>in the industry." That isn't literally true, but there is a qualitative<br/>difference between Silicon Valley and other places. You tend to keep your<br/>voice down, because there's a good chance the person at the next table would<br/>know some of the people you're talking about. I never felt that in Boston. The<br/>good news is, there's also a good chance the person at the next table could<br/>help you in some way.  <br/>  <br/>**6\. That the speakers at YC were so consistent in their advice.** Actually,<br/>I've noticed this too. I always worry the speakers will put us in an<br/>embarrassing position by contradicting what we tell the startups, but it<br/>happens surprisingly rarely.  <br/>  <br/>When I asked her what specific things she remembered speakers always saying,<br/>she mentioned: that the way to succeed was to launch something fast, listen to<br/>users, and then iterate; that startups required resilience because they were<br/>always an emotional rollercoaster; and that most VCs were sheep.  <br/>  <br/>I've been impressed by how consistently the speakers advocate launching fast<br/>and iterating. That was contrarian advice 10 years ago, but it's clearly now<br/>the established practice.  <br/>  <br/>**7\. How casual successful startup founders are.** Most of the famous<br/>founders in Silicon Valley are people you'd overlook on the street. It's not<br/>merely that they don't dress up. They don't project any kind of aura of power<br/>either. "They're not trying to impress anyone."  <br/>  <br/>Interestingly, while Kate said that she could never pick out successful<br/>founders, she could recognize VCs, both by the way they dressed and the way<br/>they carried themselves.  <br/>  <br/>**8\. How important it is for founders to have people to ask for advice.** (I<br/>swear I didn't prompt this one.) Without advice "they'd just be sort of lost."<br/>Fortunately, there are a lot of people to help them. There's a strong<br/>tradition within YC of helping other YC-funded startups. But we didn't invent<br/>that idea: it's just a slightly more concentrated form of existing Valley<br/>culture.  <br/>  <br/>**9\. What a solitary task startups are.** Architects are constantly<br/>interacting face to face with other people, whereas doing a technology<br/>startup, at least, tends to require long stretches of uninterrupted time to<br/>work. "You could do it in a box."  <br/>  <br/>  <br/>  <br/>By inverting this list, we can get a portrait of the "normal" world. It's<br/>populated by people who talk a lot with one another as they work slowly but<br/>harmoniously on conservative, expensive projects whose destinations are<br/>decided in advance, and who carefully adjust their manner to reflect their<br/>position in the hierarchy.  <br/>  <br/>That's also a fairly accurate description of the past. So startup culture may<br/>not merely be different in the way you'd expect any subculture to be, but a<br/>leading indicator.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>October 2012  <br/>  <br/>One advantage of Y Combinator's early, broad focus is that we see trends<br/>before most other people. And one of the most conspicuous trends in the last<br/>batch was the large number of hardware startups. Out of 84 companies, 7 were<br/>making hardware. On the whole they've done better than the companies that<br/>weren't.  <br/>  <br/>They've faced resistance from investors of course. Investors have a deep-<br/>seated bias against hardware. But investors' opinions are a trailing<br/>indicator. The best founders are better at seeing the future than the best<br/>investors, because the best founders are making it.  <br/>  <br/>There is no one single force driving this trend. Hardware does well on<br/>crowdfunding sites. The spread of tablets makes it possible to build new<br/>things controlled by and even incorporating them. Electric motors have<br/>improved. Wireless connectivity of various types can now be taken for granted.<br/>It's getting more straightforward to get things manufactured. Arduinos, 3D<br/>printing, laser cutters, and more accessible CNC milling are making hardware<br/>easier to prototype. Retailers are less of a bottleneck as customers<br/>increasingly buy online.  <br/>  <br/>One question I can answer is why hardware is suddenly cool. It always was<br/>cool. Physical things are great. They just haven't been as great a way to<br/>start a rapidly growing business as software. But that rule may not be<br/>permanent. It's not even that old; it only dates from about 1990. Maybe the<br/>advantage of software will turn out to have been temporary. Hackers love to<br/>build hardware, and customers love to buy it. So if the ease of shipping<br/>hardware even approached the ease of shipping software, we'd see a lot more<br/>hardware startups.  <br/>  <br/>It wouldn't be the first time something was a bad idea till it wasn't. And it<br/>wouldn't be the first time investors learned that lesson from founders.  <br/>  <br/>So if you want to work on hardware, don't be deterred from doing it because<br/>you worry investors will discriminate against you. And in particular, don't be<br/>deterred from applying to Y Combinator with a hardware idea, because we're<br/>especially interested in hardware startups.  <br/>  <br/>We know there's room for the next Steve Jobs. But there's almost certainly<br/>also room for the first <Your Name Here>.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Thanks** to Sam Altman, Trevor Blackwell, David Cann, Sanjay Dastoor, Paul<br/>Gerhardt, Cameron Robertson, Harj Taggar, and Garry Tan for reading drafts of<br/>this.  <br/>  <br/><br/>A Hardware Renaissance while Software Eats the World?  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>December 2008  <br/>  <br/> _(I originally wrote this at the request of a company producing a report<br/>about entrepreneurship. Unfortunately after reading it they decided it was too<br/>controversial to include.)_  <br/>  <br/>VC funding will probably dry up somewhat during the present recession, like it<br/>usually does in bad times. But this time the result may be different. This<br/>time the number of new startups may not decrease. And that could be dangerous<br/>for VCs.  <br/>  <br/>When VC funding dried up after the Internet Bubble, startups dried up too.<br/>There were not a lot of new startups being founded in 2003\. But startups<br/>aren't tied to VC the way they were 10 years ago. It's now possible for VCs<br/>and startups to diverge. And if they do, they may not reconverge once the<br/>economy gets better.  <br/>  <br/>The reason startups no longer depend so much on VCs is one that everyone in<br/>the startup business knows by now: it has gotten much cheaper to start a<br/>startup. There are four main reasons: Moore's law has made hardware cheap;<br/>open source has made software free; the web has made marketing and<br/>distribution free; and more powerful programming languages mean development<br/>teams can be smaller. These changes have pushed the cost of starting a startup<br/>down into the noise. In a lot of startups—probaby most startups funded by Y<br/>Combinator—the biggest expense is simply the founders' living expenses. We've<br/>had startups that were profitable on revenues of $3000 a month.  <br/>  <br/>$3000 is insignificant as revenues go. Why should anyone care about a startup<br/>making $3000 a month? Because, although insignificant as _revenue_ , this<br/>amount of money can change a startup's _funding_ situation completely.  <br/>  <br/>Someone running a startup is always calculating in the back of their mind how<br/>much "runway" they have—how long they have till the money in the bank runs out<br/>and they either have to be profitable, raise more money, or go out of<br/>business. Once you cross the threshold of profitability, however low, your<br/>runway becomes infinite. It's a qualitative change, like the stars turning<br/>into lines and disappearing when the Enterprise accelerates to warp speed.<br/>Once you're profitable you don't need investors' money. And because Internet<br/>startups have become so cheap to run, the threshold of profitability can be<br/>trivially low. Which means many Internet startups don't need VC-scale<br/>investments anymore. For many startups, VC funding has, in the language of<br/>VCs, gone from a must-have to a nice-to-have.  <br/>  <br/>This change happened while no one was looking, and its effects have been<br/>largely masked so far. It was during the trough after the Internet Bubble that<br/>it became trivially cheap to start a startup, but few realized it because<br/>startups were so out of fashion. When startups came back into fashion, around<br/>2005, investors were starting to write checks again. And while founders may<br/>not have needed VC money the way they used to, they were willing to take it if<br/>offered—partly because there was a tradition of startups taking VC money, and<br/>partly because startups, like dogs, tend to eat when given the opportunity. As<br/>long as VCs were writing checks, founders were never forced to explore the<br/>limits of how little they needed them. There were a few startups who hit these<br/>limits accidentally because of their unusual circumstances—most famously<br/>37signals, which hit the limit because they crossed into startup land from the<br/>other direction: they started as a consulting firm, so they had revenue before<br/>they had a product.  <br/>  <br/>VCs and founders are like two components that used to be bolted together.<br/>Around 2000 the bolt was removed. Because the components have so far been<br/>subjected to the same forces, they still seem to be joined together, but<br/>really one is just resting on the other. A sharp impact would make them fly<br/>apart. And the present recession could be that impact.  <br/>  <br/>Because of Y Combinator's position at the extreme end of the spectrum, we'd be<br/>the first to see signs of a separation between founders and investors, and we<br/>are in fact seeing it. For example, though the stock market crash does seem to<br/>have made investors more cautious, it doesn't seem to have had any effect on<br/>the number of people who want to start startups. We take applications for<br/>funding every 6 months. Applications for the current funding cycle closed on<br/>October 17, well after the markets tanked, and even so we got a record number,<br/>up 40% from the same cycle a year before.  <br/>  <br/>Maybe things will be different a year from now, if the economy continues to<br/>get worse, but so far there is zero slackening of interest among potential<br/>founders. That's different from the way things felt in 2001. Then there was a<br/>widespread feeling among potential founders that startups were over, and that<br/>one should just go to grad school. That isn't happening this time, and part of<br/>the reason is that even in a bad economy it's not that hard to build something<br/>that makes $3000 a month. If investors stop writing checks, who cares?  <br/>  <br/>We also see signs of a divergence between founders and investors in the<br/>attitudes of existing startups we've funded. I was talking to one recently<br/>that had a round fall through at the last minute over the sort of trifle that<br/>breaks deals when investors feel they have the upper hand—over an uncertainty<br/>about whether the founders had correctly filed their 83(b) forms, if you can<br/>believe that. And yet this startup is obviously going to succeed: their<br/>traffic and revenue graphs look like a jet taking off. So I asked them if they<br/>wanted me to introduce them to more investors. To my surprise, they said<br/>no—that they'd just spent four months dealing with investors, and they were<br/>actually a lot happier now that they didn't have to. There was a friend they<br/>wanted to hire with the investor money, and now they'd have to postpone that.<br/>But otherwise they felt they had enough in the bank to make it to<br/>profitability. To make sure, they were moving to a cheaper apartment. And in<br/>this economy I bet they got a good deal on it.  <br/>  <br/>I've detected this "investors aren't worth the trouble" vibe from several YC<br/>founders I've talked to recently. At least one startup from the most recent<br/>(summer) cycle may not even raise angel money, let alone VC. Ticketstumbler<br/>made it to profitability on Y Combinator's $15,000 investment and they hope<br/>not to need more. This surprised even us. Although YC is based on the idea of<br/>it being cheap to start a startup, we never anticipated that founders would<br/>grow successful startups on nothing more than YC funding.  <br/>  <br/>If founders decide VCs aren't worth the trouble, that could be bad for VCs.<br/>When the economy bounces back in a few years and they're ready to write checks<br/>again, they may find that founders have moved on.  <br/>  <br/>There is a founder community just as there's a VC community. They all know one<br/>another, and techniques spread rapidly between them. If one tries a new<br/>programming language or a new hosting provider and gets good results, 6 months<br/>later half of them are using it. And the same is true for funding. The current<br/>generation of founders want to raise money from VCs, and Sequoia specifically,<br/>because Larry and Sergey took money from VCs, and Sequoia specifically.<br/>Imagine what it would do to the VC business if the next hot company didn't<br/>take VC at all.  <br/>  <br/>VCs think they're playing a zero sum game. In fact, it's not even that. If you<br/>lose a deal to Benchmark, you lose that deal, but VC as an industry still<br/>wins. If you lose a deal to None, all VCs lose.  <br/>  <br/>This recession may be different from the one after the Internet Bubble. This<br/>time founders may keep starting startups. And if they do, VCs will have to<br/>keep writing checks, or they could become irrelevant.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Thanks** to Sam Altman, Trevor Blackwell, David Hornik, Jessica Livingston,<br/>Robert Morris, and Fred Wilson for reading drafts of this.  <br/>  <br/><br/>Russian Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>November 2005  <br/>  <br/>In the next few years, venture capital funds will find themselves squeezed<br/>from four directions. They're already stuck with a seller's market, because of<br/>the huge amounts they raised at the end of the Bubble and still haven't<br/>invested. This by itself is not the end of the world. In fact, it's just a<br/>more extreme version of the norm in the VC business: too much money chasing<br/>too few deals.  <br/>  <br/>Unfortunately, those few deals now want less and less money, because it's<br/>getting so cheap to start a startup. The four causes: open source, which makes<br/>software free; Moore's law, which makes hardware geometrically closer to free;<br/>the Web, which makes promotion free if you're good; and better languages,<br/>which make development a lot cheaper.  <br/>  <br/>When we started our startup in 1995, the first three were our biggest<br/>expenses. We had to pay $5000 for the Netscape Commerce Server, the only<br/>software that then supported secure http connections. We paid $3000 for a<br/>server with a 90 MHz processor and 32 meg of memory. And we paid a PR firm<br/>about $30,000 to promote our launch.  <br/>  <br/>Now you could get all three for nothing. You can get the software for free;<br/>people throw away computers more powerful than our first server; and if you<br/>make something good you can generate ten times as much traffic by word of<br/>mouth online than our first PR firm got through the print media.  <br/>  <br/>And of course another big change for the average startup is that programming<br/>languages have improved-- or rather, the median language has. At most startups<br/>ten years ago, software development meant ten programmers writing code in C++.<br/>Now the same work might be done by one or two using Python or Ruby.  <br/>  <br/>During the Bubble, a lot of people predicted that startups would outsource<br/>their development to India. I think a better model for the future is David<br/>Heinemeier Hansson, who outsourced his development to a more powerful language<br/>instead. A lot of well-known applications are now, like BaseCamp, written by<br/>just one programmer. And one guy is more than 10x cheaper than ten, because<br/>(a) he won't waste any time in meetings, and (b) since he's probably a<br/>founder, he can pay himself nothing.  <br/>  <br/>Because starting a startup is so cheap, venture capitalists now often want to<br/>give startups more money than the startups want to take. VCs like to invest<br/>several million at a time. But as one VC told me after a startup he funded<br/>would only take about half a million, "I don't know what we're going to do.<br/>Maybe we'll just have to give some of it back." Meaning give some of the fund<br/>back to the institutional investors who supplied it, because it wasn't going<br/>to be possible to invest it all.  <br/>  <br/>Into this already bad situation comes the third problem: Sarbanes-Oxley.<br/>Sarbanes-Oxley is a law, passed after the Bubble, that drastically increases<br/>the regulatory burden on public companies. And in addition to the cost of<br/>compliance, which is at least two million dollars a year, the law introduces<br/>frightening legal exposure for corporate officers. An experienced CFO I know<br/>said flatly: "I would not want to be CFO of a public company now."  <br/>  <br/>You might think that responsible corporate governance is an area where you<br/>can't go too far. But you can go too far in any law, and this remark convinced<br/>me that Sarbanes-Oxley must have. This CFO is both the smartest and the most<br/>upstanding money guy I know. If Sarbanes-Oxley deters people like him from<br/>being CFOs of public companies, that's proof enough that it's broken.  <br/>  <br/>Largely because of Sarbanes-Oxley, few startups go public now. For all<br/>practical purposes, succeeding now equals getting bought. Which means VCs are<br/>now in the business of finding promising little 2-3 man startups and pumping<br/>them up into companies that cost $100 million to acquire. They didn't mean to<br/>be in this business; it's just what their business has evolved into.  <br/>  <br/>Hence the fourth problem: the acquirers have begun to realize they can buy<br/>wholesale. Why should they wait for VCs to make the startups they want more<br/>expensive? Most of what the VCs add, acquirers don't want anyway. The<br/>acquirers already have brand recognition and HR departments. What they really<br/>want is the software and the developers, and that's what the startup is in the<br/>early phase: concentrated software and developers.  <br/>  <br/>Google, typically, seems to have been the first to figure this out. "Bring us<br/>your startups early," said Google's speaker at the Startup School. They're<br/>quite explicit about it: they like to acquire startups at just the point where<br/>they would do a Series A round. (The Series A round is the first round of real<br/>VC funding; it usually happens in the first year.) It is a brilliant strategy,<br/>and one that other big technology companies will no doubt try to duplicate.<br/>Unless they want to have still more of their lunch eaten by Google.  <br/>  <br/>Of course, Google has an advantage in buying startups: a lot of the people<br/>there are rich, or expect to be when their options vest. Ordinary employees<br/>find it very hard to recommend an acquisition; it's just too annoying to see a<br/>bunch of twenty year olds get rich when you're still working for salary. Even<br/>if it's the right thing for your company to do.  <br/>  <br/> **The Solution(s)**  <br/>  <br/>Bad as things look now, there is a way for VCs to save themselves. They need<br/>to do two things, one of which won't surprise them, and another that will seem<br/>an anathema.  <br/>  <br/>Let's start with the obvious one: lobby to get Sarbanes-Oxley loosened. This<br/>law was created to prevent future Enrons, not to destroy the IPO market. Since<br/>the IPO market was practically dead when it passed, few saw what bad effects<br/>it would have. But now that technology has recovered from the last bust, we<br/>can see clearly what a bottleneck Sarbanes-Oxley has become.  <br/>  <br/>Startups are fragile plants—seedlings, in fact. These seedlings are worth<br/>protecting, because they grow into the trees of the economy. Much of the<br/>economy's growth is their growth. I think most politicians realize that. But<br/>they don't realize just how fragile startups are, and how easily they can<br/>become collateral damage of laws meant to fix some other problem.  <br/>  <br/>Still more dangerously, when you destroy startups, they make very little<br/>noise. If you step on the toes of the coal industry, you'll hear about it. But<br/>if you inadvertantly squash the startup industry, all that happens is that the<br/>founders of the next Google stay in grad school instead of starting a company.  <br/>  <br/>My second suggestion will seem shocking to VCs: let founders cash out<br/>partially in the Series A round. At the moment, when VCs invest in a startup,<br/>all the stock they get is newly issued and all the money goes to the company.<br/>They could buy some stock directly from the founders as well.  <br/>  <br/>Most VCs have an almost religious rule against doing this. They don't want<br/>founders to get a penny till the company is sold or goes public. VCs are<br/>obsessed with control, and they worry that they'll have less leverage over the<br/>founders if the founders have any money.  <br/>  <br/>This is a dumb plan. In fact, letting the founders sell a little stock early<br/>would generally be better for the company, because it would cause the<br/>founders' attitudes toward risk to be aligned with the VCs'. As things<br/>currently work, their attitudes toward risk tend to be diametrically opposed:<br/>the founders, who have nothing, would prefer a 100% chance of $1 million to a<br/>20% chance of $10 million, while the VCs can afford to be "rational" and<br/>prefer the latter.  <br/>  <br/>Whatever they say, the reason founders are selling their companies early<br/>instead of doing Series A rounds is that they get paid up front. That first<br/>million is just worth so much more than the subsequent ones. If founders could<br/>sell a little stock early, they'd be happy to take VC money and bet the rest<br/>on a bigger outcome.  <br/>  <br/>So why not let the founders have that first million, or at least half million?<br/>The VCs would get same number of shares for the money. So what if some of the<br/>money would go to the founders instead of the company?  <br/>  <br/>Some VCs will say this is unthinkable—that they want all their money to be put<br/>to work growing the company. But the fact is, the huge size of current VC<br/>investments is dictated by the structure of VC funds, not the needs of<br/>startups. Often as not these large investments go to work destroying the<br/>company rather than growing it.  <br/>  <br/>The angel investors who funded our startup let the founders sell some stock<br/>directly to them, and it was a good deal for everyone. The angels made a huge<br/>return on that investment, so they're happy. And for us founders it blunted<br/>the terrifying all-or-nothingness of a startup, which in its raw form is more<br/>a distraction than a motivator.  <br/>  <br/>If VCs are frightened at the idea of letting founders partially cash out, let<br/>me tell them something still more frightening: you are now competing directly<br/>with Google.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Thanks** to Trevor Blackwell, Sarah Harlin, Jessica Livingston, and Robert<br/>Morris for reading drafts of this.  <br/>  <br/><br/>Romanian Translation  <br/>  <br/><br/>Hebrew Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>March 2005  <br/>  <br/>A couple months ago I got an email from a recruiter asking if I was interested<br/>in being a "technologist in residence" at a new venture capital fund. I think<br/>the idea was to play Karl Rove to the VCs' George Bush.  <br/>  <br/>I considered it for about four seconds. Work for a VC fund? Ick.  <br/>  <br/>One of my most vivid memories from our startup is going to visit Greylock, the<br/>famous Boston VCs. They were the most arrogant people I've met in my life. And<br/>I've met a lot of arrogant people. [1]  <br/>  <br/>I'm not alone in feeling this way, of course. Even a VC friend of mine<br/>dislikes VCs. "Assholes," he says.  <br/>  <br/>But lately I've been learning more about how the VC world works,  and a few<br/>days ago it hit me that there's a reason VCs are the way they are. It's not so<br/>much that the business attracts jerks, or even that the power they wield<br/>corrupts them. The real problem is the way they're paid.  <br/>  <br/>The problem with VC funds is that they're _funds_. Like the managers of mutual<br/>funds or hedge funds, VCs get paid a percentage of the money they manage:<br/>about 2% a year in management fees, plus a percentage of the gains. So they<br/>want the fund to be huge-- hundreds of millions of dollars, if possible. But<br/>that means each partner ends up being responsible for investing a lot of<br/>money. And since one person can only manage so many deals, each deal has to be<br/>for multiple millions of dollars.  <br/>  <br/>This turns out to explain nearly all the characteristics of VCs that founders<br/>hate.  <br/>  <br/>It explains why VCs take so agonizingly long to make up their minds, and why<br/>their due diligence feels like a body cavity search. [2] With so much at<br/>stake, they have to be paranoid.  <br/>  <br/>It explains why they steal your ideas. Every founder knows that VCs will tell<br/>your secrets to your competitors if they end up investing in them. It's not<br/>unheard of for VCs to meet you when they have no intention of funding you,<br/>just to pick your brain for a competitor. This prospect makes naive founders<br/>clumsily secretive. Experienced founders treat it as a cost of doing business.<br/>Either way it sucks. But again, the only reason VCs are so sneaky is the giant<br/>deals they do. With so much at stake, they have to be devious.  <br/>  <br/>It explains why VCs tend to interfere in the companies they invest in. They<br/>want to be on your board not just so that they can advise you, but so that<br/>they can watch you. Often they even install a new CEO. Yes, he may have<br/>extensive business experience. But he's also their man: these newly installed<br/>CEOs always play something of the role of a political commissar in a Red Army<br/>unit. With so much at stake, VCs can't resist micromanaging you.  <br/>  <br/>The huge investments themselves are something founders would dislike, if they<br/>realized how damaging they can be. VCs don't invest $x million because that's<br/>the amount you need, but because that's the amount the structure of their<br/>business requires them to invest. Like steroids, these sudden huge investments<br/>can do more harm than good. Google survived enormous VC funding because it<br/>could legitimately absorb large amounts of money. They had to buy a lot of<br/>servers and a lot of bandwidth to crawl the whole Web. Less fortunate startups<br/>just end up hiring armies of people to sit around having meetings.  <br/>  <br/>In principle you could take a huge VC investment, put it in treasury bills,<br/>and continue to operate frugally. You just try it.  <br/>  <br/>And of course giant investments mean giant valuations. They have to, or<br/>there's not enough stock left to keep the founders interested. You might think<br/>a high valuation is a great thing. Many founders do. But you can't eat paper.<br/>You can't benefit from a high valuation unless you can somehow achieve what<br/>those in the business  call a "liquidity event," and the higher your<br/>valuation, the narrower your options for doing that. Many a founder would be<br/>happy to sell his company for $15 million, but VCs who've just invested at a<br/>pre-money valuation of $8 million won't hear of that. You're rolling the dice<br/>again, whether you like it or not.  <br/>  <br/>Back in 1997, one of our competitors raised $20 million in a single round of<br/>VC funding. This was at the time more than the valuation of our entire<br/>company. Was I worried? Not at all: I was delighted. It was like watching a<br/>car you're chasing turn down a street that you know has no outlet.  <br/>  <br/>Their smartest move at that point would have been to take every penny of the<br/>$20 million and use it to buy us. We would have sold. Their investors would<br/>have been furious of course. But I think the main reason they never considered<br/>this was that they never imagined we could be had so cheap. They probably<br/>assumed we were on the same VC gravy train they were.  <br/>  <br/>In fact we only spent about $2 million in our entire existence. And that gave<br/>us flexibility. We could sell ourselves to Yahoo for $50 million, and everyone<br/>was delighted. If our competitor had done that, the last round of investors<br/>would presumably have lost money. I assume they could have vetoed such a deal.<br/>But no one those days was paying a lot more than Yahoo. So unless their<br/>founders could pull off an IPO (which would be difficult with Yahoo as a<br/>competitor), they had no choice but to ride the thing down.  <br/>  <br/>The puffed-up companies that went public during the Bubble didn't do it just<br/>because they were pulled into it by unscrupulous investment bankers. Most were<br/>pushed just as hard from the other side by VCs who'd invested at high<br/>valuations, leaving an IPO as the only way out. The only people dumber were<br/>retail investors. So it was literally IPO or bust. Or rather, IPO then bust,<br/>or just bust.  <br/>  <br/>Add up all the evidence of VCs' behavior, and the resulting personality is not<br/>attractive. In fact, it's the classic villain: alternately cowardly, greedy,<br/>sneaky, and overbearing.  <br/>  <br/>I used to take it for granted that VCs were like this. Complaining that VCs<br/>were jerks used to seem as naive to me as complaining that users didn't read<br/>the reference manual. Of course VCs were jerks. How could it be otherwise?  <br/>  <br/>But I realize now that they're not intrinsically jerks. VCs are like car<br/>salesmen or bureaucrats: the nature of their work turns them into jerks.  <br/>  <br/>I've met a few VCs I like. Mike Moritz seems a good guy. He even has a sense<br/>of humor, which is almost unheard of among VCs. From what I've read about John<br/>Doerr, he sounds like a good guy too, almost a hacker. But they work for the<br/>very best VC funds. And my theory explains why they'd tend to be different:<br/>just as the very most popular kids don't have to persecute nerds, the very<br/>best VCs don't have to act like VCs. They get the pick of all the best deals.<br/>So they don't have to be so paranoid and sneaky, and they can choose those<br/>rare companies, like Google, that will actually benefit from the giant sums<br/>they're compelled to invest.  <br/>  <br/>VCs often complain that in their business there's too much money chasing too<br/>few deals. Few realize that this also describes a flaw in the way funding<br/>works at the level of individual firms.  <br/>  <br/>Perhaps this was the sort of strategic insight I was supposed to come up with<br/>as a "technologist in residence." If so, the good news is that they're getting<br/>it for free. The bad news is it means that if you're not one of the very top<br/>funds, you're condemned to be the bad guys.  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] After Greylock booted founder Philip Greenspun out of ArsDigita, he wrote<br/>a hilarious but also very informative essay about it.  <br/>  <br/>[2] Since most VCs aren't tech guys, the technology side of their due<br/>diligence tends to be like a body cavity search by someone with a faulty<br/>knowledge of human anatomy. After a while we were quite sore from VCs<br/>attempting to probe our nonexistent database orifice.  <br/>  <br/>No, we don't use Oracle. We just store the data in files. Our secret is to use<br/>an OS that doesn't lose our data. Which OS? FreeBSD. Why do you use that<br/>instead of Windows NT? Because it's better and it doesn't cost anything. What,<br/>you're using a _freeware_ OS?  <br/>  <br/>How many times that conversation was repeated. Then when we got to Yahoo, we<br/>found they used FreeBSD and stored their data in files too.  <br/>  <br/><br/>Chinese Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>August 2015  <br/>  <br/>I recently got an email from a founder that helped me understand something<br/>important: why it's safe for startup founders to be nice people.  <br/>  <br/>I grew up with a cartoon idea of a very successful businessman (in the cartoon<br/>it was always a man): a rapacious, cigar-smoking, table-thumping guy in his<br/>fifties who wins by exercising power, and isn't too fussy about how. As I've<br/>written before<br/><br/>  <br/>  <br/><br/>* * *<br/><br/>April 2009  <br/>  <br/>Om Malik is the most recent of many people to ask why Twitter is such a big<br/>deal.  <br/>  <br/>The reason is that it's a new messaging protocol, where you don't specify the<br/>recipients. New protocols are rare. Or more precisely, new protocols that take<br/>off are. There are only a handful of commonly used ones: TCP/IP (the<br/>Internet), SMTP (email), HTTP (the web), and so on. So any new protocol is a<br/>big deal. But Twitter is a protocol owned by a private company. That's even<br/>rarer.  <br/>  <br/>Curiously, the fact that the founders of Twitter have been slow to monetize it<br/>may in the long run prove to be an advantage. Because they haven't tried to<br/>control it too much, Twitter feels to everyone like previous protocols. One<br/>forgets it's owned by a private company. That must have made it easier for<br/>Twitter to spread.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>August 2010  <br/>  <br/>When I went to work for Yahoo after they bought our startup in 1998, it felt<br/>like the center of the world. It was supposed to be the next big thing. It was<br/>supposed to be what Google turned out to be.  <br/>  <br/>What went wrong? The problems that hosed Yahoo go back a long time,<br/>practically to the beginning of the company. They were already very visible<br/>when I got there in 1998. Yahoo had two problems Google didn't: easy money,<br/>and ambivalence about being a technology company.  <br/>  <br/> **Money**  <br/>  <br/>The first time I met Jerry Yang, we thought we were meeting for different<br/>reasons. He thought we were meeting so he could check us out in person before<br/>buying us. I thought we were meeting so we could show him our new technology,<br/>Revenue Loop. It was a way of sorting shopping search results. Merchants bid a<br/>percentage of sales for traffic, but the results were sorted not by the bid<br/>but by the bid times the average amount a user would buy. It was like the<br/>algorithm Google uses now to sort ads, but this was in the spring of 1998,<br/>before Google was founded.  <br/>  <br/>Revenue Loop was the optimal sort for shopping search, in the sense that it<br/>sorted in order of how much money Yahoo would make from each link. But it<br/>wasn't just optimal in that sense. Ranking search results by user behavior<br/>also makes search better. Users train the search: you can start out finding<br/>matches based on mere textual similarity, and as users buy more stuff the<br/>search results get better and better.  <br/>  <br/>Jerry didn't seem to care. I was confused. I was showing him technology that<br/>extracted the maximum value from search traffic, and he didn't care? I<br/>couldn't tell whether I was explaining it badly, or he was just very poker<br/>faced.  <br/>  <br/>I didn't realize the answer till later, after I went to work at Yahoo. It was<br/>neither of my guesses. The reason Yahoo didn't care about a technique that<br/>extracted the full value of traffic was that advertisers were already<br/>overpaying for it. If Yahoo merely extracted the actual value, they'd have<br/>made less.  <br/>  <br/>Hard as it is to believe now, the big money then was in banner ads.<br/>Advertisers were willing to pay ridiculous amounts for banner ads. So Yahoo's<br/>sales force had evolved to exploit this source of revenue. Led by a large and<br/>terrifyingly formidable man called Anil Singh, Yahoo's sales guys would fly<br/>out to Procter & Gamble and come back with million dollar orders for banner ad<br/>impressions.  <br/>  <br/>The prices seemed cheap compared to print, which was what advertisers, for<br/>lack of any other reference, compared them to. But they were expensive<br/>compared to what they were worth. So these big, dumb companies were a<br/>dangerous source of revenue to depend on. But there was another source even<br/>more dangerous: other Internet startups.  <br/>  <br/>By 1998, Yahoo was the beneficiary of a de facto Ponzi scheme. Investors were<br/>excited about the Internet. One reason they were excited was Yahoo's revenue<br/>growth. So they invested in new Internet startups. The startups then used the<br/>money to buy ads on Yahoo to get traffic. Which caused yet more revenue growth<br/>for Yahoo, and further convinced investors the Internet was worth investing<br/>in. When I realized this one day, sitting in my cubicle, I jumped up like<br/>Archimedes in his bathtub, except instead of "Eureka!" I was shouting "Sell!"  <br/>  <br/>Both the Internet startups and the Procter & Gambles were doing brand<br/>advertising. They didn't care about targeting. They just wanted lots of people<br/>to see their ads. So traffic became the thing to get at Yahoo. It didn't<br/>matter what type. [1]  <br/>  <br/>It wasn't just Yahoo. All the search engines were doing it. This was why they<br/>were trying to get people to start calling them "portals" instead of "search<br/>engines." Despite the actual meaning of the word portal, what they meant by it<br/>was a site where users would find what they wanted on the site itself, instead<br/>of just passing through on their way to other destinations, as they did at a<br/>search engine.  <br/>  <br/>I remember telling David Filo in late 1998 or early 1999 that Yahoo should buy<br/>Google, because I and most of the other programmers in the company were using<br/>it instead of Yahoo for search. He told me that it wasn't worth worrying<br/>about. Search was only 6% of our traffic, and we were growing at 10% a month.<br/>It wasn't worth doing better.  <br/>  <br/>I didn't say "But search traffic is worth more than other traffic!" I said<br/>"Oh, ok." Because I didn't realize either how much search traffic was worth.<br/>I'm not sure even Larry and Sergey did then. If they had, Google presumably<br/>wouldn't have expended any effort on enterprise search.  <br/>  <br/>If circumstances had been different, the people running Yahoo might have<br/>realized sooner how important search was. But they had the most opaque<br/>obstacle in the world between them and the truth: money. As long as customers<br/>were writing big checks for banner ads, it was hard to take search seriously.<br/>Google didn't have that to distract them.  <br/>  <br/> **Hackers**  <br/>  <br/>But Yahoo also had another problem that made it hard to change directions.<br/>They'd been thrown off balance from the start by their ambivalence about being<br/>a technology company.  <br/>  <br/>One of the weirdest things about Yahoo when I went to work there was the way<br/>they insisted on calling themselves a "media company." If you walked around<br/>their offices, it seemed like a software company. The cubicles were full of<br/>programmers writing code, product managers thinking about feature lists and<br/>ship dates, support people (yes, there were actually support people) telling<br/>users to restart their browsers, and so on, just like a software company. So<br/>why did they call themselves a media company?  <br/>  <br/>One reason was the way they made money: by selling ads. In 1995 it was hard to<br/>imagine a technology company making money that way. Technology companies made<br/>money by selling their software to users. Media companies sold ads. So they<br/>must be a media company.  <br/>  <br/>Another big factor was the fear of Microsoft. If anyone at Yahoo considered<br/>the idea that they should be a technology company, the next thought would have<br/>been that Microsoft would crush them.  <br/>  <br/>It's hard for anyone much younger than me to understand the fear Microsoft<br/>still inspired in 1995. Imagine a company with several times the power Google<br/>has now, but way meaner. It was perfectly reasonable to be afraid of them.<br/>Yahoo watched them crush the first hot Internet company, Netscape. It was<br/>reasonable to worry that if they tried to be the next Netscape, they'd suffer<br/>the same fate. How were they to know that Netscape would turn out to be<br/>Microsoft's last victim?  <br/>  <br/>It would have been a clever move to pretend to be a media company to throw<br/>Microsoft off their scent. But unfortunately Yahoo actually tried to be one,<br/>sort of. Project managers at Yahoo were called "producers," for example, and<br/>the different parts of the company were called "properties." But what Yahoo<br/>really needed to be was a technology company, and by trying to be something<br/>else, they ended up being something that was neither here nor there. That's<br/>why Yahoo as a company has never had a sharply defined identity.  <br/>  <br/>The worst consequence of trying to be a media company was that they didn't<br/>take programming seriously enough. Microsoft (back in the day), Google, and<br/>Facebook have all had hacker-centric cultures. But Yahoo treated programming<br/>as a commodity. At Yahoo, user-facing software was controlled by product<br/>managers and designers. The job of programmers was just to take the work of<br/>the product managers and designers the final step, by translating it into<br/>code.  <br/>  <br/>One obvious result of this practice was that when Yahoo built things, they<br/>often weren't very good. But that wasn't the worst problem. The worst problem<br/>was that they hired bad programmers.  <br/>  <br/>Microsoft (back in the day), Google, and Facebook have all been obsessed with<br/>hiring the best programmers. Yahoo wasn't. They preferred good programmers to<br/>bad ones, but they didn't have the kind of single-minded, almost obnoxiously<br/>elitist focus on hiring the smartest people that the big winners have had. And<br/>when you consider how much competition there was for programmers when they<br/>were hiring, during the Bubble, it's not surprising that the quality of their<br/>programmers was uneven.  <br/>  <br/>In technology, once you have bad programmers, you're doomed. I can't think of<br/>an instance where a company has sunk into technical mediocrity and recovered.<br/>Good programmers want to work with other good programmers. So once the quality<br/>of programmers at your company starts to drop, you enter a death spiral from<br/>which there is no recovery. [2]  <br/>  <br/>At Yahoo this death spiral started early. If there was ever a time when Yahoo<br/>was a Google-style talent magnet, it was over by the time I got there in 1998.  <br/>  <br/>The company felt prematurely old. Most technology companies eventually get<br/>taken over by suits and middle managers. At Yahoo it felt as if they'd<br/>deliberately accelerated this process. They didn't want to be a bunch of<br/>hackers. They wanted to be suits. A media company should be run by suits.  <br/>  <br/>The first time I visited Google, they had about 500 people, the same number<br/>Yahoo had when I went to work there. But boy did things seem different. It was<br/>still very much a hacker-centric culture. I remember talking to some<br/>programmers in the cafeteria about the problem of gaming search results (now<br/>known as SEO), and they asked "what should we do?" Programmers at Yahoo<br/>wouldn't have asked that. Theirs was not to reason why; theirs was to build<br/>what product managers spec'd. I remember coming away from Google thinking<br/>"Wow, it's still a startup."  <br/>  <br/>There's not much we can learn from Yahoo's first fatal flaw. It's probably too<br/>much to hope any company could avoid being damaged by depending on a bogus<br/>source of revenue. But startups can learn an important lesson from the second<br/>one. In the software business, you can't afford not to have a hacker-centric<br/>culture.  <br/>  <br/>Probably the most impressive commitment I've heard to having a hacker-centric<br/>culture came from Mark Zuckerberg, when he spoke at Startup School in 2007. He<br/>said that in the early days Facebook made a point of hiring programmers even<br/>for jobs that would not ordinarily consist of programming, like HR and<br/>marketing.  <br/>  <br/>So which companies need to have a hacker-centric culture? Which companies are<br/>"in the software business" in this respect? As Yahoo discovered, the area<br/>covered by this rule is bigger than most people realize. The answer is: any<br/>company that needs to have good software.  <br/>  <br/>Why would great programmers want to work for a company that didn't have a<br/>hacker-centric culture, as long as there were others that did? I can imagine<br/>two reasons: if they were paid a huge amount, or if the domain was interesting<br/>and none of the companies in it were hacker-centric. Otherwise you can't<br/>attract good programmers to work in a suit-centric culture. And without good<br/>programmers you won't get good software, no matter how many people you put on<br/>a task, or how many procedures you establish to ensure "quality."  <br/>  <br/>Hacker culture often seems kind of irresponsible. That's why people proposing<br/>to destroy it use phrases like "adult supervision." That was the phrase they<br/>used at Yahoo. But there are worse things than seeming irresponsible. Losing,<br/>for example.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] The closest we got to targeting when I was there was when we created<br/>pets.yahoo.com in order to provoke a bidding war between 3 pet supply startups<br/>for the spot as top sponsor.  <br/>  <br/>[2] In theory you could beat the death spiral by buying good programmers<br/>instead of hiring them. You can get programmers who would never have come to<br/>you as employees by buying their startups. But so far the only companies smart<br/>enough to do this are companies smart enough not to need to.  <br/>  <br/> **Thanks** to Trevor Blackwell, Jessica Livingston, and Geoff Ralston for<br/>reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>October 2014  <br/>  <br/> _(This essay is derived from a guest lecture in Sam Altman'sstartup class at<br/>Stanford. It's intended for college students, but much of it is applicable to<br/>potential founders at other ages.)_  <br/>  <br/>One of the advantages of having kids is that when you have to give advice, you<br/>can ask yourself "what would I tell my own kids?" My kids are little, but I<br/>can imagine what I'd tell them about startups if they were in college, and<br/>that's what I'm going to tell you.  <br/>  <br/>Startups are very counterintuitive. I'm not sure why. Maybe it's just because<br/>knowledge about them hasn't permeated our culture yet. But whatever the<br/>reason, starting a startup is a task where you can't always trust your<br/>instincts.  <br/>  <br/>It's like skiing in that way. When you first try skiing and you want to slow<br/>down, your instinct is to lean back. But if you lean back on skis you fly down<br/>the hill out of control. So part of learning to ski is learning to suppress<br/>that impulse. Eventually you get new habits, but at first it takes a conscious<br/>effort. At first there's a list of things you're trying to remember as you<br/>start down the hill.  <br/>  <br/>Startups are as unnatural as skiing, so there's a similar list for startups.<br/>Here I'm going to give you the first part of it — the things to remember if<br/>you want to prepare yourself to start a startup.  <br/>  <br/>**Counterintuitive**  <br/>  <br/>The first item on it is the fact I already mentioned: that startups are so<br/>weird that if you trust your instincts, you'll make a lot of mistakes. If you<br/>know nothing more than this, you may at least pause before making them.  <br/>  <br/>When I was running Y Combinator I used to joke that our function was to tell<br/>founders things they would ignore. It's really true. Batch after batch, the YC<br/>partners warn founders about mistakes they're about to make, and the founders<br/>ignore them, and then come back a year later and say "I wish we'd listened."  <br/>  <br/>Why do the founders ignore the partners' advice? Well, that's the thing about<br/>counterintuitive ideas: they contradict your intuitions. They seem wrong. So<br/>of course your first impulse is to disregard them. And in fact my joking<br/>description is not merely the curse of Y Combinator but part of its raison<br/>d'etre. If founders' instincts already gave them the right answers, they<br/>wouldn't need us. You only need other people to give you advice that surprises<br/>you. That's why there are a lot of ski instructors and not many running<br/>instructors. [1]  <br/>  <br/>You can, however, trust your instincts about people. And in fact one of the<br/>most common mistakes young founders make is not to do that enough. They get<br/>involved with people who seem impressive, but about whom they feel some<br/>misgivings personally. Later when things blow up they say "I knew there was<br/>something off about him, but I ignored it because he seemed so impressive."  <br/>  <br/>If you're thinking about getting involved with someone — as a cofounder, an<br/>employee, an investor, or an acquirer — and you have misgivings about them,<br/>trust your gut. If someone seems slippery, or bogus, or a jerk, don't ignore<br/>it.  <br/>  <br/>This is one case where it pays to be self-indulgent. Work with people you<br/>genuinely like, and you've known long enough to be sure.  <br/>  <br/>**Expertise**  <br/>  <br/>The second counterintuitive point is that it's not that important to know a<br/>lot about startups. The way to succeed in a startup is not to be an expert on<br/>startups, but to be an expert on your users and the problem you're solving for<br/>them. Mark Zuckerberg didn't succeed because he was an expert on startups. He<br/>succeeded despite being a complete noob at startups, because he understood his<br/>users really well.  <br/>  <br/>If you don't know anything about, say, how to raise an angel round, don't feel<br/>bad on that account. That sort of thing you can learn when you need to, and<br/>forget after you've done it.  <br/>  <br/>In fact, I worry it's not merely unnecessary to learn in great detail about<br/>the mechanics of startups, but possibly somewhat dangerous. If I met an<br/>undergrad who knew all about convertible notes and employee agreements and<br/>(God forbid) class FF stock, I wouldn't think "here is someone who is way<br/>ahead of their peers." It would set off alarms. Because another of the<br/>characteristic mistakes of young founders is to go through the motions of<br/>starting a startup. They make up some plausible-sounding idea, raise money at<br/>a good valuation, rent a cool office, hire a bunch of people. From the outside<br/>that seems like what startups do. But the next step after rent a cool office<br/>and hire a bunch of people is: gradually realize how completely fucked they<br/>are, because while imitating all the outward forms of a startup they have<br/>neglected the one thing that's actually essential: making something people<br/>want.  <br/>  <br/>**Game**  <br/>  <br/>We saw this happen so often that we made up a name for it: playing house.<br/>Eventually I realized why it was happening. The reason young founders go<br/>through the motions of starting a startup is because that's what they've been<br/>trained to do for their whole lives up to that point. Think about what you<br/>have to do to get into college, for example. Extracurricular activities,<br/>check. Even in college classes most of the work is as artificial as running<br/>laps.  <br/>  <br/>I'm not attacking the educational system for being this way. There will always<br/>be a certain amount of fakeness in the work you do when you're being taught<br/>something, and if you measure their performance it's inevitable that people<br/>will exploit the difference to the point where much of what you're measuring<br/>is artifacts of the fakeness.  <br/>  <br/>I confess I did it myself in college. I found that in a lot of classes there<br/>might only be 20 or 30 ideas that were the right shape to make good exam<br/>questions. The way I studied for exams in these classes was not (except<br/>incidentally) to master the material taught in the class, but to make a list<br/>of potential exam questions and work out the answers in advance. When I walked<br/>into the final, the main thing I'd be feeling was curiosity about which of my<br/>questions would turn up on the exam. It was like a game.  <br/>  <br/>It's not surprising that after being trained for their whole lives to play<br/>such games, young founders' first impulse on starting a startup is to try to<br/>figure out the tricks for winning at this new game. Since fundraising appears<br/>to be the measure of success for startups (another classic noob mistake), they<br/>always want to know what the tricks are for convincing investors. We tell them<br/>the best way to convince investors is to make a startup that's actually doing<br/>well, meaning growing fast, and then simply tell investors so. Then they want<br/>to know what the tricks are for growing fast. And we have to tell them the<br/>best way to do that is simply to make something people want.  <br/>  <br/>So many of the conversations YC partners have with young founders begin with<br/>the founder asking "How do we..." and the partner replying "Just..."  <br/>  <br/>Why do the founders always make things so complicated? The reason, I realized,<br/>is that they're looking for the trick.  <br/>  <br/>So this is the third counterintuitive thing to remember about startups:<br/>starting a startup is where gaming the system stops working. Gaming the system<br/>may continue to work if you go to work for a big company. Depending on how<br/>broken the company is, you can succeed by sucking up to the right people,<br/>giving the impression of productivity, and so on. [2] But that doesn't work<br/>with startups. There is no boss to trick, only users, and all users care about<br/>is whether your product does what they want. Startups are as impersonal as<br/>physics. You have to make something people want, and you prosper only to the<br/>extent you do.  <br/>  <br/>The dangerous thing is, faking does work to some degree on investors. If<br/>you're super good at sounding like you know what you're talking about, you can<br/>fool investors for at least one and perhaps even two rounds of funding. But<br/>it's not in your interest to. The company is ultimately doomed. All you're<br/>doing is wasting your own time riding it down.  <br/>  <br/>So stop looking for the trick. There are tricks in startups, as there are in<br/>any domain, but they are an order of magnitude less important than solving the<br/>real problem. A founder who knows nothing about fundraising but has made<br/>something users love will have an easier time raising money than one who knows<br/>every trick in the book but has a flat usage graph. And more importantly, the<br/>founder who has made something users love is the one who will go on to succeed<br/>after raising the money.  <br/>  <br/>Though in a sense it's bad news in that you're deprived of one of your most<br/>powerful weapons, I think it's exciting that gaming the system stops working<br/>when you start a startup. It's exciting that there even exist parts of the<br/>world where you win by doing good work. Imagine how depressing the world would<br/>be if it were all like school and big companies, where you either have to<br/>spend a lot of time on bullshit things or lose to people who do. [3] I would<br/>have been delighted if I'd realized in college that there were parts of the<br/>real world where gaming the system mattered less than others, and a few where<br/>it hardly mattered at all. But there are, and this variation is one of the<br/>most important things to consider when you're thinking about your future. How<br/>do you win in each type of work, and what would you like to win by doing? [4]  <br/>  <br/>**All-Consuming**  <br/>  <br/>That brings us to our fourth counterintuitive point: startups are all-<br/>consuming. If you start a startup, it will take over your life to a degree you<br/>cannot imagine. And if your startup succeeds, it will take over your life for<br/>a long time: for several years at the very least, maybe for a decade, maybe<br/>for the rest of your working life. So there is a real opportunity cost here.  <br/>  <br/>Larry Page may seem to have an enviable life, but there are aspects of it that<br/>are unenviable. Basically at 25 he started running as fast as he could and it<br/>must seem to him that he hasn't stopped to catch his breath since. Every day<br/>new shit happens in the Google empire that only the CEO can deal with, and he,<br/>as CEO, has to deal with it. If he goes on vacation for even a week, a whole<br/>week's backlog of shit accumulates. And he has to bear this uncomplainingly,<br/>partly because as the company's daddy he can never show fear or weakness, and<br/>partly because billionaires get less than zero sympathy if they talk about<br/>having difficult lives. Which has the strange side effect that the difficulty<br/>of being a successful startup founder is concealed from almost everyone except<br/>those who've done it.  <br/>  <br/>Y Combinator has now funded several companies that can be called big<br/>successes, and in every single case the founders say the same thing. It never<br/>gets any easier. The nature of the problems change. You're worrying about<br/>construction delays at your London office instead of the broken air<br/>conditioner in your studio apartment. But the total volume of worry never<br/>decreases; if anything it increases.  <br/>  <br/>Starting a successful startup is similar to having kids in that it's like a<br/>button you push that changes your life irrevocably. And while it's truly<br/>wonderful having kids, there are a lot of things that are easier to do before<br/>you have them than after. Many of which will make you a better parent when you<br/>do have kids. And since you can delay pushing the button for a while, most<br/>people in rich countries do.  <br/>  <br/>Yet when it comes to startups, a lot of people seem to think they're supposed<br/>to start them while they're still in college. Are you crazy? And what are the<br/>universities thinking? They go out of their way to ensure their students are<br/>well supplied with contraceptives, and yet they're setting up entrepreneurship<br/>programs and startup incubators left and right.  <br/>  <br/>To be fair, the universities have their hand forced here. A lot of incoming<br/>students are interested in startups. Universities are, at least de facto,<br/>expected to prepare them for their careers. So students who want to start<br/>startups hope universities can teach them about startups. And whether<br/>universities can do this or not, there's some pressure to claim they can, lest<br/>they lose applicants to other universities that do.  <br/>  <br/>Can universities teach students about startups? Yes and no. They can teach<br/>students about startups, but as I explained before, this is not what you need<br/>to know. What you need to learn about are the needs of your own users, and you<br/>can't do that until you actually start the company. [5] So starting a startup<br/>is intrinsically something you can only really learn by doing it. And it's<br/>impossible to do that in college, for the reason I just explained: startups<br/>take over your life. You can't start a startup for real as a student, because<br/>if you start a startup for real you're not a student anymore. You may be<br/>nominally a student for a bit, but you won't even be that for long. [6]  <br/>  <br/>Given this dichotomy, which of the two paths should you take? Be a real<br/>student and not start a startup, or start a real startup and not be a student?<br/>I can answer that one for you. Do not start a startup in college. How to start<br/>a startup is just a subset of a bigger problem you're trying to solve: how to<br/>have a good life. And though starting a startup can be part of a good life for<br/>a lot of ambitious people, age 20 is not the optimal time to do it. Starting a<br/>startup is like a brutally fast depth-first search. Most people should still<br/>be searching breadth-first at 20.  <br/>  <br/>You can do things in your early 20s that you can't do as well before or after,<br/>like plunge deeply into projects on a whim and travel super cheaply with no<br/>sense of a deadline. For unambitious people, this sort of thing is the dreaded<br/>"failure to launch," but for the ambitious ones it can be an incomparably<br/>valuable sort of exploration. If you start a startup at 20 and you're<br/>sufficiently successful, you'll never get to do it. [7]  <br/>  <br/>Mark Zuckerberg will never get to bum around a foreign country. He can do<br/>other things most people can't, like charter jets to fly him to foreign<br/>countries. But success has taken a lot of the serendipity out of his life.<br/>Facebook is running him as much as he's running Facebook. And while it can be<br/>very cool to be in the grip of a project you consider your life's work, there<br/>are advantages to serendipity too, especially early in life. Among other<br/>things it gives you more options to choose your life's work from.  <br/>  <br/>There's not even a tradeoff here. You're not sacrificing anything if you forgo<br/>starting a startup at 20, because you're more likely to succeed if you wait.<br/>In the unlikely case that you're 20 and one of your side projects takes off<br/>like Facebook did, you'll face a choice of running with it or not, and it may<br/>be reasonable to run with it. But the usual way startups take off is for the<br/>founders to make them take off, and it's gratuitously stupid to do that at 20.  <br/>  <br/>**Try**  <br/>  <br/>Should you do it at any age? I realize I've made startups sound pretty hard.<br/>If I haven't, let me try again: starting a startup is really hard. What if<br/>it's too hard? How can you tell if you're up to this challenge?  <br/>  <br/>The answer is the fifth counterintuitive point: you can't tell. Your life so<br/>far may have given you some idea what your prospects might be if you tried to<br/>become a mathematician, or a professional football player. But unless you've<br/>had a very strange life you haven't done much that was like being a startup<br/>founder. Starting a startup will change you a lot. So what you're trying to<br/>estimate is not just what you are, but what you could grow into, and who can<br/>do that?  <br/>  <br/>For the past 9 years it was my job to predict whether people would have what<br/>it took to start successful startups. It was easy to tell how smart they were,<br/>and most people reading this will be over that threshold. The hard part was<br/>predicting how tough and ambitious<br/><br/>  <br/>  <br/><br/>* * *<br/><br/>February 2009  <br/>  <br/>I finally realized today why politics and religion yield such uniquely useless<br/>discussions.  <br/>  <br/>As a rule, any mention of religion on an online forum degenerates into a<br/>religious argument. Why? Why does this happen with religion and not with<br/>Javascript or baking or other topics people talk about on forums?  <br/>  <br/>What's different about religion is that people don't feel they need to have<br/>any particular expertise to have opinions about it. All they need is strongly<br/>held beliefs, and anyone can have those. No thread about Javascript will grow<br/>as fast as one about religion, because people feel they have to be over some<br/>threshold of expertise to post comments about that. But on religion everyone's<br/>an expert.  <br/>  <br/>Then it struck me: this is the problem with politics too. Politics, like<br/>religion, is a topic where there's no threshold of expertise for expressing an<br/>opinion. All you need is strong convictions.  <br/>  <br/>Do religion and politics have something in common that explains this<br/>similarity? One possible explanation is that they deal with questions that<br/>have no definite answers, so there's no back pressure on people's opinions.<br/>Since no one can be proven wrong, every opinion is equally valid, and sensing<br/>this, everyone lets fly with theirs.  <br/>  <br/>But this isn't true. There are certainly some political questions that have<br/>definite answers, like how much a new government policy will cost. But the<br/>more precise political questions suffer the same fate as the vaguer ones.  <br/>  <br/>I think what religion and politics have in common is that they become part of<br/>people's identity, and people can never have a fruitful argument about<br/>something that's part of their identity. By definition they're partisan.  <br/>  <br/>Which topics engage people's identity depends on the people, not the topic.<br/>For example, a discussion about a battle that included citizens of one or more<br/>of the countries involved would probably degenerate into a political argument.<br/>But a discussion today about a battle that took place in the Bronze Age<br/>probably wouldn't. No one would know what side to be on. So it's not politics<br/>that's the source of the trouble, but identity. When people say a discussion<br/>has degenerated into a religious war, what they really mean is that it has<br/>started to be driven mostly by people's identities. [1]  <br/>  <br/>Because the point at which this happens depends on the people rather than the<br/>topic, it's a mistake to conclude that because a question tends to provoke<br/>religious wars, it must have no answer. For example, the question of the<br/>relative merits of programming languages often degenerates into a religious<br/>war, because so many programmers identify as X programmers or Y programmers.<br/>This sometimes leads people to conclude the question must be unanswerable—that<br/>all languages are equally good. Obviously that's false: anything else people<br/>make can be well or badly designed; why should this be uniquely impossible for<br/>programming languages? And indeed, you can have a fruitful discussion about<br/>the relative merits of programming languages, so long as you exclude people<br/>who respond from identity.  <br/>  <br/>More generally, you can have a fruitful discussion about a topic only if it<br/>doesn't engage the identities of any of the participants. What makes politics<br/>and religion such minefields is that they engage so many people's identities.<br/>But you could in principle have a useful conversation about them with some<br/>people. And there are other topics that might seem harmless, like the relative<br/>merits of Ford and Chevy pickup trucks, that you couldn't safely talk about<br/>with others.  <br/>  <br/>The most intriguing thing about this theory, if it's right, is that it<br/>explains not merely which kinds of discussions to avoid, but how to have<br/>better ideas. If people can't think clearly about anything that has become<br/>part of their identity, then all other things being equal, the best plan is to<br/>let as few things into your identity as possible. [2]  <br/>  <br/>Most people reading this will already be fairly tolerant. But there is a step<br/>beyond thinking of yourself as x but tolerating y: not even to consider<br/>yourself an x. The more labels you have for yourself, the dumber they make<br/>you.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] When that happens, it tends to happen fast, like a core going critical.<br/>The threshold for participating goes down to zero, which brings in more<br/>people. And they tend to say incendiary things, which draw more and angrier<br/>counterarguments.  <br/>  <br/>[2] There may be some things it's a net win to include in your identity. For<br/>example, being a scientist. But arguably that is more of a placeholder than an<br/>actual label—like putting NMI on a form that asks for your middle<br/>initial—because it doesn't commit you to believing anything in particular. A<br/>scientist isn't committed to believing in natural selection in the same way a<br/>bibilical literalist is committed to rejecting it. All he's committed to is<br/>following the evidence wherever it leads.  <br/>  <br/>Considering yourself a scientist is equivalent to putting a sign in a cupboard<br/>saying "this cupboard must be kept empty." Yes, strictly speaking, you're<br/>putting something in the cupboard, but not in the ordinary sense.  <br/>  <br/> **Thanks** to Sam Altman, Trevor Blackwell, Paul Buchheit, and Robert Morris<br/>for reading drafts of this.  <br/>  <br/><br/>Russian Translation  <br/><br/>Portuguese Translation  <br/><br/>Romanian Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>December 2014  <br/>  <br/>American technology companies want the government to make immigration easier<br/>because they say they can't find enough programmers in the US. Anti-<br/>immigration people say that instead of letting foreigners take these jobs, we<br/>should train more Americans to be programmers. Who's right?  <br/>  <br/>The technology companies are right. What the anti-immigration people don't<br/>understand is that there is a huge variation in ability between competent<br/>programmers and exceptional ones, and while you can train people to be<br/>competent, you can't train them to be exceptional. Exceptional programmers<br/>have an aptitude for and interest in programming that is not merely the<br/>product of training. [1]  <br/>  <br/>The US has less than 5% of the world's population. Which means if the<br/>qualities that make someone a great programmer are evenly distributed, 95% of<br/>great programmers are born outside the US.  <br/>  <br/>The anti-immigration people have to invent some explanation to account for all<br/>the effort technology companies have expended trying to make immigration<br/>easier. So they claim it's because they want to drive down salaries. But if<br/>you talk to startups, you find practically every one over a certain size has<br/>gone through legal contortions to get programmers into the US, where they then<br/>paid them the same as they'd have paid an American. Why would they go to extra<br/>trouble to get programmers for the same price? The only explanation is that<br/>they're telling the truth: there are just not enough great programmers to go<br/>around. [2]  <br/>  <br/>I asked the CEO of a startup with about 70 programmers how many more he'd hire<br/>if he could get all the great programmers he wanted. He said "We'd hire 30<br/>tomorrow morning." And this is one of the hot startups that always win<br/>recruiting battles. It's the same all over Silicon Valley. Startups are that<br/>constrained for talent.  <br/>  <br/>It would be great if more Americans were trained as programmers, but no amount<br/>of training can flip a ratio as overwhelming as 95 to 5. Especially since<br/>programmers are being trained in other countries too. Barring some cataclysm,<br/>it will always be true that most great programmers are born outside the US. It<br/>will always be true that most people who are great at anything are born<br/>outside the US. [3]  <br/>  <br/>Exceptional performance implies immigration. A country with only a few percent<br/>of the world's population will be exceptional in some field only if there are<br/>a lot of immigrants working in it.  <br/>  <br/>But this whole discussion has taken something for granted: that if we let more<br/>great programmers into the US, they'll want to come. That's true now, and we<br/>don't realize how lucky we are that it is. If we want to keep this option<br/>open, the best way to do it is to take advantage of it: the more of the<br/>world's great programmers are here, the more the rest will want to come here.  <br/>  <br/>And if we don't, the US could be seriously fucked. I realize that's strong<br/>language, but the people dithering about this don't seem to realize the power<br/>of the forces at work here. Technology gives the best programmers huge<br/>leverage. The world market in programmers seems to be becoming dramatically<br/>more liquid. And since good people like good colleagues, that means the best<br/>programmers could collect in just a few hubs. Maybe mostly in one hub.  <br/>  <br/>What if most of the great programmers collected in one hub, and it wasn't<br/>here? That scenario may seem unlikely now, but it won't be if things change as<br/>much in the next 50 years as they did in the last 50.  <br/>  <br/>We have the potential to ensure that the US remains a technology superpower<br/>just by letting in a few thousand great programmers a year. What a colossal<br/>mistake it would be to let that opportunity slip. It could easily be the<br/>defining mistake this generation of American politicians later become famous<br/>for. And unlike other potential mistakes on that scale, it costs nothing to<br/>fix.  <br/>  <br/>So please, get on with it.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] How much better is a great programmer than an ordinary one? So much better<br/>that you can't even measure the difference directly. A great programmer<br/>doesn't merely do the same work faster. A great programmer will invent things<br/>an ordinary programmer would never even think of. This doesn't mean a great<br/>programmer is infinitely more valuable, because any invention has a finite<br/>market value. But it's easy to imagine cases where a great programmer might<br/>invent things worth 100x or even 1000x an average programmer's salary.  <br/>  <br/>[2] There are a handful of consulting firms that rent out big pools of foreign<br/>programmers they bring in on H1-B visas. By all means crack down on these. It<br/>should be easy to write legislation that distinguishes them, because they are<br/>so different from technology companies. But it is dishonest of the anti-<br/>immigration people to claim that companies like Google and Facebook are driven<br/>by the same motives. An influx of inexpensive but mediocre programmers is the<br/>last thing they'd want; it would destroy them.  <br/>  <br/>[3] Though this essay talks about programmers, the group of people we need to<br/>import is broader, ranging from designers to programmers to electrical<br/>engineers. The best one could do as a general term might be "digital talent."<br/>It seemed better to make the argument a little too narrow than to confuse<br/>everyone with a neologism.  <br/>  <br/>**Thanks** to Sam Altman, John Collison, Patrick Collison, Jessica Livingston,<br/>Geoff Ralston, Fred Wilson, and Qasar Younis for reading drafts of this.  <br/>  <br/><br/>Spanish Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>December 2019  <br/>  <br/>The most damaging thing you learned in school wasn't something you learned in<br/>any specific class. It was learning to get good grades.  <br/>  <br/>When I was in college, a particularly earnest philosophy grad student once<br/>told me that he never cared what grade he got in a class, only what he learned<br/>in it. This stuck in my mind because it was the only time I ever heard anyone<br/>say such a thing.  <br/>  <br/>For me, as for most students, the measurement of what I was learning<br/>completely dominated actual learning in college. I was fairly earnest; I was<br/>genuinely interested in most of the classes I took, and I worked hard. And yet<br/>I worked by far the hardest when I was studying for a test.  <br/>  <br/>In theory, tests are merely what their name implies: tests of what you've<br/>learned in the class. In theory you shouldn't have to prepare for a test in a<br/>class any more than you have to prepare for a blood test. In theory you learn<br/>from taking the class, from going to the lectures and doing the reading and/or<br/>assignments, and the test that comes afterward merely measures how well you<br/>learned.  <br/>  <br/>In practice, as almost everyone reading this will know, things are so<br/>different that hearing this explanation of how classes and tests are meant to<br/>work is like hearing the etymology of a word whose meaning has changed<br/>completely. In practice, the phrase "studying for a test" was almost<br/>redundant, because that was when one really studied. The difference between<br/>diligent and slack students was that the former studied hard for tests and the<br/>latter didn't. No one was pulling all-nighters two weeks into the semester.  <br/>  <br/>Even though I was a diligent student, almost all the work I did in school was<br/>aimed at getting a good grade on something.  <br/>  <br/>To many people, it would seem strange that the preceding sentence has a<br/>"though" in it. Aren't I merely stating a tautology? Isn't that what a<br/>diligent student is, a straight-A student? That's how deeply the conflation of<br/>learning with grades has infused our culture.  <br/>  <br/>Is it so bad if learning is conflated with grades? Yes, it is bad. And it<br/>wasn't till decades after college, when I was running Y Combinator, that I<br/>realized how bad it is.  <br/>  <br/>I knew of course when I was a student that studying for a test is far from<br/>identical with actual learning. At the very least, you don't retain knowledge<br/>you cram into your head the night before an exam. But the problem is worse<br/>than that. The real problem is that most tests don't come close to measuring<br/>what they're supposed to.  <br/>  <br/>If tests truly were tests of learning, things wouldn't be so bad. Getting good<br/>grades and learning would converge, just a little late. The problem is that<br/>nearly all tests given to students are terribly hackable. Most people who've<br/>gotten good grades know this, and know it so well they've ceased even to<br/>question it. You'll see when you realize how naive it sounds to act otherwise.  <br/>  <br/>Suppose you're taking a class on medieval history and the final exam is coming<br/>up. The final exam is supposed to be a test of your knowledge of medieval<br/>history, right? So if you have a couple days between now and the exam, surely<br/>the best way to spend the time, if you want to do well on the exam, is to read<br/>the best books you can find about medieval history. Then you'll know a lot<br/>about it, and do well on the exam.  <br/>  <br/>No, no, no, experienced students are saying to themselves. If you merely read<br/>good books on medieval history, most of the stuff you learned wouldn't be on<br/>the test. It's not good books you want to read, but the lecture notes and<br/>assigned reading in this class. And even most of that you can ignore, because<br/>you only have to worry about the sort of thing that could turn up as a test<br/>question. You're looking for sharply-defined chunks of information. If one of<br/>the assigned readings has an interesting digression on some subtle point, you<br/>can safely ignore that, because it's not the sort of thing that could be<br/>turned into a test question. But if the professor tells you that there were<br/>three underlying causes of the Schism of 1378, or three main consequences of<br/>the Black Death, you'd better know them. And whether they were in fact the<br/>causes or consequences is beside the point. For the purposes of this class<br/>they are.  <br/>  <br/>At a university there are often copies of old exams floating around, and these<br/>narrow still further what you have to learn. As well as learning what kind of<br/>questions this professor asks, you'll often get actual exam questions. Many<br/>professors re-use them. After teaching a class for 10 years, it would be hard<br/>not to, at least inadvertently.  <br/>  <br/>In some classes, your professor will have had some sort of political axe to<br/>grind, and if so you'll have to grind it too. The need for this varies. In<br/>classes in math or the hard sciences or engineering it's rarely necessary, but<br/>at the other end of the spectrum there are classes where you couldn't get a<br/>good grade without it.  <br/>  <br/>Getting a good grade in a class on x is so different from learning a lot about<br/>x that you have to choose one or the other, and you can't blame students if<br/>they choose grades. Everyone judges them by their grades graduate programs,<br/>employers, scholarships, even their own parents.  <br/>  <br/>I liked learning, and I really enjoyed some of the papers and programs I wrote<br/>in college. But did I ever, after turning in a paper in some class, sit down<br/>and write another just for fun? Of course not. I had things due in other<br/>classes. If it ever came to a choice of learning or grades, I chose grades. I<br/>hadn't come to college to do badly.  <br/>  <br/>Anyone who cares about getting good grades has to play this game, or they'll<br/>be surpassed by those who do. And at elite universities, that means nearly<br/>everyone, since someone who didn't care about getting good grades probably<br/>wouldn't be there in the first place. The result is that students compete to<br/>maximize the difference between learning and getting good grades.  <br/>  <br/>Why are tests so bad? More precisely, why are they so hackable? Any<br/>experienced programmer could answer that. How hackable is software whose<br/>author hasn't paid any attention to preventing it from being hacked? Usually<br/>it's as porous as a colander.  <br/>  <br/>Hackable is the default for any test imposed by an authority. The reason the<br/>tests you're given are so consistently bad so consistently far from measuring<br/>what they're supposed to measure  is simply that the people creating them<br/>haven't made much effort to prevent them from being hacked.  <br/>  <br/>But you can't blame teachers if their tests are hackable. Their job is to<br/>teach, not to create unhackable tests. The real problem is grades, or more<br/>precisely, that grades have been overloaded. If grades were merely a way for<br/>teachers to tell students what they were doing right and wrong, like a coach<br/>giving advice to an athlete, students wouldn't be tempted to hack tests. But<br/>unfortunately after a certain age grades become more than advice. After a<br/>certain age, whenever you're being taught, you're usually also being judged.  <br/>  <br/>I've used college tests as an example, but those are actually the least<br/>hackable. All the tests most students take their whole lives are at least as<br/>bad, including, most spectacularly of all, the test that gets them into<br/>college. If getting into college were merely a matter of having the quality of<br/>one's mind measured by admissions officers the way scientists measure the mass<br/>of an object, we could tell teenage kids "learn a lot" and leave it at that.<br/>You can tell how bad college admissions are, as a test, from how unlike high<br/>school that sounds. In practice, the freakishly specific nature of the stuff<br/>ambitious kids have to do in high school is directly proportionate to the<br/>hackability of college admissions. The classes you don't care about that are<br/>mostly memorization, the random "extracurricular activities" you have to<br/>participate in to show you're "well-rounded," the standardized tests as<br/>artificial as chess, the "essay" you have to write that's presumably meant to<br/>hit some very specific target, but you're not told what.  <br/>  <br/>As well as being bad in what it does to kids, this test is also bad in the<br/>sense of being very hackable. So hackable that whole industries have grown up<br/>to hack it. This is the explicit purpose of test-prep companies and admissions<br/>counsellors, but it's also a significant part of the function of private<br/>schools.  <br/>  <br/>Why is this particular test so hackable? I think because of what it's<br/>measuring. Although the popular story is that the way to get into a good<br/>college is to be really smart, admissions officers at elite colleges neither<br/>are, nor claim to be, looking only for that. What are they looking for?<br/>They're looking for people who are not simply smart, but admirable in some<br/>more general sense. And how is this more general admirableness measured? The<br/>admissions officers feel it. In other words, they accept who they like.  <br/>  <br/>So what college admissions is a test of is whether you suit the taste of some<br/>group of people. Well, of course a test like that is going to be hackable. And<br/>because it's both very hackable and there's (thought to be) a lot at stake,<br/>it's hacked like nothing else. That's why it distorts your life so much for so<br/>long.  <br/>  <br/>It's no wonder high school students often feel alienated. The shape of their<br/>lives is completely artificial.  <br/>  <br/>But wasting your time is not the worst thing the educational system does to<br/>you. The worst thing it does is to train you that the way to win is by hacking<br/>bad tests. This is a much subtler problem that I didn't recognize until I saw<br/>it happening to other people.  <br/>  <br/>When I started advising startup founders at Y Combinator, especially young<br/>ones, I was puzzled by the way they always seemed to make things<br/>overcomplicated. How, they would ask, do you raise money? What's the trick for<br/>making venture capitalists want to invest in you? The best way to make VCs<br/>want to invest in you, I would explain, is to actually be a good investment.<br/>Even if you could trick VCs into investing in a bad startup, you'd be tricking<br/>yourselves too. You're investing time in the same company you're asking them<br/>to invest money in. If it's not a good investment, why are you even doing it?  <br/>  <br/>Oh, they'd say, and then after a pause to digest this revelation, they'd ask:<br/>What makes a startup a good investment?  <br/>  <br/>So I would explain that what makes a startup promising, not just in the eyes<br/>of investors but in fact, is _growth_. Ideally in revenue, but failing that in<br/>usage. What they needed to do was get lots of users.  <br/>  <br/>How does one get lots of users? They had all kinds of ideas about that. They<br/>needed to do a big launch that would get them "exposure." They needed<br/>influential people to talk about them. They even knew they needed to launch on<br/>a tuesday, because that's when one gets the most attention.  <br/>  <br/>No, I would explain, that is not how to get lots of users. The way you get<br/>lots of users is to make the product really great. Then people will not only<br/>use it but recommend it to their friends, so your growth will be exponential<br/>once you _get it started_.  <br/>  <br/>At this point I've told the founders something you'd think would be completely<br/>obvious: that they should make a good company by making a good product. And<br/>yet their reaction would be something like the reaction many physicists must<br/>have had when they first heard about the theory of relativity: a mixture of<br/>astonishment at its apparent genius, combined with a suspicion that anything<br/>so weird couldn't possibly be right. Ok, they would say, dutifully. And could<br/>you introduce us to such-and-such influential person? And remember, we want to<br/>launch on Tuesday.  <br/>  <br/>It would sometimes take founders years to grasp these simple lessons. And not<br/>because they were lazy or stupid. They just seemed blind to what was right in<br/>front of them.  <br/>  <br/>Why, I would ask myself, do they always make things so complicated? And then<br/>one day I realized this was not a rhetorical question.  <br/>  <br/>Why did founders tie themselves in knots doing the wrong things when the<br/>answer was right in front of them? Because that was what they'd been trained<br/>to do. Their education had taught them that the way to win was to hack the<br/>test. And without even telling them they were being trained to do this. The<br/>younger ones, the recent graduates, had never faced a non-artificial test.<br/>They thought this was just how the world worked: that the first thing you did,<br/>when facing any kind of challenge, was to figure out what the trick was for<br/>hacking the test. That's why the conversation would always start with how to<br/>raise money, because that read as the test. It came at the end of YC. It had<br/>numbers attached to it, and higher numbers seemed to be better. It must be the<br/>test.  <br/>  <br/>There are certainly big chunks of the world where the way to win is to hack<br/>the test. This phenomenon isn't limited to schools. And some people, either<br/>due to ideology or ignorance, claim that this is true of startups too. But it<br/>isn't. In fact, one of the most striking things about startups is the degree<br/>to which you win by simply doing good work. There are edge cases, as there are<br/>in anything, but in general you win by getting users, and what users care<br/>about is whether the product does what they want.  <br/>  <br/>Why did it take me so long to understand why founders made startups<br/>overcomplicated? Because I hadn't realized explicitly that schools train us to<br/>win by hacking bad tests. And not just them, but me! I'd been trained to hack<br/>bad tests too, and hadn't realized it till decades later.  <br/>  <br/>I had lived as if I realized it, but without knowing why. For example, I had<br/>avoided working for big companies. But if you'd asked why, I'd have said it<br/>was because they were bogus, or bureaucratic. Or just yuck. I never understood<br/>how much of my dislike of big companies was due to the fact that you win by<br/>hacking bad tests.  <br/>  <br/>Similarly, the fact that the tests were unhackable was a lot of what attracted<br/>me to startups. But again, I hadn't realized that explicitly.  <br/>  <br/>I had in effect achieved by successive approximations something that may have<br/>a closed-form solution. I had gradually undone my training in hacking bad<br/>tests without knowing I was doing it. Could someone coming out of school<br/>banish this demon just by knowing its name, and saying begone? It seems worth<br/>trying.  <br/>  <br/>Merely talking explicitly about this phenomenon is likely to make things<br/>better, because much of its power comes from the fact that we take it for<br/>granted. After you've noticed it, it seems the elephant in the room, but it's<br/>a pretty well camouflaged elephant. The phenomenon is so old, and so<br/>pervasive. And it's simply the result of neglect. No one meant things to be<br/>this way. This is just what happens when you combine learning with grades,<br/>competition, and the naive assumption of unhackability.  <br/>  <br/>It was mind-blowing to realize that two of the things I'd puzzled about the<br/>most  the bogusness of high school, and the difficulty of getting founders to<br/>see the obvious  both had the same cause. It's rare for such a big block to<br/>slide into place so late.  <br/>  <br/>Usually when that happens it has implications in a lot of different areas, and<br/>this case seems no exception. For example, it suggests both that education<br/>could be done better, and how you might fix it. But it also suggests a<br/>potential answer to the question all big companies seem to have: how can we be<br/>more like a startup? I'm not going to chase down all the implications now.<br/>What I want to focus on here is what it means for individuals.  <br/>  <br/>To start with, it means that most ambitious kids graduating from college have<br/>something they may want to unlearn. But it also changes how you look at the<br/>world. Instead of looking at all the different kinds of work people do and<br/>thinking of them vaguely as more or less appealing, you can now ask a very<br/>specific question that will sort them in an interesting way: to what extent do<br/>you win at this kind of work by hacking bad tests?  <br/>  <br/>It would help if there was a way to recognize bad tests quickly. Is there a<br/>pattern here? It turns out there is.  <br/>  <br/>Tests can be divided into two kinds: those that are imposed by authorities,<br/>and those that aren't. Tests that aren't imposed by authorities are inherently<br/>unhackable, in the sense that no one is claiming they're tests of anything<br/>more than they actually test. A football match, for example, is simply a test<br/>of who wins, not which team is better. You can tell that from the fact that<br/>commentators sometimes say afterward that the better team won. Whereas tests<br/>imposed by authorities are usually proxies for something else. A test in a<br/>class is supposed to measure not just how well you did on that particular<br/>test, but how much you learned in the class. While tests that aren't imposed<br/>by authorities are inherently unhackable, those imposed by authorities have to<br/>be made unhackable. Usually they aren't. So as a first approximation, bad<br/>tests are roughly equivalent to tests imposed by authorities.  <br/>  <br/>You might actually like to win by hacking bad tests. Presumably some people<br/>do. But I bet most people who find themselves doing this kind of work don't<br/>like it. They just take it for granted that this is how the world works,<br/>unless you want to drop out and be some kind of hippie artisan.  <br/>  <br/>I suspect many people implicitly assume that working in a field with bad tests<br/>is the price of making lots of money. But that, I can tell you, is false. It<br/>used to be true. In the mid-twentieth century, when the economy was _composed<br/>of oligopolies_, the only way to the top was by playing their game. But it's<br/>not true now. There are now ways to get rich by doing good work, and that's<br/>part of the reason people are so much more excited about getting rich than<br/>they used to be. When I was a kid, you could either become an engineer and<br/>make cool things, or make lots of money by becoming an "executive." Now you<br/>can make lots of money by making cool things.  <br/>  <br/>Hacking bad tests is becoming less important as the link between work and<br/>authority erodes. The erosion of that link is one of the most important trends<br/>happening now, and we see its effects in almost every kind of work people do.<br/>Startups are one of the most visible examples, but we see much the same thing<br/>in writing. Writers no longer have to submit to publishers and editors to<br/>reach readers; now they can go direct.  <br/>  <br/>The more I think about this question, the more optimistic I get. This seems<br/>one of those situations where we don't realize how much something was holding<br/>us back until it's eliminated. And I can foresee the whole bogus edifice<br/>crumbling. Imagine what happens as more and more people start to ask<br/>themselves if they want to win by hacking bad tests, and decide that they<br/>don't. The kinds of work where you win by hacking bad tests will be starved of<br/>talent, and the kinds where you win by doing good work will see an influx of<br/>the most ambitious people. And as hacking bad tests shrinks in importance,<br/>education will evolve to stop training us to do it. Imagine what the world<br/>could look like if that happened.  <br/>  <br/>This is not just a lesson for individuals to unlearn, but one for society to<br/>unlearn, and we'll be amazed at the energy that's liberated when we do.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] If using tests only to measure learning sounds impossibly utopian, that is<br/>already the way things work at Lambda School. Lambda School doesn't have<br/>grades. You either graduate or you don't. The only purpose of tests is to<br/>decide at each stage of the curriculum whether you can continue to the next.<br/>So in effect the whole school is pass/fail.  <br/>  <br/>[2] If the final exam consisted of a long conversation with the professor, you<br/>could prepare for it by reading good books on medieval history. A lot of the<br/>hackability of tests in schools is due to the fact that the same test has to<br/>be given to large numbers of students.  <br/>  <br/>[3] Learning is the naive algorithm for getting good grades.  <br/>  <br/>[4] _Hacking_ has multiple senses. There's a narrow sense in which it means to<br/>compromise something. That's the sense in which one hacks a bad test. But<br/>there's another, more general sense, meaning to find a surprising solution to<br/>a problem, often by thinking differently about it. Hacking in this sense is a<br/>wonderful thing. And indeed, some of the hacks people use on bad tests are<br/>impressively ingenious; the problem is not so much the hacking as that,<br/>because the tests are hackable, they don't test what they're meant to.  <br/>  <br/>[5] The people who pick startups at Y Combinator are similar to admissions<br/>officers, except that instead of being arbitrary, their acceptance criteria<br/>are trained by a very tight feedback loop. If you accept a bad startup or<br/>reject a good one, you will usually know it within a year or two at the<br/>latest, and often within a month.  <br/>  <br/>[6] I'm sure admissions officers are tired of reading applications from kids<br/>who seem to have no personality beyond being willing to seem however they're<br/>supposed to seem to get accepted. What they don't realize is that they are, in<br/>a sense, looking in a mirror. The lack of authenticity in the applicants is a<br/>reflection of the arbitrariness of the application process. A dictator might<br/>just as well complain about the lack of authenticity in the people around him.  <br/>  <br/>[7] By good work, I don't mean morally good, but good in the sense in which a<br/>good craftsman does good work.  <br/>  <br/>[8] There are borderline cases where it's hard to say which category a test<br/>falls in. For example, is raising venture capital like college admissions, or<br/>is it like selling to a customer?  <br/>  <br/>[9] Note that a good test is merely one that's unhackable. Good here doesn't<br/>mean morally good, but good in the sense of working well. The difference<br/>between fields with bad tests and good ones is not that the former are bad and<br/>the latter are good, but that the former are bogus and the latter aren't. But<br/>those two measures are not unrelated. As Tara Ploughman said, the path from<br/>good to evil goes through bogus.  <br/>  <br/>[10] People who think the recent increase in _economy inequality_ is due to<br/>changes in tax policy seem very naive to anyone with experience in startups.<br/>Different people are getting rich now than used to, and they're getting much<br/>richer than mere tax savings could make them.  <br/>  <br/>[11] Note to tiger parents: you may think you're training your kids to win,<br/>but if you're training them to win by hacking bad tests, you are, as parents<br/>so often do, training them to fight the last war.  <br/>  <br/>  <br/>  <br/> **Thanks** to Austen Allred, Trevor Blackwell, Patrick Collison, Jessica<br/>Livingston, Robert Morris, and Harj Taggar for reading drafts of this.  <br/>  <br/><br/>Russian Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>August 2004  <br/>  <br/>In a recent talk I said something that upset a lot of people: that you could<br/>get smarter programmers to work on a Python project than you could to work on<br/>a Java project.  <br/>  <br/>I didn't mean by this that Java programmers are dumb. I meant that Python<br/>programmers are smart. It's a lot of work to learn a new programming language.<br/>And people don't learn Python because it will get them a job; they learn it<br/>because they genuinely like to program and aren't satisfied with the languages<br/>they already know.  <br/>  <br/>Which makes them exactly the kind of programmers companies should want to<br/>hire. Hence what, for lack of a better name, I'll call the Python paradox: if<br/>a company chooses to write its software in a comparatively esoteric language,<br/>they'll be able to hire better programmers, because they'll attract only those<br/>who cared enough to learn it. And for programmers the paradox is even more<br/>pronounced: the language to learn, if you want to get a good job, is a<br/>language that people don't learn merely to get a job.  <br/>  <br/>Only a few companies have been smart enough to realize this so far. But there<br/>is a kind of selection going on here too: they're exactly the companies<br/>programmers would most like to work for. Google, for example. When they<br/>advertise Java programming jobs, they also want Python experience.  <br/>  <br/>A friend of mine who knows nearly all the widely used languages uses Python<br/>for most of his projects. He says the main reason is that he likes the way<br/>source code looks. That may seem a frivolous reason to choose one language<br/>over another. But it is not so frivolous as it sounds: when you program, you<br/>spend more time reading code than writing it. You push blobs of source code<br/>around the way a sculptor does blobs of clay. So a language that makes source<br/>code ugly is maddening to an exacting programmer, as clay full of lumps would<br/>be to a sculptor.  <br/>  <br/>At the mention of ugly source code, people will of course think of Perl. But<br/>the superficial ugliness of Perl is not the sort I mean. Real ugliness is not<br/>harsh-looking syntax, but having to build programs out of the wrong concepts.<br/>Perl may look like a cartoon character swearing, but there are cases where it<br/>surpasses Python conceptually.  <br/>  <br/>So far, anyway. Both languages are of course moving targets. But they share,<br/>along with Ruby (and Icon, and Joy, and J, and Lisp, and Smalltalk) the fact<br/>that they're created by, and used by, people who really care about<br/>programming. And those tend to be the ones who do it well.  <br/>  <br/><br/>Turkish Translation  <br/><br/>Japanese Translation  <br/><br/>Portuguese Translation  <br/><br/>Italian Translation  <br/><br/>Polish Translation  <br/><br/>Romanian Translation  <br/><br/>Russian Translation  <br/><br/>Spanish Translation  <br/><br/>French Translation  <br/><br/>Telugu Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>January 2012  <br/>  <br/>A year ago I noticed a pattern in the least successful startups we'd funded:<br/>they all seemed hard to talk to. It felt as if there was some kind of wall<br/>between us. I could never quite tell if they understood what I was saying.  <br/>  <br/>This caught my attention because earlier we'd noticed a pattern among the most<br/>successful startups, and it seemed to hinge on a different quality. We found<br/>the startups that did best were the ones with the sort of founders about whom<br/>we'd say "they can take care of themselves." The startups that do best are<br/>fire-and-forget in the sense that all you have to do is give them a lead, and<br/>they'll close it, whatever type of lead it is. When they're raising money, for<br/>example, you can do the initial intros knowing that if you wanted to you could<br/>stop thinking about it at that point. You won't have to babysit the round to<br/>make sure it happens. That type of founder is going to come back with the<br/>money; the only question is how much on what terms.  <br/>  <br/>It seemed odd that the outliers at the two ends of the spectrum could be<br/>detected by what appeared to be unrelated tests. You'd expect that if the<br/>founders at one end were distinguished by the presence of quality x, at the<br/>other end they'd be distinguished by lack of x. Was there some kind of inverse<br/>relation between resourcefulness and being hard to talk to?  <br/>  <br/>It turns out there is, and the key to the mystery is the old adage "a word to<br/>the wise is sufficient." Because this phrase is not only overused, but<br/>overused in an indirect way (by prepending the subject to some advice), most<br/>people who've heard it don't know what it means. What it means is that if<br/>someone is wise, all you have to do is say one word to them, and they'll<br/>understand immediately. You don't have to explain in detail; they'll chase<br/>down all the implications.  <br/>  <br/>In much the same way that all you have to do is give the right sort of founder<br/>a one line intro to a VC, and he'll chase down the money. That's the<br/>connection. Understanding all the implications — even the inconvenient<br/>implications — of what someone tells you is a subset of resourcefulness. It's<br/>conversational resourcefulness.  <br/>  <br/>Like real world resourcefulness, conversational resourcefulness often means<br/>doing things you don't want to. Chasing down all the implications of what's<br/>said to you can sometimes lead to uncomfortable conclusions. The best word to<br/>describe the failure to do so is probably "denial," though that seems a bit<br/>too narrow. A better way to describe the situation would be to say that the<br/>unsuccessful founders had the sort of conservatism that comes from weakness.<br/>They traversed idea space as gingerly as a very old person traverses the<br/>physical world. [1]  <br/>  <br/>The unsuccessful founders weren't stupid. Intellectually they were as capable<br/>as the successful founders of following all the implications of what one said<br/>to them. They just weren't eager to.  <br/>  <br/>So being hard to talk to was not what was killing the unsuccessful startups.<br/>It was a sign of an underlying lack of resourcefulness. That's what was<br/>killing them. As well as failing to chase down the implications of what was<br/>said to them, the unsuccessful founders would also fail to chase down funding,<br/>and users, and sources of new ideas. But the most immediate evidence I had<br/>that something was amiss was that I couldn't talk to them.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] A YC partner wrote:  <br/>  <br/>My feeling with the bad groups is that coming into office hours, they've<br/>already decided what they're going to do and everything I say is being put<br/>through an internal process in their heads, which either desperately tries to<br/>munge what I've said into something that conforms with their decision or just<br/>outright dismisses it and creates a rationalization for doing so. They may not<br/>even be conscious of this process but that's what I think is happening when<br/>you say something to bad groups and they have that glazed over look. I don't<br/>think it's confusion or lack of understanding per se, it's this internal<br/>process at work.  <br/>  <br/>With the good groups, you can tell that everything you say is being looked at<br/>with fresh eyes and even if it's dismissed, it's because of some logical<br/>reason e.g. "we already tried that" or "from speaking to our users that isn't<br/>what they'd like," etc. Those groups never have that glazed over look.  <br/>  <br/>  <br/>  <br/> **Thanks** to Sam Altman, Patrick Collison, Aaron Iba, Jessica Livingston,<br/>Robert Morris, Harj Taggar, and Garry Tan for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>December 2005  <br/>  <br/>The most impressive people I know are all terrible procrastinators. So could<br/>it be that procrastination isn't always bad?  <br/>  <br/>Most people who write about procrastination write about how to cure it. But<br/>this is, strictly speaking, impossible. There are an infinite number of things<br/>you could be doing. No matter what you work on, you're not working on<br/>everything else. So the question is not how to avoid procrastination, but how<br/>to procrastinate well.  <br/>  <br/>There are three variants of procrastination, depending on what you do instead<br/>of working on something: you could work on (a) nothing, (b) something less<br/>important, or (c) something more important. That last type, I'd argue, is good<br/>procrastination.  <br/>  <br/>That's the "absent-minded professor," who forgets to shave, or eat, or even<br/>perhaps look where he's going while he's thinking about some interesting<br/>question. His mind is absent from the everyday world because it's hard at work<br/>in another.  <br/>  <br/>That's the sense in which the most impressive people I know are all<br/>procrastinators. They're type-C procrastinators: they put off working on small<br/>stuff to work on big stuff.  <br/>  <br/>What's "small stuff?" Roughly, work that has zero chance of being mentioned in<br/>your obituary. It's hard to say at the time what will turn out to be your best<br/>work (will it be your magnum opus on Sumerian temple architecture, or the<br/>detective thriller you wrote under a pseudonym?), but there's a whole class of<br/>tasks you can safely rule out: shaving, doing your laundry, cleaning the<br/>house, writing thank-you notes—anything that might be called an errand.  <br/>  <br/>Good procrastination is avoiding errands to do real work.  <br/>  <br/>Good in a sense, at least. The people who want you to do the errands won't<br/>think it's good. But you probably have to annoy them if you want to get<br/>anything done. The mildest seeming people, if they want to do real work, all<br/>have a certain degree of ruthlessness when it comes to avoiding errands.  <br/>  <br/>Some errands, like replying to letters, go away if you ignore them (perhaps<br/>taking friends with them). Others, like mowing the lawn, or filing tax<br/>returns, only get worse if you put them off. In principle it shouldn't work to<br/>put off the second kind of errand. You're going to have to do whatever it is<br/>eventually. Why not (as past-due notices are always saying) do it now?  <br/>  <br/>The reason it pays to put off even those errands is that real work needs two<br/>things errands don't: big chunks of time, and the right mood. If you get<br/>inspired by some project, it can be a net win to blow off everything you were<br/>supposed to do for the next few days to work on it. Yes, those errands may<br/>cost you more time when you finally get around to them. But if you get a lot<br/>done during those few days, you will be net more productive.  <br/>  <br/>In fact, it may not be a difference in degree, but a difference in kind. There<br/>may be types of work that can only be done in long, uninterrupted stretches,<br/>when inspiration hits, rather than dutifully in scheduled little slices.<br/>Empirically it seems to be so. When I think of the people I know who've done<br/>great things, I don't imagine them dutifully crossing items off to-do lists. I<br/>imagine them sneaking off to work on some new idea.  <br/>  <br/>Conversely, forcing someone to perform errands synchronously is bound to limit<br/>their productivity. The cost of an interruption is not just the time it takes,<br/>but that it breaks the time on either side in half. You probably only have to<br/>interrupt someone a couple times a day before they're unable to work on hard<br/>problems at all.  <br/>  <br/>I've wondered a lot about why startups are most productive at the very<br/>beginning, when they're just a couple guys in an apartment. The main reason<br/>may be that there's no one to interrupt them yet. In theory it's good when the<br/>founders finally get enough money to hire people to do some of the work for<br/>them. But it may be better to be overworked than interrupted. Once you dilute<br/>a startup with ordinary office workers—with type-B procrastinators—the whole<br/>company starts to resonate at their frequency. They're interrupt-driven, and<br/>soon you are too.  <br/>  <br/>Errands are so effective at killing great projects that a lot of people use<br/>them for that purpose. Someone who has decided to write a novel, for example,<br/>will suddenly find that the house needs cleaning. People who fail to write<br/>novels don't do it by sitting in front of a blank page for days without<br/>writing anything. They do it by feeding the cat, going out to buy something<br/>they need for their apartment, meeting a friend for coffee, checking email. "I<br/>don't have time to work," they say. And they don't; they've made sure of that.  <br/>  <br/>(There's also a variant where one has no place to work. The cure is to visit<br/>the places where famous people worked, and see how unsuitable they were.)  <br/>  <br/>I've used both these excuses at one time or another. I've learned a lot of<br/>tricks for making myself work over the last 20 years, but even now I don't win<br/>consistently. Some days I get real work done. Other days are eaten up by<br/>errands. And I know it's usually my fault: I _let_ errands eat up the day, to<br/>avoid facing some hard problem.  <br/>  <br/>The most dangerous form of procrastination is unacknowledged type-B<br/>procrastination, because it doesn't feel like procrastination. You're "getting<br/>things done." Just the wrong things.  <br/>  <br/>Any advice about procrastination that concentrates on crossing things off your<br/>to-do list is not only incomplete, but positively misleading, if it doesn't<br/>consider the possibility that the to-do list is itself a form of type-B<br/>procrastination. In fact, possibility is too weak a word. Nearly everyone's<br/>is. Unless you're working on the biggest things you could be working on,<br/>you're type-B procrastinating, no matter how much you're getting done.  <br/>  <br/>In his famous essay You and Your Research (which I recommend to anyone<br/>ambitious, no matter what they're working on), Richard Hamming suggests that<br/>you ask yourself three questions:<br/><br/>  1. What are the most important problems in your field?  <br/>  <br/><br/>  2. Are you working on one of them?  <br/>  <br/><br/>  3. Why not? <br/><br/>Hamming was at Bell Labs when he started asking such questions. In principle<br/>anyone there ought to have been able to work on the most important problems in<br/>their field. Perhaps not everyone can make an equally dramatic mark on the<br/>world; I don't know; but whatever your capacities, there are projects that<br/>stretch them. So Hamming's exercise can be generalized to:<br/><br/>> What's the best thing you could be working on, and why aren't you?<br/><br/>Most people will shy away from this question. I shy away from it myself; I see<br/>it there on the page and quickly move on to the next sentence. Hamming used to<br/>go around actually asking people this, and it didn't make him popular. But<br/>it's a question anyone ambitious should face.  <br/>  <br/>The trouble is, you may end up hooking a very big fish with this bait. To do<br/>good work, you need to do more than find good projects. Once you've found<br/>them, you have to get yourself to work on them, and that can be hard. The<br/>bigger the problem, the harder it is to get yourself to work on it.  <br/>  <br/>Of course, the main reason people find it difficult to work on a particular<br/>problem is that they don't enjoy it. When you're young, especially, you often<br/>find yourself working on stuff you don't really like-- because it seems<br/>impressive, for example, or because you've been assigned to work on it. Most<br/>grad students are stuck working on big problems they don't really like, and<br/>grad school is thus synonymous with procrastination.  <br/>  <br/>But even when you like what you're working on, it's easier to get yourself to<br/>work on small problems than big ones. Why? Why is it so hard to work on big<br/>problems? One reason is that you may not get any reward in the forseeable<br/>future. If you work on something you can finish in a day or two, you can<br/>expect to have a nice feeling of accomplishment fairly soon. If the reward is<br/>indefinitely far in the future, it seems less real.  <br/>  <br/>Another reason people don't work on big projects is, ironically, fear of<br/>wasting time. What if they fail? Then all the time they spent on it will be<br/>wasted. (In fact it probably won't be, because work on hard projects almost<br/>always leads somewhere.)  <br/>  <br/>But the trouble with big problems can't be just that they promise no immediate<br/>reward and might cause you to waste a lot of time. If that were all, they'd be<br/>no worse than going to visit your in-laws. There's more to it than that. Big<br/>problems are _terrifying_. There's an almost physical pain in facing them.<br/>It's like having a vacuum cleaner hooked up to your imagination. All your<br/>initial ideas get sucked out immediately, and you don't have any more, and yet<br/>the vacuum cleaner is still sucking.  <br/>  <br/>You can't look a big problem too directly in the eye. You have to approach it<br/>somewhat obliquely. But you have to adjust the angle just right: you have to<br/>be facing the big problem directly enough that you catch some of the<br/>excitement radiating from it, but not so much that it paralyzes you. You can<br/>tighten the angle once you get going, just as a sailboat can sail closer to<br/>the wind once it gets underway.  <br/>  <br/>If you want to work on big things, you seem to have to trick yourself into<br/>doing it. You have to work on small things that could grow into big things, or<br/>work on successively larger things, or split the moral load with<br/>collaborators. It's not a sign of weakness to depend on such tricks. The very<br/>best work has been done this way.  <br/>  <br/>When I talk to people who've managed to make themselves work on big things, I<br/>find that all blow off errands, and all feel guilty about it. I don't think<br/>they should feel guilty. There's more to do than anyone could. So someone<br/>doing the best work they can is inevitably going to leave a lot of errands<br/>undone. It seems a mistake to feel bad about that.  <br/>  <br/>I think the way to "solve" the problem of procrastination is to let delight<br/>pull you instead of making a to-do list push you. Work on an ambitious project<br/>you really enjoy, and sail as close to the wind as you can, and you'll leave<br/>the right things undone.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Thanks** to Trevor Blackwell, Jessica Livingston, and Robert Morris for<br/>reading drafts of this.  <br/>  <br/><br/>Romanian Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Hebrew Translation  <br/>  <br/><br/>German Translation  <br/>  <br/><br/>Portuguese Translation  <br/>  <br/><br/>Italian Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/><br/><br/>April 2007  <br/>  <br/>There are two different ways people judge you. Sometimes judging you correctly<br/>is the end goal. But there's a second much more common type of judgement where<br/>it isn't. We tend to regard all judgements of us as the first type. We'd<br/>probably be happier if we realized which are and which aren't.  <br/>  <br/>The first type of judgement, the type where judging you is the end goal,<br/>include court cases, grades in classes, and most competitions. Such judgements<br/>can of course be mistaken, but because the goal is to judge you correctly,<br/>there's usually some kind of appeals process. If you feel you've been<br/>misjudged, you can protest that you've been treated unfairly.  <br/>  <br/>Nearly all the judgements made on children are of this type, so we get into<br/>the habit early in life of thinking that all judgements are.  <br/>  <br/>But in fact there is a second much larger class of judgements where judging<br/>you is only a means to something else. These include college admissions,<br/>hiring and investment decisions, and of course the judgements made in dating.<br/>This kind of judgement is not really about you.  <br/>  <br/>Put yourself in the position of someone selecting players for a national team.<br/>Suppose for the sake of simplicity that this is a game with no positions, and<br/>that you have to select 20 players. There will be a few stars who clearly<br/>should make the team, and many players who clearly shouldn't. The only place<br/>your judgement makes a difference is in the borderline cases. Suppose you<br/>screw up and underestimate the 20th best player, causing him not to make the<br/>team, and his place to be taken by the 21st best. You've still picked a good<br/>team. If the players have the usual distribution of ability, the 21st best<br/>player will be only slightly worse than the 20th best. Probably the difference<br/>between them will be less than the measurement error.  <br/>  <br/>The 20th best player may feel he has been misjudged. But your goal here wasn't<br/>to provide a service estimating people's ability. It was to pick a team, and<br/>if the difference between the 20th and 21st best players is less than the<br/>measurement error, you've still done that optimally.  <br/>  <br/>It's a false analogy even to use the word unfair to describe this kind of<br/>misjudgement. It's not aimed at producing a correct estimate of any given<br/>individual, but at selecting a reasonably optimal set.  <br/>  <br/>One thing that leads us astray here is that the selector seems to be in a<br/>position of power. That makes him seem like a judge. If you regard someone<br/>judging you as a customer instead of a judge, the expectation of fairness goes<br/>away. The author of a good novel wouldn't complain that readers were _unfair_<br/>for preferring a potboiler with a racy cover. Stupid, perhaps, but not unfair.  <br/>  <br/>Our early training and our self-centeredness combine to make us believe that<br/>every judgement of us is about us. In fact most aren't. This is a rare case<br/>where being less self-centered will make people more confident. Once you<br/>realize how little most people judging you care about judging you<br/>accurately—once you realize that because of the normal distribution of most<br/>applicant pools, it matters least to judge accurately in precisely the cases<br/>where judgement has the most effect—you won't take rejection so personally.  <br/>  <br/>And curiously enough, taking rejection less personally may help you to get<br/>rejected less often. If you think someone judging you will work hard to judge<br/>you correctly, you can afford to be passive. But the more you realize that<br/>most judgements are greatly influenced by random, extraneous factors—that most<br/>people judging you are more like a fickle novel buyer than a wise and<br/>perceptive magistrate—the more you realize you can do things to influence the<br/>outcome.  <br/>  <br/>One good place to apply this principle is in college applications. Most high<br/>school students applying to college do it with the usual child's mix of<br/>inferiority and self-centeredness: inferiority in that they assume that<br/>admissions committees must be all-seeing; self-centeredness in that they<br/>assume admissions committees care enough about them to dig down into their<br/>application and figure out whether they're good or not. These combine to make<br/>applicants passive in applying and hurt when they're rejected. If college<br/>applicants realized how quick and impersonal most selection processes are,<br/>they'd make more effort to sell themselves, and take the outcome less<br/>personally.  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>March 2007  <br/>  <br/> _(This essay is derived from talks at the 2007 Startup School and the<br/>Berkeley CSUA.)_  <br/>  <br/>We've now been doing Y Combinator long enough to have some data about success<br/>rates. Our first batch, in the summer of 2005, had eight startups in it. Of<br/>those eight, it now looks as if at least four succeeded. Three have been<br/>acquired: Reddit was a merger of two, Reddit and Infogami, and a third was<br/>acquired that we can't talk about yet. Another from that batch was Loopt,<br/>which is doing so well they could probably be acquired in about ten minutes if<br/>they wanted to.  <br/>  <br/>So about half the founders from that first summer, less than two years ago,<br/>are now rich, at least by their standards. (One thing you learn when you get<br/>rich is that there are many degrees of it.)  <br/>  <br/>I'm not ready to predict our success rate will stay as high as 50%. That first<br/>batch could have been an anomaly. But we should be able to do better than the<br/>oft-quoted (and probably made up) standard figure of 10%. I'd feel safe aiming<br/>at 25%.  <br/>  <br/>Even the founders who fail don't seem to have such a bad time. Of those first<br/>eight startups, three are now probably dead. In two cases the founders just<br/>went on to do other things at the end of the summer. I don't think they were<br/>traumatized by the experience. The closest to a traumatic failure was Kiko,<br/>whose founders kept working on their startup for a whole year before being<br/>squashed by Google Calendar. But they ended up happy. They sold their software<br/>on eBay for a quarter of a million dollars. After they paid back their angel<br/>investors, they had about a year's salary each. [1] Then they immediately went<br/>on to start a new and much more exciting startup, Justin.TV.  <br/>  <br/>So here is an even more striking statistic: 0% of that first batch had a<br/>terrible experience. They had ups and downs, like every startup, but I don't<br/>think any would have traded it for a job in a cubicle. And that statistic is<br/>probably not an anomaly. Whatever our long-term success rate ends up being, I<br/>think the rate of people who wish they'd gotten a regular job will stay close<br/>to 0%.  <br/>  <br/>The big mystery to me is: why don't more people start startups? If nearly<br/>everyone who does it prefers it to a regular job, and a significant percentage<br/>get rich, why doesn't everyone want to do this? A lot of people think we get<br/>thousands of applications for each funding cycle. In fact we usually only get<br/>several hundred. Why don't more people apply? And while it must seem to anyone<br/>watching this world that startups are popping up like crazy, the number is<br/>small compared to the number of people with the necessary skills. The great<br/>majority of programmers still go straight from college to cubicle, and stay<br/>there.  <br/>  <br/>It seems like people are not acting in their own interest. What's going on?<br/>Well, I can answer that. Because of Y Combinator's position at the very start<br/>of the venture funding process, we're probably the world's leading experts on<br/>the psychology of people who aren't sure if they want to start a company.  <br/>  <br/>There's nothing wrong with being unsure. If you're a hacker thinking about<br/>starting a startup and hesitating before taking the leap, you're part of a<br/>grand tradition. Larry and Sergey seem to have felt the same before they<br/>started Google, and so did Jerry and Filo before they started Yahoo. In fact,<br/>I'd guess the most successful startups are the ones started by uncertain<br/>hackers rather than gung-ho business guys.  <br/>  <br/>We have some evidence to support this. Several of the most successful startups<br/>we've funded told us later that they only decided to apply at the last moment.<br/>Some decided only hours before the deadline.  <br/>  <br/>The way to deal with uncertainty is to analyze it into components. Most people<br/>who are reluctant to do something have about eight different reasons mixed<br/>together in their heads, and don't know themselves which are biggest. Some<br/>will be justified and some bogus, but unless you know the relative proportion<br/>of each, you don't know whether your overall uncertainty is mostly justified<br/>or mostly bogus.  <br/>  <br/>So I'm going to list all the components of people's reluctance to start<br/>startups, and explain which are real. Then would-be founders can use this as a<br/>checklist to examine their own feelings.  <br/>  <br/>I admit my goal is to increase your self-confidence. But there are two things<br/>different here from the usual confidence-building exercise. One is that I'm<br/>motivated to be honest. Most people in the confidence-building business have<br/>already achieved their goal when you buy the book or pay to attend the seminar<br/>where they tell you how great you are. Whereas if I encourage people to start<br/>startups who shouldn't, I make my own life worse. If I encourage too many<br/>people to apply to Y Combinator, it just means more work for me, because I<br/>have to read all the applications.  <br/>  <br/>The other thing that's going to be different is my approach. Instead of being<br/>positive, I'm going to be negative. Instead of telling you "come on, you can<br/>do it" I'm going to consider all the reasons you aren't doing it, and show why<br/>most (but not all) should be ignored. We'll start with the one everyone's born<br/>with.  <br/>  <br/> **1\. Too young**  <br/>  <br/>A lot of people think they're too young to start a startup. Many are right.<br/>The median age worldwide is about 27, so probably a third of the population<br/>can truthfully say they're too young.  <br/>  <br/>What's too young? One of our goals with Y Combinator was to discover the lower<br/>bound on the age of startup founders. It always seemed to us that investors<br/>were too conservative here—that they wanted to fund professors, when really<br/>they should be funding grad students or even undergrads.  <br/>  <br/>The main thing we've discovered from pushing the edge of this envelope is not<br/>where the edge is, but how fuzzy it is. The outer limit may be as low as 16.<br/>We don't look beyond 18 because people younger than that can't legally enter<br/>into contracts. But the most successful founder we've funded so far, Sam<br/>Altman, was 19 at the time.  <br/>  <br/>Sam Altman, however, is an outlying data point. When he was 19, he seemed like<br/>he had a 40 year old inside him. There are other 19 year olds who are 12<br/>inside.  <br/>  <br/>There's a reason we have a distinct word "adult" for people over a certain<br/>age. There is a threshold you cross. It's conventionally fixed at 21, but<br/>different people cross it at greatly varying ages. You're old enough to start<br/>a startup if you've crossed this threshold, whatever your age.  <br/>  <br/>How do you tell? There are a couple tests adults use. I realized these tests<br/>existed after meeting Sam Altman, actually. I noticed that I felt like I was<br/>talking to someone much older. Afterward I wondered, what am I even measuring?<br/>What made him seem older?  <br/>  <br/>One test adults use is whether you still have the kid flake reflex. When<br/>you're a little kid and you're asked to do something hard, you can cry and say<br/>"I can't do it" and the adults will probably let you off. As a kid there's a<br/>magic button you can press by saying "I'm just a kid" that will get you out of<br/>most difficult situations. Whereas adults, by definition, are not allowed to<br/>flake. They still do, of course, but when they do they're ruthlessly pruned.  <br/>  <br/>The other way to tell an adult is by how they react to a challenge. Someone<br/>who's not yet an adult will tend to respond to a challenge from an adult in a<br/>way that acknowledges their dominance. If an adult says "that's a stupid<br/>idea," a kid will either crawl away with his tail between his legs, or rebel.<br/>But rebelling presumes inferiority as much as submission. The adult response<br/>to "that's a stupid idea," is simply to look the other person in the eye and<br/>say "Really? Why do you think so?"  <br/>  <br/>There are a lot of adults who still react childishly to challenges, of course.<br/>What you don't often find are kids who react to challenges like adults. When<br/>you do, you've found an adult, whatever their age.  <br/>  <br/> **2\. Too inexperienced**  <br/>  <br/>I once wrote that startup founders should be at least 23, and that people<br/>should work for another company for a few years before starting their own. I<br/>no longer believe that, and what changed my mind is the example of the<br/>startups we've funded.  <br/>  <br/>I still think 23 is a better age than 21. But the best way to get experience<br/>if you're 21 is to start a startup. So, paradoxically, if you're too<br/>inexperienced to start a startup, what you should do is start one. That's a<br/>way more efficient cure for inexperience than a normal job. In fact, getting a<br/>normal job may actually make you less able to start a startup, by turning you<br/>into a tame animal who thinks he needs an office to work in and a product<br/>manager to tell him what software to write.  <br/>  <br/>What really convinced me of this was the Kikos. They started a startup right<br/>out of college. Their inexperience caused them to make a lot of mistakes. But<br/>by the time we funded their second startup, a year later, they had become<br/>extremely formidable. They were certainly not tame animals. And there is no<br/>way they'd have grown so much if they'd spent that year working at Microsoft,<br/>or even Google. They'd still have been diffident junior programmers.  <br/>  <br/>So now I'd advise people to go ahead and start startups right out of college.<br/>There's no better time to take risks than when you're young. Sure, you'll<br/>probably fail. But even failure will get you to the ultimate goal faster than<br/>getting a job.  <br/>  <br/>It worries me a bit to be saying this, because in effect we're advising people<br/>to educate themselves by failing at our expense, but it's the truth.  <br/>  <br/> **3\. Not determined enough**  <br/>  <br/>You need a lot of determination to succeed as a startup founder. It's probably<br/>the single best predictor of success.  <br/>  <br/>Some people may not be determined enough to make it. It's hard for me to say<br/>for sure, because I'm so determined that I can't imagine what's going on in<br/>the heads of people who aren't. But I know they exist.  <br/>  <br/>Most hackers probably underestimate their determination. I've seen a lot<br/>become visibly more determined as they get used to running a startup. I can<br/>think of several we've funded who would have been delighted at first to be<br/>bought for $2 million, but are now set on world domination.  <br/>  <br/>How can you tell if you're determined enough, when Larry and Sergey themselves<br/>were unsure at first about starting a company? I'm guessing here, but I'd say<br/>the test is whether you're sufficiently driven to work on your own projects.<br/>Though they may have been unsure whether they wanted to start a company, it<br/>doesn't seem as if Larry and Sergey were meek little research assistants,<br/>obediently doing their advisors' bidding. They started projects of their own.  <br/>  <br/>**4\. Not smart enough**  <br/>  <br/>You may need to be moderately smart to succeed as a startup founder. But if<br/>you're worried about this, you're probably mistaken. If you're smart enough to<br/>worry that you might not be smart enough to start a startup, you probably are.  <br/>  <br/>And in any case, starting a startup just doesn't require that much<br/>intelligence. Some startups do. You have to be good at math to write<br/>Mathematica. But most companies do more mundane stuff where the decisive<br/>factor is effort, not brains. Silicon Valley can warp your perspective on<br/>this, because there's a cult of smartness here. People who aren't smart at<br/>least try to act that way. But if you think it takes a lot of intelligence to<br/>get rich, try spending a couple days in some of the fancier bits of New York<br/>or LA.  <br/>  <br/>If you don't think you're smart enough to start a startup doing something<br/>technically difficult, just write enterprise software. Enterprise software<br/>companies aren't technology companies, they're sales companies, and sales<br/>depends mostly on effort.  <br/>  <br/> **5\. Know nothing about business**  <br/>  <br/>This is another variable whose coefficient should be zero. You don't need to<br/>know anything about business to start a startup. The initial focus should be<br/>the product. All you need to know in this phase is how to build things people<br/>want. If you succeed, you'll have to think about how to make money from it.<br/>But this is so easy you can pick it up on the fly.  <br/>  <br/>I get a fair amount of flak for telling founders just to make something great<br/>and not worry too much about making money. And yet all the empirical evidence<br/>points that way: pretty much 100% of startups that make something popular<br/>manage to make money from it. And acquirers tell me privately that revenue is<br/>not what they buy startups for, but their strategic value. Which means,<br/>because they made something people want. Acquirers know the rule holds for<br/>them too: if users love you, you can always make money from that somehow, and<br/>if they don't, the cleverest business model in the world won't save you.  <br/>  <br/>So why do so many people argue with me? I think one reason is that they hate<br/>the idea that a bunch of twenty year olds could get rich from building<br/>something cool that doesn't make any money. They just don't want that to be<br/>possible. But how possible it is doesn't depend on how much they want it to<br/>be.  <br/>  <br/>For a while it annoyed me to hear myself described as some kind of<br/>irresponsible pied piper, leading impressionable young hackers down the road<br/>to ruin. But now I realize this kind of controversy is a sign of a good idea.  <br/>  <br/>The most valuable truths are the ones most people don't believe. They're like<br/>undervalued stocks. If you start with them, you'll have the whole field to<br/>yourself. So when you find an idea you know is good but most people disagree<br/>with, you should not merely ignore their objections, but push aggressively in<br/>that direction. In this case, that means you should seek out ideas that would<br/>be popular but seem hard to make money from.  <br/>  <br/>We'll bet a seed round you can't make something popular that we can't figure<br/>out how to make money from.  <br/>  <br/> **6\. No cofounder**  <br/>  <br/>Not having a cofounder is a real problem. A startup is too much for one person<br/>to bear. And though we differ from other investors on a lot of questions, we<br/>all agree on this. All investors, without exception, are more likely to fund<br/>you with a cofounder than without.  <br/>  <br/>We've funded two single founders, but in both cases we suggested their first<br/>priority should be to find a cofounder. Both did. But we'd have preferred them<br/>to have cofounders before they applied. It's not super hard to get a cofounder<br/>for a project that's just been funded, and we'd rather have cofounders<br/>committed enough to sign up for something super hard.  <br/>  <br/>If you don't have a cofounder, what should you do? Get one. It's more<br/>important than anything else. If there's no one where you live who wants to<br/>start a startup with you, move where there are people who do. If no one wants<br/>to work with you on your current idea, switch to an idea people want to work<br/>on.  <br/>  <br/>If you're still in school, you're surrounded by potential cofounders. A few<br/>years out it gets harder to find them. Not only do you have a smaller pool to<br/>draw from, but most already have jobs, and perhaps even families to support.<br/>So if you had friends in college you used to scheme about startups with, stay<br/>in touch with them as well as you can. That may help keep the dream alive.  <br/>  <br/>It's possible you could meet a cofounder through something like a user's group<br/>or a conference. But I wouldn't be too optimistic. You need to work with<br/>someone to know whether you want them as a cofounder. [2]  <br/>  <br/>The real lesson to draw from this is not how to find a cofounder, but that you<br/>should start startups when you're young and there are lots of them around.  <br/>  <br/> **7\. No idea**  <br/>  <br/>In a sense, it's not a problem if you don't have a good idea, because most<br/>startups change their idea anyway. In the average Y Combinator startup, I'd<br/>guess 70% of the idea is new at the end of the first three months. Sometimes<br/>it's 100%.  <br/>  <br/>In fact, we're so sure the founders are more important than the initial idea<br/>that we're going to try something new this funding cycle. We're going to let<br/>people apply with no idea at all. If you want, you can answer the question on<br/>the application form that asks what you're going to do with "We have no idea."<br/>If you seem really good we'll accept you anyway. We're confident we can sit<br/>down with you and cook up some promising project.  <br/>  <br/>Really this just codifies what we do already. We put little weight on the<br/>idea. We ask mainly out of politeness. The kind of question on the application<br/>form that we really care about is the one where we ask what cool things you've<br/>made. If what you've made is version one of a promising startup, so much the<br/>better, but the main thing we care about is whether you're good at making<br/>things. Being lead developer of a popular open source project counts almost as<br/>much.  <br/>  <br/>That solves the problem if you get funded by Y Combinator. What about in the<br/>general case? Because in another sense, it is a problem if you don't have an<br/>idea. If you start a startup with no idea, what do you do next?  <br/>  <br/>So here's the brief recipe for getting startup ideas. Find something that's<br/>missing in your own life, and supply that need—no matter how specific to you<br/>it seems. Steve Wozniak built himself a computer; who knew so many other<br/>people would want them? A need that's narrow but genuine is a better starting<br/>point than one that's broad but hypothetical. So even if the problem is simply<br/>that you don't have a date on Saturday night, if you can think of a way to fix<br/>that by writing software, you're onto something, because a lot of other people<br/>have the same problem.  <br/>  <br/> **8\. No room for more startups**  <br/>  <br/>A lot of people look at the ever-increasing number of startups and think "this<br/>can't continue." Implicit in their thinking is a fallacy: that there is some<br/>limit on the number of startups there could be. But this is false. No one<br/>claims there's any limit on the number of people who can work for salary at<br/>1000-person companies. Why should there be any limit on the number who can<br/>work for equity at 5-person companies? [3]  <br/>  <br/>Nearly everyone who works is satisfying some kind of need. Breaking up<br/>companies into smaller units doesn't make those needs go away. Existing needs<br/>would probably get satisfied more efficiently by a network of startups than by<br/>a few giant, hierarchical organizations, but I don't think that would mean<br/>less opportunity, because satisfying current needs would lead to more.<br/>Certainly this tends to be the case in individuals. Nor is there anything<br/>wrong with that. We take for granted things that medieval kings would have<br/>considered effeminate luxuries, like whole buildings heated to spring<br/>temperatures year round. And if things go well, our descendants will take for<br/>granted things we would consider shockingly luxurious. There is no absolute<br/>standard for material wealth. Health care is a component of it, and that alone<br/>is a black hole. For the foreseeable future, people will want ever more<br/>material wealth, so there is no limit to the amount of work available for<br/>companies, and for startups in particular.  <br/>  <br/>Usually the limited-room fallacy is not expressed directly. Usually it's<br/>implicit in statements like "there are only so many startups Google,<br/>Microsoft, and Yahoo can buy." Maybe, though the list of acquirers is a lot<br/>longer than that. And whatever you think of other acquirers, Google is not<br/>stupid. The reason big companies buy startups is that they've created<br/>something valuable. And why should there be any limit to the number of<br/>valuable startups companies can acquire, any more than there is a limit to the<br/>amount of wealth individual people want? Maybe there would be practical limits<br/>on the number of startups any one acquirer could assimilate, but if there is<br/>value to be had, in the form of upside that founders are willing to forgo in<br/>return for an immediate payment, acquirers will evolve to consume it. Markets<br/>are pretty smart that way.  <br/>  <br/> **9\. Family to support**  <br/>  <br/>This one is real. I wouldn't advise anyone with a family to start a startup.<br/>I'm not saying it's a bad idea, just that I don't want to take responsibility<br/>for advising it. I'm willing to take responsibility for telling 22 year olds<br/>to start startups. So what if they fail? They'll learn a lot, and that job at<br/>Microsoft will still be waiting for them if they need it. But I'm not prepared<br/>to cross moms.  <br/>  <br/>What you can do, if you have a family and want to start a startup, is start a<br/>consulting business you can then gradually turn into a product business.<br/>Empirically the chances of pulling that off seem very small. You're never<br/>going to produce Google this way. But at least you'll never be without an<br/>income.  <br/>  <br/>Another way to decrease the risk is to join an existing startup instead of<br/>starting your own. Being one of the first employees of a startup is a lot like<br/>being a founder, in both the good ways and the bad. You'll be roughly 1/n^2<br/>founder, where n is your employee number.  <br/>  <br/>As with the question of cofounders, the real lesson here is to start startups<br/>when you're young.  <br/>  <br/> **10\. Independently wealthy**  <br/>  <br/>This is my excuse for not starting a startup. Startups are stressful. Why do<br/>it if you don't need the money? For every "serial entrepreneur," there are<br/>probably twenty sane ones who think "Start another company? Are you crazy?"  <br/>  <br/>I've come close to starting new startups a couple times, but I always pull<br/>back because I don't want four years of my life to be consumed by random<br/>schleps. I know this business well enough to know you can't do it half-<br/>heartedly. What makes a good startup founder so dangerous is his willingness<br/>to endure infinite schleps.  <br/>  <br/>There is a bit of a problem with retirement, though. Like a lot of people, I<br/>like to work. And one of the many weird little problems you discover when you<br/>get rich is that a lot of the interesting people you'd like to work with are<br/>not rich. They need to work at something that pays the bills. Which means if<br/>you want to have them as colleagues, you have to work at something that pays<br/>the bills too, even though you don't need to. I think this is what drives a<br/>lot of serial entrepreneurs, actually.  <br/>  <br/>That's why I love working on Y Combinator so much. It's an excuse to work on<br/>something interesting with people I like.  <br/>  <br/> **11\. Not ready for commitment**  <br/>  <br/>This was my reason for not starting a startup for most of my twenties. Like a<br/>lot of people that age, I valued freedom most of all. I was reluctant to do<br/>anything that required a commitment of more than a few months. Nor would I<br/>have wanted to do anything that completely took over my life the way a startup<br/>does. And that's fine. If you want to spend your time travelling around, or<br/>playing in a band, or whatever, that's a perfectly legitimate reason not to<br/>start a company.  <br/>  <br/>If you start a startup that succeeds, it's going to consume at least three or<br/>four years. (If it fails, you'll be done a lot quicker.) So you shouldn't do<br/>it if you're not ready for commitments on that scale. Be aware, though, that<br/>if you get a regular job, you'll probably end up working there for as long as<br/>a startup would take, and you'll find you have much less spare time than you<br/>might expect. So if you're ready to clip on that ID badge and go to that<br/>orientation session, you may also be ready to start that startup.  <br/>  <br/> **12\. Need for structure**  <br/>  <br/>I'm told there are people who need structure in their lives. This seems to be<br/>a nice way of saying they need someone to tell them what to do. I believe such<br/>people exist. There's plenty of empirical evidence: armies, religious cults,<br/>and so on. They may even be the majority.  <br/>  <br/>If you're one of these people, you probably shouldn't start a startup. In<br/>fact, you probably shouldn't even go to work for one. In a good startup, you<br/>don't get told what to do very much. There may be one person whose job title<br/>is CEO, but till the company has about twelve people no one should be telling<br/>anyone what to do. That's too inefficient. Each person should just do what<br/>they need to without anyone telling them.  <br/>  <br/>If that sounds like a recipe for chaos, think about a soccer team. Eleven<br/>people manage to work together in quite complicated ways, and yet only in<br/>occasional emergencies does anyone tell anyone else what to do. A reporter<br/>once asked David Beckham if there were any language problems at Real Madrid,<br/>since the players were from about eight different countries. He said it was<br/>never an issue, because everyone was so good they never had to talk. They all<br/>just did the right thing.  <br/>  <br/>How do you tell if you're independent-minded enough to start a startup? If<br/>you'd bristle at the suggestion that you aren't, then you probably are.  <br/>  <br/> **13\. Fear of uncertainty**  <br/>  <br/>Perhaps some people are deterred from starting startups because they don't<br/>like the uncertainty. If you go to work for Microsoft, you can predict fairly<br/>accurately what the next few years will be like—all too accurately, in fact.<br/>If you start a startup, anything might happen.  <br/>  <br/>Well, if you're troubled by uncertainty, I can solve that problem for you: if<br/>you start a startup, it will probably fail. Seriously, though, this is not a<br/>bad way to think about the whole experience. Hope for the best, but expect the<br/>worst. In the worst case, it will at least be interesting. In the best case<br/>you might get rich.  <br/>  <br/>No one will blame you if the startup tanks, so long as you made a serious<br/>effort. There may once have been a time when employers would regard that as a<br/>mark against you, but they wouldn't now. I asked managers at big companies,<br/>and they all said they'd prefer to hire someone who'd tried to start a startup<br/>and failed over someone who'd spent the same time working at a big company.  <br/>  <br/>Nor will investors hold it against you, as long as you didn't fail out of<br/>laziness or incurable stupidity. I'm told there's a lot of stigma attached to<br/>failing in other places—in Europe, for example. Not here. In America,<br/>companies, like practically everything else, are disposable.  <br/>  <br/> **14\. Don't realize what you're avoiding**  <br/>  <br/>One reason people who've been out in the world for a year or two make better<br/>founders than people straight from college is that they know what they're<br/>avoiding. If their startup fails, they'll have to get a job, and they know how<br/>much jobs suck.  <br/>  <br/>If you've had summer jobs in college, you may think you know what jobs are<br/>like, but you probably don't. Summer jobs at technology companies are not real<br/>jobs. If you get a summer job as a waiter, that's a real job. Then you have to<br/>carry your weight. But software companies don't hire students for the summer<br/>as a source of cheap labor. They do it in the hope of recruiting them when<br/>they graduate. So while they're happy if you produce, they don't expect you<br/>to.  <br/>  <br/>That will change if you get a real job after you graduate. Then you'll have to<br/>earn your keep. And since most of what big companies do is boring, you're<br/>going to have to work on boring stuff. Easy, compared to college, but boring.<br/>At first it may seem cool to get paid for doing easy stuff, after paying to do<br/>hard stuff in college. But that wears off after a few months. Eventually it<br/>gets demoralizing to work on dumb stuff, even if it's easy and you get paid a<br/>lot.  <br/>  <br/>And that's not the worst of it. The thing that really sucks about having a<br/>regular job is the expectation that you're supposed to be there at certain<br/>times. Even Google is afflicted with this, apparently. And what this means, as<br/>everyone who's had a regular job can tell you, is that there are going to be<br/>times when you have absolutely no desire to work on anything, and you're going<br/>to have to go to work anyway and sit in front of your screen and pretend to.<br/>To someone who likes work, as most good hackers do, this is torture.  <br/>  <br/>In a startup, you skip all that. There's no concept of office hours in most<br/>startups. Work and life just get mixed together. But the good thing about that<br/>is that no one minds if you have a life at work. In a startup you can do<br/>whatever you want most of the time. If you're a founder, what you want to do<br/>most of the time is work. But you never have to pretend to.  <br/>  <br/>If you took a nap in your office in a big company, it would seem<br/>unprofessional. But if you're starting a startup and you fall asleep in the<br/>middle of the day, your cofounders will just assume you were tired.  <br/>  <br/> **15\. Parents want you to be a doctor**  <br/>  <br/>A significant number of would-be startup founders are probably dissuaded from<br/>doing it by their parents. I'm not going to say you shouldn't listen to them.<br/>Families are entitled to their own traditions, and who am I to argue with<br/>them? But I will give you a couple reasons why a safe career might not be what<br/>your parents really want for you.  <br/>  <br/>One is that parents tend to be more conservative for their kids than they<br/>would be for themselves. This is actually a rational response to their<br/>situation. Parents end up sharing more of their kids' ill fortune than good<br/>fortune. Most parents don't mind this; it's part of the job; but it does tend<br/>to make them excessively conservative. And erring on the side of conservatism<br/>is still erring. In almost everything, reward is proportionate to risk. So by<br/>protecting their kids from risk, parents are, without realizing it, also<br/>protecting them from rewards. If they saw that, they'd want you to take more<br/>risks.  <br/>  <br/>The other reason parents may be mistaken is that, like generals, they're<br/>always fighting the last war. If they want you to be a doctor, odds are it's<br/>not just because they want you to help the sick, but also because it's a<br/>prestigious and lucrative career. [4] But not so lucrative or prestigious as<br/>it was when their opinions were formed. When I was a kid in the seventies, a<br/>doctor was _the_ thing to be. There was a sort of golden triangle involving<br/>doctors, Mercedes 450SLs, and tennis. All three vertices now seem pretty<br/>dated.  <br/>  <br/>The parents who want you to be a doctor may simply not realize how much things<br/>have changed. Would they be that unhappy if you were Steve Jobs instead? So I<br/>think the way to deal with your parents' opinions about what you should do is<br/>to treat them like feature requests. Even if your only goal is to please them,<br/>the way to do that is not simply to give them what they ask for. Instead think<br/>about why they're asking for something, and see if there's a better way to<br/>give them what they need.  <br/>  <br/> **16\. A job is the default**  <br/>  <br/>This leads us to the last and probably most powerful reason people get regular<br/>jobs: it's the default thing to do. Defaults are enormously powerful,<br/>precisely because they operate without any conscious choice.  <br/>  <br/>To almost everyone except criminals, it seems an axiom that if you need money,<br/>you should get a job. Actually this tradition is not much more than a hundred<br/>years old. Before that, the default way to make a living was by farming. It's<br/>a bad plan to treat something only a hundred years old as an axiom. By<br/>historical standards, that's something that's changing pretty rapidly.  <br/>  <br/>We may be seeing another such change right now. I've read a lot of economic<br/>history, and I understand the startup world pretty well, and it now seems to<br/>me fairly likely that we're seeing the beginning of a change like the one from<br/>farming to manufacturing.  <br/>  <br/>And you know what? If you'd been around when that change began (around 1000 in<br/>Europe) it would have seemed to nearly everyone that running off to the city<br/>to make your fortune was a crazy thing to do. Though serfs were in principle<br/>forbidden to leave their manors, it can't have been that hard to run away to a<br/>city. There were no guards patrolling the perimeter of the village. What<br/>prevented most serfs from leaving was that it seemed insanely risky. Leave<br/>one's plot of land? Leave the people you'd spent your whole life with, to live<br/>in a giant city of three or four thousand complete strangers? How would you<br/>live? How would you get food, if you didn't grow it?  <br/>  <br/>Frightening as it seemed to them, it's now the default with us to live by our<br/>wits. So if it seems risky to you to start a startup, think how risky it once<br/>seemed to your ancestors to live as we do now. Oddly enough, the people who<br/>know this best are the very ones trying to get you to stick to the old model.<br/>How can Larry and Sergey say you should come work as their employee, when they<br/>didn't get jobs themselves?  <br/>  <br/>Now we look back on medieval peasants and wonder how they stood it. How grim<br/>it must have been to till the same fields your whole life with no hope of<br/>anything better, under the thumb of lords and priests you had to give all your<br/>surplus to and acknowledge as your masters. I wouldn't be surprised if one day<br/>people look back on what we consider a normal job in the same way. How grim it<br/>would be to commute every day to a cubicle in some soulless office complex,<br/>and be told what to do by someone you had to acknowledge as a boss—someone who<br/>could call you into their office and say "take a seat," and you'd sit! Imagine<br/>having to ask _permission_ to release software to users. Imagine being sad on<br/>Sunday afternoons because the weekend was almost over, and tomorrow you'd have<br/>to get up and go to work. How did they stand it?  <br/>  <br/>It's exciting to think we may be on the cusp of another shift like the one<br/>from farming to manufacturing. That's why I care about startups. Startups<br/>aren't interesting just because they're a way to make a lot of money. I<br/>couldn't care less about other ways to do that, like speculating in<br/>securities. At most those are interesting the way puzzles are. There's more<br/>going on with startups. They may represent one of those rare, historic shifts<br/>in the way wealth is created.  <br/>  <br/>That's ultimately what drives us to work on Y Combinator. We want to make<br/>money, if only so we don't have to stop doing it, but that's not the main<br/>goal. There have only been a handful of these great economic shifts in human<br/>history. It would be an amazing hack to make one happen faster.  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] The only people who lost were us. The angels had convertible debt, so they<br/>had first claim on the proceeds of the auction. Y Combinator only got 38 cents<br/>on the dollar.  <br/>  <br/>[2] The best kind of organization for that might be an open source project,<br/>but those don't involve a lot of face to face meetings. Maybe it would be<br/>worth starting one that did.  <br/>  <br/>[3] There need to be some number of big companies to acquire the startups, so<br/>the number of big companies couldn't decrease to zero.  <br/>  <br/>[4] Thought experiment: If doctors did the same work, but as impoverished<br/>outcasts, which parents would still want their kids to be doctors?  <br/>  <br/> **Thanks** to Trevor Blackwell, Jessica Livingston, and Robert Morris for<br/>reading drafts of this, to the founders of Zenter for letting me use their<br/>web-based PowerPoint killer even though it isn't launched yet, and to Ming-Hay<br/>Luk of the Berkeley CSUA for inviting me to speak.  <br/>  <br/>  <br/>  <br/>Comment on this essay.  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Korean Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>The Web is a Writing Environment  <br/>  <br/><br/>A Sell-Out's Tale  <br/>  <br/><br/>How to Pitch Bloggers  <br/>  <br/><br/>Blogging for Milk  <br/>  <br/><br/>7 Habits of Highly Effective Blog PR  <br/>  <br/><br/>PR People Need To Learn To Deal With New Gatekeepers  <br/>  <br/><br/>Marqui Blogosphere Program  <br/>  <br/><br/>PR Watch  <br/>  <br/><br/>Real Men Exfoliate  <br/>  <br/><br/>How the News is Made  <br/>  <br/><br/>January 2006: The suit is back yet again  <br/>  <br/><br/>The Decline of the Tie  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>September 2017  <br/>  <br/>The most valuable insights are both general and surprising. F = ma for<br/>example. But general and surprising is a hard combination to achieve. That<br/>territory tends to be picked clean, precisely because those insights are so<br/>valuable.  <br/>  <br/>Ordinarily, the best that people can do is one without the other: either<br/>surprising without being general (e.g. gossip), or general without being<br/>surprising (e.g. platitudes).  <br/>  <br/>Where things get interesting is the moderately valuable insights. You get<br/>those from small additions of whichever quality was missing. The more common<br/>case is a small addition of generality: a piece of gossip that's more than<br/>just gossip, because it teaches something interesting about the world. But<br/>another less common approach is to focus on the most general ideas and see if<br/>you can find something new to say about them. Because these start out so<br/>general, you only need a small delta of novelty to produce a useful insight.  <br/>  <br/>A small delta of novelty is all you'll be able to get most of the time. Which<br/>means if you take this route, your ideas will seem a lot like ones that<br/>already exist. Sometimes you'll find you've merely rediscovered an idea that<br/>did already exist. But don't be discouraged. Remember the huge multiplier that<br/>kicks in when you do manage to think of something even a little new.  <br/>  <br/>Corollary: the more general the ideas you're talking about, the less you<br/>should worry about repeating yourself. If you write enough, it's inevitable<br/>you will. Your brain is much the same from year to year and so are the stimuli<br/>that hit it. I feel slightly bad when I find I've said something close to what<br/>I've said before, as if I were plagiarizing myself. But rationally one<br/>shouldn't. You won't say something exactly the same way the second time, and<br/>that variation increases the chance you'll get that tiny but critical delta of<br/>novelty.  <br/>  <br/>And of course, ideas beget ideas. (That sounds _familiar_.) An idea with a<br/>small amount of novelty could lead to one with more. But only if you keep<br/>going. So it's doubly important not to let yourself be discouraged by people<br/>who say there's not much new about something you've discovered. "Not much new"<br/>is a real achievement when you're talking about the most general ideas.  <br/>  <br/>It's not true that there's nothing new under the sun. There are some domains<br/>where there's almost nothing new. But there's a big difference between nothing<br/>and almost nothing, when it's multiplied by the area under the sun.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Thanks** to Sam Altman, Patrick Collison, and Jessica Livingston for reading<br/>drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>September 2013  <br/>  <br/>Most startups that raise money do it more than once. A typical trajectory<br/>might be (1) to get started with a few tens of thousands from something like Y<br/>Combinator or individual angels, then (2) raise a few hundred thousand to a<br/>few million to build the company, and then (3) once the company is clearly<br/>succeeding, raise one or more later rounds to accelerate growth.  <br/>  <br/>Reality can be messier. Some companies raise money twice in phase 2\. Others<br/>skip phase 1 and go straight to phase 2. And at Y Combinator we get an<br/>increasing number of companies that have already raised amounts in the<br/>hundreds of thousands. But the three phase path is at least the one about<br/>which individual startups' paths oscillate.  <br/>  <br/>This essay focuses on phase 2 fundraising. That's the type the startups we<br/>fund are doing on Demo Day, and this essay is the advice we give them.  <br/>  <br/>**Forces**  <br/>  <br/>Fundraising is hard in both senses: hard like lifting a heavy weight, and hard<br/>like solving a puzzle. It's hard like lifting a weight because it's<br/>intrinsically hard to convince people to part with large sums of money. That<br/>problem is irreducible; it should be hard. But much of the other kind of<br/>difficulty can be eliminated. Fundraising only seems a puzzle because it's an<br/>alien world to most founders, and I hope to fix that by supplying a map<br/>through it.  <br/>  <br/>To founders, the behavior of investors is often opaque — partly because their<br/>motivations are obscure, but partly because they deliberately mislead you. And<br/>the misleading ways of investors combine horribly with the wishful thinking of<br/>inexperienced founders. At YC we're always warning founders about this danger,<br/>and investors are probably more circumspect with YC startups than with other<br/>companies they talk to, and even so we witness a constant series of explosions<br/>as these two volatile components combine. [1]  <br/>  <br/>If you're an inexperienced founder, the only way to survive is by imposing<br/>external constraints on yourself. You can't trust your intuitions. I'm going<br/>to give you a set of rules here that will get you through this process if<br/>anything will. At certain moments you'll be tempted to ignore them. So rule<br/>number zero is: these rules exist for a reason. You wouldn't need a rule to<br/>keep you going in one direction if there weren't powerful forces pushing you<br/>in another.  <br/>  <br/>The ultimate source of the forces acting on you are the forces acting on<br/>investors. Investors are pinched between two kinds of fear: fear of investing<br/>in startups that fizzle, and fear of missing out on startups that take off.<br/>The cause of all this fear is the very thing that makes startups such<br/>attractive investments: the successful ones grow very fast. But that fast<br/>growth means investors can't wait around. If you wait till a startup is<br/>obviously a success, it's too late. To get the really high returns, you have<br/>to invest in startups when it's still unclear how they'll do. But that in turn<br/>makes investors nervous they're about to invest in a flop. As indeed they<br/>often are.  <br/>  <br/>What investors would like to do, if they could, is wait. When a startup is<br/>only a few months old, every week that passes gives you significantly more<br/>information about them. But if you wait too long, other investors might take<br/>the deal away from you. And of course the other investors are all subject to<br/>the same forces. So what tends to happen is that they all wait as long as they<br/>can, then when some act the rest have to.  <br/>  <br/>**Don't raise money unless you want it and it wants you.**  <br/>  <br/>Such a high proportion of successful startups raise money that it might seem<br/>fundraising is one of the defining qualities of a startup. Actually it isn't.<br/>Rapid growth is what makes a company a startup. Most companies in a position<br/>to grow rapidly find that (a) taking outside money helps them grow faster, and<br/>(b) their growth potential makes it easy to attract such money. It's so common<br/>for both (a) and (b) to be true of a successful startup that practically all<br/>do raise outside money. But there may be cases where a startup either wouldn't<br/>want to grow faster, or outside money wouldn't help them to, and if you're one<br/>of them, don't raise money.  <br/>  <br/>The other time not to raise money is when you won't be able to. If you try to<br/>raise money before you can convince investors, you'll not only waste your<br/>time, but also burn your reputation with those investors.  <br/>  <br/>**Be in fundraising mode or not.**  <br/>  <br/>One of the things that surprises founders most about fundraising is how<br/>distracting it is. When you start fundraising, everything else grinds to a<br/>halt. The problem is not the time fundraising consumes but that it becomes the<br/>top idea in your mind. A startup can't endure that level of distraction for<br/>long. An early stage startup grows mostly because the founders make it grow,<br/>and if the founders look away, growth usually drops sharply.  <br/>  <br/>Because fundraising is so distracting, a startup should either be in<br/>fundraising mode or not. And when you do decide to raise money, you should<br/>focus your whole attention on it so you can get it done quickly and get back<br/>to work. [2]  <br/>  <br/>You can take money from investors when you're not in fundraising mode. You<br/>just can't expend any attention on it. There are two things that take<br/>attention: convincing investors, and negotiating with them. So when you're not<br/>in fundraising mode, you should take money from investors only if they require<br/>no convincing, and are willing to invest on terms you'll take without<br/>negotiation. For example, if a reputable investor is willing to invest on a<br/>convertible note, using standard paperwork, that is either uncapped or capped<br/>at a good valuation, you can take that without having to think. [3] The terms<br/>will be whatever they turn out to be in your next equity round. And "no<br/>convincing" means just that: zero time spent meeting with investors or<br/>preparing materials for them. If an investor says they're ready to invest, but<br/>they need you to come in for one meeting to meet some of the partners, tell<br/>them no, if you're not in fundraising mode, because that's fundraising. [4]<br/>Tell them politely; tell them you're focusing on the company right now, and<br/>that you'll get back to them when you're fundraising; but do not get sucked<br/>down the slippery slope.  <br/>  <br/>Investors will try to lure you into fundraising when you're not. It's great<br/>for them if they can, because they can thereby get a shot at you before<br/>everyone else. They'll send you emails saying they want to meet to learn more<br/>about you. If you get cold-emailed by an associate at a VC firm, you shouldn't<br/>meet even if you are in fundraising mode. Deals don't happen that way. [5] But<br/>even if you get an email from a partner you should try to delay meeting till<br/>you're in fundraising mode. They may say they just want to meet and chat, but<br/>investors never just want to meet and chat. What if they like you? What if<br/>they start to talk about giving you money? Will you be able to resist having<br/>that conversation? Unless you're experienced enough at fundraising to have a<br/>casual conversation with investors that stays casual, it's safer to tell them<br/>that you'd be happy to later, when you're fundraising, but that right now you<br/>need to focus on the company. [6]  <br/>  <br/>Companies that are successful at raising money in phase 2 sometimes tack on a<br/>few investors after leaving fundraising mode. This is fine; if fundraising<br/>went well, you'll be able to do it without spending time convincing them or<br/>negotiating about terms.  <br/>  <br/>**Get introductions to investors.**  <br/>  <br/>Before you can talk to investors, you have to be introduced to them. If you're<br/>presenting at a Demo Day, you'll be introduced to a whole bunch<br/>simultaneously. But even if you are, you should supplement these with intros<br/>you collect yourself.  <br/>  <br/>Do you have to be introduced? In phase 2, yes. Some investors will let you<br/>email them a business plan, but you can tell from the way their sites are<br/>organized that they don't really want startups to approach them directly.  <br/>  <br/>Intros vary greatly in effectiveness. The best type of intro is from a well-<br/>known investor who has just invested in you. So when you get an investor to<br/>commit, ask them to introduce you to other investors they respect. [7] The<br/>next best type of intro is from a founder of a company they've funded. You can<br/>also get intros from other people in the startup community, like lawyers and<br/>reporters.  <br/>  <br/>There are now sites like AngelList, FundersClub, and WeFunder that can<br/>introduce you to investors. We recommend startups treat them as auxiliary<br/>sources of money. Raise money first from leads you get yourself. Those will on<br/>average be better investors. Plus you'll have an easier time raising money on<br/>these sites once you can say you've already raised some from well-known<br/>investors.  <br/>  <br/>**Hear no till you hear yes.**  <br/>  <br/>Treat investors as saying no till they unequivocally say yes, in the form of a<br/>definite offer with no contingencies.  <br/>  <br/>I mentioned earlier that investors prefer to wait if they can. What's<br/>particularly dangerous for founders is the way they wait. Essentially, they<br/>lead you on. They seem like they're about to invest right up till the moment<br/>they say no. If they even say no. Some of the worse ones never actually do say<br/>no; they just stop replying to your emails. They hope that way to get a free<br/>option on investing. If they decide later that they want to invest — usually<br/>because they've heard you're a hot deal — they can pretend they just got<br/>distracted and then restart the conversation as if they'd been about to. [8]  <br/>  <br/>That's not the worst thing investors will do. Some will use language that<br/>makes it sound as if they're committing, but which doesn't actually commit<br/>them. And wishful thinking founders are happy to meet them half way. [9]  <br/>  <br/>Fortunately, the next rule is a tactic for neutralizing this behavior. But to<br/>work it depends on you not being tricked by the no that sounds like yes. It's<br/>so common for founders to be misled/mistaken about this that we designed a<br/>protocol to fix the problem. If you believe an investor has committed, get<br/>them to confirm it. If you and they have different views of reality, whether<br/>the source of the discrepancy is their sketchiness or your wishful thinking,<br/>the prospect of confirming a commitment in writing will flush it out. And till<br/>they confirm, regard them as saying no.  <br/>  <br/>**Do breadth-first search weighted by expected value.**  <br/>  <br/>When you talk to investors your m.o. should be breadth-first search, weighted<br/>by expected value. You should always talk to investors in parallel rather than<br/>serially. You can't afford the time it takes to talk to investors serially,<br/>plus if you only talk to one investor at a time, they don't have the pressure<br/>of other investors to make them act. But you shouldn't pay the same attention<br/>to every investor, because some are more promising prospects than others. The<br/>optimal solution is to talk to all potential investors in parallel, but give<br/>higher priority to the more promising ones. [10]  <br/>  <br/>Expected value = how likely an investor is to say yes, multiplied by how good<br/>it would be if they did. So for example, an eminent investor who would invest<br/>a lot, but will be hard to convince, might have the same expected value as an<br/>obscure angel who won't invest much, but will be easy to convince. Whereas an<br/>obscure angel who will only invest a small amount, and yet needs to meet<br/>multiple times before making up his mind, has very low expected value. Meet<br/>such investors last, if at all. [11]  <br/>  <br/>Doing breadth-first search weighted by expected value will save you from<br/>investors who never explicitly say no but merely drift away, because you'll<br/>drift away from them at the same rate. It protects you from investors who<br/>flake in much the same way that a distributed algorithm protects you from<br/>processors that fail. If some investor isn't returning your emails, or wants<br/>to have lots of meetings but isn't progressing toward making you an offer, you<br/>automatically focus less on them. But you have to be disciplined about<br/>assigning probabilities. You can't let how much you want an investor influence<br/>your estimate of how much they want you.  <br/>  <br/>**Know where you stand.**  <br/>  <br/>How do you judge how well you're doing with an investor, when investors<br/>habitually seem more positive than they are? By looking at their actions<br/>rather than their words. Every investor has some track they need to move along<br/>from the first conversation to wiring the money, and you should always know<br/>what that track consists of, where you are on it, and how fast you're moving<br/>forward.  <br/>  <br/>Never leave a meeting with an investor without asking what happens next. What<br/>more do they need in order to decide? Do they need another meeting with you?<br/>To talk about what? And how soon? Do they need to do something internally,<br/>like talk to their partners, or investigate some issue? How long do they<br/>expect it to take? Don't be too pushy, but know where you stand. If investors<br/>are vague or resist answering such questions, assume the worst; investors who<br/>are seriously interested in you will usually be happy to talk about what has<br/>to happen between now and wiring the money, because they're already running<br/>through that in their heads. [12]  <br/>  <br/>If you're experienced at negotiations, you already know how to ask such<br/>questions. [13] If you're not, there's a trick you can use in this situation.<br/>Investors know you're inexperienced at raising money. Inexperience there<br/>doesn't make you unattractive. Being a noob at technology would, if you're<br/>starting a technology startup, but not being a noob at fundraising. Larry and<br/>Sergey were noobs at fundraising. So you can just confess that you're<br/>inexperienced at this and ask how their process works and where you are in it.<br/>[14]  <br/>  <br/>**Get the first commitment.**  <br/>  <br/>The biggest factor in most investors' opinions of you is the opinion of other<br/>investors. Once you start getting investors to commit, it becomes increasingly<br/>easy to get more to. But the other side of this coin is that it's often hard<br/>to get the first commitment.  <br/>  <br/>Getting the first substantial offer can be half the total difficulty of<br/>fundraising. What counts as a substantial offer depends on who it's from and<br/>how much it is. Money from friends and family doesn't usually count, no matter<br/>how much. But if you get $50k from a well known VC firm or angel investor,<br/>that will usually be enough to set things rolling. [15]  <br/>  <br/>**Close committed money.**  <br/>  <br/>It's not a deal till the money's in the bank. I often hear inexperienced<br/>founders say things like "We've raised $800,000," only to discover that zero<br/>of it is in the bank so far. Remember the twin fears that torment investors?<br/>The fear of missing out that makes them jump early, and the fear of jumping<br/>onto a turd that results? This is a market where people are exceptionally<br/>prone to buyer's remorse. And it's also one that furnishes them plenty of<br/>excuses to gratify it. The public markets snap startup investing around like a<br/>whip. If the Chinese economy blows up tomorrow, all bets are off. But there<br/>are lots of surprises for individual startups too, and they tend to be<br/>concentrated around fundraising. Tomorrow a big competitor could appear, or<br/>you could get C&Ded, or your cofounder could quit. [16]  <br/>  <br/>Even a day's delay can bring news that causes an investor to change their<br/>mind. So when someone commits, get the money. Knowing where you stand doesn't<br/>end when they say they'll invest. After they say yes, know what the timetable<br/>is for getting the money, and then babysit that process till it happens.<br/>Institutional investors have people in charge of wiring money, but you may<br/>have to hunt angels down in person to collect a check.  <br/>  <br/>Inexperienced investors are the ones most likely to get buyer's remorse.<br/>Established ones have learned to treat saying yes as like diving off a diving<br/>board, and they also have more brand to preserve. But I've heard of cases of<br/>even top-tier VC firms welching on deals.  <br/>  <br/>**Avoid investors who don't "lead."**  <br/>  <br/>Since getting the first offer is most of the difficulty of fundraising, that<br/>should be part of your calculation of expected value when you start. You have<br/>to estimate not just the probability that an investor will say yes, but the<br/>probability that they'd be the _first_ to say yes, and the latter is not<br/>simply a constant fraction of the former. Some investors are known for<br/>deciding quickly, and those are extra valuable early on.  <br/>  <br/>Conversely, an investor who will only invest once other investors have is<br/>worthless initially. And while most investors are influenced by how interested<br/>other investors are in you, there are some who have an explicit policy of only<br/>investing after other investors have. You can recognize this contemptible<br/>subspecies of investor because they often talk about "leads." They say that<br/>they don't lead, or that they'll invest once you have a lead. Sometimes they<br/>even claim to be willing to lead themselves, by which they mean they won't<br/>invest till you get $x from other investors. (It's great if by "lead" they<br/>mean they'll invest unilaterally, and in addition will help you raise more.<br/>What's lame is when they use the term to mean they won't invest unless you can<br/>raise more elsewhere.) [17]  <br/>  <br/>Where does this term "lead" come from? Up till a few years ago, startups<br/>raising money in phase 2 would usually raise equity rounds in which several<br/>investors invested at the same time using the same paperwork. You'd negotiate<br/>the terms with one "lead" investor, and then all the others would sign the<br/>same documents and all the money change hands at the closing.  <br/>  <br/>Series A rounds still work that way, but things now work differently for most<br/>fundraising prior to the series A. Now there are rarely actual rounds before<br/>the A round, or leads for them. Now startups simply raise money from investors<br/>one at a time till they feel they have enough.  <br/>  <br/>Since there are no longer leads, why do investors use that term? Because it's<br/>a more legitimate-sounding way of saying what they really mean. All they<br/>really mean is that their interest in you is a function of other investors'<br/>interest in you. I.e. the spectral signature of all mediocre investors. But<br/>when phrased in terms of leads, it sounds like there is something structural<br/>and therefore legitimate about their behavior.  <br/>  <br/>When an investor tells you "I want to invest in you, but I don't lead,"<br/>translate that in your mind to "No, except yes if you turn out to be a hot<br/>deal." And since that's the default opinion of any investor about any startup,<br/>they've essentially just told you nothing.  <br/>  <br/>When you first start fundraising, the expected value of an investor who won't<br/>"lead" is zero, so talk to such investors last if at all.  <br/>  <br/>**Have multiple plans.**  <br/>  <br/>Many investors will ask how much you're planning to raise. This question makes<br/>founders feel they should be planning to raise a specific amount. But in fact<br/>you shouldn't. It's a mistake to have fixed plans in an undertaking as<br/>unpredictable as fundraising.  <br/>  <br/>So why do investors ask how much you plan to raise? For much the same reasons<br/>a salesperson in a store will ask "How much were you planning to spend?" if<br/>you walk in looking for a gift for a friend. You probably didn't have a<br/>precise amount in mind; you just want to find something good, and if it's<br/>inexpensive, so much the better. The salesperson asks you this not because<br/>you're supposed to have a plan to spend a specific amount, but so they can<br/>show you only things that cost the most you'll pay.  <br/>  <br/>Similarly, when investors ask how much you plan to raise, it's not because<br/>you're supposed to have a plan. It's to see whether you'd be a suitable<br/>recipient for the size of investment they like to make, and also to judge your<br/>ambition, reasonableness, and how far you are along with fundraising.  <br/>  <br/>If you're a wizard at fundraising, you can say "We plan to raise a $7 million<br/>series A round, and we'll be accepting termsheets next tuesday." I've known a<br/>handful of founders who could pull that off without having VCs laugh in their<br/>faces. But if you're in the inexperienced but earnest majority, the solution<br/>is analogous to the solution I recommend for pitching your startup: do the<br/>right thing and then just tell investors what you're doing.  <br/>  <br/>And the right strategy, in fundraising, is to have multiple plans depending on<br/>how much you can raise. Ideally you should be able to tell investors something<br/>like: we can make it to profitability without raising any more money, but if<br/>we raise a few hundred thousand we can hire one or two smart friends, and if<br/>we raise a couple million, we can hire a whole engineering team, etc.  <br/>  <br/>Different plans match different investors. If you're talking to a VC firm that<br/>only does series A rounds (though there are few of those left), it would be a<br/>waste of time talking about any but your most expensive plan. Whereas if<br/>you're talking to an angel who invests $20k at a time and you haven't raised<br/>any money yet, you probably want to focus on your least expensive plan.  <br/>  <br/>If you're so fortunate as to have to think about the upper limit on what you<br/>should raise, a good rule of thumb is to multiply the number of people you<br/>want to hire times $15k times 18 months. In most startups, nearly all the<br/>costs are a function of the number of people, and $15k per month is the<br/>conventional total cost (including benefits and even office space) per person.<br/>$15k per month is high, so don't actually spend that much. But it's ok to use<br/>a high estimate when fundraising to add a margin for error. If you have<br/>additional expenses, like manufacturing, add in those at the end. Assuming you<br/>have none and you think you might hire 20 people, the most you'd want to raise<br/>is 20 x $15k x 18 = $5.4 million. [18]  <br/>  <br/>**Underestimate how much you want.**  <br/>  <br/>Though you can focus on different plans when talking to different types of<br/>investors, you should on the whole err on the side of underestimating the<br/>amount you hope to raise.  <br/>  <br/>For example, if you'd like to raise $500k, it's better to say initially that<br/>you're trying to raise $250k. Then when you reach $150k you're more than half<br/>done. That sends two useful signals to investors: that you're doing well, and<br/>that they have to decide quickly because you're running out of room. Whereas<br/>if you'd said you were raising $500k, you'd be less than a third done at<br/>$150k. If fundraising stalled there for an appreciable time, you'd start to<br/>read as a failure.  <br/>  <br/>Saying initially that you're raising $250k doesn't limit you to raising that<br/>much. When you reach your initial target and you still have investor interest,<br/>you can just decide to raise more. Startups do that all the time. In fact,<br/>most startups that are very successful at fundraising end up raising more than<br/>they originally intended.  <br/>  <br/>I'm not saying you should lie, but that you should lower your expectations<br/>initially. There is almost no downside in starting with a low number. It not<br/>only won't cap the amount you raise, but will on the whole tend to increase<br/>it.  <br/>  <br/>A good metaphor here is angle of attack. If you try to fly at too steep an<br/>angle of attack, you just stall. If you say right out of the gate that you<br/>want to raise a $5 million series A round, unless you're in a very strong<br/>position, you not only won't get that but won't get anything. Better to start<br/>at a low angle of attack, build up speed, and then gradually increase the<br/>angle if you want.  <br/>  <br/>**Be profitable if you can.**  <br/>  <br/>You will be in a much stronger position if your collection of plans includes<br/>one for raising zero dollars — i.e. if you can make it to profitability<br/>without raising any additional money. Ideally you want to be able to say to<br/>investors "We'll succeed no matter what, but raising money will help us do it<br/>faster."  <br/>  <br/>There are many analogies between fundraising and dating, and this is one of<br/>the strongest. No one wants you if you seem desperate. And the best way not to<br/>seem desperate is not to _be_ desperate. That's one reason we urge startups<br/>during YC to keep expenses low and to try to make it to ramen profitability<br/>before Demo Day. Though it sounds slightly paradoxical, if you want to raise<br/>money, the best thing you can do is get yourself to the point where you don't<br/>need to.  <br/>  <br/>There are almost two distinct modes of fundraising: one in which founders who<br/>need money knock on doors seeking it, knowing that otherwise the company will<br/>die or at the very least people will have to be fired, and one in which<br/>founders who don't need money take some to grow faster than they could merely<br/>on their own revenues. To emphasize the distinction I'm going to name them:<br/>type A fundraising is when you don't need money, and type B fundraising is<br/>when you do.  <br/>  <br/>Inexperienced founders read about famous startups doing what was type A<br/>fundraising, and decide they should raise money too, since that seems to be<br/>how startups work. Except when they raise money they don't have a clear path<br/>to profitability and are thus doing type B fundraising. And they are then<br/>surprised how difficult and unpleasant it is.  <br/>  <br/>Of course not all startups can make it to ramen profitability in a few months.<br/>And some that don't still manage to have the upper hand over investors, if<br/>they have some other advantage like extraordinary growth numbers or<br/>exceptionally formidable founders. But as time passes it gets increasingly<br/>difficult to fundraise from a position of strength without being profitable.<br/>[19]  <br/>  <br/>**Don't optimize for valuation.**  <br/>  <br/>When you raise money, what should your valuation be? The most important thing<br/>to understand about valuation is that it's not that important.  <br/>  <br/>Founders who raise money at high valuations tend to be unduly proud of it.<br/>Founders are often competitive people, and since valuation is usually the only<br/>visible number attached to a startup, they end up competing to raise money at<br/>the highest valuation. This is stupid, because fundraising is not the test<br/>that matters. The real test is revenue. Fundraising is just a means to that<br/>end. Being proud of how well you did at fundraising is like being proud of<br/>your college grades.  <br/>  <br/>Not only is fundraising not the test that matters, valuation is not even the<br/>thing to optimize about fundraising. The number one thing you want from phase<br/>2 fundraising is to get the money you need, so you can get back to focusing on<br/>the real test, the success of your company. Number two is good investors.<br/>Valuation is at best third.  <br/>  <br/>The empirical evidence shows just how unimportant it is. Dropbox and Airbnb<br/>are the most successful companies we've funded so far, and they raised money<br/>after Y Combinator at premoney valuations of $4 million and $2.6 million<br/>respectively. Prices are so much higher now that if you can raise money at all<br/>you'll probably raise it at higher valuations than Dropbox and Airbnb. So let<br/>that satisfy your competitiveness. You're doing better than Dropbox and<br/>Airbnb! At a test that doesn't matter.  <br/>  <br/>When you start fundraising, your initial valuation (or valuation cap) will be<br/>set by the deal you make with the first investor who commits. You can increase<br/>the price for later investors, if you get a lot of interest, but by default<br/>the valuation you got from the first investor becomes your asking price.  <br/>  <br/>So if you're raising money from multiple investors, as most companies do in<br/>phase 2, you have to be careful to avoid raising the first from an over-eager<br/>investor at a price you won't be able to sustain. You can of course lower your<br/>price if you need to (in which case you should give the same terms to<br/>investors who invested earlier at a higher price), but you may lose a bunch of<br/>leads in the process of realizing you need to do this.  <br/>  <br/>What you can do if you have eager first investors is raise money from them on<br/>an uncapped convertible note with an MFN clause. This is essentially a way of<br/>saying that the valuation cap of the note will be determined by the next<br/>investors you raise money from.  <br/>  <br/>It will be easier to raise money at a lower valuation. It shouldn't be, but it<br/>is. Since phase 2 prices vary at most 10x and the big successes generate<br/>returns of at least 100x, investors should pick startups entirely based on<br/>their estimate of the probability that the company will be a big success and<br/>hardly at all on price. But although it's a mistake for investors to care<br/>about price, a significant number do. A startup that investors seem to like<br/>but won't invest in at a cap of $x will have an easier time at $x/2. [20]  <br/>  <br/>**Yes/no before valuation.**  <br/>  <br/>Some investors want to know what your valuation is before they even talk to<br/>you about investing. If your valuation has already been set by a prior<br/>investment at a specific valuation or cap, you can tell them that number. But<br/>if it isn't set because you haven't closed anyone yet, and they try to push<br/>you to name a price, resist doing so. If this would be the first investor<br/>you've closed, then this could be the tipping point of fundraising. That means<br/>closing this investor is the first priority, and you need to get the<br/>conversation onto that instead of being dragged sideways into a discussion of<br/>price.  <br/>  <br/>Fortunately there is a way to avoid naming a price in this situation. And it<br/>is not just a negotiating trick; it's how you (both) should be operating. Tell<br/>them that valuation is not the most important thing to you and that you<br/>haven't thought much about it, that you are looking for investors you want to<br/>partner with and who want to partner with you, and that you should talk first<br/>about whether they want to invest at all. Then if they decide they do want to<br/>invest, you can figure out a price. But first things first.  <br/>  <br/>Since valuation isn't that important and getting fundraising rolling is, we<br/>usually tell founders to give the first investor who commits as low a price as<br/>they need to. This is a safe technique so long as you combine it with the next<br/>one. [21]  <br/>  <br/>**Beware "valuation sensitive" investors.**  <br/>  <br/>Occasionally you'll encounter investors who describe themselves as "valuation<br/>sensitive." What this means in practice is that they are compulsive<br/>negotiators who will suck up a lot of your time trying to push your price<br/>down. You should therefore never approach such investors first. While you<br/>shouldn't chase high valuations, you also don't want your valuation to be set<br/>artificially low because the first investor who committed happened to be a<br/>compulsive negotiator. Some such investors have value, but the time to<br/>approach them is near the end of fundraising, when you're in a position to say<br/>"this is the price everyone else has paid; take it or leave it" and not mind<br/>if they leave it. This way, you'll not only get market price, but it will also<br/>take less time.  <br/>  <br/>Ideally you know which investors have a reputation for being "valuation<br/>sensitive" and can postpone dealing with them till last, but occasionally one<br/>you didn't know about will pop up early on. The rule of doing breadth first<br/>search weighted by expected value already tells you what to do in this case:<br/>slow down your interactions with them.  <br/>  <br/>There are a handful of investors who will try to invest at a lower valuation<br/>even when your price has already been set. Lowering your price is a backup<br/>plan you resort to when you discover you've let the price get set too high to<br/>close all the money you need. So you'd only want to talk to this sort of<br/>investor if you were about to do that anyway. But since investor meetings have<br/>to be arranged at least a few days in advance and you can't predict when<br/>you'll need to resort to lowering your price, this means in practice that you<br/>should approach this type of investor last if at all.  <br/>  <br/>If you're surprised by a lowball offer, treat it as a backup offer and delay<br/>responding to it. When someone makes an offer in good faith, you have a moral<br/>obligation to respond in a reasonable time. But lowballing you is a dick move<br/>that should be met with the corresponding countermove.  <br/>  <br/>**Accept offers greedily.**  <br/>  <br/>I'm a little leery of using the term "greedily" when writing about fundraising<br/>lest non-programmers misunderstand me, but a greedy algorithm is simply one<br/>that doesn't try to look into the future. A greedy algorithm takes the best of<br/>the options in front of it right now. And that is how startups should approach<br/>fundraising in phases 2 and later. Don't try to look into the future because<br/>(a) the future is unpredictable, and indeed in this business you're often<br/>being deliberately misled about it and (b) your first priority in fundraising<br/>should be to get it finished and get back to work anyway.  <br/>  <br/>If someone makes you an acceptable offer, take it. If you have multiple<br/>incompatible offers, take the best. Don't reject an acceptable offer in the<br/>hope of getting a better one in the future.  <br/>  <br/>These simple rules cover a wide variety of cases. If you're raising money from<br/>many investors, roll them up as they say yes. As you start to feel you've<br/>raised enough, the threshold for acceptable will start to get higher.  <br/>  <br/>In practice offers exist for stretches of time, not points. So when you get an<br/>acceptable offer that would be incompatible with others (e.g. an offer to<br/>invest most of the money you need), you can tell the other investors you're<br/>talking to that you have an offer good enough to accept, and give them a few<br/>days to make their own. This could lose you some that might have made an offer<br/>if they had more time. But by definition you don't care; the initial offer was<br/>acceptable.  <br/>  <br/>Some investors will try to prevent others from having time to decide by giving<br/>you an "exploding" offer, meaning one that's only valid for a few days. Offers<br/>from the very best investors explode less frequently and less rapidly — Fred<br/>Wilson never gives exploding offers, for example — because they're confident<br/>you'll pick them. But lower-tier investors sometimes give offers with very<br/>short fuses, because they believe no one who had other options would choose<br/>them. A deadline of three working days is acceptable. You shouldn't need more<br/>than that if you've been talking to investors in parallel. But a deadline any<br/>shorter is a sign you're dealing with a sketchy investor. You can usually call<br/>their bluff, and you may need to. [22]  <br/>  <br/>It might seem that instead of accepting offers greedily, your goal should be<br/>to get the best investors as partners. That is certainly a good goal, but in<br/>phase 2 "get the best investors" only rarely conflicts with "accept offers<br/>greedily," because the best investors don't usually take any longer to decide<br/>than the others. The only case where the two strategies give conflicting<br/>advice is when you have to forgo an offer from an acceptable investor to see<br/>if you'll get an offer from a better one. If you talk to investors in parallel<br/>and push back on exploding offers with excessively short deadlines, that will<br/>almost never happen. But if it does, "get the best investors" is in the<br/>average case bad advice. The best investors are also the most selective,<br/>because they get their pick of all the startups. They reject nearly everyone<br/>they talk to, which means in the average case it's a bad trade to exchange a<br/>definite offer from an acceptable investor for a potential offer from a better<br/>one.  <br/>  <br/>(The situation is different in phase 1. You can't apply to all the incubators<br/>in parallel, because some offset their schedules to prevent this. In phase 1,<br/>"accept offers greedily" and "get the best investors" do conflict, so if you<br/>want to apply to multiple incubators, you should do it in such a way that the<br/>ones you want most decide first.)  <br/>  <br/>Sometimes when you're raising money from multiple investors, a series A will<br/>emerge out of those conversations, and these rules even cover what to do in<br/>that case. When an investor starts to talk to you about a series A, keep<br/>taking smaller investments till they actually give you a termsheet. There's no<br/>practical difficulty. If the smaller investments are on convertible notes,<br/>they'll just convert into the series A round. The series A investor won't like<br/>having all these other random investors as bedfellows, but if it bothers them<br/>so much they should get on with giving you a termsheet. Till they do, you<br/>don't know for sure they will, and the greedy algorithm tells you what to do.<br/>[23]  <br/>  <br/>**Don't sell more than 25% in phase 2.**  <br/>  <br/>If you do well, you will probably raise a series A round eventually. I say<br/>probably because things are changing with series A rounds. Startups may start<br/>to skip them. But only one company we've funded has so far, so tentatively<br/>assume the path to huge passes through an A round. [24]  <br/>  <br/>Which means you should avoid doing things in earlier rounds that will mess up<br/>raising an A round. For example, if you've sold more than about 40% of your<br/>company total, it starts to get harder to raise an A round, because VCs worry<br/>there will not be enough stock left to keep the founders motivated.  <br/>  <br/>Our rule of thumb is not to sell more than 25% in phase 2, on top of whatever<br/>you sold in phase 1, which should be less than 15%. If you're raising money on<br/>uncapped notes, you'll have to guess what the eventual equity round valuation<br/>might be. Guess conservatively.  <br/>  <br/>(Since the goal of this rule is to avoid messing up the series A, there's<br/>obviously an exception if you end up raising a series A in phase 2, as a<br/>handful of startups do.)  <br/>  <br/>**Have one person handle fundraising.**  <br/>  <br/>If you have multiple founders, pick one to handle fundraising so the other(s)<br/>can keep working on the company. And since the danger of fundraising is not<br/>the time taken up by the actual meetings but that it becomes the top idea in<br/>your mind, the founder who handles fundraising should make a conscious effort<br/>to insulate the other founder(s) from the details of the process. [25]  <br/>  <br/>(If the founders mistrust one another, this could cause some friction. But if<br/>the founders mistrust one another, you have worse problems to worry about than<br/>how to organize fundraising.)  <br/>  <br/>The founder who handles fundraising should be the CEO, who should in turn be<br/>the most formidable of the founders. Even if the CEO is a programmer and<br/>another founder is a salesperson? Yes. If you happen to be that type of<br/>founding team, you're effectively a single founder when it comes to<br/>fundraising.  <br/>  <br/>It's ok to bring all the founders to meet an investor who will invest a lot,<br/>and who needs this meeting as the final step before deciding. But wait till<br/>that point. Introducing an investor to your cofounder(s) should be like<br/>introducing a girl/boyfriend to your parents — something you do only when<br/>things reach a certain stage of seriousness.  <br/>  <br/>Even if there are still one or more founders focusing on the company during<br/>fundraising, growth will slow. But try to get as much growth as you can,<br/>because fundraising is a segment of time, not a point, and what happens to the<br/>company during that time affects the outcome. If your numbers grow<br/>significantly between two investor meetings, investors will be hot to close,<br/>and if your numbers are flat or down they'll start to get cold feet.  <br/>  <br/>**You'll need an executive summary and (maybe) a deck.**  <br/>  <br/>Traditionally phase 2 fundraising consists of presenting a slide deck in<br/>person to investors. Sequoia describes what such a deck should contain, and<br/>since they're the customer you can take their word for it.  <br/>  <br/>I say "traditionally" because I'm ambivalent about decks, and (though perhaps<br/>this is wishful thinking) they seem to be on the way out. A lot of the most<br/>successful startups we fund never make decks in phase 2. They just talk to<br/>investors and explain what they plan to do. Fundraising usually takes off fast<br/>for the startups that are most successful at it, and they're thus able to<br/>excuse themselves by saying that they haven't had time to make a deck.  <br/>  <br/>You'll also want an executive summary, which should be no more than a page<br/>long and describe in the most matter of fact language what you plan to do, why<br/>it's a good idea, and what progress you've made so far. The point of the<br/>summary is to remind the investor (who may have met many startups that day)<br/>what you talked about.  <br/>  <br/>Assume that if you give someone a copy of your deck or executive summary, it<br/>will be passed on to whoever you'd least like to have it. But don't refuse on<br/>that account to give copies to investors you meet. You just have to treat such<br/>leaks as a cost of doing business. In practice it's not that high a cost.<br/>Though founders are rightly indignant when their plans get leaked to<br/>competitors, I can't think of a startup whose outcome has been affected by it.  <br/>  <br/>Sometimes an investor will ask you to send them your deck and/or executive<br/>summary before they decide whether to meet with you. I wouldn't do that. It's<br/>a sign they're not really interested.  <br/>  <br/>**Stop fundraising when it stops working.**  <br/>  <br/>When do you stop fundraising? Ideally when you've raised enough. But what if<br/>you haven't raised as much as you'd like? When do you give up?  <br/>  <br/>It's hard to give general advice about this, because there have been cases of<br/>startups that kept trying to raise money even when it seemed hopeless, and<br/>miraculously succeeded. But what I usually tell founders is to stop<br/>fundraising when you start to get a lot of air in the straw. When you're<br/>drinking through a straw, you can tell when you get to the end of the liquid<br/>because you start to get a lot of air in the straw. When your fundraising<br/>options run out, they usually run out in the same way. Don't keep sucking on<br/>the straw if you're just getting air. It's not going to get better.  <br/>  <br/>**Don't get addicted to fundraising.**  <br/>  <br/>Fundraising is a chore for most founders, but some find it more interesting<br/>than working on their startup. The work at an early stage startup often<br/>consists of unglamorous schleps. Whereas fundraising, when it's going well,<br/>can be quite the opposite. Instead of sitting in your grubby apartment<br/>listening to users complain about bugs in your software, you're being offered<br/>millions of dollars by famous investors over lunch at a nice restaurant. [26]  <br/>  <br/>The danger of fundraising is particularly acute for people who are good at it.<br/>It's always fun to work on something you're good at. If you're one of these<br/>people, beware. Fundraising is not what will make your company successful.<br/>Listening to users complain about bugs in your software is what will make you<br/>successful. And the big danger of getting addicted to fundraising is not<br/>merely that you'll spend too long on it or raise too much money. It's that<br/>you'll start to think of yourself as being already successful, and lose your<br/>taste for the schleps you need to undertake to actually be successful.<br/>Startups can be destroyed by this.  <br/>  <br/>When I see a startup with young founders that is fabulously successful at<br/>fundraising, I mentally decrease my estimate of the probability that they'll<br/>succeed. The press may be writing about them as if they'd been anointed as the<br/>next Google, but I'm thinking "this is going to end badly."  <br/>  <br/>**Don't raise too much.**  <br/>  <br/>Though only a handful of startups have to worry about this, it is possible to<br/>raise too much. The dangers of raising too much are subtle but insidious. One<br/>is that it will set impossibly high expectations. If you raise an excessive<br/>amount of money, it will be at a high valuation, and the danger of raising<br/>money at too high a valuation is that you won't be able to increase it<br/>sufficiently the next time you raise money.  <br/>  <br/>A company's valuation is expected to rise each time it raises money. If not<br/>it's a sign of a company in trouble, which makes you unattractive to<br/>investors. So if you raise money in phase 2 at a post-money valuation of $30<br/>million, the pre-money valuation of your next round, if you want to raise one,<br/>is going to have to be at least $50 million. And you have to be doing really,<br/>really well to raise money at $50 million.  <br/>  <br/>It's very dangerous to let the competitiveness of your current round set the<br/>performance threshold you have to meet to raise your next one, because the two<br/>are only loosely coupled.  <br/>  <br/>But the money itself may be more dangerous than the valuation. The more you<br/>raise, the more you spend, and spending a lot of money can be disastrous for<br/>an early stage startup. Spending a lot makes it harder to become profitable,<br/>and perhaps even worse, it makes you more rigid, because the main way to spend<br/>money is people, and the more people you have, the harder it is to change<br/>directions. So if you do raise a huge amount of money, don't spend it. (You<br/>will find that advice almost impossible to follow, so hot will be the money<br/>burning a hole in your pocket, but I feel obliged at least to try.)  <br/>  <br/>**Be nice.**  <br/>  <br/>Startups raising money occasionally alienate investors by seeming arrogant.<br/>Sometimes because they are arrogant, and sometimes because they're noobs<br/>clumsily attempting to mimic the toughness they've observed in experienced<br/>founders.  <br/>  <br/>It's a mistake to behave arrogantly to investors. While there are certain<br/>situations in which certain investors like certain kinds of arrogance,<br/>investors vary greatly in this respect, and a flick of the whip that will<br/>bring one to heel will make another roar with indignation. The only safe<br/>strategy is never to seem arrogant at all.  <br/>  <br/>That will require some diplomacy if you follow the advice I've given here,<br/>because the advice I've given is essentially how to play hardball back. When<br/>you refuse to meet an investor because you're not in fundraising mode, or slow<br/>down your interactions with an investor who moves too slow, or treat a<br/>contingent offer as the no it actually is and then, by accepting offers<br/>greedily, end up leaving that investor out, you're going to be doing things<br/>investors don't like. So you must cushion the blow with soft words. At YC we<br/>tell startups they can blame us. And now that I've written this, everyone else<br/>can blame me if they want. That plus the inexperience card should work in most<br/>situations: sorry, we think you're great, but PG said startups shouldn't ___,<br/>and since we're new to fundraising, we feel like we have to play it safe.  <br/>  <br/>The danger of behaving arrogantly is greatest when you're doing well. When<br/>everyone wants you, it's hard not to let it go to your head. Especially if<br/>till recently no one wanted you. But restrain yourself. The startup world is a<br/>small place, and startups have lots of ups and downs. This is a domain where<br/>it's more true than usual that pride goeth before a fall. [27]  <br/>  <br/>Be nice when investors reject you as well. The best investors are not wedded<br/>to their initial opinion of you. If they reject you in phase 2 and you end up<br/>doing well, they'll often invest in phase 3\. In fact investors who reject you<br/>are some of your warmest leads for future fundraising. Any investor who spent<br/>significant time deciding probably came close to saying yes. Often you have<br/>some internal champion who only needs a little more evidence to convince the<br/>skeptics. So it's wise not merely to be nice to investors who reject you, but<br/>(unless they behaved badly) to treat it as the beginning of a relationship.  <br/>  <br/>**The bar will be higher next time.**  <br/>  <br/>Assume the money you raise in phase 2 will be the last you ever raise. You<br/>must make it to profitability on this money if you can.  <br/>  <br/>Over the past several years, the investment community has evolved from a<br/>strategy of anointing a small number of winners early and then supporting them<br/>for years to a strategy of spraying money at early stage startups and then<br/>ruthlessly culling them at the next stage. This is probably the optimal<br/>strategy for investors. It's too hard to pick winners early on. Better to let<br/>the market do it for you. But it often comes as a surprise to startups how<br/>much harder it is to raise money in phase 3.  <br/>  <br/>When your company is only a couple months old, all it has to be is a promising<br/>experiment that's worth funding to see how it turns out. The next time you<br/>raise money, the experiment has to have worked. You have to be on a trajectory<br/>that leads to going public. And while there are some ideas where the proof<br/>that the experiment worked might consist of e.g. query response times, usually<br/>the proof is profitability. Usually phase 3 fundraising has to be type A<br/>fundraising.  <br/>  <br/>In practice there are two ways startups hose themselves between phases 2 and<br/>3. Some are just too slow to become profitable. They raise enough money to<br/>last for two years. There doesn't seem any particular urgency to be<br/>profitable. So they don't make any effort to make money for a year. But by<br/>that time, not making money has become habitual. When they finally decide to<br/>try, they find they can't.  <br/>  <br/>The other way companies hose themselves is by letting their expenses grow too<br/>fast. Which almost always means hiring too many people. You usually shouldn't<br/>go out and hire 8 people as soon as you raise money at phase 2. Usually you<br/>want to wait till you have growth (and thus usually revenues) to justify them.<br/>A lot of VCs will encourage you to hire aggressively. VCs generally tell you<br/>to spend too much, partly because as money people they err on the side of<br/>solving problems by spending money, and partly because they want you to sell<br/>them more of your company in subsequent rounds. Don't listen to them.  <br/>  <br/>**Don't make things complicated.**  <br/>  <br/>I realize it may seem odd to sum up this huge treatise by saying that my<br/>overall advice is not to make fundraising too complicated, but if you go back<br/>and look at this list you'll see it's basically a simple recipe with a lot of<br/>implications and edge cases. Avoid investors till you decide to raise money,<br/>and then when you do, talk to them all in parallel, prioritized by expected<br/>value, and accept offers greedily. That's fundraising in one sentence. Don't<br/>introduce complicated optimizations, and don't let investors introduce<br/>complications either.  <br/>  <br/>Fundraising is not what will make you successful. It's just a means to an end.<br/>Your primary goal should be to get it over with and get back to what will make<br/>you successful — making things and talking to users — and the path I've<br/>described will for most startups be the surest way to that destination.  <br/>  <br/>Be good, take care of yourselves, and _don't leave the path_.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] The worst explosions happen when unpromising-seeming startups encounter<br/>mediocre investors. Good investors don't lead startups on; their reputations<br/>are too valuable. And startups that seem promising can usually get enough<br/>money from good investors that they don't have to talk to mediocre ones. It is<br/>the unpromising-seeming startups that have to resort to raising money from<br/>mediocre investors. And it's particularly damaging when these investors flake,<br/>because unpromising-seeming startups are usually more desperate for money.  <br/>  <br/>(Not all unpromising-seeming startups do badly. Some are merely ugly ducklings<br/>in the sense that they violate current startup fashions.)  <br/>  <br/>[2] One YC founder told me:<br/><br/>> I think in general we've done ok at fundraising, but I managed to screw up<br/>> twice at the exact same thing — trying to focus on building the company and<br/>> fundraising at the same time.<br/><br/>[3] There is one subtle danger you have to watch out for here, which I warn<br/>about later: beware of getting too high a valuation from an eager investor,<br/>lest that set an impossibly high target when raising additional money.  <br/>  <br/>[4] If they really need a meeting, then they're not ready to invest,<br/>regardless of what they say. They're still deciding, which means you're being<br/>asked to come in and convince them. Which is fundraising.  <br/>  <br/>[5] Associates at VC firms regularly cold email startups. Naive founders think<br/>"Wow, a VC is interested in us!" But an associate is not a VC. They have no<br/>decision-making power. And while they may introduce startups they like to<br/>partners at their firm, the partners discriminate against deals that come to<br/>them this way. I don't know of a single VC investment that began with an<br/>associate cold-emailing a startup. If you want to approach a specific firm,<br/>get an intro to a partner from someone they respect.  <br/>  <br/>It's ok to talk to an associate if you get an intro to a VC firm or they see<br/>you at a Demo Day and they begin by having an associate vet you. That's not a<br/>promising lead and should therefore get low priority, but it's not as<br/>completely worthless as a cold email.  <br/>  <br/>Because the title "associate" has gotten a bad reputation, a few VC firms have<br/>started to give their associates the title "partner," which can make things<br/>very confusing. If you're a YC startup you can ask us who's who; otherwise you<br/>may have to do some research online. There may be a special title for actual<br/>partners. If someone speaks for the firm in the press or a blog on the firm's<br/>site, they're probably a real partner. If they're on boards of directors<br/>they're probably a real partner.  <br/>  <br/>There are titles between "associate" and "partner," including "principal" and<br/>"venture partner." The meanings of these titles vary too much to generalize.  <br/>  <br/>[6] For similar reasons, avoid casual conversations with potential acquirers.<br/>They can lead to distractions even more dangerous than fundraising. Don't even<br/>take a meeting with a potential acquirer unless you want to sell your company<br/>right now.  <br/>  <br/>[7] Joshua Reeves specifically suggests asking each investor to intro you to<br/>two more investors.  <br/>  <br/>Don't ask investors who say no for introductions to other investors. That will<br/>in many cases be an anti-recommendation.  <br/>  <br/>[8] This is not always as deliberate as its sounds. A lot of the delays and<br/>disconnects between founders and investors are induced by the customs of the<br/>venture business, which have evolved the way they have because they suit<br/>investors' interests.  <br/>  <br/>[9] One YC founder who read a draft of this essay wrote:<br/><br/>> This is the most important section. I think it might bear stating even more<br/>> clearly. "Investors will deliberately affect more interest than they have to<br/>> preserve optionality. If an investor seems very interested in you, they<br/>> still probably won't invest. The solution for this is to assume the worst —<br/>> that an investor is just feigning interest — until you get a definite<br/>> commitment."<br/><br/>[10] Though you should probably pack investor meetings as closely as you can,<br/>Jeff Byun mentions one reason not to: if you pack investor meetings too<br/>closely, you'll have less time for your pitch to evolve.  <br/>  <br/>Some founders deliberately schedule a handful of lame investors first, to get<br/>the bugs out of their pitch.  <br/>  <br/>[11] There is not an efficient market in this respect. Some of the most<br/>useless investors are also the highest maintenance.  <br/>  <br/>[12] Incidentally, this paragraph is sales 101. If you want to see it in<br/>action, go talk to a car dealer.  <br/>  <br/>[13] I know one very smooth founder who used to end investor meetings with<br/>"So, can I count you in?" delivered as if it were "Can you pass the salt?"<br/>Unless you're very smooth (if you're not sure...), do not do this yourself.<br/>There is nothing more unconvincing, for an investor, than a nerdy founder<br/>trying to deliver the lines meant for a smooth one.  <br/>  <br/>Investors are fine with funding nerds. So if you're a nerd, just try to be a<br/>good nerd, rather than doing a bad imitation of a smooth salesman.  <br/>  <br/>[14] Ian Hogarth suggests a good way to tell how serious potential investors<br/>are: the resources they expend on you after the first meeting. An investor<br/>who's seriously interested will already be working to help you even before<br/>they've committed.  <br/>  <br/>[15] In principle you might have to think about so-called "signalling risk."<br/>If a prestigious VC makes a small seed investment in you, what if they don't<br/>want to invest the next time you raise money? Other investors might assume<br/>that the VC knows you well, since they're an existing investor, and if they<br/>don't want to invest in your next round, that must mean you suck. The reason I<br/>say "in principle" is that in practice signalling hasn't been much of a<br/>problem so far. It rarely arises, and in the few cases where it does, the<br/>startup in question usually is doing badly and is doomed anyway.  <br/>  <br/>If you have the luxury of choosing among seed investors, you can play it safe<br/>by excluding VC firms. But it isn't critical to.  <br/>  <br/>[16] Sometimes a competitor will deliberately threaten you with a lawsuit just<br/>as you start fundraising, because they know you'll have to disclose the threat<br/>to potential investors and they hope this will make it harder for you to raise<br/>money. If this happens it will probably frighten you more than investors.<br/>Experienced investors know about this trick, and know the actual lawsuits<br/>rarely happen. So if you're attacked in this way, be forthright with<br/>investors. They'll be more alarmed if you seem evasive than if you tell them<br/>everything.  <br/>  <br/>[17] A related trick is to claim that they'll only invest contingently on<br/>other investors doing so because otherwise you'd be "undercapitalized." This<br/>is almost always bullshit. They can't estimate your minimum capital needs that<br/>precisely.  <br/>  <br/>[18] You won't hire all those 20 people at once, and you'll probably have some<br/>revenues before 18 months are out. But those too are acceptable or at least<br/>accepted additions to the margin for error.  <br/>  <br/>[19] Type A fundraising is so much better that it might even be worth doing<br/>something different if it gets you there sooner. One YC founder told me that<br/>if he were a first-time founder again he'd "leave ideas that are up-front<br/>capital intensive to founders with established reputations."  <br/>  <br/>[20] I don't know whether this happens because they're innumerate, or because<br/>they believe they have zero ability to predict startup outcomes (in which case<br/>this behavior at least wouldn't be irrational). In either case the<br/>implications are similar.  <br/>  <br/>[21] If you're a YC startup and you have an investor who for some reason<br/>insists that you decide the price, any YC partner can estimate a market price<br/>for you.  <br/>  <br/>[22] You should respond in kind when investors behave upstandingly too. When<br/>an investor makes you a clean offer with no deadline, you have a moral<br/>obligation to respond promptly.  <br/>  <br/>[23] Tell the investors talking to you about an A round about the smaller<br/>investments you raise as you raise them. You owe them such updates on your cap<br/>table, and this is also a good way to pressure them to act. They won't like<br/>you raising other money and may pressure you to stop, but they can't<br/>legitimately ask you to commit to them till they also commit to you. If they<br/>want you to stop raising money, the way to do it is to give you a series A<br/>termsheet with a no-shop clause.  <br/>  <br/>You can relent a little if the potential series A investor has a great<br/>reputation and they're clearly working fast to get you a termsheet,<br/>particularly if a third party like YC is involved to ensure there are no<br/>misunderstandings. But be careful.  <br/>  <br/>[24] The company is Weebly, which made it to profitability on a seed<br/>investment of $650k. They did try to raise a series A in the fall of 2008 but<br/>(no doubt partly because it was the fall of 2008) the terms they were offered<br/>were so bad that they decided to skip raising an A round.  <br/>  <br/>[25] Another advantage of having one founder take fundraising meetings is that<br/>you never have to negotiate in real time, which is something inexperienced<br/>founders should avoid. One YC founder told me:<br/><br/>> Investors are professional negotiators and can negotiate on the spot very<br/>> easily. If only one founder is in the room, you can say "I need to circle<br/>> back with my co-founder" before making any commitments. I used to do this<br/>> all the time.<br/><br/>[26] You'll be lucky if fundraising feels pleasant enough to become addictive.<br/>More often you have to worry about the other extreme — becoming demoralized<br/>when investors reject you. As one (very successful) YC founder wrote after<br/>reading a draft of this:<br/><br/>> It's hard to mentally deal with the sheer scale of rejection in fundraising<br/>> and if you are not in the right mindset you will fail. Users may love you<br/>> but these supposedly smart investors may not understand you at all. At this<br/>> point for me, rejection still rankles but I've come to accept that investors<br/>> are just not super thoughtful for the most part and you need to play the<br/>> game according to certain somewhat depressing rules (many of which you are<br/>> listing) in order to win.<br/><br/>[27] The actual sentence in the King James Bible is "Pride goeth before<br/>destruction, and an haughty spirit before a fall."  <br/>  <br/> **Thanks** to Slava Akhmechet, Sam Altman, Nate Blecharczyk, Adora Cheung,<br/>Bill Clerico, John Collison, Patrick Collison, Parker Conrad, Ron Conway,<br/>Travis Deyle, Jason Freedman, Joe Gebbia, Mattan Griffel, Kevin Hale, Jacob<br/>Heller, Ian Hogarth, Justin Kan, Professor Moriarty, Nikhil Nirmel, David<br/>Petersen, Geoff Ralston, Joshua Reeves, Yuri Sagalov, Emmett Shear, Rajat<br/>Suri, Garry Tan, and Nick Tomarello for reading drafts of this.  <br/>  <br/><br/>Russian Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>August 2005  <br/>  <br/> _(This essay is derived from a talk at Oscon 2005.)_  <br/>  <br/>Lately companies have been paying more attention to open source. Ten years ago<br/>there seemed a real danger Microsoft would extend its monopoly to servers. It<br/>seems safe to say now that open source has prevented that. A recent survey<br/>found 52% of companies are replacing Windows servers with Linux servers. [1]  <br/>  <br/>More significant, I think, is _which_ 52% they are. At this point, anyone<br/>proposing to run Windows on servers should be prepared to explain what they<br/>know about servers that Google, Yahoo, and Amazon don't.  <br/>  <br/>But the biggest thing business has to learn from open source is not about<br/>Linux or Firefox, but about the forces that produced them. Ultimately these<br/>will affect a lot more than what software you use.  <br/>  <br/>We may be able to get a fix on these underlying forces by triangulating from<br/>open source and blogging. As you've probably noticed, they have a lot in<br/>common.  <br/>  <br/>Like open source, blogging is something people do themselves, for free,<br/>because they enjoy it. Like open source hackers, bloggers compete with people<br/>working for money, and often win. The method of ensuring quality is also the<br/>same: Darwinian. Companies ensure quality through rules to prevent employees<br/>from screwing up. But you don't need that when the audience can communicate<br/>with one another. People just produce whatever they want; the good stuff<br/>spreads, and the bad gets ignored. And in both cases, feedback from the<br/>audience improves the best work.  <br/>  <br/>Another thing blogging and open source have in common is the Web. People have<br/>always been willing to do great work for free, but before the Web it was<br/>harder to reach an audience or collaborate on projects.  <br/>  <br/> **Amateurs**  <br/>  <br/>I think the most important of the new principles business has to learn is that<br/>people work a lot harder on stuff they like. Well, that's news to no one. So<br/>how can I claim business has to learn it? When I say business doesn't know<br/>this, I mean the structure of business doesn't reflect it.  <br/>  <br/>Business still reflects an older model, exemplified by the French word for<br/>working: _travailler_. It has an English cousin, travail, and what it means is<br/>torture. [2]  <br/>  <br/>This turns out not to be the last word on work, however. As societies get<br/>richer, they learn something about work that's a lot like what they learn<br/>about diet. We know now that the healthiest diet is the one our peasant<br/>ancestors were forced to eat because they were poor. Like rich food, idleness<br/>only seems desirable when you don't get enough of it. I think we were designed<br/>to work, just as we were designed to eat a certain amount of fiber, and we<br/>feel bad if we don't.  <br/>  <br/>There's a name for people who work for the love of it: amateurs. The word now<br/>has such bad connotations that we forget its etymology, though it's staring us<br/>in the face. "Amateur" was originally rather a complimentary word. But the<br/>thing to be in the twentieth century was professional, which amateurs, by<br/>definition, are not.  <br/>  <br/>That's why the business world was so surprised by one lesson from open source:<br/>that people working for love often surpass those working for money. Users<br/>don't switch from Explorer to Firefox because they want to hack the source.<br/>They switch because it's a better browser.  <br/>  <br/>It's not that Microsoft isn't trying. They know controlling the browser is one<br/>of the keys to retaining their monopoly. The problem is the same they face in<br/>operating systems: they can't pay people enough to build something better than<br/>a group of inspired hackers will build for free.  <br/>  <br/>I suspect professionalism was always overrated-- not just in the literal sense<br/>of working for money, but also connotations like formality and detachment.<br/>Inconceivable as it would have seemed in, say, 1970, I think professionalism<br/>was largely a fashion, driven by conditions that happened to exist in the<br/>twentieth century.  <br/>  <br/>One of the most powerful of those was the existence of "channels."<br/>Revealingly, the same term was used for both products and information: there<br/>were distribution channels, and TV and radio channels.  <br/>  <br/>It was the narrowness of such channels that made professionals seem so<br/>superior to amateurs. There were only a few jobs as professional journalists,<br/>for example, so competition ensured the average journalist was fairly good.<br/>Whereas anyone can express opinions about current events in a bar. And so the<br/>average person expressing his opinions in a bar sounds like an idiot compared<br/>to a journalist writing about the subject.  <br/>  <br/>On the Web, the barrier for publishing your ideas is even lower. You don't<br/>have to buy a drink, and they even let kids in. Millions of people are<br/>publishing online, and the average level of what they're writing, as you might<br/>expect, is not very good. This has led some in the media to conclude that<br/>blogs don't present much of a threat-- that blogs are just a fad.  <br/>  <br/>Actually, the fad is the word "blog," at least the way the print media now use<br/>it. What they mean by "blogger" is not someone who publishes in a weblog<br/>format, but anyone who publishes online. That's going to become a problem as<br/>the Web becomes the default medium for publication. So I'd like to suggest an<br/>alternative word for someone who publishes online. How about "writer?"  <br/>  <br/>Those in the print media who dismiss the writing online because of its low<br/>average quality are missing an important point: no one reads the _average_<br/>blog. In the old world of channels, it meant something to talk about average<br/>quality, because that's what you were getting whether you liked it or not. But<br/>now you can read any writer you want. So the average quality of writing online<br/>isn't what the print media are competing against. They're competing against<br/>the best writing online. And, like Microsoft, they're losing.  <br/>  <br/>I know that from my own experience as a reader. Though most print publications<br/>are online, I probably read two or three articles on individual people's sites<br/>for every one I read on the site of a newspaper or magazine.  <br/>  <br/>And when I read, say, New York Times stories, I never reach them through the<br/>Times front page. Most I find through aggregators like Google News or Slashdot<br/>or Delicious. Aggregators show how much better you can do than the channel.<br/>The New York Times front page is a list of articles written by people who work<br/>for the New York Times. Delicious is a list of articles that are interesting.<br/>And it's only now that you can see the two side by side that you notice how<br/>little overlap there is.  <br/>  <br/>Most articles in the print media are boring. For example, the president<br/>notices that a majority of voters now think invading Iraq was a mistake, so he<br/>makes an address to the nation to drum up support. Where is the man bites dog<br/>in that? I didn't hear the speech, but I could probably tell you exactly what<br/>he said. A speech like that is, in the most literal sense, not news: there is<br/>nothing _new_ in it. [3]  <br/>  <br/>Nor is there anything new, except the names and places, in most "news" about<br/>things going wrong. A child is abducted; there's a tornado; a ferry sinks;<br/>someone gets bitten by a shark; a small plane crashes. And what do you learn<br/>about the world from these stories? Absolutely nothing. They're outlying data<br/>points; what makes them gripping also makes them irrelevant.  <br/>  <br/>As in software, when professionals produce such crap, it's not surprising if<br/>amateurs can do better. Live by the channel, die by the channel: if you depend<br/>on an oligopoly, you sink into bad habits that are hard to overcome when you<br/>suddenly get competition. [4]  <br/>  <br/> **Workplaces**  <br/>  <br/>Another thing blogs and open source software have in common is that they're<br/>often made by people working at home. That may not seem surprising. But it<br/>should be. It's the architectural equivalent of a home-made aircraft shooting<br/>down an F-18. Companies spend millions to build office buildings for a single<br/>purpose: to be a place to work. And yet people working in their own homes,<br/>which aren't even designed to be workplaces, end up being more productive.  <br/>  <br/>This proves something a lot of us have suspected. The average office is a<br/>miserable place to get work done. And a lot of what makes offices bad are the<br/>very qualities we associate with professionalism. The sterility of offices is<br/>supposed to suggest efficiency. But suggesting efficiency is a different thing<br/>from actually being efficient.  <br/>  <br/>The atmosphere of the average workplace is to productivity what flames painted<br/>on the side of a car are to speed. And it's not just the way offices look<br/>that's bleak. The way people act is just as bad.  <br/>  <br/>Things are different in a startup. Often as not a startup begins in an<br/>apartment. Instead of matching beige cubicles they have an assortment of<br/>furniture they bought used. They work odd hours, wearing the most casual of<br/>clothing. They look at whatever they want online without worrying whether it's<br/>"work safe." The cheery, bland language of the office is replaced by wicked<br/>humor. And you know what? The company at this stage is probably the most<br/>productive it's ever going to be.  <br/>  <br/>Maybe it's not a coincidence. Maybe some aspects of professionalism are<br/>actually a net lose.  <br/>  <br/>To me the most demoralizing aspect of the traditional office is that you're<br/>supposed to be there at certain times. There are usually a few people in a<br/>company who really have to, but the reason most employees work fixed hours is<br/>that the company can't measure their productivity.  <br/>  <br/>The basic idea behind office hours is that if you can't make people work, you<br/>can at least prevent them from having fun. If employees have to be in the<br/>building a certain number of hours a day, and are forbidden to do non-work<br/>things while there, then they must be working. In theory. In practice they<br/>spend a lot of their time in a no-man's land, where they're neither working<br/>nor having fun.  <br/>  <br/>If you could measure how much work people did, many companies wouldn't need<br/>any fixed workday. You could just say: this is what you have to do. Do it<br/>whenever you like, wherever you like. If your work requires you to talk to<br/>other people in the company, then you may need to be here a certain amount.<br/>Otherwise we don't care.  <br/>  <br/>That may seem utopian, but it's what we told people who came to work for our<br/>company. There were no fixed office hours. I never showed up before 11 in the<br/>morning. But we weren't saying this to be benevolent. We were saying: if you<br/>work here we expect you to get a lot done. Don't try to fool us just by being<br/>here a lot.  <br/>  <br/>The problem with the facetime model is not just that it's demoralizing, but<br/>that the people pretending to work interrupt the ones actually working. I'm<br/>convinced the facetime model is the main reason large organizations have so<br/>many meetings. Per capita, large organizations accomplish very little. And yet<br/>all those people have to be on site at least eight hours a day. When so much<br/>time goes in one end and so little achievement comes out the other, something<br/>has to give. And meetings are the main mechanism for taking up the slack.  <br/>  <br/>For one year I worked at a regular nine to five job, and I remember well the<br/>strange, cozy feeling that comes over one during meetings. I was very aware,<br/>because of the novelty, that I was being paid for programming. It seemed just<br/>amazing, as if there was a machine on my desk that spat out a dollar bill<br/>every two minutes no matter what I did. Even while I was in the bathroom! But<br/>because the imaginary machine was always running, I felt I always ought to be<br/>working. And so meetings felt wonderfully relaxing. They counted as work, just<br/>like programming, but they were so much easier. All you had to do was sit and<br/>look attentive.  <br/>  <br/>Meetings are like an opiate with a network effect. So is email, on a smaller<br/>scale. And in addition to the direct cost in time, there's the cost in<br/>fragmentation-- breaking people's day up into bits too small to be useful.  <br/>  <br/>You can see how dependent you've become on something by removing it suddenly.<br/>So for big companies I propose the following experiment. Set aside one day<br/>where meetings are forbidden-- where everyone has to sit at their desk all day<br/>and work without interruption on things they can do without talking to anyone<br/>else. Some amount of communication is necessary in most jobs, but I'm sure<br/>many employees could find eight hours worth of stuff they could do by<br/>themselves. You could call it "Work Day."  <br/>  <br/>The other problem with pretend work is that it often looks better than real<br/>work. When I'm writing or hacking I spend as much time just thinking as I do<br/>actually typing. Half the time I'm sitting drinking a cup of tea, or walking<br/>around the neighborhood. This is a critical phase-- this is where ideas come<br/>from-- and yet I'd feel guilty doing this in most offices, with everyone else<br/>looking busy.  <br/>  <br/>It's hard to see how bad some practice is till you have something to compare<br/>it to. And that's one reason open source, and even blogging in some cases, are<br/>so important. They show us what real work looks like.  <br/>  <br/>We're funding eight new startups at the moment. A friend asked what they were<br/>doing for office space, and seemed surprised when I said we expected them to<br/>work out of whatever apartments they found to live in. But we didn't propose<br/>that to save money. We did it because we want their software to be good.<br/>Working in crappy informal spaces is one of the things startups do right<br/>without realizing it. As soon as you get into an office, work and life start<br/>to drift apart.  <br/>  <br/>That is one of the key tenets of professionalism. Work and life are supposed<br/>to be separate. But that part, I'm convinced, is a mistake.  <br/>  <br/> **Bottom-Up**  <br/>  <br/>The third big lesson we can learn from open source and blogging is that ideas<br/>can bubble up from the bottom, instead of flowing down from the top. Open<br/>source and blogging both work bottom-up: people make what they want, and the<br/>best stuff prevails.  <br/>  <br/>Does this sound familiar? It's the principle of a market economy. Ironically,<br/>though open source and blogs are done for free, those worlds resemble market<br/>economies, while most companies, for all their talk about the value of free<br/>markets, are run internally like communist states.  <br/>  <br/>There are two forces that together steer design: ideas about what to do next,<br/>and the enforcement of quality. In the channel era, both flowed down from the<br/>top. For example, newspaper editors assigned stories to reporters, then edited<br/>what they wrote.  <br/>  <br/>Open source and blogging show us things don't have to work that way. Ideas and<br/>even the enforcement of quality can flow bottom-up. And in both cases the<br/>results are not merely acceptable, but better. For example, open source<br/>software is more reliable precisely because it's open source; anyone can find<br/>mistakes.  <br/>  <br/>The same happens with writing. As we got close to publication, I found I was<br/>very worried about the essays in Hackers & Painters that hadn't been online.<br/>Once an essay has had a couple thousand page views I feel reasonably confident<br/>about it. But these had had literally orders of magnitude less scrutiny. It<br/>felt like releasing software without testing it.  <br/>  <br/>That's what all publishing used to be like. If you got ten people to read a<br/>manuscript, you were lucky. But I'd become so used to publishing online that<br/>the old method now seemed alarmingly unreliable, like navigating by dead<br/>reckoning once you'd gotten used to a GPS.  <br/>  <br/>The other thing I like about publishing online is that you can write what you<br/>want and publish when you want. Earlier this year I wrote something that<br/>seemed suitable for a magazine, so I sent it to an editor I know. As I was<br/>waiting to hear back, I found to my surprise that I was hoping they'd reject<br/>it. Then I could put it online right away. If they accepted it, it wouldn't be<br/>read by anyone for months, and in the meantime I'd have to fight word-by-word<br/>to save it from being mangled by some twenty five year old copy editor. [5]  <br/>  <br/>Many employees would _like_ to build great things for the companies they work<br/>for, but more often than not management won't let them. How many of us have<br/>heard stories of employees going to management and saying, please let us build<br/>this thing to make money for you-- and the company saying no? The most famous<br/>example is probably Steve Wozniak, who originally wanted to build<br/>microcomputers for his then-employer, HP. And they turned him down. On the<br/>blunderometer, this episode ranks with IBM accepting a non-exclusive license<br/>for DOS. But I think this happens all the time. We just don't hear about it<br/>usually, because to prove yourself right you have to quit and start your own<br/>company, like Wozniak did.  <br/>  <br/> **Startups**  <br/>  <br/>So these, I think, are the three big lessons open source and blogging have to<br/>teach business: (1) that people work harder on stuff they like, (2) that the<br/>standard office environment is very unproductive, and (3) that bottom-up often<br/>works better than top-down.  <br/>  <br/>I can imagine managers at this point saying: what is this guy talking about?<br/>What good does it do me to know that my programmers would be more productive<br/>working at home on their own projects? I need their asses in here working on<br/>version 3.2 of our software, or we're never going to make the release date.  <br/>  <br/>And it's true, the benefit that specific manager could derive from the forces<br/>I've described is near zero. When I say business can learn from open source, I<br/>don't mean any specific business can. I mean business can learn about new<br/>conditions the same way a gene pool does. I'm not claiming companies can get<br/>smarter, just that dumb ones will die.  <br/>  <br/>So what will business look like when it has assimilated the lessons of open<br/>source and blogging? I think the big obstacle preventing us from seeing the<br/>future of business is the assumption that people working for you have to be<br/>employees. But think about what's going on underneath: the company has some<br/>money, and they pay it to the employee in the hope that he'll make something<br/>worth more than they paid him. Well, there are other ways to arrange that<br/>relationship. Instead of paying the guy money as a salary, why not give it to<br/>him as investment? Then instead of coming to your office to work on your<br/>projects, he can work wherever he wants on projects of his own.  <br/>  <br/>Because few of us know any alternative, we have no idea how much better we<br/>could do than the traditional employer-employee relationship. Such customs<br/>evolve with glacial slowness. Our employer-employee relationship still retains<br/>a big chunk of master-servant DNA. [6]  <br/>  <br/>I dislike being on either end of it. I'll work my ass off for a customer, but<br/>I resent being told what to do by a boss. And being a boss is also horribly<br/>frustrating; half the time it's easier just to do stuff yourself than to get<br/>someone else to do it for you. I'd rather do almost anything than give or<br/>receive a performance review.  <br/>  <br/>On top of its unpromising origins, employment has accumulated a lot of cruft<br/>over the years. The list of what you can't ask in job interviews is now so<br/>long that for convenience I assume it's infinite. Within the office you now<br/>have to walk on eggshells lest anyone say or do something that makes the<br/>company prey to a lawsuit. And God help you if you fire anyone.  <br/>  <br/>Nothing shows more clearly that employment is not an ordinary economic<br/>relationship than companies being sued for firing people. In any purely<br/>economic relationship you're free to do what you want. If you want to stop<br/>buying steel pipe from one supplier and start buying it from another, you<br/>don't have to explain why. No one can accuse you of _unjustly_ switching pipe<br/>suppliers. Justice implies some kind of paternal obligation that isn't there<br/>in transactions between equals.  <br/>  <br/>Most of the legal restrictions on employers are intended to protect employees.<br/>But you can't have action without an equal and opposite reaction. You can't<br/>expect employers to have some kind of paternal responsibility toward employees<br/>without putting employees in the position of children. And that seems a bad<br/>road to go down.  <br/>  <br/>Next time you're in a moderately large city, drop by the main post office and<br/>watch the body language of the people working there. They have the same sullen<br/>resentment as children made to do something they don't want to. Their union<br/>has exacted pay increases and work restrictions that would have been the envy<br/>of previous generations of postal workers, and yet they don't seem any happier<br/>for it. It's demoralizing to be on the receiving end of a paternalistic<br/>relationship, no matter how cozy the terms. Just ask any teenager.  <br/>  <br/>I see the disadvantages of the employer-employee relationship because I've<br/>been on both sides of a better one: the investor-founder relationship. I<br/>wouldn't claim it's painless. When I was running a startup, the thought of our<br/>investors used to keep me up at night. And now that I'm an investor, the<br/>thought of our startups keeps me up at night. All the pain of whatever problem<br/>you're trying to solve is still there. But the pain hurts less when it isn't<br/>mixed with resentment.  <br/>  <br/>I had the misfortune to participate in what amounted to a controlled<br/>experiment to prove that. After Yahoo bought our startup I went to work for<br/>them. I was doing exactly the same work, except with bosses. And to my horror<br/>I started acting like a child. The situation pushed buttons I'd forgotten I<br/>had.  <br/>  <br/>The big advantage of investment over employment, as the examples of open<br/>source and blogging suggest, is that people working on projects of their own<br/>are enormously more productive. And a startup is a project of one's own in two<br/>senses, both of them important: it's creatively one's own, and also<br/>economically ones's own.  <br/>  <br/>Google is a rare example of a big company in tune with the forces I've<br/>described. They've tried hard to make their offices less sterile than the<br/>usual cube farm. They give employees who do great work large grants of stock<br/>to simulate the rewards of a startup. They even let hackers spend 20% of their<br/>time on their own projects.  <br/>  <br/>Why not let people spend 100% of their time on their own projects, and instead<br/>of trying to approximate the value of what they create, give them the actual<br/>market value? Impossible? That is in fact what venture capitalists do.  <br/>  <br/>So am I claiming that no one is going to be an employee anymore-- that<br/>everyone should go and start a startup? Of course not. But more people could<br/>do it than do it now. At the moment, even the smartest students leave school<br/>thinking they have to get a job. Actually what they need to do is make<br/>something valuable. A job is one way to do that, but the more ambitious ones<br/>will ordinarily be better off taking money from an investor than an employer.  <br/>  <br/>Hackers tend to think business is for MBAs. But business administration is not<br/>what you're doing in a startup. What you're doing is business _creation_. And<br/>the first phase of that is mostly product creation-- that is, hacking. That's<br/>the hard part. It's a lot harder to create something people love than to take<br/>something people love and figure out how to make money from it.  <br/>  <br/>Another thing that keeps people away from starting startups is the risk.<br/>Someone with kids and a mortgage should think twice before doing it. But most<br/>young hackers have neither.  <br/>  <br/>And as the example of open source and blogging suggests, you'll enjoy it more,<br/>even if you fail. You'll be working on your own thing, instead of going to<br/>some office and doing what you're told. There may be more pain in your own<br/>company, but it won't hurt as much.  <br/>  <br/>That may be the greatest effect, in the long run, of the forces underlying<br/>open source and blogging: finally ditching the old paternalistic employer-<br/>employee relationship, and replacing it with a purely economic one, between<br/>equals.  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] Survey by Forrester Research reported in the cover story of Business Week,<br/>31 Jan 2005. Apparently someone believed you have to replace the actual server<br/>in order to switch the operating system.  <br/>  <br/>[2] It derives from the late Latin _tripalium_ , a torture device so called<br/>because it consisted of three stakes. I don't know how the stakes were used.<br/>"Travel" has the same root.  <br/>  <br/>[3] It would be much bigger news, in that sense, if the president faced<br/>unscripted questions by giving a press conference.  <br/>  <br/>[4] One measure of the incompetence of newspapers is that so many still make<br/>you register to read stories. I have yet to find a blog that tried that.  <br/>  <br/>[5] They accepted the article, but I took so long to send them the final<br/>version that by the time I did the section of the magazine they'd accepted it<br/>for had disappeared in a reorganization.  <br/>  <br/>[6] The word "boss" is derived from the Dutch _baas_ , meaning "master."  <br/>  <br/> **Thanks** to Sarah Harlin, Jessica Livingston, and Robert Morris for reading<br/>drafts of this.  <br/>  <br/><br/>French Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>Arabic Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>October 2011  <br/>  <br/>If you look at a list of US cities sorted by population, the number of<br/>successful startups per capita varies by orders of magnitude. Somehow it's as<br/>if most places were sprayed with startupicide.  <br/>  <br/>I wondered about this for years. I could see the average town was like a roach<br/>motel for startup ambitions: smart, ambitious people went in, but no startups<br/>came out. But I was never able to figure out exactly what happened inside the<br/>motel—exactly what was killing all the potential startups. [1]  <br/>  <br/>A couple weeks ago I finally figured it out. I was framing the question wrong.<br/>The problem is not that most towns kill startups. It's that death is the<br/>default for startups, and most towns don't save them. Instead of thinking of<br/>most places as being sprayed with startupicide, it's more accurate to think of<br/>startups as all being poisoned, and a few places being sprayed with the<br/>antidote.  <br/>  <br/>Startups in other places are just doing what startups naturally do: fail. The<br/>real question is, what's _saving_ startups in places like Silicon Valley? [2]  <br/>  <br/> **Environment**  <br/>  <br/>I think there are two components to the antidote: being in a place where<br/>startups are the cool thing to do, and chance meetings with people who can<br/>help you. And what drives them both is the number of startup people around<br/>you.  <br/>  <br/>The first component is particularly helpful in the first stage of a startup's<br/>life, when you go from merely having an interest in starting a company to<br/>actually doing it. It's quite a leap to start a startup. It's an unusual thing<br/>to do. But in Silicon Valley it seems normal. [3]  <br/>  <br/>In most places, if you start a startup, people treat you as if you're<br/>unemployed. People in the Valley aren't automatically impressed with you just<br/>because you're starting a company, but they pay attention. Anyone who's been<br/>here any amount of time knows not to default to skepticism, no matter how<br/>inexperienced you seem or how unpromising your idea sounds at first, because<br/>they've all seen inexperienced founders with unpromising sounding ideas who a<br/>few years later were billionaires.  <br/>  <br/>Having people around you care about what you're doing is an extraordinarily<br/>powerful force. Even the most willful people are susceptible to it. About a<br/>year after we started Y Combinator I said something to a partner at a well<br/>known VC firm that gave him the (mistaken) impression I was considering<br/>starting another startup. He responded so eagerly that for about half a second<br/>I found myself considering doing it.  <br/>  <br/>In most other cities, the prospect of starting a startup just doesn't seem<br/>real. In the Valley it's not only real but fashionable. That no doubt causes a<br/>lot of people to start startups who shouldn't. But I think that's ok. Few<br/>people are suited to running a startup, and it's very hard to predict<br/>beforehand which are (as I know all too well from being in the business of<br/>trying to predict beforehand), so lots of people starting startups who<br/>shouldn't is probably the optimal state of affairs. As long as you're at a<br/>point in your life when you can bear the risk of failure, the best way to find<br/>out if you're suited to running a startup is to try it.  <br/>  <br/> **Chance**  <br/>  <br/>The second component of the antidote is chance meetings with people who can<br/>help you. This force works in both phases: both in the transition from the<br/>desire to start a startup to starting one, and the transition from starting a<br/>company to succeeding. The power of chance meetings is more variable than<br/>people around you caring about startups, which is like a sort of background<br/>radiation that affects everyone equally, but at its strongest it is far<br/>stronger.  <br/>  <br/>Chance meetings produce miracles to compensate for the disasters that<br/>characteristically befall startups. In the Valley, terrible things happen to<br/>startups all the time, just like they do to startups everywhere. The reason<br/>startups are more likely to make it here is that great things happen to them<br/>too. In the Valley, lightning has a sign bit.  <br/>  <br/>For example, you start a site for college students and you decide to move to<br/>the Valley for the summer to work on it. And then on a random suburban street<br/>in Palo Alto you happen to run into Sean Parker, who understands the domain<br/>really well because he started a similar startup himself, and also knows all<br/>the investors. And moreover has advanced views, for 2004, on founders<br/>retaining control of their companies.  <br/>  <br/>You can't say precisely what the miracle will be, or even for sure that one<br/>will happen. The best one can say is: if you're in a startup hub, unexpected<br/>good things will probably happen to you, especially if you deserve them.  <br/>  <br/>I bet this is true even for startups we fund. Even with us working to make<br/>things happen for them on purpose rather than by accident, the frequency of<br/>helpful chance meetings in the Valley is so high that it's still a significant<br/>increment on what we can deliver.  <br/>  <br/>Chance meetings play a role like the role relaxation plays in having ideas.<br/>Most people have had the experience of working hard on some problem, not being<br/>able to solve it, giving up and going to bed, and then thinking of the answer<br/>in the shower in the morning. What makes the answer appear is letting your<br/>thoughts drift a bit—and thus drift off the wrong path you'd been pursuing<br/>last night and onto the right one adjacent to it.  <br/>  <br/>Chance meetings let your acquaintance drift in the same way taking a shower<br/>lets your thoughts drift. The critical thing in both cases is that they drift<br/>just the right amount. The meeting between Larry Page and Sergey Brin was a<br/>good example. They let their acquaintance drift, but only a little; they were<br/>both meeting someone they had a lot in common with.  <br/>  <br/>For Larry Page the most important component of the antidote was Sergey Brin,<br/>and vice versa. The antidote is people. It's not the physical infrastructure<br/>of Silicon Valley that makes it work, or the weather, or anything like that.<br/>Those helped get it started, but now that the reaction is self-sustaining what<br/>drives it is the people.  <br/>  <br/>Many observers have noticed that one of the most distinctive things about<br/>startup hubs is the degree to which people help one another out, with no<br/>expectation of getting anything in return. I'm not sure why this is so.<br/>Perhaps it's because startups are less of a zero sum game than most types of<br/>business; they are rarely killed by competitors. Or perhaps it's because so<br/>many startup founders have backgrounds in the sciences, where collaboration is<br/>encouraged.  <br/>  <br/>A large part of YC's function is to accelerate that process. We're a sort of<br/>Valley within the Valley, where the density of people working on startups and<br/>their willingness to help one another are both artificially amplified.  <br/>  <br/> **Numbers**  <br/>  <br/>Both components of the antidote—an environment that encourages startups, and<br/>chance meetings with people who help you—are driven by the same underlying<br/>cause: the number of startup people around you. To make a startup hub, you<br/>need a _lot_ of people interested in startups.  <br/>  <br/>There are three reasons. The first, obviously, is that if you don't have<br/>enough density, the chance meetings don't happen. [4] The second is that<br/>different startups need such different things, so you need a lot of people to<br/>supply each startup with what they need most. Sean Parker was exactly what<br/>Facebook needed in 2004. Another startup might have needed a database guy, or<br/>someone with connections in the movie business.  <br/>  <br/>This is one of the reasons we fund such a large number of companies,<br/>incidentally. The bigger the community, the greater the chance it will contain<br/>the person who has that one thing you need most.  <br/>  <br/>The third reason you need a lot of people to make a startup hub is that once<br/>you have enough people interested in the same problem, they start to set the<br/>social norms. And it is a particularly valuable thing when the atmosphere<br/>around you encourages you to do something that would otherwise seem too<br/>ambitious. In most places the atmosphere pulls you back toward the mean.  <br/>  <br/>I flew into the Bay Area a few days ago. I notice this every time I fly over<br/>the Valley: somehow you can sense something is going on. Obviously you can<br/>sense prosperity in how well kept a place looks. But there are different kinds<br/>of prosperity. Silicon Valley doesn't look like Boston, or New York, or LA, or<br/>DC. I tried asking myself what word I'd use to describe the feeling the Valley<br/>radiated, and the word that came to mind was optimism.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] I'm not saying it's impossible to succeed in a city with few other<br/>startups, just harder. If you're sufficiently good at generating your own<br/>morale, you can survive without external encouragement. Wufoo was based in<br/>Tampa and they succeeded. But the Wufoos are exceptionally disciplined.  <br/>  <br/>[2] Incidentally, this phenomenon is not limited to startups. Most unusual<br/>ambitions fail, unless the person who has them manages to find the right sort<br/>of community.  <br/>  <br/>[3] Starting a company is common, but starting a startup is rare. I've talked<br/>about the distinction between the two elsewhere, but essentially a startup is<br/>a new business designed for scale. Most new businesses are service businesses<br/>and except in rare cases those don't scale.  <br/>  <br/>[4] As I was writing this, I had a demonstration of the density of startup<br/>people in the Valley. Jessica and I bicycled to University Ave in Palo Alto to<br/>have lunch at the fabulous Oren's Hummus. As we walked in, we met Charlie<br/>Cheever sitting near the door. Selina Tobaccowala stopped to say hello on her<br/>way out. Then Josh Wilson came in to pick up a take out order. After lunch we<br/>went to get frozen yogurt. On the way we met Rajat Suri. When we got to the<br/>yogurt place, we found Dave Shen there, and as we walked out we ran into Yuri<br/>Sagalov. We walked with him for a block or so and we ran into Muzzammil<br/>Zaveri, and then a block later we met Aydin Senkut. This is everyday life in<br/>Palo Alto. I wasn't trying to meet people; I was just having lunch. And I'm<br/>sure for every startup founder or investor I saw that I knew, there were 5<br/>more I didn't. If Ron Conway had been with us he would have met 30 people he<br/>knew.  <br/>  <br/>  <br/>  <br/> **Thanks** to Sam Altman, Paul Buchheit, Jessica Livingston, and Harj Taggar<br/>for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>November 2019  <br/>  <br/>Everyone knows that to do great work you need both natural ability and<br/>determination. But there's a third ingredient that's not as well understood:<br/>an obsessive interest in a particular topic.  <br/>  <br/>To explain this point I need to burn my reputation with some group of people,<br/>and I'm going to choose bus ticket collectors. There are people who collect<br/>old bus tickets. Like many collectors, they have an obsessive interest in the<br/>minutiae of what they collect. They can keep track of distinctions between<br/>different types of bus tickets that would be hard for the rest of us to<br/>remember. Because we don't care enough. What's the point of spending so much<br/>time thinking about old bus tickets?  <br/>  <br/>Which leads us to the second feature of this kind of obsession: there is no<br/>point. A bus ticket collector's love is disinterested. They're not doing it to<br/>impress us or to make themselves rich, but for its own sake.  <br/>  <br/>When you look at the lives of people who've done great work, you see a<br/>consistent pattern. They often begin with a bus ticket collector's obsessive<br/>interest in something that would have seemed pointless to most of their<br/>contemporaries. One of the most striking features of Darwin's book about his<br/>voyage on the Beagle is the sheer depth of his interest in natural history.<br/>His curiosity seems infinite. Ditto for Ramanujan, sitting by the hour working<br/>out on his slate what happens to series.  <br/>  <br/>It's a mistake to think they were "laying the groundwork" for the discoveries<br/>they made later. There's too much intention in that metaphor. Like bus ticket<br/>collectors, they were doing it because they liked it.  <br/>  <br/>But there is a difference between Ramanujan and a bus ticket collector. Series<br/>matter, and bus tickets don't.  <br/>  <br/>If I had to put the recipe for genius into one sentence, that might be it: to<br/>have a disinterested obsession with something that matters.  <br/>  <br/>Aren't I forgetting about the other two ingredients? Less than you might<br/>think. An obsessive interest in a topic is both a proxy for ability and a<br/>substitute for determination. Unless you have sufficient mathematical<br/>aptitude, you won't find series interesting. And when you're obsessively<br/>interested in something, you don't need as much determination: you don't need<br/>to push yourself as hard when curiosity is pulling you.  <br/>  <br/>An obsessive interest will even bring you luck, to the extent anything can.<br/>Chance, as Pasteur said, favors the prepared mind, and if there's one thing an<br/>obsessed mind is, it's prepared.  <br/>  <br/>The disinterestedness of this kind of obsession is its most important feature.<br/>Not just because it's a filter for earnestness, but because it helps you<br/>discover new ideas.  <br/>  <br/>The paths that lead to new ideas tend to look unpromising. If they looked<br/>promising, other people would already have explored them. How do the people<br/>who do great work discover these paths that others overlook? The popular story<br/>is that they simply have better vision: because they're so talented, they see<br/>paths that others miss. But if you look at the way great discoveries are made,<br/>that's not what happens. Darwin didn't pay closer attention to individual<br/>species than other people because he saw that this would lead to great<br/>discoveries, and they didn't. He was just really, really interested in such<br/>things.  <br/>  <br/>Darwin couldn't turn it off. Neither could Ramanujan. They didn't discover the<br/>hidden paths that they did because they seemed promising, but because they<br/>couldn't help it. That's what allowed them to follow paths that someone who<br/>was merely ambitious would have ignored.  <br/>  <br/>What rational person would decide that the way to write great novels was to<br/>begin by spending several years creating an imaginary elvish language, like<br/>Tolkien, or visiting every household in southwestern Britain, like Trollope?<br/>No one, including Tolkien and Trollope.  <br/>  <br/>The bus ticket theory is similar to Carlyle's famous definition of genius as<br/>an infinite capacity for taking pains. But there are two differences. The bus<br/>ticket theory makes it clear that the source of this infinite capacity for<br/>taking pains is not infinite diligence, as Carlyle seems to have meant, but<br/>the sort of infinite interest that collectors have. It also adds an important<br/>qualification: an infinite capacity for taking pains about something that<br/>matters.  <br/>  <br/>So what matters? You can never be sure. It's precisely because no one can tell<br/>in advance which paths are promising that you can discover new ideas by<br/>working on what you're interested in.  <br/>  <br/>But there are some heuristics you can use to guess whether an obsession might<br/>be one that matters. For example, it's more promising if you're creating<br/>something, rather than just consuming something someone else creates. It's<br/>more promising if something you're interested in is difficult, especially if<br/>it's _more difficult for other people_ than it is for you. And the obsessions<br/>of talented people are more likely to be promising. When talented people<br/>become interested in random things, they're not truly random.  <br/>  <br/>But you can never be sure. In fact, here's an interesting idea that's also<br/>rather alarming if it's true: it may be that to do great work, you also have<br/>to waste a lot of time.  <br/>  <br/>In many different areas, reward is proportionate to risk. If that rule holds<br/>here, then the way to find paths that lead to truly great work is to be<br/>willing to expend a lot of effort on things that turn out to be every bit as<br/>unpromising as they seem.  <br/>  <br/>I'm not sure if this is true. On one hand, it seems surprisingly difficult to<br/>waste your time so long as you're working hard on something interesting. So<br/>much of what you do ends up being useful. But on the other hand, the rule<br/>about the relationship between risk and reward is so powerful that it seems to<br/>hold wherever risk occurs. _Newton's_ case, at least, suggests that the<br/>risk/reward rule holds here. He's famous for one particular obsession of his<br/>that turned out to be unprecedentedly fruitful: using math to describe the<br/>world. But he had two other obsessions, alchemy and theology, that seem to<br/>have been complete wastes of time. He ended up net ahead. His bet on what we<br/>now call physics paid off so well that it more than compensated for the other<br/>two. But were the other two necessary, in the sense that he had to take big<br/>risks to make such big discoveries? I don't know.  <br/>  <br/>Here's an even more alarming idea: might one make all bad bets? It probably<br/>happens quite often. But we don't know how often, because these people don't<br/>become famous.  <br/>  <br/>It's not merely that the returns from following a path are hard to predict.<br/>They change dramatically over time. 1830 was a really good time to be<br/>obsessively interested in natural history. If Darwin had been born in 1709<br/>instead of 1809, we might never have heard of him.  <br/>  <br/>What can one do in the face of such uncertainty? One solution is to hedge your<br/>bets, which in this case means to follow the obviously promising paths instead<br/>of your own private obsessions. But as with any hedge, you're decreasing<br/>reward when you decrease risk. If you forgo working on what you like in order<br/>to follow some more conventionally ambitious path, you might miss something<br/>wonderful that you'd otherwise have discovered. That too must happen all the<br/>time, perhaps even more often than the genius whose bets all fail.  <br/>  <br/>The other solution is to let yourself be interested in lots of different<br/>things. You don't decrease your upside if you switch between equally genuine<br/>interests based on which seems to be working so far. But there is a danger<br/>here too: if you work on too many different projects, you might not get deeply<br/>enough into any of them.  <br/>  <br/>One interesting thing about the bus ticket theory is that it may help explain<br/>why different types of people excel at different kinds of work. Interest is<br/>much more unevenly distributed than ability. If natural ability is all you<br/>need to do great work, and natural ability is evenly distributed, you have to<br/>invent elaborate theories to explain the skewed distributions we see among<br/>those who actually do great work in various fields. But it may be that much of<br/>the skew has a simpler explanation: different people are interested in<br/>different things.  <br/>  <br/>The bus ticket theory also explains why people are less likely to do great<br/>work after they have children. Here interest has to compete not just with<br/>external obstacles, but with another interest, and one that for most people is<br/>extremely powerful. It's harder to find time for work after you have kids, but<br/>that's the easy part. The real change is that you don't want<br/><br/>Spanish Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>June 2006  <br/>  <br/> _(This essay is derived from talks at Usenix 2006 and Railsconf 2006.)_  <br/>  <br/>A couple years ago my friend Trevor and I went to look at the Apple garage. As<br/>we stood there, he said that as a kid growing up in Saskatchewan he'd been<br/>amazed at the dedication Jobs and Wozniak must have had to work in a garage.  <br/>  <br/>"Those guys must have been freezing!"  <br/>  <br/>That's one of California's hidden advantages: the mild climate means there's<br/>lots of marginal space. In cold places that margin gets trimmed off. There's a<br/>sharper line between outside and inside, and only projects that are officially<br/>sanctioned — by organizations, or parents, or wives, or at least by oneself —<br/>get proper indoor space. That raises the activation energy for new ideas. You<br/>can't just tinker. You have to justify.  <br/>  <br/>Some of Silicon Valley's most famous companies began in garages: Hewlett-<br/>Packard in 1938, Apple in 1976, Google in 1998. In Apple's case the garage<br/>story is a bit of an urban legend. Woz says all they did there was assemble<br/>some computers, and that he did all the actual design of the Apple I and Apple<br/>II in his apartment or his cube at HP. [1] This was apparently too marginal<br/>even for Apple's PR people.  <br/>  <br/>By conventional standards, Jobs and Wozniak were marginal people too.<br/>Obviously they were smart, but they can't have looked good on paper. They were<br/>at the time a pair of college dropouts with about three years of school<br/>between them, and hippies to boot. Their previous business experience<br/>consisted of making "blue boxes" to hack into the phone system, a business<br/>with the rare distinction of being both illegal and unprofitable.  <br/>  <br/> **Outsiders**  <br/>  <br/>Now a startup operating out of a garage in Silicon Valley would feel part of<br/>an exalted tradition, like the poet in his garret, or the painter who can't<br/>afford to heat his studio and thus has to wear a beret indoors. But in 1976 it<br/>didn't seem so cool. The world hadn't yet realized that starting a computer<br/>company was in the same category as being a writer or a painter. It hadn't<br/>been for long. Only in the preceding couple years had the dramatic fall in the<br/>cost of hardware allowed outsiders to compete.  <br/>  <br/>In 1976, everyone looked down on a company operating out of a garage,<br/>including the founders. One of the first things Jobs did when they got some<br/>money was to rent office space. He wanted Apple to seem like a real company.  <br/>  <br/>They already had something few real companies ever have: a fabulously well<br/>designed product. You'd think they'd have had more confidence. But I've talked<br/>to a lot of startup founders, and it's always this way. They've built<br/>something that's going to change the world, and they're worried about some nit<br/>like not having proper business cards.  <br/>  <br/>That's the paradox I want to explore: great new things often come from the<br/>margins, and yet the people who discover them are looked down on by everyone,<br/>including themselves.  <br/>  <br/>It's an old idea that new things come from the margins. I want to examine its<br/>internal structure. Why do great ideas come from the margins? What kind of<br/>ideas? And is there anything we can do to encourage the process?  <br/>  <br/> **Insiders**  <br/>  <br/>One reason so many good ideas come from the margin is simply that there's so<br/>much of it. There have to be more outsiders than insiders, if insider means<br/>anything. If the number of outsiders is huge it will always seem as if a lot<br/>of ideas come from them, even if few do per capita. But I think there's more<br/>going on than this. There are real disadvantages to being an insider, and in<br/>some kinds of work they can outweigh the advantages.  <br/>  <br/>Imagine, for example, what would happen if the government decided to<br/>commission someone to write an official Great American Novel. First there'd be<br/>a huge ideological squabble over who to choose. Most of the best writers would<br/>be excluded for having offended one side or the other. Of the remainder, the<br/>smart ones would refuse such a job, leaving only a few with the wrong sort of<br/>ambition. The committee would choose one at the height of his career — that<br/>is, someone whose best work was behind him — and hand over the project with<br/>copious free advice about how the book should show in positive terms the<br/>strength and diversity of the American people, etc, etc.  <br/>  <br/>The unfortunate writer would then sit down to work with a huge weight of<br/>expectation on his shoulders. Not wanting to blow such a public commission,<br/>he'd play it safe. This book had better command respect, and the way to ensure<br/>that would be to make it a tragedy. Audiences have to be enticed to laugh, but<br/>if you kill people they feel obliged to take you seriously. As everyone knows,<br/>America plus tragedy equals the Civil War, so that's what it would have to be<br/>about. Better stick to the standard cartoon version that the Civil War was<br/>about slavery; people would be confused otherwise; plus you can show a lot of<br/>strength and diversity. When finally completed twelve years later, the book<br/>would be a 900-page pastiche of existing popular novels — roughly _Gone with<br/>the Wind_ plus _Roots_. But its bulk and celebrity would make it a bestseller<br/>for a few months, until blown out of the water by a talk-show host's<br/>autobiography. The book would be made into a movie and thereupon forgotten,<br/>except by the more waspish sort of reviewers, among whom it would be a byword<br/>for bogusness like Milli Vanilli or Battlefield Earth.  <br/>  <br/>Maybe I got a little carried away with this example. And yet is this not at<br/>each point the way such a project would play out? The government knows better<br/>than to get into the novel business, but in other fields where they have a<br/>natural monopoly, like nuclear waste dumps, aircraft carriers, and regime<br/>change, you'd find plenty of projects isomorphic to this one — and indeed,<br/>plenty that were less successful.  <br/>  <br/>This little thought experiment suggests a few of the disadvantages of insider<br/>projects: the selection of the wrong kind of people, the excessive scope, the<br/>inability to take risks, the need to seem serious, the weight of expectations,<br/>the power of vested interests, the undiscerning audience, and perhaps most<br/>dangerous, the tendency of such work to become a duty rather than a pleasure.  <br/>  <br/> **Tests**  <br/>  <br/>A world with outsiders and insiders implies some kind of test for<br/>distinguishing between them. And the trouble with most tests for selecting<br/>elites is that there are two ways to pass them: to be good at what they try to<br/>measure, and to be good at hacking the test itself.  <br/>  <br/>So the first question to ask about a field is how honest its tests are,<br/>because this tells you what it means to be an outsider. This tells you how<br/>much to trust your instincts when you disagree with authorities, whether it's<br/>worth going through the usual channels to become one yourself, and perhaps<br/>whether you want to work in this field at all.  <br/>  <br/>Tests are least hackable when there are consistent standards for quality, and<br/>the people running the test really care about its integrity. Admissions to PhD<br/>programs in the hard sciences are fairly honest, for example. The professors<br/>will get whoever they admit as their own grad students, so they try hard to<br/>choose well, and they have a fair amount of data to go on. Whereas<br/>undergraduate admissions seem to be much more hackable.  <br/>  <br/>One way to tell whether a field has consistent standards is the overlap<br/>between the leading practitioners and the people who teach the subject in<br/>universities. At one end of the scale you have fields like math and physics,<br/>where nearly all the teachers are among the best practitioners. In the middle<br/>are medicine, law, history, architecture, and computer science, where many<br/>are. At the bottom are business, literature, and the visual arts, where<br/>there's almost no overlap between the teachers and the leading practitioners.<br/>It's this end that gives rise to phrases like "those who can't do, teach."  <br/>  <br/>Incidentally, this scale might be helpful in deciding what to study in<br/>college. When I was in college the rule seemed to be that you should study<br/>whatever you were most interested in. But in retrospect you're probably better<br/>off studying something moderately interesting with someone who's good at it<br/>than something very interesting with someone who isn't. You often hear people<br/>say that you shouldn't major in business in college, but this is actually an<br/>instance of a more general rule: don't learn things from teachers who are bad<br/>at them.  <br/>  <br/>How much you should worry about being an outsider depends on the quality of<br/>the insiders. If you're an amateur mathematician and think you've solved a<br/>famous open problem, better go back and check. When I was in grad school, a<br/>friend in the math department had the job of replying to people who sent in<br/>proofs of Fermat's last theorem and so on, and it did not seem as if he saw it<br/>as a valuable source of tips — more like manning a mental health hotline.<br/>Whereas if the stuff you're writing seems different from what English<br/>professors are interested in, that's not necessarily a problem.  <br/>  <br/> **Anti-Tests**  <br/>  <br/>Where the method of selecting the elite is thoroughly corrupt, most of the<br/>good people will be outsiders. In art, for example, the image of the poor,<br/>misunderstood genius is not just one possible image of a great artist: it's<br/>the _standard_ image. I'm not saying it's correct, incidentally, but it is<br/>telling how well this image has stuck. You couldn't make a rap like that stick<br/>to math or medicine. [2]  <br/>  <br/>If it's corrupt enough, a test becomes an anti-test, filtering out the people<br/>it should select by making them to do things only the wrong people would do.<br/>Popularity in high school seems to be such a test. There are plenty of similar<br/>ones in the grownup world. For example, rising up through the hierarchy of the<br/>average big company demands an attention to politics few thoughtful people<br/>could spare. [3] Someone like Bill Gates can grow a company under him, but<br/>it's hard to imagine him having the patience to climb the corporate ladder at<br/>General Electric — or Microsoft, actually.  <br/>  <br/>It's kind of strange when you think about it, because lord-of-the-flies<br/>schools and bureaucratic companies are both the default. There are probably a<br/>lot of people who go from one to the other and never realize the whole world<br/>doesn't work this way.  <br/>  <br/>I think that's one reason big companies are so often blindsided by startups.<br/>People at big companies don't realize the extent to which they live in an<br/>environment that is one large, ongoing test for the wrong qualities.  <br/>  <br/>If you're an outsider, your best chances for beating insiders are obviously in<br/>fields where corrupt tests select a lame elite. But there's a catch: if the<br/>tests are corrupt, your victory won't be recognized, at least in your<br/>lifetime. You may feel you don't need that, but history suggests it's<br/>dangerous to work in fields with corrupt tests. You may beat the insiders, and<br/>yet not do as good work, on an absolute scale, as you would in a field that<br/>was more honest.  <br/>  <br/>Standards in art, for example, were almost as corrupt in the first half of the<br/>eighteenth century as they are today. This was the era of those fluffy<br/>idealized portraits of countesses with their lapdogs. Chardin decided to skip<br/>all that and paint ordinary things as he saw them. He's now considered the<br/>best of that period — and yet not the equal of Leonardo or Bellini or Memling,<br/>who all had the additional encouragement of honest standards.  <br/>  <br/>It can be worth participating in a corrupt contest, however, if it's followed<br/>by another that isn't corrupt. For example, it would be worth competing with a<br/>company that can spend more than you on marketing, as long as you can survive<br/>to the next round, when customers compare your actual products. Similarly, you<br/>shouldn't be discouraged by the comparatively corrupt test of college<br/>admissions, because it's followed immediately by less hackable tests. [4]  <br/>  <br/> **Risk**  <br/>  <br/>Even in a field with honest tests, there are still advantages to being an<br/>outsider. The most obvious is that outsiders have nothing to lose. They can do<br/>risky things, and if they fail, so what? Few will even notice.  <br/>  <br/>The eminent, on the other hand, are weighed down by their eminence. Eminence<br/>is like a suit: it impresses the wrong people, and it constrains the wearer.  <br/>  <br/>Outsiders should realize the advantage they have here. Being able to take<br/>risks is hugely valuable. Everyone values safety too much, both the obscure<br/>and the eminent. No one wants to look like a fool. But it's very useful to be<br/>able to. If most of your ideas aren't stupid, you're probably being too<br/>conservative. You're not bracketing the problem.  <br/>  <br/>Lord Acton said we should judge talent at its best and character at its worst.<br/>For example, if you write one great book and ten bad ones, you still count as<br/>a great writer — or at least, a better writer than someone who wrote eleven<br/>that were merely good. Whereas if you're a quiet, law-abiding citizen most of<br/>the time but occasionally cut someone up and bury them in your backyard,<br/>you're a bad guy.  <br/>  <br/>Almost everyone makes the mistake of treating ideas as if they were<br/>indications of character rather than talent — as if having a stupid idea made<br/>you stupid. There's a huge weight of tradition advising us to play it safe.<br/>"Even a fool is thought wise if he keeps silent," says the Old Testament<br/>(Proverbs 17:28).  <br/>  <br/>Well, that may be fine advice for a bunch of goatherds in Bronze Age<br/>Palestine. There conservatism would be the order of the day. But times have<br/>changed. It might still be reasonable to stick with the Old Testament in<br/>political questions, but materially the world now has a lot more state.<br/>Tradition is less of a guide, not just because things change faster, but<br/>because the space of possibilities is so large. The more complicated the world<br/>gets, the more valuable it is to be willing to look like a fool.  <br/>  <br/> **Delegation**  <br/>  <br/>And yet the more successful people become, the more heat they get if they<br/>screw up — or even seem to screw up. In this respect, as in many others, the<br/>eminent are prisoners of their own success. So the best way to understand the<br/>advantages of being an outsider may be to look at the disadvantages of being<br/>an insider.  <br/>  <br/>If you ask eminent people what's wrong with their lives, the first thing<br/>they'll complain about is the lack of time. A friend of mine at Google is<br/>fairly high up in the company and went to work for them long before they went<br/>public. In other words, he's now rich enough not to have to work. I asked him<br/>if he could still endure the annoyances of having a job, now that he didn't<br/>have to. And he said that there weren't really any annoyances, except — and he<br/>got a wistful look when he said this — that he got _so much email_.  <br/>  <br/>The eminent feel like everyone wants to take a bite out of them. The problem<br/>is so widespread that people pretending to be eminent do it by pretending to<br/>be overstretched.  <br/>  <br/>The lives of the eminent become scheduled, and that's not good for thinking.<br/>One of the great advantages of being an outsider is long, uninterrupted blocks<br/>of time. That's what I remember about grad school: apparently endless supplies<br/>of time, which I spent worrying about, but not writing, my dissertation.<br/>Obscurity is like health food — unpleasant, perhaps, but good for you. Whereas<br/>fame tends to be like the alcohol produced by fermentation. When it reaches a<br/>certain concentration, it kills off the yeast that produced it.  <br/>  <br/>The eminent generally respond to the shortage of time by turning into<br/>managers. They don't have time to work. They're surrounded by junior people<br/>they're supposed to help or supervise. The obvious solution is to have the<br/>junior people do the work. Some good stuff happens this way, but there are<br/>problems it doesn't work so well for: the kind where it helps to have<br/>everything in one head.  <br/>  <br/>For example, it recently emerged that the famous glass artist Dale Chihuly<br/>hasn't actually blown glass for 27 years. He has assistants do the work for<br/>him. But one of the most valuable sources of ideas in the visual arts is the<br/>resistance of the medium. That's why oil paintings look so different from<br/>watercolors. In principle you could make any mark in any medium; in practice<br/>the medium steers you. And if you're no longer doing the work yourself, you<br/>stop learning from this.  <br/>  <br/>So if you want to beat those eminent enough to delegate, one way to do it is<br/>to take advantage of direct contact with the medium. In the arts it's obvious<br/>how: blow your own glass, edit your own films, stage your own plays. And in<br/>the process pay close attention to accidents and to new ideas you have on the<br/>fly. This technique can be generalized to any sort of work: if you're an<br/>outsider, don't be ruled by plans. Planning is often just a weakness forced on<br/>those who delegate.  <br/>  <br/>Is there a general rule for finding problems best solved in one head? Well,<br/>you can manufacture them by taking any project usually done by multiple people<br/>and trying to do it all yourself. Wozniak's work was a classic example: he did<br/>everything himself, hardware and software, and the result was miraculous. He<br/>claims not one bug was ever found in the Apple II, in either hardware or<br/>software.  <br/>  <br/>Another way to find good problems to solve in one head is to focus on the<br/>grooves in the chocolate bar — the places where tasks are divided when they're<br/>split between several people. If you want to beat delegation, focus on a<br/>vertical slice: for example, be both writer and editor, or both design<br/>buildings and construct them.  <br/>  <br/>One especially good groove to span is the one between tools and things made<br/>with them. For example, programming languages and applications are usually<br/>written by different people, and this is responsible for a lot of the worst<br/>flaws in programming languages. I think every language should be designed<br/>simultaneously with a large application written in it, the way C was with<br/>Unix.  <br/>  <br/>Techniques for competing with delegation translate well into business, because<br/>delegation is endemic there. Instead of avoiding it as a drawback of senility,<br/>many companies embrace it as a sign of maturity. In big companies software is<br/>often designed, implemented, and sold by three separate types of people. In<br/>startups one person may have to do all three. And though this feels stressful,<br/>it's one reason startups win. The needs of customers and the means of<br/>satisfying them are all in one head.  <br/>  <br/> **Focus**  <br/>  <br/>The very skill of insiders can be a weakness. Once someone is good at<br/>something, they tend to spend all their time doing that. This kind of focus is<br/>very valuable, actually. Much of the skill of experts is the ability to ignore<br/>false trails. But focus has drawbacks: you don't learn from other fields, and<br/>when a new approach arrives, you may be the last to notice.  <br/>  <br/>For outsiders this translates into two ways to win. One is to work on a<br/>variety of things. Since you can't derive as much benefit (yet) from a narrow<br/>focus, you may as well cast a wider net and derive what benefit you can from<br/>similarities between fields. Just as you can compete with delegation by<br/>working on larger vertical slices, you can compete with specialization by<br/>working on larger horizontal slices — by both writing and illustrating your<br/>book, for example.  <br/>  <br/>The second way to compete with focus is to see what focus overlooks. In<br/>particular, new things. So if you're not good at anything yet, consider<br/>working on something so new that no one else is either. It won't have any<br/>prestige yet, if no one is good at it, but you'll have it all to yourself.  <br/>  <br/>The potential of a new medium is usually underestimated, precisely because no<br/>one has yet explored its possibilities. Before Durer tried making engravings,<br/>no one took them very seriously. Engraving was for making little devotional<br/>images — basically fifteenth century baseball cards of saints. Trying to make<br/>masterpieces in this medium must have seemed to Durer's contemporaries the way<br/>that, say, making masterpieces in comics might seem to the average person<br/>today.  <br/>  <br/>In the computer world we get not new mediums but new platforms: the<br/>minicomputer, the microprocessor, the web-based application. At first they're<br/>always dismissed as being unsuitable for real work. And yet someone always<br/>decides to try anyway, and it turns out you can do more than anyone expected.<br/>So in the future when you hear people say of a new platform: yeah, it's<br/>popular and cheap, but not ready yet for real work, jump on it.  <br/>  <br/>As well as being more comfortable working on established lines, insiders<br/>generally have a vested interest in perpetuating them. The professor who made<br/>his reputation by discovering some new idea is not likely to be the one to<br/>discover its replacement. This is particularly true with companies, who have<br/>not only skill and pride anchoring them to the status quo, but money as well.<br/>The Achilles heel of successful companies is their inability to cannibalize<br/>themselves. Many innovations consist of replacing something with a cheaper<br/>alternative, and companies just don't want to see a path whose immediate<br/>effect is to cut an existing source of revenue.  <br/>  <br/>So if you're an outsider you should actively seek out contrarian projects.<br/>Instead of working on things the eminent have made prestigious, work on things<br/>that could steal that prestige.  <br/>  <br/>The really juicy new approaches are not the ones insiders reject as<br/>impossible, but those they ignore as undignified. For example, after Wozniak<br/>designed the Apple II he offered it first to his employer, HP. They passed.<br/>One of the reasons was that, to save money, he'd designed the Apple II to use<br/>a TV as a monitor, and HP felt they couldn't produce anything so declasse.  <br/>  <br/> **Less**  <br/>  <br/>Wozniak used a TV as a monitor for the simple reason that he couldn't afford a<br/>monitor. Outsiders are not merely free but compelled to make things that are<br/>cheap and lightweight. And both are good bets for growth: cheap things spread<br/>faster, and lightweight things evolve faster.  <br/>  <br/>The eminent, on the other hand, are almost forced to work on a large scale.<br/>Instead of garden sheds they must design huge art museums. One reason they<br/>work on big things is that they can: like our hypothetical novelist, they're<br/>flattered by such opportunities. They also know that big projects will by<br/>their sheer bulk impress the audience. A garden shed, however lovely, would be<br/>easy to ignore; a few might even snicker at it. You can't snicker at a giant<br/>museum, no matter how much you dislike it. And finally, there are all those<br/>people the eminent have working for them; they have to choose projects that<br/>can keep them all busy.  <br/>  <br/>Outsiders are free of all this. They can work on small things, and there's<br/>something very pleasing about small things. Small things can be perfect; big<br/>ones always have something wrong with them. But there's a magic in small<br/>things that goes beyond such rational explanations. All kids know it. Small<br/>things have more personality.  <br/>  <br/>Plus making them is more fun. You can do what you want; you don't have to<br/>satisfy committees. And perhaps most important, small things can be done fast.<br/>The prospect of seeing the finished project hangs in the air like the smell of<br/>dinner cooking. If you work fast, maybe you could have it done tonight.  <br/>  <br/>Working on small things is also a good way to learn. The most important kinds<br/>of learning happen one project at a time. ("Next time, I won't...") The faster<br/>you cycle through projects, the faster you'll evolve.  <br/>  <br/>Plain materials have a charm like small scale. And in addition there's the<br/>challenge of making do with less. Every designer's ears perk up at the mention<br/>of that game, because it's a game you can't lose. Like the JV playing the<br/>varsity, if you even tie, you win. So paradoxically there are cases where<br/>fewer resources yield better results, because the designers' pleasure at their<br/>own ingenuity more than compensates. [5]  <br/>  <br/>So if you're an outsider, take advantage of your ability to make small and<br/>inexpensive things. Cultivate the pleasure and simplicity of that kind of<br/>work; one day you'll miss it.  <br/>  <br/> **Responsibility**  <br/>  <br/>When you're old and eminent, what will you miss about being young and obscure?<br/>What people seem to miss most is the lack of responsibilities.  <br/>  <br/>Responsibility is an occupational disease of eminence. In principle you could<br/>avoid it, just as in principle you could avoid getting fat as you get old, but<br/>few do. I sometimes suspect that responsibility is a trap and that the most<br/>virtuous route would be to shirk it, but regardless it's certainly<br/>constraining.  <br/>  <br/>When you're an outsider you're constrained too, of course. You're short of<br/>money, for example. But that constrains you in different ways. How does<br/>responsibility constrain you? The worst thing is that it allows you not to<br/>focus on real work. Just as the most dangerous forms of procrastination are<br/>those that seem like work, the danger of responsibilities is not just that<br/>they can consume a whole day, but that they can do it without setting off the<br/>kind of alarms you'd set off if you spent a whole day sitting on a park bench.  <br/>  <br/>A lot of the pain of being an outsider is being aware of one's own<br/>procrastination. But this is actually a good thing. You're at least close<br/>enough to work that the smell of it makes you hungry.  <br/>  <br/>As an outsider, you're just one step away from getting things done. A huge<br/>step, admittedly, and one that most people never seem to make, but only one<br/>step. If you can summon up the energy to get started, you can work on projects<br/>with an intensity (in both senses) that few insiders can match. For insiders<br/>work turns into a duty, laden with responsibilities and expectations. It's<br/>never so pure as it was when they were young.  <br/>  <br/>Work like a dog being taken for a walk, instead of an ox being yoked to the<br/>plow. That's what they miss.  <br/>  <br/> **Audience**  <br/>  <br/>A lot of outsiders make the mistake of doing the opposite; they admire the<br/>eminent so much that they copy even their flaws. Copying is a good way to<br/>learn, but copy the right things. When I was in college I imitated the pompous<br/>diction of famous professors. But this wasn't what _made_ them eminent — it<br/>was more a flaw their eminence had allowed them to sink into. Imitating it was<br/>like pretending to have gout in order to seem rich.  <br/>  <br/>Half the distinguishing qualities of the eminent are actually disadvantages.<br/>Imitating these is not only a waste of time, but will make you seem a fool to<br/>your models, who are often well aware of it.  <br/>  <br/>What are the genuine advantages of being an insider? The greatest is an<br/>audience. It often seems to outsiders that the great advantage of insiders is<br/>money — that they have the resources to do what they want. But so do people<br/>who inherit money, and that doesn't seem to help, not as much as an audience.<br/>It's good for morale to know people want to see what you're making; it draws<br/>work out of you.  <br/>  <br/>If I'm right that the defining advantage of insiders is an audience, then we<br/>live in exciting times, because just in the last ten years the Internet has<br/>made audiences a lot more liquid. Outsiders don't have to content themselves<br/>anymore with a proxy audience of a few smart friends. Now, thanks to the<br/>Internet, they can start to grow themselves actual audiences. This is great<br/>news for the marginal, who retain the advantages of outsiders while<br/>increasingly being able to siphon off what had till recently been the<br/>prerogative of the elite.  <br/>  <br/>Though the Web has been around for more than ten years, I think we're just<br/>beginning to see its democratizing effects. Outsiders are still learning how<br/>to steal audiences. But more importantly, audiences are still learning how to<br/>be stolen — they're still just beginning to realize how much deeper bloggers<br/>can dig than journalists, how much more interesting a democratic news site can<br/>be than a front page controlled by editors, and how much funnier a bunch of<br/>kids with webcams can be than mass-produced sitcoms.  <br/>  <br/>The big media companies shouldn't worry that people will post their<br/>copyrighted material on YouTube. They should worry that people will post their<br/>own stuff on YouTube, and audiences will watch that instead.  <br/>  <br/> **Hacking**  <br/>  <br/>If I had to condense the power of the marginal into one sentence it would be:<br/>just try hacking something together. That phrase draws in most threads I've<br/>mentioned here. Hacking something together means deciding what to do as you're<br/>doing it, not a subordinate executing the vision of his boss. It implies the<br/>result won't be pretty, because it will be made quickly out of inadequate<br/>materials. It may work, but it won't be the sort of thing the eminent would<br/>want to put their name on. Something hacked together means something that<br/>barely solves the problem, or maybe doesn't solve the problem at all, but<br/>another you discovered en route. But that's ok, because the main value of that<br/>initial version is not the thing itself, but what it leads to. Insiders who<br/>daren't walk through the mud in their nice clothes will never make it to the<br/>solid ground on the other side.  <br/>  <br/>The word "try" is an especially valuable component. I disagree here with Yoda,<br/>who said there is no try. There is try. It implies there's no punishment if<br/>you fail. You're driven by curiosity instead of duty. That means the wind of<br/>procrastination will be in your favor: instead of avoiding this work, this<br/>will be what you do as a way of avoiding other work. And when you do it,<br/>you'll be in a better mood. The more the work depends on imagination, the more<br/>that matters, because most people have more ideas when they're happy.  <br/>  <br/>If I could go back and redo my twenties, that would be one thing I'd do more<br/>of: just try hacking things together. Like many people that age, I spent a lot<br/>of time worrying about what I should do. I also spent some time trying to<br/>build stuff. I should have spent less time worrying and more time building. If<br/>you're not sure what to do, make something.  <br/>  <br/>Raymond Chandler's advice to thriller writers was "When in doubt, have a man<br/>come through a door with a gun in his hand." He followed that advice. Judging<br/>from his books, he was often in doubt. But though the result is occasionally<br/>cheesy, it's never boring. In life, as in books, action is underrated.  <br/>  <br/>Fortunately the number of things you can just hack together keeps increasing.<br/>People fifty years ago would be astonished that one could just hack together a<br/>movie, for example. Now you can even hack together distribution. Just make<br/>stuff and put it online.  <br/>  <br/> **Inappropriate**  <br/>  <br/>If you really want to score big, the place to focus is the margin of the<br/>margin: the territories only recently captured from the insiders. That's where<br/>you'll find the juiciest projects still undone, either because they seemed too<br/>risky, or simply because there were too few insiders to explore everything.  <br/>  <br/>This is why I spend most of my time writing essays lately. The writing of<br/>essays used to be limited to those who could get them published. In principle<br/>you could have written them and just shown them to your friends; in practice<br/>that didn't work. [6] An essayist needs the resistance of an audience, just as<br/>an engraver needs the resistance of the plate.  <br/>  <br/>Up till a few years ago, writing essays was the ultimate insider's game.<br/>Domain experts were allowed to publish essays about their field, but the pool<br/>allowed to write on general topics was about eight people who went to the<br/>right parties in New York. Now the reconquista has overrun this territory,<br/>and, not surprisingly, found it sparsely cultivated. There are so many essays<br/>yet unwritten. They tend to be the naughtier ones; the insiders have pretty<br/>much exhausted the motherhood and apple pie topics.  <br/>  <br/>This leads to my final suggestion: a technique for determining when you're on<br/>the right track. You're on the right track when people complain that you're<br/>unqualified, or that you've done something inappropriate. If people are<br/>complaining, that means you're doing something rather than sitting around,<br/>which is the first step. And if they're driven to such empty forms of<br/>complaint, that means you've probably done something good.  <br/>  <br/>If you make something and people complain that it doesn't _work_ , that's a<br/>problem. But if the worst thing they can hit you with is your own status as an<br/>outsider, that implies that in every other respect you've succeeded. Pointing<br/>out that someone is unqualified is as desperate as resorting to racial slurs.<br/>It's just a legitimate sounding way of saying: we don't like your type around<br/>here.  <br/>  <br/>But the best thing of all is when people call what you're doing inappropriate.<br/>I've been hearing this word all my life and I only recently realized that it<br/>is, in fact, the sound of the homing beacon. "Inappropriate" is the null<br/>criticism. It's merely the adjective form of "I don't like it."  <br/>  <br/>So that, I think, should be the highest goal for the marginal. Be<br/>inappropriate. When you hear people saying that, you're golden. And they,<br/>incidentally, are busted.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] The facts about Apple's early history are from an interview with Steve<br/>Wozniak in Jessica Livingston's _Founders at Work_.  <br/>  <br/>[2] As usual the popular image is several decades behind reality. Now the<br/>misunderstood artist is not a chain-smoking drunk who pours his soul into big,<br/>messy canvases that philistines see and say "that's not art" because it isn't<br/>a picture of anything. The philistines have now been trained that anything<br/>hung on a wall is art. Now the misunderstood artist is a coffee-drinking vegan<br/>cartoonist whose work they see and say "that's not art" because it looks like<br/>stuff they've seen in the Sunday paper.  <br/>  <br/>[3] In fact this would do fairly well as a definition of politics: what<br/>determines rank in the absence of objective tests.  <br/>  <br/>[4] In high school you're led to believe your whole future depends on where<br/>you go to college, but it turns out only to buy you a couple years. By your<br/>mid-twenties the people worth impressing already judge you more by what you've<br/>done than where you went to school.  <br/>  <br/>[5] Managers are presumably wondering, how can I make this miracle happen? How<br/>can I make the people working for me do more with less? Unfortunately the<br/>constraint probably has to be self-imposed. If you're _expected_ to do more<br/>with less, then you're being starved, not eating virtuously.  <br/>  <br/>[6] Without the prospect of publication, the closest most people come to<br/>writing essays is to write in a journal. I find I never get as deeply into<br/>subjects as I do in proper essays. As the name implies, you don't go back and<br/>rewrite journal entries over and over for two weeks.  <br/>  <br/> **Thanks** to Sam Altman, Trevor Blackwell, Paul Buchheit, Sarah Harlin,<br/>Jessica Livingston, Jackie McDonough, Robert Morris, Olin Shivers, and Chris<br/>Small for reading drafts of this, and to Chris Small and Chad Fowler for<br/>inviting me to speak.  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Chinese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>August 2006, rev. April 2007, September 2010  <br/>  <br/>In a few days it will be Demo Day, when the startups we funded this summer<br/>present to investors. Y Combinator funds startups twice a year, in January and<br/>June. Ten weeks later we invite all the investors we know to hear them present<br/>what they've built so far.  <br/>  <br/>Ten weeks is not much time. The average startup probably doesn't have much to<br/>show for itself after ten weeks. But the average startup fails. When you look<br/>at the ones that went on to do great things, you find a lot that began with<br/>someone pounding out a prototype in a week or two of nonstop work. Startups<br/>are a counterexample to the rule that haste makes waste.  <br/>  <br/>(Too much money seems to be as bad for startups as too much time, so we don't<br/>give them much money either.)  <br/>  <br/>A week before Demo Day, we have a dress rehearsal called Rehearsal Day. At<br/>other Y Combinator events we allow outside guests, but not at Rehearsal Day.<br/>No one except the other founders gets to see the rehearsals.  <br/>  <br/>The presentations on Rehearsal Day are often pretty rough. But this is to be<br/>expected. We try to pick founders who are good at building things, not ones<br/>who are slick presenters. Some of the founders are just out of college, or<br/>even still in it, and have never spoken to a group of people they didn't<br/>already know.  <br/>  <br/>So we concentrate on the basics. On Demo Day each startup will only get ten<br/>minutes, so we encourage them to focus on just two goals: (a) explain what<br/>you're doing, and (b) explain why users will want it.  <br/>  <br/>That might sound easy, but it's not when the speakers have no experience<br/>presenting, and they're explaining technical matters to an audience that's<br/>mostly non-technical.  <br/>  <br/>This situation is constantly repeated when startups present to investors:<br/>people who are bad at explaining, talking to people who are bad at<br/>understanding. Practically every successful startup, including stars like<br/>Google, presented at some point to investors who didn't get it and turned them<br/>down. Was it because the founders were bad at presenting, or because the<br/>investors were obtuse? It's probably always some of both.  <br/>  <br/>At the most recent Rehearsal Day, we four Y Combinator partners found<br/>ourselves saying a lot of the same things we said at the last two. So at<br/>dinner afterward we collected all our tips about presenting to investors. Most<br/>startups face similar challenges, so we hope these will be useful to a wider<br/>audience.  <br/>  <br/>**1\. Explain what you're doing.**  <br/>  <br/>Investors' main question when judging a very early startup is whether you've<br/>made a compelling product. Before they can judge whether you've built a good<br/>x, they have to understand what kind of x you've built. They will get very<br/>frustrated if instead of telling them what you do, you make them sit through<br/>some kind of preamble.  <br/>  <br/>Say what you're doing as soon as possible, preferably in the first sentence.<br/>"We're Jeff and Bob and we've built an easy to use web-based database. Now<br/>we'll show it to you and explain why people need this."  <br/>  <br/>If you're a great public speaker you may be able to violate this rule. Last<br/>year one founder spent the whole first half of his talk on a fascinating<br/>analysis of the limits of the conventional desktop metaphor. He got away with<br/>it, but unless you're a captivating speaker, which most hackers aren't, it's<br/>better to play it safe.  <br/>  <br/> **2\. Get rapidly to demo.**  <br/>  <br/> _This section is now obsolete for YC founders presenting at Demo Day, because<br/>Demo Day presentations are now so short that they rarely include much if any<br/>demo. They seem to work just as well without, however, which makes me think I<br/>was wrong to emphasize demos so much before._  <br/>  <br/>A demo explains what you've made more effectively than any verbal description.<br/>The only thing worth talking about first is the problem you're trying to solve<br/>and why it's important. But don't spend more than a tenth of your time on<br/>that. Then demo.  <br/>  <br/>When you demo, don't run through a catalog of features. Instead start with the<br/>problem you're solving, and then show how your product solves it. Show<br/>features in an order driven by some kind of purpose, rather than the order in<br/>which they happen to appear on the screen.  <br/>  <br/>If you're demoing something web-based, assume that the network connection will<br/>mysteriously die 30 seconds into your presentation, and come prepared with a<br/>copy of the server software running on your laptop.  <br/>  <br/> **3\. Better a narrow description than a vague one.**  <br/>  <br/>One reason founders resist describing their projects concisely is that, at<br/>this early stage, there are all kinds of possibilities. The most concise<br/>descriptions seem misleadingly narrow. So for example a group that has built<br/>an easy web-based database might resist calling their applicaton that, because<br/>it could be so much more. In fact, it could be anything...  <br/>  <br/>The problem is, as you approach (in the calculus sense) a description of<br/>something that could be anything, the content of your description approaches<br/>zero. If you describe your web-based database as "a system to allow people to<br/>collaboratively leverage the value of information," it will go in one investor<br/>ear and out the other. They'll just discard that sentence as meaningless<br/>boilerplate, and hope, with increasing impatience, that in the next sentence<br/>you'll actually explain what you've made.  <br/>  <br/>Your primary goal is not to describe everything your system might one day<br/>become, but simply to convince investors you're worth talking to further. So<br/>approach this like an algorithm that gets the right answer by successive<br/>approximations. Begin with a description that's gripping but perhaps overly<br/>narrow, then flesh it out to the extent you can. It's the same principle as<br/>incremental development: start with a simple prototype, then add features, but<br/>at every point have working code. In this case, "working code" means a working<br/>description in the investor's head.  <br/>  <br/> **4\. Don't talk and drive.**  <br/>  <br/>Have one person talk while another uses the computer. If the same person does<br/>both, they'll inevitably mumble downwards at the computer screen instead of<br/>talking clearly at the audience.  <br/>  <br/>As long as you're standing near the audience and looking at them, politeness<br/>(and habit) compel them to pay attention to you. Once you stop looking at them<br/>to fuss with something on your computer, their minds drift off to the errands<br/>they have to run later.  <br/>  <br/> **5\. Don't talk about secondary matters at length.**  <br/>  <br/>If you only have a few minutes, spend them explaining what your product does<br/>and why it's great. Second order issues like competitors or resumes should be<br/>single slides you go through quickly at the end. If you have impressive<br/>resumes, just flash them on the screen for 15 seconds and say a few words. For<br/>competitors, list the top 3 and explain in one sentence each what they lack<br/>that you have. And put this kind of thing at the end, after you've made it<br/>clear what you've built.  <br/>  <br/> **6\. Don't get too deeply into business models.**  <br/>  <br/>It's good to talk about how you plan to make money, but mainly because it<br/>shows you care about that and have thought about it. Don't go into detail<br/>about your business model, because (a) that's not what smart investors care<br/>about in a brief presentation, and (b) any business model you have at this<br/>point is probably wrong anyway.  <br/>  <br/>Recently a VC who came to speak at Y Combinator talked about a company he just<br/>invested in. He said their business model was wrong and would probably change<br/>three times before they got it right. The founders were experienced guys who'd<br/>done startups before and who'd just succeeded in getting millions from one of<br/>the top VC firms, and even their business model was crap. (And yet he invested<br/>anyway, because he expected it to be crap at this stage.)  <br/>  <br/>If you're solving an important problem, you're going to sound a lot smarter<br/>talking about that than the business model. The business model is just a bunch<br/>of guesses, and guesses about stuff that's probably not your area of<br/>expertise. So don't spend your precious few minutes talking about crap when<br/>you could be talking about solid, interesting things you know a lot about: the<br/>problem you're solving and what you've built so far.  <br/>  <br/>As well as being a bad use of time, if your business model seems spectacularly<br/>wrong, that will push the stuff you want investors to remember out of their<br/>heads. They'll just remember you as the company with the boneheaded plan for<br/>making money, rather than the company that solved that important problem.  <br/>  <br/> **7\. Talk slowly and clearly at the audience.**  <br/>  <br/>Everyone at Rehearsal Day could see the difference between the people who'd<br/>been out in the world for a while and had presented to groups, and those who<br/>hadn't.  <br/>  <br/>You need to use a completely different voice and manner talking to a roomful<br/>of people than you would in conversation. Everyday life gives you no practice<br/>in this. If you can't already do it, the best solution is to treat it as a<br/>consciously artificial trick, like juggling.  <br/>  <br/>However, that doesn't mean you should talk like some kind of announcer.<br/>Audiences tune that out. What you need to do is talk in this artificial way,<br/>and yet make it seem conversational. (Writing is the same. Good writing is an<br/>elaborate effort to seem spontaneous.)  <br/>  <br/>If you want to write out your whole presentation beforehand and memorize it,<br/>that's ok. That has worked for some groups in the past. But make sure to write<br/>something that sounds like spontaneous, informal speech, and deliver it that<br/>way too.  <br/>  <br/>Err on the side of speaking slowly. At Rehearsal Day, one of the founders<br/>mentioned a rule actors use: if you feel you're speaking too slowly, you're<br/>speaking at about the right speed.  <br/>  <br/> **8\. Have one person talk.**  <br/>  <br/>Startups often want to show that all the founders are equal partners. This is<br/>a good instinct; investors dislike unbalanced teams. But trying to show it by<br/>partitioning the presentation is going too far. It's distracting. You can<br/>demonstrate your respect for one another in more subtle ways. For example,<br/>when one of the groups presented at Demo Day, the more extroverted of the two<br/>founders did most of the talking, but he described his co-founder as the best<br/>hacker he'd ever met, and you could tell he meant it.  <br/>  <br/>Pick the one or at most two best speakers, and have them do most of the<br/>talking.  <br/>  <br/>Exception: If one of the founders is an expert in some specific technical<br/>field, it can be good for them to talk about that for a minute or so. This<br/>kind of "expert witness" can add credibility, even if the audience doesn't<br/>understand all the details. If Jobs and Wozniak had 10 minutes to present the<br/>Apple II, it might be a good plan to have Jobs speak for 9 minutes and have<br/>Woz speak for a minute in the middle about some of the technical feats he'd<br/>pulled off in the design. (Though of course if it were actually those two,<br/>Jobs would speak for the entire 10 minutes.)  <br/>  <br/> **9\. Seem confident.**  <br/>  <br/>Between the brief time available and their lack of technical background, many<br/>in the audience will have a hard time evaluating what you're doing. Probably<br/>the single biggest piece of evidence, initially, will be your own confidence<br/>in it. You have to show you're impressed with what you've made.  <br/>  <br/>And I mean show, not tell. Never say "we're passionate" or "our product is<br/>great." People just ignore that—or worse, write you off as bullshitters. Such<br/>messages must be implicit.  <br/>  <br/>What you must not do is seem nervous and apologetic. If you've truly made<br/>something good, you're doing investors a _favor_ by telling them about it. If<br/>you don't genuinely believe that, perhaps you ought to change what your<br/>company is doing. If you don't believe your startup has such promise that<br/>you'd be doing them a favor by letting them invest, why are you investing your<br/>time in it?  <br/>  <br/> **10\. Don't try to seem more than you are.**  <br/>  <br/>Don't worry if your company is just a few months old and doesn't have an<br/>office yet, or your founders are technical people with no business experience.<br/>Google was like that once, and they turned out ok. Smart investors can see<br/>past such superficial flaws. They're not looking for finished, smooth<br/>presentations. They're looking for raw talent. All you need to convince them<br/>of is that you're smart and that you're onto something good. If you try too<br/>hard to conceal your rawness—by trying to seem corporate, or pretending to<br/>know about stuff you don't—you may just conceal your talent.  <br/>  <br/>You can afford to be candid about what you haven't figured out yet. Don't go<br/>out of your way to bring it up (e.g. by having a slide about what might go<br/>wrong), but don't try to pretend either that you're further along than you<br/>are. If you're a hacker and you're presenting to experienced investors,<br/>they're probably better at detecting bullshit than you are at producing it.  <br/>  <br/> **11\. Don't put too many words on slides.**  <br/>  <br/>When there are a lot of words on a slide, people just skip reading it. So look<br/>at your slides and ask of each word "could I cross this out?" This includes<br/>gratuitous clip art. Try to get your slides under 20 words if you can.  <br/>  <br/>Don't read your slides. They should be something in the background as you face<br/>the audience and talk to them, not something you face and read to an audience<br/>sitting behind you.  <br/>  <br/>Cluttered sites don't do well in demos, especially when they're projected onto<br/>a screen. At the very least, crank up the font size big enough to make all the<br/>text legible. But cluttered sites are bad anyway, so perhaps you should use<br/>this opportunity to make your design simpler.  <br/>  <br/> **12\. Specific numbers are good.**  <br/>  <br/>If you have any kind of data, however preliminary, tell the audience. Numbers<br/>stick in people's heads. If you can claim that the median visitor generates 12<br/>page views, that's great.  <br/>  <br/>But don't give them more than four or five numbers, and only give them numbers<br/>specific to you. You don't need to tell them the size of the market you're in.<br/>Who cares, really, if it's 500 million or 5 billion a year? Talking about that<br/>is like an actor at the beginning of his career telling his parents how much<br/>Tom Hanks makes. Yeah, sure, but first you have to become Tom Hanks. The<br/>important part is not whether he makes ten million a year or a hundred, but<br/>how you get there.  <br/>  <br/> **13\. Tell stories about users.**  <br/>  <br/>The biggest fear of investors looking at early stage startups is that you've<br/>built something based on your own a priori theories of what the world needs,<br/>but that no one will actually want. So it's good if you can talk about<br/>problems specific users have and how you solve them.  <br/>  <br/>Greg Mcadoo said one thing Sequoia looks for is the "proxy for demand." What<br/>are people doing now, using inadequate tools, that shows they need what you're<br/>making?  <br/>  <br/>Another sign of user need is when people pay a lot for something. It's easy to<br/>convince investors there will be demand for a cheaper alternative to something<br/>popular, if you preserve the qualities that made it popular.  <br/>  <br/>The best stories about user needs are about your own. A remarkable number of<br/>famous startups grew out of some need the founders had: Apple, Microsoft,<br/>Yahoo, Google. Experienced investors know that, so stories of this type will<br/>get their attention. The next best thing is to talk about the needs of people<br/>you know personally, like your friends or siblings.  <br/>  <br/> **14\. Make a soundbite stick in their heads.**  <br/>  <br/>Professional investors hear a lot of pitches. After a while they all blur<br/>together. The first cut is simply to be one of those they remember. And the<br/>way to ensure that is to create a descriptive phrase about yourself that<br/>sticks in their heads.  <br/>  <br/>In Hollywood, these phrases seem to be of the form "x meets y."  In the<br/>startup world, they're usually "the x of y" or "the x y." Viaweb's was "the<br/>Microsoft Word of ecommerce."  <br/>  <br/>Find one and launch it clearly (but apparently casually) in your talk,<br/>preferably near the beginning.  <br/>  <br/>It's a good exercise for you, too, to sit down and try to figure out how to<br/>describe your startup in one compelling phrase. If you can't, your plans may<br/>not be sufficiently focused.  <br/>  <br/>  <br/><br/>How to Fund a Startup  <br/>  <br/><br/>Hackers' Guide to Investors  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>Image: Casey Muller: Trevor Blackwell at Rehearsal Day, summer 2006<br/><br/>April 2009  <br/>  <br/>Recently I realized I'd been holding two ideas in my head that would explode<br/>if combined.  <br/>  <br/>The first is that startups may represent a new economic phase, on the scale of<br/>the Industrial Revolution. I'm not sure of this, but there seems a decent<br/>chance it's true. People are dramatically more productive<br/><br/>  <br/>  <br/><br/>* * *<br/><br/>November 2019  <br/>  <br/>If you discover something new, there's a significant chance you'll be accused<br/>of some form of heresy.  <br/>  <br/>To discover new things, you have to work on ideas that are good but non-<br/>obvious; if an idea is obviously good, other people are probably already<br/>working on it. One common way for a good idea to be non-obvious is for it to<br/>be hidden in the shadow of some mistaken assumption that people are very<br/>attached to. But anything you discover from working on such an idea will tend<br/>to contradict the mistaken assumption that was concealing it. And you will<br/>thus get a lot of heat from people attached to the mistaken assumption.<br/>Galileo and Darwin are famous examples of this phenomenon, but it's probably<br/>always an ingredient in the resistance to new ideas.  <br/>  <br/>So it's particularly dangerous for an organization or society to have a<br/>culture of pouncing on heresy. When you suppress heresies, you don't just<br/>prevent people from contradicting the mistaken assumption you're trying to<br/>protect. You also suppress any idea that implies indirectly that it's false.  <br/>  <br/>Every cherished mistaken assumption has a dead zone of unexplored ideas around<br/>it. And the more preposterous the assumption, the bigger the dead zone it<br/>creates.  <br/>  <br/>There is a positive side to this phenomenon though. If you're looking for new<br/>ideas, one way to find them is by _looking for heresies_. When you look at the<br/>question this way, the depressingly large dead zones around mistaken<br/>assumptions become excitingly large mines of new ideas.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>March 2008, rev May 2013  <br/>  <br/> _(This essay grew out of something I wrote for myself to figure out what we<br/>do. Even though Y Combinator is now 3 years old, we're still trying to<br/>understand its implications.)_  <br/>  <br/>I was annoyed recently to read a description of Y Combinator that said "Y<br/>Combinator does seed funding for startups." What was especially annoying about<br/>it was that I wrote it. This doesn't really convey what we do. And the reason<br/>it's inaccurate is that, paradoxically, funding very early stage startups is<br/>not mainly about funding.  <br/>  <br/>Saying YC does seed funding for startups is a description in terms of earlier<br/>models. It's like calling a car a horseless carriage.  <br/>  <br/>When you scale animals you can't just keep everything in proportion. For<br/>example, volume grows as the cube of linear dimension, but surface area only<br/>as the square. So as animals get bigger they have trouble radiating heat.<br/>That's why mice and rabbits are furry and elephants and hippos aren't. You<br/>can't make a mouse by scaling down an elephant.  <br/>  <br/>YC represents a new, smaller kind of animal—so much smaller that all the rules<br/>are different.  <br/>  <br/>Before us, most companies in the startup funding business were venture capital<br/>funds. VCs generally fund later stage companies than we do. And they supply so<br/>much money that, even though the other things they do may be very valuable,<br/>it's not that inaccurate to regard VCs as sources of money. Good VCs are<br/>"smart money," but they're still money.  <br/>  <br/>All good investors supply a combination of money and help. But these scale<br/>differently, just as volume and surface area do. Late stage investors supply<br/>huge amounts of money and comparatively little help: when a company about to<br/>go public gets a mezzanine round of $50 million, the deal tends to be almost<br/>entirely about money. As you move earlier in the venture funding process, the<br/>ratio of help to money increases, because earlier stage companies have<br/>different needs. Early stage companies need less money because they're smaller<br/>and cheaper to run, but they need more help because life is so precarious for<br/>them. So when VCs do a series A round for, say, $2 million, they generally<br/>expect to offer a significant amount of help along with the money.  <br/>  <br/>Y Combinator occupies the earliest end of the spectrum. We're at least one and<br/>generally two steps before VC funding. (Though some startups go straight from<br/>YC to VC, the most common trajectory is to do an angel round first.) And what<br/>happens at Y Combinator is as different from what happens in a series A round<br/>as a series A round is from a mezzanine financing.  <br/>  <br/>At our end, money is almost a negligible factor. The startup usually consists<br/>of just the founders. Their living expenses are the company's main expense,<br/>and since most founders are under 30, their living expenses are low. But at<br/>this early stage companies need a lot of help. Practically every question is<br/>still unanswered. Some companies we've funded have been working on their<br/>software for a year or more, but others haven't decided what to work on, or<br/>even who the founders should be.  <br/>  <br/>When PR people and journalists recount the histories of startups after they've<br/>become big, they always underestimate how uncertain things were at first.<br/>They're not being deliberately misleading. When you look at a company like<br/>Google, it's hard to imagine they could once have been small and helpless.<br/>Sure, at one point they were a just a couple guys in a garage—but even then<br/>their greatness was assured, and all they had to do was roll forward along the<br/>railroad tracks of destiny.  <br/>  <br/>Far from it. A lot of startups with just as promising beginnings end up<br/>failing. Google has such momentum now that it would be hard for anyone to stop<br/>them. But all it would have taken in the beginning would have been for two<br/>Google employees to focus on the wrong things for six months, and the company<br/>could have died.  <br/>  <br/>We know, because we've been there, just how vulnerable startups are in the<br/>earliest phases. Curiously enough, that's why founders tend to get so rich<br/>from them. Reward is always proportionate to risk, and very early stage<br/>startups are insanely risky.  <br/>  <br/>What we really do at Y Combinator is get startups launched straight. One of<br/>many metaphors you could use for YC is a steam catapult on an aircraft<br/>carrier. We get startups airborne. Barely airborne, but enough that they can<br/>accelerate fast.  <br/>  <br/>When you're launching planes they have to be set up properly or you're just<br/>launching projectiles. They have to be pointed straight down the deck; the<br/>wings have to be trimmed properly; the engines have to be at full power; the<br/>pilot has to be ready. These are the kind of problems we deal with. After we<br/>fund startups we work closely with them for three months—so closely in fact<br/>that we insist they move to where we are. And what we do in those three months<br/>is make sure everything is set up for launch. If there are tensions between<br/>cofounders we help sort them out. We get all the paperwork set up properly so<br/>there are no nasty surprises later. If the founders aren't sure what to focus<br/>on first, we try to figure that out. If there is some obstacle right in front<br/>of them, we either try to remove it, or shift the startup sideways. The goal<br/>is to get every distraction out of the way so the founders can use that time<br/>to build (or finish building) something impressive. And then near the end of<br/>the three months we push the button on the steam catapult in the form of Demo<br/>Day, where the current group of startups present to pretty much every investor<br/>in Silicon Valley.  <br/>  <br/>Launching companies isn't identical with launching products. Though we do<br/>spend a lot of time on launch strategies for products, there are some things<br/>that take too long to build for a startup to launch them before raising their<br/>next round of funding. Several of the most promising startups we've funded<br/>haven't launched their products yet, but are definitely launched as companies.  <br/>  <br/>In the earliest stage, startups not only have more questions to answer, but<br/>they tend to be different kinds of questions. In later stage startups the<br/>questions are about deals, or hiring, or organization. In the earliest phase<br/>they tend to be about technology and design. What do you make? That's the<br/>first problem to solve. That's why our motto is "Make something people want."<br/>This is always a good thing for companies to do, but it's even more important<br/>early on, because it sets the bounds for every other question. Who you hire,<br/>how much money you raise, how you market yourself—they all depend on what<br/>you're making.  <br/>  <br/>Because the early problems are so much about technology and design, you<br/>probably need to be hackers to do what we do. While some VCs have technical<br/>backgrounds, I don't know any who still write code. Their expertise is mostly<br/>in business—as it should be, because that's the kind of expertise you need in<br/>the phase between series A and (if you're lucky) IPO.  <br/>  <br/>We're so different from VCs that we're really a different kind of animal. Can<br/>we claim founders are better off as a result of this new type of venture firm?<br/>I'm pretty sure the answer is yes, because YC is an improved version of what<br/>happened to our startup, and our case was not atypical. We started Viaweb with<br/>$10,000 in seed money from our friend Julian. He was a lawyer and arranged all<br/>our paperwork, so we could just code. We spent three months building a version<br/>1, which we then presented to investors to raise more money. Sounds familiar,<br/>doesn't it? But YC improves on that significantly. Julian knew a lot about law<br/>and business, but his advice ended there; he was not a startup guy. So we made<br/>some basic mistakes early on. And when we presented to investors, we presented<br/>to only 2, because that was all we knew. If we'd had our later selves to<br/>encourage and advise us, and Demo Day to present at, we would have been in<br/>much better shape. We probably could have raised money at 3 to 5 times the<br/>valuation we did.  <br/>  <br/>If we take 7% of a company we fund, the founders only have to do 7.5% better<br/>in their next round of funding to end up net ahead. We certainly manage that.  <br/>  <br/>So who is our 7% coming out of? If the founders end up net ahead it's not<br/>coming out of them. So is it coming out of later stage investors? Well, they<br/>do end up paying more. But I think they pay more because the company is<br/>actually more valuable. And later stage investors have no problem with that.<br/>The returns of a VC fund depend on the quality of the companies they invest<br/>in, not how cheaply they can buy stock in them.  <br/>  <br/>If what we do is useful, why wasn't anyone doing it before? There are two<br/>answers to that. One is that people were doing it before, just haphazardly on<br/>a smaller scale. Before us, seed funding came primarily from individual angel<br/>investors. Larry and Sergey, for example, got their seed funding from Andy<br/>Bechtolsheim, one of the founders of Sun. And because he was a startup guy he<br/>probably gave them useful advice. But raising money from angel investors is a<br/>hit or miss thing. It's a sideline for most of them, so they only do a handful<br/>of deals a year and they don't spend a lot of time on the startups they invest<br/>in. And they're hard to reach, because they don't want random startups<br/>pestering them with business plans. The Google guys were lucky because they<br/>knew someone who knew Bechtolsheim. It generally takes a personal introduction<br/>with angels.  <br/>  <br/>The other reason no one was doing quite what we do is that till recently it<br/>was a lot more expensive to start a startup. You'll notice we haven't funded<br/>any biotech startups. That's still expensive. But advancing technology has<br/>made web startups so cheap that you really can get a company airborne for<br/>$15,000. If you understand how to operate a steam catapult, at least.  <br/>  <br/>So in effect what's happened is that a new ecological niche has opened up, and<br/>Y Combinator is the new kind of animal that has moved into it. We're not a<br/>replacement for venture capital funds. We occupy a new, adjacent niche. And<br/>conditions in our niche are really quite different. It's not just that the<br/>problems we face are different; the whole structure of the business is<br/>different. VCs are playing a zero-sum game. They're all competing for a slice<br/>of a fixed amount of "deal flow," and that explains a lot of their behavior.<br/>Whereas our m.o. is to create new deal flow, by encouraging hackers who would<br/>have gotten jobs to start their own startups instead. We compete more with<br/>employers than VCs.  <br/>  <br/>It's not surprising something like this would happen. Most fields become more<br/>specialized—more articulated—as they develop, and startups are certainly an<br/>area in which there has been a lot of development over the past couple<br/>decades. The venture business in its present form is only about forty years<br/>old. It stands to reason it would evolve.  <br/>  <br/>And it's natural that the new niche would at first be described, even by its<br/>inhabitants, in terms of the old one. But really Y Combinator is not in the<br/>startup funding business. Really we're more of a small, furry steam catapult.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Thanks** to Trevor Blackwell, Jessica Livingston, and Robert Morris for<br/>reading drafts of this.  <br/>  <br/>Comment on this essay.  <br/>  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>September 2009  <br/>  <br/>I bet you the current issue of _Cosmopolitan_ has an article whose title<br/>begins with a number. "7 Things He Won't Tell You about Sex," or something<br/>like that. Some popular magazines feature articles of this type on the cover<br/>of every issue. That can't be happening by accident. Editors must know they<br/>attract readers.  <br/>  <br/>Why do readers like the list of n things so much? Mainly because it's easier<br/>to read than a regular article. [1] Structurally, the list of n things is a<br/>degenerate case of essay. An essay can go anywhere the writer wants. In a list<br/>of n things the writer agrees to constrain himself to a collection of points<br/>of roughly equal importance, and he tells the reader explicitly what they are.  <br/>  <br/>Some of the work of reading an article is understanding its structure—figuring<br/>out what in high school we'd have called its "outline." Not explicitly, of<br/>course, but someone who really understands an article probably has something<br/>in his brain afterward that corresponds to such an outline. In a list of n<br/>things, this work is done for you. Its structure is an exoskeleton.  <br/>  <br/>As well as being explicit, the structure is guaranteed to be of the simplest<br/>possible type: a few main points with few to no subordinate ones, and no<br/>particular connection between them.  <br/>  <br/>Because the main points are unconnected, the list of n things is random<br/>access. There's no thread of reasoning you have to follow. You could read the<br/>list in any order. And because the points are independent of one another, they<br/>work like watertight compartments in an unsinkable ship. If you get bored<br/>with, or can't understand, or don't agree with one point, you don't have to<br/>give up on the article. You can just abandon that one and skip to the next. A<br/>list of n things is parallel and therefore fault tolerant.  <br/>  <br/>There are times when this format is what a writer wants. One, obviously, is<br/>when what you have to say actually is a list of n things. I once wrote an<br/>essay about the mistakes that kill startups, and a few people made fun of me<br/>for writing something whose title began with a number. But in that case I<br/>really was trying to make a complete catalog of a number of independent<br/>things. In fact, one of the questions I was trying to answer was how many<br/>there were.  <br/>  <br/>There are other less legitimate reasons for using this format. For example, I<br/>use it when I get close to a deadline. If I have to give a talk and I haven't<br/>started it a few days beforehand, I'll sometimes play it safe and make the<br/>talk a list of n things.  <br/>  <br/>The list of n things is easier for writers as well as readers. When you're<br/>writing a real essay, there's always a chance you'll hit a dead end. A real<br/>essay is a train of thought, and some trains of thought just peter out. That's<br/>an alarming possibility when you have to give a talk in a few days. What if<br/>you run out of ideas? The compartmentalized structure of the list of n things<br/>protects the writer from his own stupidity in much the same way it protects<br/>the reader. If you run out of ideas on one point, no problem: it won't kill<br/>the essay. You can take out the whole point if you need to, and the essay will<br/>still survive.  <br/>  <br/>Writing a list of n things is so relaxing. You think of n/2 of them in the<br/>first 5 minutes. So bang, there's the structure, and you just have to fill it<br/>in. As you think of more points, you just add them to the end. Maybe you take<br/>out or rearrange or combine a few, but at every stage you have a valid (though<br/>initially low-res) list of n things. It's like the sort of programming where<br/>you write a version 1 very quickly and then gradually modify it, but at every<br/>point have working code—or the style of painting where you begin with a<br/>complete but very blurry sketch done in an hour, then spend a week cranking up<br/>the resolution.  <br/>  <br/>Because the list of n things is easier for writers too, it's not always a<br/>damning sign when readers prefer it. It's not necessarily evidence readers are<br/>lazy; it could also mean they don't have much confidence in the writer. The<br/>list of n things is in that respect the cheeseburger of essay forms. If you're<br/>eating at a restaurant you suspect is bad, your best bet is to order the<br/>cheeseburger. Even a bad cook can make a decent cheeseburger. And there are<br/>pretty strict conventions about what a cheeseburger should look like. You can<br/>assume the cook isn't going to try something weird and artistic. The list of n<br/>things similarly limits the damage that can be done by a bad writer. You know<br/>it's going to be about whatever the title says, and the format prevents the<br/>writer from indulging in any flights of fancy.  <br/>  <br/>Because the list of n things is the easiest essay form, it should be a good<br/>one for beginning writers. And in fact it is what most beginning writers are<br/>taught. The classic 5 paragraph essay is really a list of n things for n = 3.<br/>But the students writing them don't realize they're using the same structure<br/>as the articles they read in _Cosmopolitan_. They're not allowed to include<br/>the numbers, and they're expected to spackle over the gaps with gratuitous<br/>transitions ("Furthermore...") and cap the thing at either end with<br/>introductory and concluding paragraphs so it will look superficially like a<br/>real essay. [2]  <br/>  <br/>It seems a fine plan to start students off with the list of n things. It's the<br/>easiest form. But if we're going to do that, why not do it openly? Let them<br/>write lists of n things like the pros, with numbers and no transitions or<br/>"conclusion."  <br/>  <br/>There is one case where the list of n things is a dishonest format: when you<br/>use it to attract attention by falsely claiming the list is an exhaustive one.<br/>I.e. if you write an article that purports to be about _the_ 7 secrets of<br/>success. That kind of title is the same sort of reflexive challenge as a<br/>whodunit. You have to at least look at the article to check whether they're<br/>the same 7 you'd list. Are you overlooking one of the secrets of success?<br/>Better check.  <br/>  <br/>It's fine to put "The" before the number if you really believe you've made an<br/>exhaustive list. But evidence suggests most things with titles like this are<br/>linkbait.  <br/>  <br/>The greatest weakness of the list of n things is that there's so little room<br/>for new thought. The main point of essay writing, when done right, is the new<br/>ideas you have while doing it. A real essay, as the name implies, is dynamic:<br/>you don't know what you're going to write when you start. It will be about<br/>whatever you discover in the course of writing it.  <br/>  <br/>This can only happen in a very limited way in a list of n things. You make the<br/>title first, and that's what it's going to be about. You can't have more new<br/>ideas in the writing than will fit in the watertight compartments you set up<br/>initially. And your brain seems to know this: because you don't have room for<br/>new ideas, you don't have them.  <br/>  <br/>Another advantage of admitting to beginning writers that the 5 paragraph essay<br/>is really a list of n things is that we can warn them about this. It only lets<br/>you experience the defining characteristic of essay writing on a small scale:<br/>in thoughts of a sentence or two. And it's particularly dangerous that the 5<br/>paragraph essay buries the list of n things within something that looks like a<br/>more sophisticated type of essay. If you don't know you're using this form,<br/>you don't know you need to escape it.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Articles of this type are also startlingly popular on Delicious, but I<br/>think that's because delicious/popular is driven by bookmarking, not because<br/>Delicious users are stupid. Delicious users are collectors, and a list of n<br/>things seems particularly collectible because it's a collection itself.  <br/>  <br/>[2] Most "word problems" in school math textbooks are similarly misleading.<br/>They look superficially like the application of math to real problems, but<br/>they're not. So if anything they reinforce the impression that math is merely<br/>a complicated but pointless collection of stuff to be memorized.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/><br/>Russian Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>December 2010  <br/>  <br/>I was thinking recently how inconvenient it was not to have a general term for<br/>iPhones, iPads, and the corresponding things running Android. The closest to a<br/>general term seems to be "mobile devices," but that (a) applies to any mobile<br/>phone, and (b) doesn't really capture what's distinctive about the iPad.  <br/>  <br/>After a few seconds it struck me that what we'll end up calling these things<br/>is tablets. The only reason we even consider calling them "mobile devices" is<br/>that the iPhone preceded the iPad. If the iPad had come first, we wouldn't<br/>think of the iPhone as a phone; we'd think of it as a tablet small enough to<br/>hold up to your ear.  <br/>  <br/>The iPhone isn't so much a phone as a replacement for a phone. That's an<br/>important distinction, because it's an early instance of what will become a<br/>common pattern. Many if not most of the special-purpose objects around us are<br/>going to be replaced by apps running on tablets.  <br/>  <br/>This is already clear in cases like GPSes, music players, and cameras. But I<br/>think it will surprise people how many things are going to get replaced. We<br/>funded one startup that's replacing keys. The fact that you can change font<br/>sizes easily means the iPad effectively replaces reading glasses. I wouldn't<br/>be surprised if by playing some clever tricks with the accelerometer you could<br/>even replace the bathroom scale.  <br/>  <br/>The advantages of doing things in software on a single device are so great<br/>that everything that can get turned into software will. So for the next couple<br/>years, a good recipe for startups will be to look around you for things that<br/>people haven't realized yet can be made unnecessary by a tablet app.  <br/>  <br/>In 1938 Buckminster Fuller coined the term ephemeralization to describe the<br/>increasing tendency of physical machinery to be replaced by what we would now<br/>call software. The reason tablets are going to take over the world is not<br/>(just) that Steve Jobs and Co are industrial design wizards, but because they<br/>have this force behind them. The iPhone and the iPad have effectively drilled<br/>a hole that will allow ephemeralization to flow into a lot of new areas. No<br/>one who has studied the history of technology would want to underestimate the<br/>power of that force.  <br/>  <br/>I worry about the power Apple could have with this force behind them. I don't<br/>want to see another era of client monoculture like the Microsoft one in the<br/>80s and 90s. But if ephemeralization is one of the main forces driving the<br/>spread of tablets, that suggests a way to compete with Apple: be a better<br/>platform for it.  <br/>  <br/>It has turned out to be a great thing that Apple tablets have accelerometers<br/>in them. Developers have used the accelerometer in ways Apple could never have<br/>imagined. That's the nature of platforms. The more versatile the tool, the<br/>less you can predict how people will use it. So tablet makers should be<br/>thinking: what else can we put in there? Not merely hardware, but software<br/>too. What else can we give developers access to? Give hackers an inch and<br/>they'll take you a mile.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Thanks** to Sam Altman, Paul Buchheit, Jessica Livingston, and Robert Morris<br/>for reading drafts of this.  <br/>  <br/>  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>August 2011  <br/>  <br/>I realized recently that we may be able to solve part of the patent problem<br/>without waiting for the government.  <br/>  <br/>I've never been 100% sure whether patents help or hinder technological<br/>progress. When I was a kid I thought they helped. I thought they protected<br/>inventors from having their ideas stolen by big companies. Maybe that was<br/>truer in the past, when more things were physical. But regardless of whether<br/>patents are in general a good thing, there do seem to be bad ways of using<br/>them. And since bad uses of patents seem to be increasing, there is an<br/>increasing call for patent reform.  <br/>  <br/>The problem with patent reform is that it has to go through the government.<br/>That tends to be slow. But recently I realized we can also attack the problem<br/>downstream. As well as pinching off the stream of patents at the point where<br/>they're issued, we may in some cases be able to pinch it off at the point<br/>where they're used.  <br/>  <br/>One way of using patents that clearly does not encourage innovation is when<br/>established companies with bad products use patents to suppress small<br/>competitors with good products. This is the type of abuse we may be able to<br/>decrease without having to go through the government.  <br/>  <br/>The way to do it is to get the companies that are above pulling this sort of<br/>trick to pledge publicly not to. Then the ones that won't make such a pledge<br/>will be very conspicuous. Potential employees won't want to work for them. And<br/>investors, too, will be able to see that they're the sort of company that<br/>competes by litigation rather than by making good products.  <br/>  <br/>Here's the pledge:<br/><br/>> No first use of software patents against companies with less than 25 people.<br/><br/>I've deliberately traded precision for brevity. The patent pledge is not<br/>legally binding. It's like Google's "Don't be evil." They don't define what<br/>evil is, but by publicly saying that, they're saying they're willing to be<br/>held to a standard that, say, Altria is not. And though constraining, "Don't<br/>be evil" has been good for Google. Technology companies win by attracting the<br/>most productive people, and the most productive people are attracted to<br/>employers who hold themselves to a higher standard than the law requires. [1]  <br/>  <br/>The patent pledge is in effect a narrower but open source "Don't be evil." I<br/>encourage every technology company to adopt it. If you want to help fix<br/>patents, encourage your employer to.  <br/>  <br/>Already most technology companies wouldn't sink to using patents on startups.<br/>You don't see Google or Facebook suing startups for patent infringement. They<br/>don't need to. So for the better technology companies, the patent pledge<br/>requires no change in behavior. They're just promising to do what they'd do<br/>anyway. And when all the companies that won't use patents on startups have<br/>said so, the holdouts will be very conspicuous.  <br/>  <br/>The patent pledge doesn't fix every problem with patents. It won't stop patent<br/>trolls, for example; they're already pariahs. But the problem the patent<br/>pledge does fix may be more serious than the problem of patent trolls. Patent<br/>trolls are just parasites. A clumsy parasite may occasionally kill the host,<br/>but that's not its goal. Whereas companies that sue startups for patent<br/>infringement generally do it with explicit goal of keeping their product off<br/>the market.  <br/>  <br/>Companies that use patents on startups are attacking innovation at the root.<br/>Now there's something any individual can do about this problem, without<br/>waiting for the government: ask companies where they stand.  <br/>  <br/>  <br/>  <br/>Patent Pledge Site  <br/>  <br/>  <br/>  <br/>**Notes:**  <br/>  <br/>[1] Because the pledge is deliberately vague, we're going to need common sense<br/>when intepreting it. And even more vice versa: the pledge is vague in order to<br/>make people use common sense when interpreting it.  <br/>  <br/>So for example I've deliberately avoided saying whether the 25 people have to<br/>be employees, or whether contractors count too. If a company has to split<br/>hairs that fine about whether a suit would violate the patent pledge, it's<br/>probably still a dick move.  <br/>  <br/><br/>The Investment That Didn't Happen  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>April 2008  <br/>  <br/>There are some topics I save up because they'll be so much fun to write about.<br/>This is one of them: a list of my heroes.  <br/>  <br/>I'm not claiming this is a list of the _n_ most admirable people. Who could<br/>make such a list, even if they wanted to?  <br/>  <br/>Einstein isn't on the list, for example, even though he probably deserves to<br/>be on any shortlist of admirable people. I once asked a physicist friend if<br/>Einstein was really as smart as his fame implies, and she said that yes, he<br/>was. So why isn't he on the list? Because I had to ask. This is a list of<br/>people who've influenced me, not people who would have if I understood their<br/>work.  <br/>  <br/>My test was to think of someone and ask "is this person my hero?" It often<br/>returned surprising answers. For example, it returned false for Montaigne, who<br/>was arguably the inventor of the essay. Why? When I thought about what it<br/>meant to call someone a hero, it meant I'd decide what to do by asking what<br/>they'd do in the same situation. That's a stricter standard than admiration.  <br/>  <br/>After I made the list, I looked to see if there was a pattern, and there was,<br/>a very clear one. Everyone on the list had two qualities: they cared almost<br/>excessively about their work, and they were absolutely honest. By honest I<br/>don't mean trustworthy so much as that they never pander: they never say or do<br/>something because that's what the audience wants. They are all fundamentally<br/>subversive for this reason, though they conceal it to varying degrees.  <br/>  <br/>**Jack Lambert**  <br/>  <br/>I grew up in Pittsburgh in the 1970s. Unless you were there it's hard to<br/>imagine how that town felt about the Steelers. Locally, all the news was bad.<br/>The steel industry was dying. But the Steelers were the best team in<br/>football—and moreover, in a way that seemed to reflect the personality of the<br/>city. They didn't do anything fancy. They just got the job done.  <br/>  <br/>Other players were more famous: Terry Bradshaw, Franco Harris, Lynn Swann. But<br/>they played offense, and you always get more attention for that. It seemed to<br/>me as a twelve year old football expert that the best of them all was Jack<br/>Lambert. And what made him so good was that he was utterly relentless. He<br/>didn't just care about playing well; he cared almost too much. He seemed to<br/>regard it as a personal insult when someone from the other team had possession<br/>of the ball on his side of the line of scrimmage.  <br/>  <br/>The suburbs of Pittsburgh in the 1970s were a pretty dull place. School was<br/>boring. All the adults around were bored with their jobs working for big<br/>companies. Everything that came to us through the mass media was (a) blandly<br/>uniform and (b) produced elsewhere. Jack Lambert was the exception. He was<br/>like nothing else I'd seen.  <br/>  <br/>**Kenneth Clark**  <br/>  <br/>Kenneth Clark is the best nonfiction writer I know of, on any subject. Most<br/>people who write about art history don't really like art; you can tell from a<br/>thousand little signs. But Clark did, and not just intellectually, but the way<br/>one anticipates a delicious dinner.  <br/>  <br/>What really makes him stand out, though, is the quality of his ideas. His<br/>style is deceptively casual, but there is more in his books than in a library<br/>of art monographs. Reading _The Nude_ is like a ride in a Ferrari. Just as<br/>you're getting settled, you're slammed back in your seat by the acceleration.<br/>Before you can adjust, you're thrown sideways as the car screeches into the<br/>first turn. His brain throws off ideas almost too fast to grasp them. Finally<br/>at the end of the chapter you come to a halt, with your eyes wide and a big<br/>smile on your face.  <br/>  <br/>Kenneth Clark was a star in his day, thanks to the documentary series<br/>_Civilisation_. And if you read only one book about art history,<br/>_Civilisation_ is the one I'd recommend. It's much better than the drab Sears<br/>Catalogs of art that undergraduates are forced to buy for Art History 101.  <br/>  <br/>**Larry Mihalko**  <br/>  <br/>A lot of people have a great teacher at some point in their childhood. Larry<br/>Mihalko was mine. When I look back it's like there's a line drawn between<br/>third and fourth grade. After Mr. Mihalko, everything was different.  <br/>  <br/>Why? First of all, he was intellectually curious. I had a few other teachers<br/>who were smart, but I wouldn't describe them as intellectually curious. In<br/>retrospect, he was out of place as an elementary school teacher, and I think<br/>he knew it. That must have been hard for him, but it was wonderful for us, his<br/>students. His class was a constant adventure. I used to like going to school<br/>every day.  <br/>  <br/>The other thing that made him different was that he liked us. Kids are good at<br/>telling that. The other teachers were at best benevolently indifferent. But<br/>Mr. Mihalko seemed like he actually wanted to be our friend. On the last day<br/>of fourth grade, he got out one of the heavy school record players and played<br/>James Taylor's "You've Got a Friend" to us. Just call out my name, and you<br/>know wherever I am, I'll come running. He died at 59 of lung cancer. I've<br/>never cried like I cried at his funeral.  <br/>  <br/>**Leonardo**  <br/>  <br/>One of the things I've learned about making things that I didn't realize when<br/>I was a kid is that much of the best stuff isn't made for audiences, but for<br/>oneself. You see paintings and drawings in museums and imagine they were made<br/>for you to look at. Actually a lot of the best ones were made as a way of<br/>exploring the world, not as a way to please other people. The best of these<br/>explorations are sometimes more pleasing than stuff made explicitly to please.  <br/>  <br/>Leonardo did a lot of things. One of his most admirable qualities was that he<br/>did so many different things that were admirable. What people know of him now<br/>is his paintings and his more flamboyant inventions, like flying machines.<br/>That makes him seem like some kind of dreamer who sketched artists'<br/>conceptions of rocket ships on the side. In fact he made a large number of far<br/>more practical technical discoveries. He was as good an engineer as a painter.  <br/>  <br/>His most impressive work, to me, is his drawings. They're clearly made more as<br/>a way of studying the world than producing something beautiful. And yet they<br/>can hold their own with any work of art ever made. No one else, before or<br/>since, was that good when no one was looking.  <br/>  <br/>**Robert Morris**  <br/>  <br/>Robert Morris has a very unusual quality: he's never wrong. It might seem this<br/>would require you to be omniscient, but actually it's surprisingly easy. Don't<br/>say anything unless you're fairly sure of it. If you're not omniscient, you<br/>just don't end up saying much.  <br/>  <br/>More precisely, the trick is to pay careful attention to how you qualify what<br/>you say. By using this trick, Robert has, as far as I know, managed to be<br/>mistaken only once, and that was when he was an undergrad. When the Mac came<br/>out, he said that little desktop computers would never be suitable for real<br/>hacking.  <br/>  <br/>It's wrong to call it a trick in his case, though. If it were a conscious<br/>trick, he would have slipped in a moment of excitement. With Robert this<br/>quality is wired-in. He has an almost superhuman integrity. He's not just<br/>generally correct, but also correct about how correct he is.  <br/>  <br/>You'd think it would be such a great thing never to be wrong that everyone<br/>would do this. It doesn't seem like that much extra work to pay as much<br/>attention to the error on an idea as to the idea itself. And yet practically<br/>no one does. I know how hard it is, because since meeting Robert I've tried to<br/>do in software what he seems to do in hardware.  <br/>  <br/>**P. G. Wodehouse**  <br/>  <br/>People are finally starting to admit that Wodehouse was a great writer. If you<br/>want to be thought a great novelist in your own time, you have to sound<br/>intellectual. If what you write is popular, or entertaining, or funny, you're<br/>ipso facto suspect. That makes Wodehouse doubly impressive, because it meant<br/>that to write as he wanted to, he had to commit to being despised in his own<br/>lifetime.  <br/>  <br/>Evelyn Waugh called him a great writer, but to most people at the time that<br/>would have read as a chivalrous or deliberately perverse gesture. At the time<br/>any random autobiographical novel by a recent college grad could count on more<br/>respectful treatment from the literary establishment.  <br/>  <br/>Wodehouse may have begun with simple atoms, but the way he composed them into<br/>molecules was near faultless. His rhythm in particular. It makes me self-<br/>conscious to write about it. I can think of only two other writers who came<br/>near him for style: Evelyn Waugh and Nancy Mitford. Those three used the<br/>English language like they owned it.  <br/>  <br/>But Wodehouse has something neither of them did. He's at ease. Evelyn Waugh<br/>and Nancy Mitford cared what other people thought of them: he wanted to seem<br/>aristocratic; she was afraid she wasn't smart enough. But Wodehouse didn't<br/>give a damn what anyone thought of him. He wrote exactly what he wanted.  <br/>  <br/>**Alexander Calder**  <br/>  <br/>Calder's on this list because he makes me happy. Can his work stand up to<br/>Leonardo's? Probably not. There might not be anything from the 20th Century<br/>that can. But what was good about Modernism, Calder had, and had in a way that<br/>he made seem effortless.  <br/>  <br/>What was good about Modernism was its freshness. Art became stuffy in the<br/>nineteenth century. The paintings that were popular at the time were mostly<br/>the art equivalent of McMansions—big, pretentious, and fake. Modernism meant<br/>starting over, making things with the same earnest motives that children<br/>might. The artists who benefited most from this were the ones who had<br/>preserved a child's confidence, like Klee and Calder.  <br/>  <br/>Klee was impressive because he could work in so many different styles. But<br/>between the two I like Calder better, because his work seemed happier.<br/>Ultimately the point of art is to engage the viewer. It's hard to predict what<br/>will; often something that seems interesting at first will bore you after a<br/>month. Calder's sculptures never get boring. They just sit there quietly<br/>radiating optimism, like a battery that never runs out. As far as I can tell<br/>from books and photographs, the happiness of Calder's work is his own<br/>happiness showing through.  <br/>  <br/>**Jane Austen**  <br/>  <br/>Everyone admires Jane Austen. Add my name to the list. To me she seems the<br/>best novelist of all time.  <br/>  <br/>I'm interested in how things work. When I read most novels, I pay as much<br/>attention to the author's choices as to the story. But in her novels I can't<br/>see the gears at work. Though I'd really like to know how she does what she<br/>does, I can't figure it out, because she's so good that her stories don't seem<br/>made up. I feel like I'm reading a description of something that actually<br/>happened.  <br/>  <br/>I used to read a lot of novels when I was younger. I can't read most anymore,<br/>because they don't have enough information in them. Novels seem so<br/>impoverished compared to history and biography. But reading Austen is like<br/>reading nonfiction. She writes so well you don't even notice her.  <br/>  <br/>**John McCarthy**  <br/>  <br/>John McCarthy invented Lisp, the field of (or at least the term) artificial<br/>intelligence, and was an early member of both of the top two computer science<br/>departments, MIT and Stanford. No one would dispute that he's one of the<br/>greats, but he's an especial hero to me because of Lisp.  <br/>  <br/>It's hard for us now to understand what a conceptual leap that was at the<br/>time. Paradoxically, one of the reasons his achievement is hard to appreciate<br/>is that it was so successful. Practically every programming language invented<br/>in the last 20 years includes ideas from Lisp, and each year the median<br/>language gets more Lisplike.  <br/>  <br/>In 1958 these ideas were anything but obvious. In 1958 there seem to have been<br/>two ways of thinking about programming. Some people thought of it as math, and<br/>proved things about Turing Machines. Others thought of it as a way to get<br/>things done, and designed languages all too influenced by the technology of<br/>the day. McCarthy alone bridged the gap. He designed a language that was math.<br/>But designed is not really the word; discovered is more like it.  <br/>  <br/>**The Spitfire**  <br/>  <br/>As I was making this list I found myself thinking of people like Douglas Bader<br/>and R.J. Mitchell and Jeffrey Quill and I realized that though all of them had<br/>done many things in their lives, there was one factor above all that connected<br/>them: the Spitfire.  <br/>  <br/>This is supposed to be a list of heroes. How can a machine be on it? Because<br/>that machine was not just a machine. It was a lens of heroes. Extraordinary<br/>devotion went into it, and extraordinary courage came out.  <br/>  <br/>It's a cliche to call World War II a contest between good and evil, but<br/>between fighter designs, it really was. The Spitfire's original nemesis, the<br/>ME 109, was a brutally practical plane. It was a killing machine. The Spitfire<br/>was optimism embodied. And not just in its beautiful lines: it was at the edge<br/>of what could be manufactured. But taking the high road worked. In the air,<br/>beauty had the edge, just.  <br/>  <br/>**Steve Jobs**  <br/>  <br/>People alive when Kennedy was killed usually remember exactly where they were<br/>when they heard about it. I remember exactly where I was when a friend asked<br/>if I'd heard Steve Jobs had cancer. It was like the floor dropped out. A few<br/>seconds later she told me that it was a rare operable type, and that he'd be<br/>ok. But those seconds seemed long.  <br/>  <br/>I wasn't sure whether to include Jobs on this list. A lot of people at Apple<br/>seem to be afraid of him, which is a bad sign. But he compels admiration.  <br/>  <br/>There's no name for what Steve Jobs is, because there hasn't been anyone quite<br/>like him before. He doesn't design Apple's products himself. Historically the<br/>closest analogy to what he does are the great Renaissance patrons of the arts.<br/>As the CEO of a company, that makes him unique.  <br/>  <br/>Most CEOs delegate taste to a subordinate. The design paradox means they're<br/>choosing more or less at random. But Steve Jobs actually has taste<br/>himself—such good taste that he's shown the world how much more important<br/>taste is than they realized.  <br/>  <br/>**Isaac Newton**  <br/>  <br/>Newton has a strange role in my pantheon of heroes: he's the one I reproach<br/>myself with. He worked on big things, at least for part of his life. It's so<br/>easy to get distracted working on small stuff. The questions you're answering<br/>are pleasantly familiar. You get immediate rewards—in fact, you get bigger<br/>rewards in your time if you work on matters of passing importance. But I'm<br/>uncomfortably aware that this is the route to well-deserved obscurity.  <br/>  <br/>To do really great things, you have to seek out questions people didn't even<br/>realize were questions. There have probably been other people who did this as<br/>well as Newton, for their time, but Newton is my model of this kind of<br/>thought. I can just begin to understand what it must have felt like for him.  <br/>  <br/>You only get one life. Why not do something huge? The phrase "paradigm shift"<br/>is overused now, but Kuhn was onto something. And you know more are out there,<br/>separated from us by what will later seem a surprisingly thin wall of laziness<br/>and stupidity. If we work like Newton.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Thanks** to Trevor Blackwell, Jessica Livingston, and Jackie McDonough for<br/>reading drafts of this.  <br/>  <br/><br/>Japanese Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>February 2008  <br/>  <br/>The fiery reaction to the release of Arc had an unexpected consequence: it<br/>made me realize I had a design philosophy. The main complaint of the more<br/>articulate critics was that Arc seemed so flimsy. After years of working on<br/>it, all I had to show for myself were a few thousand lines of macros? Why<br/>hadn't I worked on more substantial problems?  <br/>  <br/>As I was mulling over these remarks it struck me how familiar they seemed.<br/>This was exactly the kind of thing people said at first about Viaweb, and Y<br/>Combinator, and most of my essays.  <br/>  <br/>When we launched Viaweb, it seemed laughable to VCs and e-commerce "experts."<br/>We were just a couple guys in an apartment, which did not seem cool in 1995<br/>the way it does now. And the thing we'd built, as far as they could tell,<br/>wasn't even software. Software, to them, equalled big, honking Windows apps.<br/>Since Viaweb was the first web-based<br/><br/>  <br/>  <br/><br/>* * *<br/><br/>November 2016  <br/>  <br/>If you're a California voter, there is an important proposition on your ballot<br/>this year: Proposition 62, which bans the death penalty.  <br/>  <br/>When I was younger I used to think the debate about the death penalty was<br/>about when it's ok to take a human life. Is it ok to kill a killer?  <br/>  <br/>But that is not the issue here.  <br/>  <br/>The real world does not work like the version I was shown on TV growing up.<br/>The police often arrest the wrong person. Defendants' lawyers are often<br/>incompetent. And prosecutors are often motivated more by publicity than<br/>justice.  <br/>  <br/>In the real world, about 4% of people sentenced to death are innocent. So this<br/>is not about whether it's ok to kill killers. This is about whether it's ok to<br/>kill innocent people.  <br/>  <br/>A child could answer that one for you.  <br/>  <br/>This year, in California, you have a chance to end this, by voting yes on<br/>Proposition 62. But beware, because there is another proposition, Proposition<br/>66, whose goal is to make it easier to execute people. So yes on 62, no on 66.  <br/>  <br/>It's time.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>December 2008  <br/>  <br/>A few months ago I read a _New York Times_ article on South Korean cram<br/>schools that said<br/><br/>> Admission to the right university can make or break an ambitious young South<br/>> Korean.<br/><br/>A parent added:<br/><br/>> "In our country, college entrance exams determine 70 to 80 percent of a<br/>> person's future."<br/><br/>It was striking how old fashioned this sounded. And yet when I was in high<br/>school it wouldn't have seemed too far off as a description of the US. Which<br/>means things must have been changing here.  <br/>  <br/>The course of people's lives in the US now seems to be determined less by<br/>credentials and more by performance than it was 25 years ago. Where you go to<br/>college still matters, but not like it used to.  <br/>  <br/>What happened?  <br/>  <br/>_____  <br/>  <br/>Judging people by their academic credentials was in its time an advance. The<br/>practice seems to have begun in China, where starting in 587 candidates for<br/>the imperial civil service had to take an exam on classical literature. [1] It<br/>was also a test of wealth, because the knowledge it tested was so specialized<br/>that passing required years of expensive training. But though wealth was a<br/>necessary condition for passing, it was not a sufficient one. By the standards<br/>of the rest of the world in 587, the Chinese system was very enlightened.<br/>Europeans didn't introduce formal civil service exams till the nineteenth<br/>century, and even then they seem to have been influenced by the Chinese<br/>example.  <br/>  <br/>Before credentials, government positions were obtained mainly by family<br/>influence, if not outright bribery. It was a great step forward to judge<br/>people by their performance on a test. But by no means a perfect solution.<br/>When you judge people that way, you tend to get cram schools—which they did in<br/>Ming China and nineteenth century England just as much as in present day South<br/>Korea.  <br/>  <br/>What cram schools are, in effect, is leaks in a seal. The use of credentials<br/>was an attempt to seal off the direct transmission of power between<br/>generations, and cram schools represent that power finding holes in the seal.<br/>Cram schools turn wealth in one generation into credentials in the next.  <br/>  <br/>It's hard to beat this phenomenon, because the schools adjust to suit whatever<br/>the tests measure. When the tests are narrow and predictable, you get cram<br/>schools on the classic model, like those that prepared candidates for<br/>Sandhurst (the British West Point) or the classes American students take now<br/>to improve their SAT scores. But as the tests get broader, the schools do too.<br/>Preparing a candidate for the Chinese imperial civil service exams took years,<br/>as prep school does today. But the raison d'etre of all these institutions has<br/>been the same: to beat the system. [2]  <br/>  <br/>_____  <br/>  <br/>History suggests that, all other things being equal, a society prospers in<br/>proportion to its ability to prevent parents from influencing their children's<br/>success directly. It's a fine thing for parents to help their children<br/>indirectly—for example, by helping them to become smarter or more disciplined,<br/>which then makes them more successful. The problem comes when parents use<br/>direct methods: when they are able to use their own wealth or power as a<br/>substitute for their children's qualities.  <br/>  <br/>Parents will tend to do this when they can. Parents will die for their kids,<br/>so it's not surprising to find they'll also push their scruples to the limits<br/>for them. Especially if other parents are doing it.  <br/>  <br/>Sealing off this force has a double advantage. Not only does a society get<br/>"the best man for the job," but parents' ambitions are diverted from direct<br/>methods to indirect ones—to actually trying to raise their kids well.  <br/>  <br/>But we should expect it to be very hard to contain parents' efforts to obtain<br/>an unfair advantage for their kids. We're dealing with one of the most<br/>powerful forces in human nature. We shouldn't expect naive solutions to work,<br/>any more than we'd expect naive solutions for keeping heroin out of a prison<br/>to work.  <br/>  <br/>_____  <br/>  <br/>The obvious way to solve the problem is to make credentials better. If the<br/>tests a society uses are currently hackable, we can study the way people beat<br/>them and try to plug the holes. You can use the cram schools to show you where<br/>most of the holes are. They also tell you when you're succeeding in fixing<br/>them: when cram schools become less popular.  <br/>  <br/>A more general solution would be to push for increased transparency,<br/>especially at critical social bottlenecks like college admissions. In the US<br/>this process still shows many outward signs of corruption. For example, legacy<br/>admissions. The official story is that legacy status doesn't carry much<br/>weight, because all it does is break ties: applicants are bucketed by ability,<br/>and legacy status is only used to decide between the applicants in the bucket<br/>that straddles the cutoff. But what this means is that a university can make<br/>legacy status have as much or as little weight as they want, by adjusting the<br/>size of the bucket that straddles the cutoff.  <br/>  <br/>By gradually chipping away at the abuse of credentials, you could probably<br/>make them more airtight. But what a long fight it would be. Especially when<br/>the institutions administering the tests don't really want them to be<br/>airtight.  <br/>  <br/>_____  <br/>  <br/>Fortunately there's a better way to prevent the direct transmission of power<br/>between generations. Instead of trying to make credentials harder to hack, we<br/>can also make them matter less.  <br/>  <br/>Let's think about what credentials are for. What they are, functionally, is a<br/>way of predicting performance. If you could measure actual performance, you<br/>wouldn't need them.  <br/>  <br/>So why did they even evolve? Why haven't we just been measuring actual<br/>performance? Think about where credentialism first appeared: in selecting<br/>candidates for large organizations. Individual performance is hard to measure<br/>in large organizations, and the harder performance is to measure, the more<br/>important it is to predict it. If an organization could immediately and<br/>cheaply measure the performance of recruits, they wouldn't need to examine<br/>their credentials. They could take everyone and keep just the good ones.  <br/>  <br/>Large organizations can't do this. But a bunch of small organizations in a<br/>market can come close. A market takes every organization and keeps just the<br/>good ones. As organizations get smaller, this approaches taking every person<br/>and keeping just the good ones. So all other things being equal, a society<br/>consisting of more, smaller organizations will care less about credentials.  <br/>  <br/>_____  <br/>  <br/>That's what's been happening in the US. That's why those quotes from Korea<br/>sound so old fashioned. They're talking about an economy like America's a few<br/>decades ago, dominated by a few big companies. The route for the ambitious in<br/>that sort of environment is to join one and climb to the top. Credentials<br/>matter a lot then. In the culture of a large organization, an elite pedigree<br/>becomes a self-fulfilling prophecy.  <br/>  <br/>This doesn't work in small companies. Even if your colleagues were impressed<br/>by your credentials, they'd soon be parted from you if your performance didn't<br/>match, because the company would go out of business and the people would be<br/>dispersed.  <br/>  <br/>In a world of small companies, performance is all anyone cares about. People<br/>hiring for a startup don't care whether you've even graduated from college,<br/>let alone which one. All they care about is what you can do. Which is in fact<br/>all that should matter, even in a large organization. The reason credentials<br/>have such prestige is that for so long the large organizations in a society<br/>tended to be the most powerful. But in the US at least they don't have the<br/>monopoly on power they once did, precisely because they can't measure (and<br/>thus reward) individual performance. Why spend twenty years climbing the<br/>corporate ladder when you can get rewarded directly by the market?  <br/>  <br/>I realize I see a more exaggerated version of the change than most other<br/>people. As a partner at an early stage venture funding firm, I'm like a<br/>jumpmaster shoving people out of the old world of credentials and into the new<br/>one of performance. I'm an agent of the change I'm seeing. But I don't think<br/>I'm imagining it. It was not so easy 25 years ago for an ambitious person to<br/>choose to be judged directly by the market. You had to go through bosses, and<br/>they were influenced by where you'd been to college.  <br/>  <br/>_____  <br/>  <br/>What made it possible for small organizations to succeed in America? I'm still<br/>not entirely sure. Startups are certainly a large part of it. Small<br/>organizations can develop new ideas faster than large ones, and new ideas are<br/>increasingly valuable.  <br/>  <br/>But I don't think startups account for all the shift from credentials to<br/>measurement. My friend Julian Weber told me that when he went to work for a<br/>New York law firm in the 1950s they paid associates far less than firms do<br/>today. Law firms then made no pretense of paying people according to the value<br/>of the work they'd done. Pay was based on seniority. The younger employees<br/>were paying their dues. They'd be rewarded later.  <br/>  <br/>The same principle prevailed at industrial companies. When my father was<br/>working at Westinghouse in the 1970s, he had people working for him who made<br/>more than he did, because they'd been there longer.  <br/>  <br/>Now companies increasingly have to pay employees market price for the work<br/>they do. One reason is that employees no longer trust companies to deliver<br/>deferred rewards: why work to accumulate deferred rewards at a company that<br/>might go bankrupt, or be taken over and have all its implicit obligations<br/>wiped out? The other is that some companies broke ranks and started to pay<br/>young employees large amounts. This was particularly true in consulting, law,<br/>and finance, where it led to the phenomenon of yuppies. The word is rarely<br/>used today because it's no longer surprising to see a 25 year old with money,<br/>but in 1985 the sight of a 25 year old _professional_ able to afford a new BMW<br/>was so novel that it called forth a new word.  <br/>  <br/>The classic yuppie worked for a small organization. He didn't work for General<br/>Widget, but for the law firm that handled General Widget's acquisitions or the<br/>investment bank that floated their bond issues.  <br/>  <br/>Startups and yuppies entered the American conceptual vocabulary roughly<br/>simultaneously in the late 1970s and early 1980s. I don't think there was a<br/>causal connection. Startups happened because technology started to change so<br/>fast that big companies could no longer keep a lid on the smaller ones. I<br/>don't think the rise of yuppies was inspired by it; it seems more as if there<br/>was a change in the social conventions (and perhaps the laws) governing the<br/>way big companies worked. But the two phenomena rapidly fused to produce a<br/>principle that now seems obvious: paying energetic young people market rates,<br/>and getting correspondingly high performance from them.  <br/>  <br/>At about the same time the US economy rocketed out of the doldrums that had<br/>afflicted it for most of the 1970s. Was there a connection? I don't know<br/>enough to say, but it felt like it at the time. There was a lot of energy<br/>released.  <br/>  <br/>_____  <br/>  <br/>Countries worried about their competitiveness are right to be concerned about<br/>the number of startups started within them. But they would do even better to<br/>examine the underlying principle. Do they let energetic young people get paid<br/>market rate for the work they do? The young are the test, because when people<br/>aren't rewarded according to performance, they're invariably rewarded<br/>according to seniority instead.  <br/>  <br/>All it takes is a few beachheads in your economy that pay for performance.<br/>Measurement spreads like heat. If one part of a society is better at<br/>measurement than others, it tends to push the others to do better. If people<br/>who are young but smart and driven can make more by starting their own<br/>companies than by working for existing ones, the existing companies are forced<br/>to pay more to keep them. So market rates gradually permeate every<br/>organization, even the government. [3]  <br/>  <br/>The measurement of performance will tend to push even the organizations<br/>issuing credentials into line. When we were kids I used to annoy my sister by<br/>ordering her to do things I knew she was about to do anyway. As credentials<br/>are superseded by performance, a similar role is the best former gatekeepers<br/>can hope for. Once credential granting institutions are no longer in the self-<br/>fullfilling prophecy business, they'll have to work harder to predict the<br/>future.  <br/>  <br/>_____  <br/>  <br/>Credentials are a step beyond bribery and influence. But they're not the final<br/>step. There's an even better way to block the transmission of power between<br/>generations: to encourage the trend toward an economy made of more, smaller<br/>units. Then you can measure what credentials merely predict.  <br/>  <br/>No one likes the transmission of power between generations—not the left or the<br/>right. But the market forces favored by the right turn out to be a better way<br/>of preventing it than the credentials the left are forced to fall back on.  <br/>  <br/>The era of credentials began to end when the power of large organizations<br/>peaked in the late twentieth century. Now we seem to be entering a new era<br/>based on measurement. The reason the new model has advanced so rapidly is that<br/>it works so much better. It shows no sign of slowing.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Miyazaki, Ichisada (Conrad Schirokauer trans.), _China's Examination Hell:<br/>The Civil Service Examinations of Imperial China,_ Yale University Press,<br/>1981.  <br/>  <br/>Scribes in ancient Egypt took exams, but they were more the type of<br/>proficiency test any apprentice might have to pass.  <br/>  <br/>[2] When I say the raison d'etre of prep schools is to get kids into better<br/>colleges, I mean this in the narrowest sense. I'm not saying that's all prep<br/>schools do, just that if they had zero effect on college admissions there<br/>would be far less demand for them.  <br/>  <br/>[3] Progressive tax rates will tend to damp this effect, however, by<br/>decreasing the difference between good and bad measurers.  <br/>  <br/> **Thanks** to Trevor Blackwell, Sarah Harlin, Jessica Livingston, and David<br/>Sloo for reading drafts of this.  <br/>  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>December 2019  <br/>  <br/>There are two distinct ways to be politically moderate: on purpose and by<br/>accident. Intentional moderates are trimmers, deliberately choosing a position<br/>mid-way between the extremes of right and left. Accidental moderates end up in<br/>the middle, on average, because they make up their own minds about each<br/>question, and the far right and far left are roughly equally wrong.  <br/>  <br/>You can distinguish intentional from accidental moderates by the distribution<br/>of their opinions. If the far left opinion on some matter is 0 and the far<br/>right opinion 100, an intentional moderate's opinion on every question will be<br/>near 50. Whereas an accidental moderate's opinions will be scattered over a<br/>broad range, but will, like those of the intentional moderate, average to<br/>about 50.  <br/>  <br/>Intentional moderates are similar to those on the far left and the far right<br/>in that their opinions are, in a sense, not their own. The defining quality of<br/>an ideologue, whether on the left or the right, is to acquire one's opinions<br/>in bulk. You don't get to pick and choose. Your opinions about taxation can be<br/>predicted from your opinions about same-sex marriage. And although intentional<br/>moderates might seem to be the opposite of ideologues, their beliefs (though<br/>in their case the word "positions" might be more accurate) are also acquired<br/>in bulk. If the median opinion shifts to the right or left, the intentional<br/>moderate must shift with it. Otherwise they stop being moderate.  <br/>  <br/>Accidental moderates, on the other hand, not only choose their own answers,<br/>but choose their own questions. They may not care at all about questions that<br/>the left and right both think are terribly important. So you can only even<br/>measure the politics of an accidental moderate from the intersection of the<br/>questions they care about and those the left and right care about, and this<br/>can sometimes be vanishingly small.  <br/>  <br/>It is not merely a manipulative rhetorical trick to say "if you're not with<br/>us, you're against us," but often simply false.  <br/>  <br/>Moderates are sometimes derided as cowards, particularly by the extreme left.<br/>But while it may be accurate to call intentional moderates cowards, openly<br/>being an accidental moderate requires the most courage of all, because you get<br/>attacked from both right and left, and you don't have the comfort of being an<br/>orthodox member of a large group to sustain you.  <br/>  <br/>Nearly all the most impressive people I know are accidental moderates. If I<br/>knew a lot of professional athletes, or people in the entertainment business,<br/>that might be different. Being on the far left or far right doesn't affect how<br/>fast you run or how well you sing. But someone who works with ideas has to be<br/>independent-minded to do it well.  <br/>  <br/>Or more precisely, you have to be independent-minded about the ideas you work<br/>with. You could be mindlessly doctrinaire in your politics and still be a good<br/>mathematician. In the 20th century, a lot of very smart people were Marxists <br/>just no one who was smart about the subjects Marxism involves. But if the<br/>ideas you use in your work intersect with the politics of your time, you have<br/>two choices: be an accidental moderate, or be mediocre.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] It's possible in theory for one side to be entirely right and the other to<br/>be entirely wrong. Indeed, ideologues must always believe this is the case.<br/>But historically it rarely has been.  <br/>  <br/>[2] For some reason the far right tend to ignore moderates rather than despise<br/>them as backsliders. I'm not sure why. Perhaps it means that the far right is<br/>less ideological than the far left. Or perhaps that they are more confident,<br/>or more resigned, or simply more disorganized. I just don't know.  <br/>  <br/>[3] Having heretical opinions doesn't mean you have to express them openly. It<br/>may be _easier to have them_ if you don't.  <br/>  <br/>**Thanks** to Austen Allred, Trevor Blackwell, Patrick Collison, Jessica<br/>Livingston, Amjad Masad, Ryan Petersen, and Harj Taggar for reading drafts of<br/>this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>July 2004  <br/>  <br/> _(This essay is derived from a talk at Oscon 2004.)_  <br/>  <br/>A few months ago I finished a new book, and in reviews I keep noticing words<br/>like "provocative'' and "controversial.'' To say nothing of "idiotic.''  <br/>  <br/>I didn't mean to make the book controversial. I was trying to make it<br/>efficient. I didn't want to waste people's time telling them things they<br/>already knew. It's more efficient just to give them the diffs. But I suppose<br/>that's bound to yield an alarming book.  <br/>  <br/> **Edisons**  <br/>  <br/>There's no controversy about which idea is most controversial: the suggestion<br/>that variation in wealth might not be as big a problem as we think.  <br/>  <br/>I didn't say in the book that variation in wealth was in itself a good thing.<br/>I said in some situations it might be a sign of good things. A throbbing<br/>headache is not a good thing, but it can be a sign of a good thing-- for<br/>example, that you're recovering consciousness after being hit on the head.  <br/>  <br/>Variation in wealth can be a sign of variation in productivity. (In a society<br/>of one, they're identical.) And _that_ is almost certainly a good thing: if<br/>your society has no variation in productivity, it's probably not because<br/>everyone is Thomas Edison. It's probably because you have no Thomas Edisons.  <br/>  <br/>In a low-tech society you don't see much variation in productivity. If you<br/>have a tribe of nomads collecting sticks for a fire, how much more productive<br/>is the best stick gatherer going to be than the worst? A factor of two?<br/>Whereas when you hand people a complex tool like a computer, the variation in<br/>what they can do with it is enormous.  <br/>  <br/>That's not a new idea. Fred Brooks wrote about it in 1974, and the study he<br/>quoted was published in 1968. But I think he underestimated the variation<br/>between programmers. He wrote about productivity in lines of code: the best<br/>programmers can solve a given problem in a tenth the time. But what if the<br/>problem isn't given? In programming, as in many fields, the hard part isn't<br/>solving problems, but deciding what problems to solve. Imagination is hard to<br/>measure, but in practice it dominates the kind of productivity that's measured<br/>in lines of code.  <br/>  <br/>Productivity varies in any field, but there are few in which it varies so<br/>much. The variation between programmers is so great that it becomes a<br/>difference in kind. I don't think this is something intrinsic to programming,<br/>though. In every field, technology magnifies differences in productivity. I<br/>think what's happening in programming is just that we have a lot of<br/>technological leverage. But in every field the lever is getting longer, so the<br/>variation we see is something that more and more fields will see as time goes<br/>on. And the success of companies, and countries, will depend increasingly on<br/>how they deal with it.  <br/>  <br/>If variation in productivity increases with technology, then the contribution<br/>of the most productive individuals will not only be disproportionately large,<br/>but will actually grow with time. When you reach the point where 90% of a<br/>group's output is created by 1% of its members, you lose big if something<br/>(whether Viking raids, or central planning) drags their productivity down to<br/>the average.  <br/>  <br/>If we want to get the most out of them, we need to understand these especially<br/>productive people. What motivates them? What do they need to do their jobs?<br/>How do you recognize them? How do you get them to come and work for you? And<br/>then of course there's the question, how do you become one?  <br/>  <br/> **More than Money**  <br/>  <br/>I know a handful of super-hackers, so I sat down and thought about what they<br/>have in common. Their defining quality is probably that they really love to<br/>program. Ordinary programmers write code to pay the bills. Great hackers think<br/>of it as something they do for fun, and which they're delighted to find people<br/>will pay them for.  <br/>  <br/>Great programmers are sometimes said to be indifferent to money. This isn't<br/>quite true. It is true that all they really care about is doing interesting<br/>work. But if you make enough money, you get to work on whatever you want, and<br/>for that reason hackers _are_ attracted by the idea of making really large<br/>amounts of money. But as long as they still have to show up for work every<br/>day, they care more about what they do there than how much they get paid for<br/>it.  <br/>  <br/>Economically, this is a fact of the greatest importance, because it means you<br/>don't have to pay great hackers anything like what they're worth. A great<br/>programmer might be ten or a hundred times as productive as an ordinary one,<br/>but he'll consider himself lucky to get paid three times as much. As I'll<br/>explain later, this is partly because great hackers don't know how good they<br/>are. But it's also because money is not the main thing they want.  <br/>  <br/>What do hackers want? Like all craftsmen, hackers like good tools. In fact,<br/>that's an understatement. Good hackers find it unbearable to use bad tools.<br/>They'll simply refuse to work on projects with the wrong infrastructure.  <br/>  <br/>At a startup I once worked for, one of the things pinned up on our bulletin<br/>board was an ad from IBM. It was a picture of an AS400, and the headline read,<br/>I think, "hackers despise it.'' [1]  <br/>  <br/>When you decide what infrastructure to use for a project, you're not just<br/>making a technical decision. You're also making a social decision, and this<br/>may be the more important of the two. For example, if your company wants to<br/>write some software, it might seem a prudent choice to write it in Java. But<br/>when you choose a language, you're also choosing a community. The programmers<br/>you'll be able to hire to work on a Java project won't be as smart as the ones<br/>you could get to work on a project written in Python. And the quality of your<br/>hackers probably matters more than the language you choose. Though, frankly,<br/>the fact that good hackers prefer Python to Java should tell you something<br/>about the relative merits of those languages.  <br/>  <br/>Business types prefer the most popular languages because they view languages<br/>as standards. They don't want to bet the company on Betamax. The thing about<br/>languages, though, is that they're not just standards. If you have to move<br/>bits over a network, by all means use TCP/IP. But a programming language isn't<br/>just a format. A programming language is a medium of expression.  <br/>  <br/>I've read that Java has just overtaken Cobol as the most popular language. As<br/>a standard, you couldn't wish for more. But as a medium of expression, you<br/>could do a lot better. Of all the great programmers I can think of, I know of<br/>only one who would voluntarily program in Java. And of all the great<br/>programmers I can think of who don't work for Sun, on Java, I know of zero.  <br/>  <br/>Great hackers also generally insist on using open source software. Not just<br/>because it's better, but because it gives them more control. Good hackers<br/>insist on control. This is part of what makes them good hackers: when<br/>something's broken, they need to fix it. You want them to feel this way about<br/>the software they're writing for you. You shouldn't be surprised when they<br/>feel the same way about the operating system.  <br/>  <br/>A couple years ago a venture capitalist friend told me about a new startup he<br/>was involved with. It sounded promising. But the next time I talked to him, he<br/>said they'd decided to build their software on Windows NT, and had just hired<br/>a very experienced NT developer to be their chief technical officer. When I<br/>heard this, I thought, these guys are doomed. One, the CTO couldn't be a first<br/>rate hacker, because to become an eminent NT developer he would have had to<br/>use NT voluntarily, multiple times, and I couldn't imagine a great hacker<br/>doing that; and two, even if he was good, he'd have a hard time hiring anyone<br/>good to work for him if the project had to be built on NT. [2]  <br/>  <br/> **The Final Frontier**  <br/>  <br/>After software, the most important tool to a hacker is probably his office.<br/>Big companies think the function of office space is to express rank. But<br/>hackers use their offices for more than that: they use their office as a place<br/>to think in. And if you're a technology company, their thoughts are your<br/>product. So making hackers work in a noisy, distracting environment is like<br/>having a paint factory where the air is full of soot.  <br/>  <br/>The cartoon strip Dilbert has a lot to say about cubicles, and with good<br/>reason. All the hackers I know despise them. The mere prospect of being<br/>interrupted is enough to prevent hackers from working on hard problems. If you<br/>want to get real work done in an office with cubicles, you have two options:<br/>work at home, or come in early or late or on a weekend, when no one else is<br/>there. Don't companies realize this is a sign that something is broken? An<br/>office environment is supposed to be something that _helps_ you work, not<br/>something you work despite.  <br/>  <br/>Companies like Cisco are proud that everyone there has a cubicle, even the<br/>CEO. But they're not so advanced as they think; obviously they still view<br/>office space as a badge of rank. Note too that Cisco is famous for doing very<br/>little product development in house. They get new technology by buying the<br/>startups that created it-- where presumably the hackers did have somewhere<br/>quiet to work.  <br/>  <br/>One big company that understands what hackers need is Microsoft. I once saw a<br/>recruiting ad for Microsoft with a big picture of a door. Work for us, the<br/>premise was, and we'll give you a place to work where you can actually get<br/>work done. And you know, Microsoft is remarkable among big companies in that<br/>they are able to develop software in house. Not well, perhaps, but well<br/>enough.  <br/>  <br/>If companies want hackers to be productive, they should look at what they do<br/>at home. At home, hackers can arrange things themselves so they can get the<br/>most done. And when they work at home, hackers don't work in noisy, open<br/>spaces; they work in rooms with doors. They work in cosy, neighborhoody places<br/>with people around and somewhere to walk when they need to mull something<br/>over, instead of in glass boxes set in acres of parking lots. They have a sofa<br/>they can take a nap on when they feel tired, instead of sitting in a coma at<br/>their desk, pretending to work. There's no crew of people with vacuum cleaners<br/>that roars through every evening during the prime hacking hours. There are no<br/>meetings or, God forbid, corporate retreats or team-building exercises. And<br/>when you look at what they're doing on that computer, you'll find it<br/>reinforces what I said earlier about tools. They may have to use Java and<br/>Windows at work, but at home, where they can choose for themselves, you're<br/>more likely to find them using Perl and Linux.  <br/>  <br/>Indeed, these statistics about Cobol or Java being the most popular language<br/>can be misleading. What we ought to look at, if we want to know what tools are<br/>best, is what hackers choose when they can choose freely-- that is, in<br/>projects of their own. When you ask that question, you find that open source<br/>operating systems already have a dominant market share, and the number one<br/>language is probably Perl.  <br/>  <br/> **Interesting**  <br/>  <br/>Along with good tools, hackers want interesting projects. What makes a project<br/>interesting? Well, obviously overtly sexy applications like stealth planes or<br/>special effects software would be interesting to work on. But any application<br/>can be interesting if it poses novel technical challenges. So it's hard to<br/>predict which problems hackers will like, because some become interesting only<br/>when the people working on them discover a new kind of solution. Before ITA<br/>(who wrote the software inside Orbitz), the people working on airline fare<br/>searches probably thought it was one of the most boring applications<br/>imaginable. But ITA made it interesting by redefining the problem in a more<br/>ambitious way.  <br/>  <br/>I think the same thing happened at Google. When Google was founded, the<br/>conventional wisdom among the so-called portals was that search was boring and<br/>unimportant. But the guys at Google didn't think search was boring, and that's<br/>why they do it so well.  <br/>  <br/>This is an area where managers can make a difference. Like a parent saying to<br/>a child, I bet you can't clean up your whole room in ten minutes, a good<br/>manager can sometimes redefine a problem as a more interesting one. Steve Jobs<br/>seems to be particularly good at this, in part simply by having high<br/>standards. There were a lot of small, inexpensive computers before the Mac. He<br/>redefined the problem as: make one that's beautiful. And that probably drove<br/>the developers harder than any carrot or stick could.  <br/>  <br/>They certainly delivered. When the Mac first appeared, you didn't even have to<br/>turn it on to know it would be good; you could tell from the case. A few weeks<br/>ago I was walking along the street in Cambridge, and in someone's trash I saw<br/>what appeared to be a Mac carrying case. I looked inside, and there was a Mac<br/>SE. I carried it home and plugged it in, and it booted. The happy Macintosh<br/>face, and then the finder. My God, it was so simple. It was just like ...<br/>Google.  <br/>  <br/>Hackers like to work for people with high standards. But it's not enough just<br/>to be exacting. You have to insist on the right things. Which usually means<br/>that you have to be a hacker yourself. I've seen occasional articles about how<br/>to manage programmers. Really there should be two articles: one about what to<br/>do if you are yourself a programmer, and one about what to do if you're not.<br/>And the second could probably be condensed into two words: give up.  <br/>  <br/>The problem is not so much the day to day management. Really good hackers are<br/>practically self-managing. The problem is, if you're not a hacker, you can't<br/>tell who the good hackers are. A similar problem explains why American cars<br/>are so ugly. I call it the _design paradox._ You might think that you could<br/>make your products beautiful just by hiring a great designer to design them.<br/>But if you yourself don't have good taste, how are you going to recognize a<br/>good designer? By definition you can't tell from his portfolio. And you can't<br/>go by the awards he's won or the jobs he's had, because in design, as in most<br/>fields, those tend to be driven by fashion and schmoozing, with actual ability<br/>a distant third. There's no way around it: you can't manage a process intended<br/>to produce beautiful things without knowing what beautiful is. American cars<br/>are ugly because American car companies are run by people with bad taste.  <br/>  <br/>Many people in this country think of taste as something elusive, or even<br/>frivolous. It is neither. To drive design, a manager must be the most<br/>demanding user of a company's products. And if you have really good taste, you<br/>can, as Steve Jobs does, make satisfying you the kind of problem that good<br/>people like to work on.  <br/>  <br/> **Nasty Little Problems**  <br/>  <br/>It's pretty easy to say what kinds of problems are not interesting: those<br/>where instead of solving a few big, clear, problems, you have to solve a lot<br/>of nasty little ones. One of the worst kinds of projects is writing an<br/>interface to a piece of software that's full of bugs. Another is when you have<br/>to customize something for an individual client's complex and ill-defined<br/>needs. To hackers these kinds of projects are the death of a thousand cuts.  <br/>  <br/>The distinguishing feature of nasty little problems is that you don't learn<br/>anything from them. Writing a compiler is interesting because it teaches you<br/>what a compiler is. But writing an interface to a buggy piece of software<br/>doesn't teach you anything, because the bugs are random. [3] So it's not just<br/>fastidiousness that makes good hackers avoid nasty little problems. It's more<br/>a question of self-preservation. Working on nasty little problems makes you<br/>stupid. Good hackers avoid it for the same reason models avoid cheeseburgers.  <br/>  <br/>Of course some problems inherently have this character. And because of supply<br/>and demand, they pay especially well. So a company that found a way to get<br/>great hackers to work on tedious problems would be very successful. How would<br/>you do it?  <br/>  <br/>One place this happens is in startups. At our startup we had Robert Morris<br/>working as a system administrator. That's like having the Rolling Stones play<br/>at a bar mitzvah. You can't hire that kind of talent. But people will do any<br/>amount of drudgery for companies of which they're the founders. [4]  <br/>  <br/>Bigger companies solve the problem by partitioning the company. They get smart<br/>people to work for them by establishing a separate R&D department where<br/>employees don't have to work directly on customers' nasty little problems. [5]<br/>In this model, the research department functions like a mine. They produce new<br/>ideas; maybe the rest of the company will be able to use them.  <br/>  <br/>You may not have to go to this extreme. Bottom-up programming suggests another<br/>way to partition the company: have the smart people work as toolmakers. If<br/>your company makes software to do x, have one group that builds tools for<br/>writing software of that type, and another that uses these tools to write the<br/>applications. This way you might be able to get smart people to write 99% of<br/>your code, but still keep them almost as insulated from users as they would be<br/>in a traditional research department. The toolmakers would have users, but<br/>they'd only be the company's own developers. [6]  <br/>  <br/>If Microsoft used this approach, their software wouldn't be so full of<br/>security holes, because the less smart people writing the actual applications<br/>wouldn't be doing low-level stuff like allocating memory. Instead of writing<br/>Word directly in C, they'd be plugging together big Lego blocks of Word-<br/>language. (Duplo, I believe, is the technical term.)  <br/>  <br/> **Clumping**  <br/>  <br/>Along with interesting problems, what good hackers like is other good hackers.<br/>Great hackers tend to clump together-- sometimes spectacularly so, as at Xerox<br/>Parc. So you won't attract good hackers in linear proportion to how good an<br/>environment you create for them. The tendency to clump means it's more like<br/>the square of the environment. So it's winner take all. At any given time,<br/>there are only about ten or twenty places where hackers most want to work, and<br/>if you aren't one of them, you won't just have fewer great hackers, you'll<br/>have zero.  <br/>  <br/>Having great hackers is not, by itself, enough to make a company successful.<br/>It works well for Google and ITA, which are two of the hot spots right now,<br/>but it didn't help Thinking Machines or Xerox. Sun had a good run for a while,<br/>but their business model is a down elevator. In that situation, even the best<br/>hackers can't save you.  <br/>  <br/>I think, though, that all other things being equal, a company that can attract<br/>great hackers will have a huge advantage. There are people who would disagree<br/>with this. When we were making the rounds of venture capital firms in the<br/>1990s, several told us that software companies didn't win by writing great<br/>software, but through brand, and dominating channels, and doing the right<br/>deals.  <br/>  <br/>They really seemed to believe this, and I think I know why. I think what a lot<br/>of VCs are looking for, at least unconsciously, is the next Microsoft. And of<br/>course if Microsoft is your model, you shouldn't be looking for companies that<br/>hope to win by writing great software. But VCs are mistaken to look for the<br/>next Microsoft, because no startup can be the next Microsoft unless some other<br/>company is prepared to bend over at just the right moment and be the next IBM.  <br/>  <br/>It's a mistake to use Microsoft as a model, because their whole culture<br/>derives from that one lucky break. Microsoft is a bad data point. If you throw<br/>them out, you find that good products do tend to win in the market. What VCs<br/>should be looking for is the next Apple, or the next Google.  <br/>  <br/>I think Bill Gates knows this. What worries him about Google is not the power<br/>of their brand, but the fact that they have better hackers. [7]  <br/>  <br/>**Recognition**  <br/>  <br/>So who are the great hackers? How do you know when you meet one? That turns<br/>out to be very hard. Even hackers can't tell. I'm pretty sure now that my<br/>friend Trevor Blackwell is a great hacker. You may have read on Slashdot how<br/>he made his own Segway. The remarkable thing about this project was that he<br/>wrote all the software in one day (in Python, incidentally).  <br/>  <br/>For Trevor, that's par for the course. But when I first met him, I thought he<br/>was a complete idiot. He was standing in Robert Morris's office babbling at<br/>him about something or other, and I remember standing behind him making<br/>frantic gestures at Robert to shoo this nut out of his office so we could go<br/>to lunch. Robert says he misjudged Trevor at first too. Apparently when Robert<br/>first met him, Trevor had just begun a new scheme that involved writing down<br/>everything about every aspect of his life on a stack of index cards, which he<br/>carried with him everywhere. He'd also just arrived from Canada, and had a<br/>strong Canadian accent and a mullet.  <br/>  <br/>The problem is compounded by the fact that hackers, despite their reputation<br/>for social obliviousness, sometimes put a good deal of effort into seeming<br/>smart. When I was in grad school I used to hang around the MIT AI Lab<br/>occasionally. It was kind of intimidating at first. Everyone there spoke so<br/>fast. But after a while I learned the trick of speaking fast. You don't have<br/>to think any faster; just use twice as many words to say everything.  <br/>  <br/>With this amount of noise in the signal, it's hard to tell good hackers when<br/>you meet them. I can't tell, even now. You also can't tell from their resumes.<br/>It seems like the only way to judge a hacker is to work with him on something.  <br/>  <br/>And this is the reason that high-tech areas only happen around universities.<br/>The active ingredient here is not so much the professors as the students.<br/>Startups grow up around universities because universities bring together<br/>promising young people and make them work on the same projects. The smart ones<br/>learn who the other smart ones are, and together they cook up new projects of<br/>their own.  <br/>  <br/>Because you can't tell a great hacker except by working with him, hackers<br/>themselves can't tell how good they are. This is true to a degree in most<br/>fields. I've found that people who are great at something are not so much<br/>convinced of their own greatness as mystified at why everyone else seems so<br/>incompetent.  <br/>  <br/>But it's particularly hard for hackers to know how good they are, because it's<br/>hard to compare their work. This is easier in most other fields. In the<br/>hundred meters, you know in 10 seconds who's fastest. Even in math there seems<br/>to be a general consensus about which problems are hard to solve, and what<br/>constitutes a good solution. But hacking is like writing. Who can say which of<br/>two novels is better? Certainly not the authors.  <br/>  <br/>With hackers, at least, other hackers can tell. That's because, unlike<br/>novelists, hackers collaborate on projects. When you get to hit a few<br/>difficult problems over the net at someone, you learn pretty quickly how hard<br/>they hit them back. But hackers can't watch themselves at work. So if you ask<br/>a great hacker how good he is, he's almost certain to reply, I don't know.<br/>He's not just being modest. He really doesn't know.  <br/>  <br/>And none of us know, except about people we've actually worked with. Which<br/>puts us in a weird situation: we don't know who our heroes should be. The<br/>hackers who become famous tend to become famous by random accidents of PR.<br/>Occasionally I need to give an example of a great hacker, and I never know who<br/>to use. The first names that come to mind always tend to be people I know<br/>personally, but it seems lame to use them. So, I think, maybe I should say<br/>Richard Stallman, or Linus Torvalds, or Alan Kay, or someone famous like that.<br/>But I have no idea if these guys are great hackers. I've never worked with<br/>them on anything.  <br/>  <br/>If there is a Michael Jordan of hacking, no one knows, including him.  <br/>  <br/> **Cultivation**  <br/>  <br/>Finally, the question the hackers have all been wondering about: how do you<br/>become a great hacker? I don't know if it's possible to make yourself into<br/>one. But it's certainly possible to do things that make you stupid, and if you<br/>can make yourself stupid, you can probably make yourself smart too.  <br/>  <br/>The key to being a good hacker may be to work on what you like. When I think<br/>about the great hackers I know, one thing they have in common is the extreme<br/>difficulty of making them work on anything they don't want to. I don't know if<br/>this is cause or effect; it may be both.  <br/>  <br/>To do something well you have to love it. So to the extent you can preserve<br/>hacking as something you love, you're likely to do it well. Try to keep the<br/>sense of wonder you had about programming at age 14. If you're worried that<br/>your current job is rotting your brain, it probably is.  <br/>  <br/>The best hackers tend to be smart, of course, but that's true in a lot of<br/>fields. Is there some quality that's unique to hackers? I asked some friends,<br/>and the number one thing they mentioned was curiosity. I'd always supposed<br/>that all smart people were curious-- that curiosity was simply the first<br/>derivative of knowledge. But apparently hackers are particularly curious,<br/>especially about how things work. That makes sense, because programs are in<br/>effect giant descriptions of how things work.  <br/>  <br/>Several friends mentioned hackers' ability to concentrate-- their ability, as<br/>one put it, to "tune out everything outside their own heads.'' I've certainly<br/>noticed this. And I've heard several hackers say that after drinking even half<br/>a beer they can't program at all. So maybe hacking does require some special<br/>ability to focus. Perhaps great hackers can load a large amount of context<br/>into their head, so that when they look at a line of code, they see not just<br/>that line but the whole program around it. John McPhee wrote that Bill<br/>Bradley's success as a basketball player was due partly to his extraordinary<br/>peripheral vision. "Perfect'' eyesight means about 47 degrees of vertical<br/>peripheral vision. Bill Bradley had 70; he could see the basket when he was<br/>looking at the floor. Maybe great hackers have some similar inborn ability. (I<br/>cheat by using a very dense language, which shrinks the court.)  <br/>  <br/>This could explain the disconnect over cubicles. Maybe the people in charge of<br/>facilities, not having any concentration to shatter, have no idea that working<br/>in a cubicle feels to a hacker like having one's brain in a blender. (Whereas<br/>Bill, if the rumors of autism are true, knows all too well.)  <br/>  <br/>One difference I've noticed between great hackers and smart people in general<br/>is that hackers are more politically incorrect. To the extent there is a<br/>secret handshake among good hackers, it's when they know one another well<br/>enough to express opinions that would get them stoned to death by the general<br/>public. And I can see why political incorrectness would be a useful quality in<br/>programming. Programs are very complex and, at least in the hands of good<br/>programmers, very fluid. In such situations it's helpful to have a habit of<br/>questioning assumptions.  <br/>  <br/>Can you cultivate these qualities? I don't know. But you can at least not<br/>repress them. So here is my best shot at a recipe. If it is possible to make<br/>yourself into a great hacker, the way to do it may be to make the following<br/>deal with yourself: you never have to work on boring projects (unless your<br/>family will starve otherwise), and in return, you'll never allow yourself to<br/>do a half-assed job. All the great hackers I know seem to have made that deal,<br/>though perhaps none of them had any choice in the matter.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] In fairness, I have to say that IBM makes decent hardware. I wrote this on<br/>an IBM laptop.  <br/>  <br/>[2] They did turn out to be doomed. They shut down a few months later.  <br/>  <br/>[3] I think this is what people mean when they talk about the "meaning of<br/>life." On the face of it, this seems an odd idea. Life isn't an expression;<br/>how could it have meaning? But it can have a quality that feels a lot like<br/>meaning. In a project like a compiler, you have to solve a lot of problems,<br/>but the problems all fall into a pattern, as in a signal. Whereas when the<br/>problems you have to solve are random, they seem like noise.  <br/>  <br/>[4] Einstein at one point worked designing refrigerators. (He had equity.)  <br/>  <br/>[5] It's hard to say exactly what constitutes research in the computer world,<br/>but as a first approximation, it's software that doesn't have users.  <br/>  <br/>I don't think it's publication that makes the best hackers want to work in<br/>research departments. I think it's mainly not having to have a three hour<br/>meeting with a product manager about problems integrating the Korean version<br/>of Word 13.27 with the talking paperclip.  <br/>  <br/>[6] Something similar has been happening for a long time in the construction<br/>industry. When you had a house built a couple hundred years ago, the local<br/>builders built everything in it. But increasingly what builders do is assemble<br/>components designed and manufactured by someone else. This has, like the<br/>arrival of desktop publishing, given people the freedom to experiment in<br/>disastrous ways, but it is certainly more efficient.  <br/>  <br/>[7] Google is much more dangerous to Microsoft than Netscape was. Probably<br/>more dangerous than any other company has ever been. Not least because they're<br/>determined to fight. On their job listing page, they say that one of their<br/>"core values'' is "Don't be evil.'' From a company selling soybean oil or<br/>mining equipment, such a statement would merely be eccentric. But I think all<br/>of us in the computer world recognize who that is a declaration of war on.  <br/>  <br/> **Thanks** to Jessica Livingston, Robert Morris, and Sarah Harlin for reading<br/>earlier versions of this talk.  <br/>  <br/><br/>Audio of talk  <br/>  <br/><br/>The Python Paradox  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Italian Translation  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/><br/><br/>* * *<br/><br/>March 2012  <br/>  <br/>Y Combinator's 7th birthday was March 11. As usual we were so busy we didn't<br/>notice till a few days after. I don't think we've ever managed to remember our<br/>birthday on our birthday.<br/><br/>On March 11 2005, Jessica and I were walking home from dinner in Harvard<br/>Square. Jessica was working at an investment bank at the time, but she didn't<br/>like it much, so she had interviewed for a job as director of marketing at a<br/>Boston VC fund. The VC fund was doing what now seems a comically familiar<br/>thing for a VC fund to do: taking a long time to make up their mind. Meanwhile<br/>I had been telling Jessica all the things they should change about the VC<br/>business  essentially the ideas now underlying Y Combinator: investors should<br/>be making more, smaller investments, they should be funding hackers instead of<br/>suits, they should be willing to fund younger founders, etc.<br/><br/>At the time I had been thinking about doing some angel investing. I had just<br/>given a talk to the undergraduate computer club at Harvard about how to start<br/>a startup, and it hit me afterward that although I had always meant to do<br/>angel investing, 7 years had now passed since I got enough money to do it, and<br/>I still hadn't started. I had also been thinking about ways to work with<br/>Robert Morris and Trevor Blackwell again. A few hours before I had sent them<br/>an email trying to figure out what we could do together.<br/><br/>Between Harvard Square and my house the idea gelled. We'd start our own<br/>investment firm and Jessica could work for that instead. As we turned onto<br/>Walker Street we decided to do it. I agreed to put $100k into the new fund and<br/>Jessica agreed to quit her job to work for it. Over the next couple days I<br/>recruited Robert and Trevor, who put in another $50k each. So YC started with<br/>$200k.<br/><br/>Jessica was so happy to be able to quit her job and start her own company that<br/>I took her picture when we got home.<br/><br/>The company wasn't called Y Combinator yet. At first we called it Cambridge<br/>Seed. But that name never saw the light of day, because by the time we<br/>announced it a few days later, we'd changed the name to Y Combinator. We<br/>realized early on that what we were doing could be national in scope and we<br/>didn't want a name that tied us to one place.<br/><br/>Initially we only had part of the idea. We were going to do seed funding with<br/>standardized terms. Before YC, seed funding was very haphazard. You'd get that<br/>first $10k from your friend's rich uncle. The deal terms were often a<br/>disaster; often neither the investor nor the founders nor the lawyer knew what<br/>the documents should look like. Facebook's early history as a Florida LLC<br/>shows how random things could be in those days. We were going to be something<br/>there had not been before: a standard source of seed funding.<br/><br/>We modelled YC on the seed funding we ourselves had taken when we started<br/>Viaweb. We started Viaweb with $10k we got from our friend Julian Weber, the<br/>husband of Idelle Weber, whose painting class I took as a grad student at<br/>Harvard. Julian knew about business, but you would not describe him as a suit.<br/>Among other things he'd been president of the _National Lampoon_. He was also<br/>a lawyer, and got all our paperwork set up properly. In return for $10k,<br/>getting us set up as a company, teaching us what business was about, and<br/>remaining calm in times of crisis, Julian got 10% of Viaweb. I remember<br/>thinking once what a good deal Julian got. And then a second later I realized<br/>that without Julian, Viaweb would never have made it. So even though it was a<br/>good deal for him, it was a good deal for us too. That's why I knew there was<br/>room for something like Y Combinator.<br/><br/>Initially we didn't have what turned out to be the most important idea:<br/>funding startups synchronously, instead of asynchronously as it had always<br/>been done before. Or rather we had the idea, but we didn't realize its<br/>significance. We decided very early that the first thing we'd do would be to<br/>fund a bunch of startups over the coming summer. But we didn't realize<br/>initially that this would be the way we'd do all our investing. The reason we<br/>began by funding a bunch of startups at once was not that we thought it would<br/>be a better way to fund startups, but simply because we wanted to learn how to<br/>be angel investors, and a summer program for undergrads seemed the fastest way<br/>to do it. No one takes summer jobs that seriously. The opportunity cost for a<br/>bunch of undergrads to spend a summer working on startups was low enough that<br/>we wouldn't feel guilty encouraging them to do it.<br/><br/>We knew students would already be making plans for the summer, so we did what<br/>we're always telling startups to do: we launched fast. Here are the initial<br/>announcement and description of what was at the time called the Summer<br/>Founders Program.<br/><br/>We got lucky in that the length and structure of a summer program turns out to<br/>be perfect for what we do. The structure of the YC cycle is still almost<br/>identical to what it was that first summer.<br/><br/>We also got lucky in who the first batch of founders were. We never expected<br/>to make any money from that first batch. We thought of the money we were<br/>investing as a combination of an educational expense and a charitable<br/>donation. But the founders in the first batch turned out to be surprisingly<br/>good. And great people too. We're still friends with a lot of them today.<br/><br/>It's hard for people to realize now how inconsequential YC seemed at the time.<br/>I can't blame people who didn't take us seriously, because we ourselves didn't<br/>take that first summer program seriously in the very beginning. But as the<br/>summer progressed we were increasingly impressed by how well the startups were<br/>doing. Other people started to be impressed too. Jessica and I invented a<br/>term, "the Y Combinator effect," to describe the moment when the realization<br/>hit someone that YC was not totally lame. When people came to YC to speak at<br/>the dinners that first summer, they came in the spirit of someone coming to<br/>address a Boy Scout troop. By the time they left the building they were all<br/>saying some variant of "Wow, these companies might actually succeed."<br/><br/>Now YC is well enough known that people are no longer surprised when the<br/>companies we fund are legit, but it took a while for reputation to catch up<br/>with reality. That's one of the reasons we especially like funding ideas that<br/>might be dismissed as "toys"  because YC itself was dismissed as one<br/>initially.<br/><br/>When we saw how well it worked to fund companies synchronously, we decided<br/>we'd keep doing that. We'd fund two batches of startups a year.<br/><br/>We funded the second batch in Silicon Valley. That was a last minute decision.<br/>In retrospect I think what pushed me over the edge was going to Foo Camp that<br/>fall. The density of startup people in the Bay Area was so much greater than<br/>in Boston, and the weather was so nice. I remembered that from living there in<br/>the 90s. Plus I didn't want someone else to copy us and describe it as the Y<br/>Combinator of Silicon Valley. I wanted YC to be the Y Combinator of Silicon<br/>Valley. So doing the winter batch in California seemed like one of those rare<br/>cases where the self-indulgent choice and the ambitious one were the same.<br/><br/>If we'd had enough time to do what we wanted, Y Combinator would have been in<br/>Berkeley. That was our favorite part of the Bay Area. But we didn't have time<br/>to get a building in Berkeley. We didn't have time to get our own building<br/>anywhere. The only way to get enough space in time was to convince Trevor to<br/>let us take over part of his (as it then seemed) giant building in Mountain<br/>View. Yet again we lucked out, because Mountain View turned out to be the<br/>ideal place to put something like YC. But even then we barely made it. The<br/>first dinner in California, we had to warn all the founders not to touch the<br/>walls, because the paint was still wet.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>December 2019  <br/>  <br/>Before I had kids, I was afraid of having kids. Up to that point I felt about<br/>kids the way the young Augustine felt about living virtuously. I'd have been<br/>sad to think I'd never have children. But did I want them now? No.  <br/>  <br/>If I had kids, I'd become a parent, and parents, as I'd known since I was a<br/>kid, were uncool. They were dull and responsible and had no fun. And while<br/>it's not surprising that kids would believe that, to be honest I hadn't seen<br/>much as an adult to change my mind. Whenever I'd noticed parents with kids,<br/>the kids seemed to be terrors, and the parents pathetic harried creatures,<br/>even when they prevailed.  <br/>  <br/>When people had babies, I congratulated them enthusiastically, because that<br/>seemed to be what one did. But I didn't feel it at all. "Better you than me,"<br/>I was thinking.  <br/>  <br/>Now when people have babies I congratulate them enthusiastically and I mean<br/>it. Especially the first one. I feel like they just got the best gift in the<br/>world.  <br/>  <br/>What changed, of course, is that I had kids. Something I dreaded turned out to<br/>be wonderful.  <br/>  <br/>Partly, and I won't deny it, this is because of serious chemical changes that<br/>happened almost instantly when our first child was born. It was like someone<br/>flipped a switch. I suddenly felt protective not just toward our child, but<br/>toward all children. As I was driving my wife and new son home from the<br/>hospital, I approached a crosswalk full of pedestrians, and I found myself<br/>thinking "I have to be really careful of all these people. Every one of them<br/>is someone's child!"  <br/>  <br/>So to some extent you can't trust me when I say having kids is great. To some<br/>extent I'm like a religious cultist telling you that you'll be happy if you<br/>join the cult too  but only because joining the cult will alter your mind in<br/>a way that will make you happy to be a cult member. But not entirely. There<br/>were some things about having kids that I clearly got wrong before I had them.  <br/>  <br/>For example, there was a huge amount of selection bias in my observations of<br/>parents and children. Some parents may have noticed that I wrote "Whenever I'd<br/>noticed parents with kids." Of course the times I noticed kids were when<br/>things were going wrong. I only noticed them when they made noise. And where<br/>was I when I noticed them? Ordinarily I never went to places with kids, so the<br/>only times I encountered them were in shared bottlenecks like airplanes. Which<br/>is not exactly a representative sample. Flying with a toddler is something<br/>very few parents enjoy.  <br/>  <br/>What I didn't notice, because they tend to be much quieter, were all the great<br/>moments parents had with kids. People don't talk about these much  the magic<br/>is hard to put into words, and all other parents know about them anyway  but<br/>one of the great things about having kids is that there are so many times when<br/>you feel there is nowhere else you'd rather be, and nothing else you'd rather<br/>be doing. You don't have to be doing anything special. You could just be going<br/>somewhere together, or putting them to bed, or pushing them on the swings at<br/>the park. But you wouldn't trade these moments for anything. One doesn't tend<br/>to associate kids with peace, but that's what you feel. You don't need to look<br/>any further than where you are right now.  <br/>  <br/>Before I had kids, I had moments of this kind of peace, but they were rarer.<br/>With kids it can happen several times a day.  <br/>  <br/>My other source of data about kids was my own childhood, and that was<br/>similarly misleading. I was pretty bad, and was always in trouble for<br/>something or other. So it seemed to me that parenthood was essentially law<br/>enforcement. I didn't realize there were good times too.  <br/>  <br/>I remember my mother telling me once when I was about 30 that she'd really<br/>enjoyed having me and my sister. My god, I thought, this woman is a saint. She<br/>not only endured all the pain we subjected her to, but actually enjoyed it?<br/>Now I realize she was simply telling the truth.  <br/>  <br/>She said that one reason she liked having us was that we'd been interesting to<br/>talk to. That took me by surprise when I had kids. You don't just love them.<br/>They become your friends too. They're really interesting. And while I admit<br/>small children are disastrously fond of repetition (anything worth doing once<br/>is worth doing fifty times) it's often genuinely fun to play with them. That<br/>surprised me too. Playing with a 2 year old was fun when I was 2 and<br/>definitely not fun when I was 6. Why would it become fun again later? But it<br/>does.  <br/>  <br/>There are of course times that are pure drudgery. Or worse still, terror.<br/>Having kids is one of those intense types of experience that are hard to<br/>imagine unless you've had them. But it is not, as I implicitly believed before<br/>having kids, simply your DNA heading for the lifeboats.  <br/>  <br/>Some of my worries about having kids were right, though. They definitely make<br/>you less productive. I know having kids makes some people get their act<br/>together, but if your act was already together, you're going to have less time<br/>to do it in. In particular, you're going to have to work to a schedule. Kids<br/>have schedules. I'm not sure if it's because that's how kids are, or because<br/>it's the only way to integrate their lives with adults', but once you have<br/>kids, you tend to have to work on their schedule.  <br/>  <br/>You will have chunks of time to work. But you can't let work spill<br/>promiscuously through your whole life, like I used to before I had kids.<br/>You're going to have to work at the same time every day, whether inspiration<br/>is flowing or not, and there are going to be times when you have to stop, even<br/>if it is.  <br/>  <br/>I've been able to adapt to working this way. Work, like love, finds a way. If<br/>there are only certain times it can happen, it happens at those times. So<br/>while I don't get as much done as before I had kids, I get enough done.  <br/>  <br/>I hate to say this, because being ambitious has always been a part of my<br/>identity, but having kids may make one less ambitious. It hurts to see that<br/>sentence written down. I squirm to avoid it. But if there weren't something<br/>real there, why would I squirm? The fact is, once you have kids, you're<br/>probably going to care more about them than you do about yourself. And<br/>attention is a zero-sum game. Only one idea at a time can be the _top idea in<br/>your mind_. Once you have kids, it will often be your kids, and that means it<br/>will less often be some project you're working on.  <br/>  <br/>I have some hacks for sailing close to this wind. For example, when I write<br/>essays, I think about what I'd want my kids to know. That drives me to get<br/>things right. And when I was writing _Bel_, I told my kids that once I<br/>finished it I'd take them to Africa. When you say that sort of thing to a<br/>little kid, they treat it as a promise. Which meant I had to finish or I'd be<br/>taking away their trip to Africa. Maybe if I'm really lucky such tricks could<br/>put me net ahead. But the wind is there, no question.  <br/>  <br/>On the other hand, what kind of wimpy ambition do you have if it won't survive<br/>having kids? Do you have so little to spare?  <br/>  <br/>And while having kids may be warping my present judgement, it hasn't<br/>overwritten my memory. I remember perfectly well what life was like before.<br/>Well enough to miss some things a lot, like the ability to take off for some<br/>other country at a moment's notice. That was so great. Why did I never do<br/>that?  <br/>  <br/>See what I did there? The fact is, most of the freedom I had before kids, I<br/>never used. I paid for it in loneliness, but I never used it.  <br/>  <br/>I had plenty of happy times before I had kids. But if I count up happy<br/>moments, not just potential happiness but actual happy moments, there are more<br/>after kids than before. Now I practically have it on tap, almost any bedtime.  <br/>  <br/>People's experiences as parents vary a lot, and I know I've been lucky. But I<br/>think the worries I had before having kids must be pretty common, and judging<br/>by other parents' faces when they see their kids, so must the happiness that<br/>kids bring.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Note**  <br/>  <br/>[1] Adults are sophisticated enough to see 2 year olds for the fascinatingly<br/>complex characters they are, whereas to most 6 year olds, 2 year olds are just<br/>defective 6 year olds.  <br/>  <br/>  <br/>  <br/> **Thanks** to Trevor Blackwell, Jessica Livingston, and Robert Morris for<br/>reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>April 2010  <br/>  <br/>The best way to come up with startup ideas is to ask yourself the question:<br/>what do you wish someone would make for you?  <br/>  <br/>There are two types of startup ideas: those that grow organically out of your<br/>own life, and those that you decide, from afar, are going to be necessary to<br/>some class of users other than you. Apple was the first type. Apple happened<br/>because Steve Wozniak wanted a computer. Unlike most people who wanted<br/>computers, he could design one, so he did. And since lots of other people<br/>wanted the same thing, Apple was able to sell enough of them to get the<br/>company rolling. They still rely on this principle today, incidentally. The<br/>iPhone is the phone Steve Jobs wants. [1]  <br/>  <br/>Our own startup, Viaweb, was of the second type. We made software for building<br/>online stores. We didn't need this software ourselves. We weren't direct<br/>marketers. We didn't even know when we started that our users were called<br/>"direct marketers." But we were comparatively old when we started the company<br/>(I was 30 and Robert Morris was 29), so we'd seen enough to know users would<br/>need this type of software. [2]  <br/>  <br/>There is no sharp line between the two types of ideas, but the most successful<br/>startups seem to be closer to the Apple type than the Viaweb type. When he was<br/>writing that first Basic interpreter for the Altair, Bill Gates was writing<br/>something he would use, as were Larry and Sergey when they wrote the first<br/>versions of Google.  <br/>  <br/>Organic ideas are generally preferable to the made up kind, but particularly<br/>so when the founders are young. It takes experience to predict what other<br/>people will want. The worst ideas we see at Y Combinator are from young<br/>founders making things they think other people will want.  <br/>  <br/>So if you want to start a startup and don't know yet what you're going to do,<br/>I'd encourage you to focus initially on organic ideas. What's missing or<br/>broken in your daily life? Sometimes if you just ask that question you'll get<br/>immediate answers. It must have seemed obviously broken to Bill Gates that you<br/>could only program the Altair in machine language.  <br/>  <br/>You may need to stand outside yourself a bit to see brokenness, because you<br/>tend to get used to it and take it for granted. You can be sure it's there,<br/>though. There are always great ideas sitting right under our noses. In 2004 it<br/>was ridiculous that Harvard undergrads were still using a Facebook printed on<br/>paper. Surely that sort of thing should have been online.  <br/>  <br/>There are ideas that obvious lying around now. The reason you're overlooking<br/>them is the same reason you'd have overlooked the idea of building Facebook in<br/>2004: organic startup ideas usually don't seem like startup ideas at first. We<br/>know now that Facebook was very successful, but put yourself back in 2004.<br/>Putting undergraduates' profiles online wouldn't have seemed like much of a<br/>startup idea. And in fact, it wasn't initially a startup idea. When Mark spoke<br/>at a YC dinner this winter he said he wasn't trying to start a company when he<br/>wrote the first version of Facebook. It was just a project. So was the Apple I<br/>when Woz first started working on it. He didn't think he was starting a<br/>company. If these guys had thought they were starting companies, they might<br/>have been tempted to do something more "serious," and that would have been a<br/>mistake.  <br/>  <br/>So if you want to come up with organic startup ideas, I'd encourage you to<br/>focus more on the idea part and less on the startup part. Just fix things that<br/>seem broken, regardless of whether it seems like the problem is important<br/>enough to build a company on. If you keep pursuing such threads it would be<br/>hard not to end up making something of value to a lot of people, and when you<br/>do, surprise, you've got a company. [3]  <br/>  <br/>Don't be discouraged if what you produce initially is something other people<br/>dismiss as a toy. In fact, that's a good sign. That's probably why everyone<br/>else has been overlooking the idea. The first microcomputers were dismissed as<br/>toys. And the first planes, and the first cars. At this point, when someone<br/>comes to us with something that users like but that we could envision forum<br/>trolls dismissing as a toy, it makes us especially likely to invest.  <br/>  <br/>While young founders are at a disadvantage when coming up with made-up ideas,<br/>they're the best source of organic ones, because they're at the forefront of<br/>technology. They use the latest stuff. They only just decided what to use, so<br/>why wouldn't they? And because they use the latest stuff, they're in a<br/>position to discover valuable types of fixable brokenness first.  <br/>  <br/>There's nothing more valuable than an unmet need that is just becoming<br/>fixable. If you find something broken that you can fix for a lot of people,<br/>you've found a gold mine. As with an actual gold mine, you still have to work<br/>hard to get the gold out of it. But at least you know where the seam is, and<br/>that's the hard part.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] This suggests a way to predict areas where Apple will be weak: things<br/>Steve Jobs doesn't use. E.g. I doubt he is much into gaming.  <br/>  <br/>[2] In retrospect, we should have _become_ direct marketers. If I were doing<br/>Viaweb again, I'd open our own online store. If we had, we'd have understood<br/>users a lot better. I'd encourage anyone starting a startup to become one of<br/>its users, however unnatural it seems.  <br/>  <br/>[3] Possible exception: It's hard to compete directly with open source<br/>software. You can build things for programmers, but there has to be some part<br/>you can charge for.  <br/>  <br/> **Thanks** to Sam Altman, Trevor Blackwell, and Jessica Livingston for<br/>reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>March 2009  <br/>  <br/>A couple days ago I finally got being a good startup founder down to two<br/>words: relentlessly resourceful.  <br/>  <br/>Till then the best I'd managed was to get the opposite quality down to one:<br/>hapless. Most dictionaries say hapless means unlucky. But the dictionaries are<br/>not doing a very good job. A team that outplays its opponents but loses<br/>because of a bad decision by the referee could be called unlucky, but not<br/>hapless. Hapless implies passivity. To be hapless is to be battered by<br/>circumstances—to let the world have its way with you, instead of having your<br/>way with the world.  [1]  <br/>  <br/>Unfortunately there's no antonym of hapless, which makes it difficult to tell<br/>founders what to aim for. "Don't be hapless" is not much of rallying cry.  <br/>  <br/>It's not hard to express the quality we're looking for in metaphors. The best<br/>is probably a running back. A good running back is not merely determined, but<br/>flexible as well. They want to get downfield, but they adapt their plans on<br/>the fly.  <br/>  <br/>Unfortunately this is just a metaphor, and not a useful one to most people<br/>outside the US. "Be like a running back" is no better than "Don't be hapless."  <br/>  <br/>But finally I've figured out how to express this quality directly. I was<br/>writing a talk for investors, and I had to explain what to look for in<br/>founders. What would someone who was the opposite of hapless be like? They'd<br/>be relentlessly resourceful. Not merely relentless. That's not enough to make<br/>things go your way except in a few mostly uninteresting domains. In any<br/>interesting domain, the difficulties will be novel. Which means you can't<br/>simply plow through them, because you don't know initially how hard they are;<br/>you don't know whether you're about to plow through a block of foam or<br/>granite. So you have to be resourceful. You have to keep trying new things.  <br/>  <br/>Be relentlessly resourceful.  <br/>  <br/>That sounds right, but is it simply a description of how to be successful in<br/>general? I don't think so. This isn't the recipe for success in writing or<br/>painting, for example. In that kind of work the recipe is more to be actively<br/>curious. Resourceful implies the obstacles are external, which they generally<br/>are in startups. But in writing and painting they're mostly internal; the<br/>obstacle is your own obtuseness. [2]  <br/>  <br/>There probably are other fields where "relentlessly resourceful" is the recipe<br/>for success. But though other fields may share it, I think this is the best<br/>short description we'll find of what makes a good startup founder. I doubt it<br/>could be made more precise.  <br/>  <br/>Now that we know what we're looking for, that leads to other questions. For<br/>example, can this quality be taught? After four years of trying to teach it to<br/>people, I'd say that yes, surprisingly often it can. Not to everyone, but to<br/>many people. [3] Some people are just constitutionally passive, but others<br/>have a latent ability to be relentlessly resourceful that only needs to be<br/>brought out.  <br/>  <br/>This is particularly true of young people who have till now always been under<br/>the thumb of some kind of authority. Being relentlessly resourceful is<br/>definitely not the recipe for success in big companies, or in most schools. I<br/>don't even want to think what the recipe is in big companies, but it is<br/>certainly longer and messier, involving some combination of resourcefulness,<br/>obedience, and building alliances.  <br/>  <br/>Identifying this quality also brings us closer to answering a question people<br/>often wonder about: how many startups there could be. There is not, as some<br/>people seem to think, any economic upper bound on this number. There's no<br/>reason to believe there is any limit on the amount of newly created wealth<br/>consumers can absorb, any more than there is a limit on the number of theorems<br/>that can be proven. So probably the limiting factor on the number of startups<br/>is the pool of potential founders. Some people would make good founders, and<br/>others wouldn't. And now that we can say what makes a good founder, we know<br/>how to put an upper bound on the size of the pool.  <br/>  <br/>This test is also useful to individuals. If you want to know whether you're<br/>the right sort of person to start a startup, ask yourself whether you're<br/>relentlessly resourceful. And if you want to know whether to recruit someone<br/>as a cofounder, ask if they are.  <br/>  <br/>You can even use it tactically. If I were running a startup, this would be the<br/>phrase I'd tape to the mirror. "Make something people want" is the<br/>destination, but "Be relentlessly resourceful" is how you get there.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] I think the reason the dictionaries are wrong is that the meaning of the<br/>word has shifted. No one writing a dictionary from scratch today would say<br/>that hapless meant unlucky. But a couple hundred years ago they might have.<br/>People were more at the mercy of circumstances in the past, and as a result a<br/>lot of the words we use for good and bad outcomes have origins in words about<br/>luck.  <br/>  <br/>When I was living in Italy, I was once trying to tell someone that I hadn't<br/>had much success in doing something, but I couldn't think of the Italian word<br/>for success. I spent some time trying to describe the word I meant. Finally<br/>she said "Ah! Fortuna!"  <br/>  <br/>[2] There are aspects of startups where the recipe is to be actively curious.<br/>There can be times when what you're doing is almost pure discovery.<br/>Unfortunately these times are a small proportion of the whole. On the other<br/>hand, they are in research too.  <br/>  <br/>[3] I'd almost say to most people, but I realize (a) I have no idea what most<br/>people are like, and (b) I'm pathologically optimistic about people's ability<br/>to change.  <br/>  <br/> **Thanks** to Trevor Blackwell and Jessica Livingston for reading drafts of<br/>this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>September 2004  <br/>  <br/> _(This essay is derived from an invited talk at ICFP 2004.)_  <br/>  <br/>I had a front row seat for the Internet Bubble, because I worked at Yahoo<br/>during 1998 and 1999. One day, when the stock was trading around $200, I sat<br/>down and calculated what I thought the price should be. The answer I got was<br/>$12. I went to the next cubicle and told my friend Trevor. "Twelve!" he said.<br/>He tried to sound indignant, but he didn't quite manage it. He knew as well as<br/>I did that our valuation was crazy.  <br/>  <br/>Yahoo was a special case. It was not just our price to earnings ratio that was<br/>bogus. Half our earnings were too. Not in the Enron way, of course. The<br/>finance guys seemed scrupulous about reporting earnings. What made our<br/>earnings bogus was that Yahoo was, in effect, the center of a Ponzi scheme.<br/>Investors looked at Yahoo's earnings and said to themselves, here is proof<br/>that Internet companies can make money. So they invested in new startups that<br/>promised to be the next Yahoo. And as soon as these startups got the money,<br/>what did they do with it? Buy millions of dollars worth of advertising on<br/>Yahoo to promote their brand. Result: a capital investment in a startup this<br/>quarter shows up as Yahoo earnings next quarter—stimulating another round of<br/>investments in startups.  <br/>  <br/>As in a Ponzi scheme, what seemed to be the returns of this system were simply<br/>the latest round of investments in it. What made it not a Ponzi scheme was<br/>that it was unintentional. At least, I think it was. The venture capital<br/>business is pretty incestuous, and there were presumably people in a position,<br/>if not to create this situation, to realize what was happening and to milk it.  <br/>  <br/>A year later the game was up. Starting in January 2000, Yahoo's stock price<br/>began to crash, ultimately losing 95% of its value.  <br/>  <br/>Notice, though, that even with all the fat trimmed off its market cap, Yahoo<br/>was still worth a lot. Even at the morning-after valuations of March and April<br/>2001, the people at Yahoo had managed to create a company worth about $8<br/>billion in just six years.  <br/>  <br/>The fact is, despite all the nonsense we heard during the Bubble about the<br/>"new economy," there was a core of truth. You need that to get a really big<br/>bubble: you need to have something solid at the center, so that even smart<br/>people are sucked in. (Isaac Newton and Jonathan Swift both lost money in the<br/>South Sea Bubble of 1720.)  <br/>  <br/>Now the pendulum has swung the other way. Now anything that became fashionable<br/>during the Bubble is ipso facto unfashionable. But that's a mistake—an even<br/>bigger mistake than believing what everyone was saying in 1999. Over the long<br/>term, what the Bubble got right will be more important than what it got wrong.  <br/>  <br/> **1\. Retail VC**  <br/>  <br/>After the excesses of the Bubble, it's now considered dubious to take<br/>companies public before they have earnings. But there is nothing intrinsically<br/>wrong with that idea. Taking a company public at an early stage is simply<br/>retail VC: instead of going to venture capital firms for the last round of<br/>funding, you go to the public markets.  <br/>  <br/>By the end of the Bubble, companies going public with no earnings were being<br/>derided as "concept stocks," as if it were inherently stupid to invest in<br/>them. But investing in concepts isn't stupid; it's what VCs do, and the best<br/>of them are far from stupid.  <br/>  <br/>The stock of a company that doesn't yet have earnings is worth _something._ It<br/>may take a while for the market to learn how to value such companies, just as<br/>it had to learn to value common stocks in the early 20th century. But markets<br/>are good at solving that kind of problem. I wouldn't be surprised if the<br/>market ultimately did a better job than VCs do now.  <br/>  <br/>Going public early will not be the right plan for every company. And it can of<br/>course be disruptive—by distracting the management, or by making the early<br/>employees suddenly rich. But just as the market will learn how to value<br/>startups, startups will learn how to minimize the damage of going public.  <br/>  <br/> **2\. The Internet**  <br/>  <br/>The Internet genuinely is a big deal. That was one reason even smart people<br/>were fooled by the Bubble. Obviously it was going to have a huge effect.<br/>Enough of an effect to triple the value of Nasdaq companies in two years? No,<br/>as it turned out. But it was hard to say for certain at the time. [1]  <br/>  <br/>The same thing happened during the Mississippi and South Sea Bubbles. What<br/>drove them was the invention of organized public finance (the South Sea<br/>Company, despite its name, was really a competitor of the Bank of England).<br/>And that did turn out to be a big deal, in the long run.  <br/>  <br/>Recognizing an important trend turns out to be easier than figuring out how to<br/>profit from it. The mistake investors always seem to make is to take the trend<br/>too literally. Since the Internet was the big new thing, investors supposed<br/>that the more Internettish the company, the better. Hence such parodies as<br/>Pets.Com.  <br/>  <br/>In fact most of the money to be made from big trends is made indirectly. It<br/>was not the railroads themselves that made the most money during the railroad<br/>boom, but the companies on either side, like Carnegie's steelworks, which made<br/>the rails, and Standard Oil, which used railroads to get oil to the East<br/>Coast, where it could be shipped to Europe.  <br/>  <br/>I think the Internet will have great effects, and that what we've seen so far<br/>is nothing compared to what's coming. But most of the winners will only<br/>indirectly be Internet companies; for every Google there will be ten JetBlues.  <br/>  <br/> **3\. Choices**  <br/>  <br/>Why will the Internet have great effects? The general argument is that new<br/>forms of communication always do. They happen rarely (till industrial times<br/>there were just speech, writing, and printing), but when they do, they always<br/>cause a big splash.  <br/>  <br/>The specific argument, or one of them, is the Internet gives us more choices.<br/>In the "old" economy, the high cost of presenting information to people meant<br/>they had only a narrow range of options to choose from. The tiny, expensive<br/>pipeline to consumers was tellingly named "the channel." Control the channel<br/>and you could feed them what you wanted, on your terms. And it was not just<br/>big corporations that depended on this principle. So, in their way, did labor<br/>unions, the traditional news media, and the art and literary establishments.<br/>Winning depended not on doing good work, but on gaining control of some<br/>bottleneck.  <br/>  <br/>There are signs that this is changing. Google has over 82 million unique users<br/>a month and annual revenues of about three billion dollars. [2] And yet have<br/>you ever seen a Google ad? Something is going on here.  <br/>  <br/>Admittedly, Google is an extreme case. It's very easy for people to switch to<br/>a new search engine. It costs little effort and no money to try a new one, and<br/>it's easy to see if the results are better. And so Google doesn't _have_ to<br/>advertise. In a business like theirs, being the best is enough.  <br/>  <br/>The exciting thing about the Internet is that it's shifting everything in that<br/>direction. The hard part, if you want to win by making the best stuff, is the<br/>beginning. Eventually everyone will learn by word of mouth that you're the<br/>best, but how do you survive to that point? And it is in this crucial stage<br/>that the Internet has the most effect. First, the Internet lets anyone find<br/>you at almost zero cost. Second, it dramatically speeds up the rate at which<br/>reputation spreads by word of mouth. Together these mean that in many fields<br/>the rule will be: Build it, and they will come. Make something great and put<br/>it online. That is a big change from the recipe for winning in the past<br/>century.  <br/>  <br/> **4\. Youth**  <br/>  <br/>The aspect of the Internet Bubble that the press seemed most taken with was<br/>the youth of some of the startup founders. This too is a trend that will last.<br/>There is a huge standard deviation among 26 year olds. Some are fit only for<br/>entry level jobs, but others are ready to rule the world if they can find<br/>someone to handle the paperwork for them.  <br/>  <br/>A 26 year old may not be very good at managing people or dealing with the SEC.<br/>Those require experience. But those are also commodities, which can be handed<br/>off to some lieutenant. The most important quality in a CEO is his vision for<br/>the company's future. What will they build next? And in that department, there<br/>are 26 year olds who can compete with anyone.  <br/>  <br/>In 1970 a company president meant someone in his fifties, at least. If he had<br/>technologists working for him, they were treated like a racing stable: prized,<br/>but not powerful. But as technology has grown more important, the power of<br/>nerds has grown to reflect it. Now it's not enough for a CEO to have someone<br/>smart he can ask about technical matters. Increasingly, he has to be that<br/>person himself.  <br/>  <br/>As always, business has clung to old forms. VCs still seem to want to install<br/>a legitimate-looking talking head as the CEO. But increasingly the founders of<br/>the company are the real powers, and the grey-headed man installed by the VCs<br/>more like a music group's manager than a general.  <br/>  <br/> **5\. Informality**  <br/>  <br/>In New York, the Bubble had dramatic consequences: suits went out of fashion.<br/>They made one seem old. So in 1998 powerful New York types were suddenly<br/>wearing open-necked shirts and khakis and oval wire-rimmed glasses, just like<br/>guys in Santa Clara.  <br/>  <br/>The pendulum has swung back a bit, driven in part by a panicked reaction by<br/>the clothing industry. But I'm betting on the open-necked shirts. And this is<br/>not as frivolous a question as it might seem. Clothes are important, as all<br/>nerds can sense, though they may not realize it consciously.  <br/>  <br/>If you're a nerd, you can understand how important clothes are by asking<br/>yourself how you'd feel about a company that made you wear a suit and tie to<br/>work. The idea sounds horrible, doesn't it? In fact, horrible far out of<br/>proportion to the mere discomfort of wearing such clothes. A company that made<br/>programmers wear suits would have something deeply wrong with it.  <br/>  <br/>And what would be wrong would be that how one presented oneself counted more<br/>than the quality of one's ideas. _That's_ the problem with formality. Dressing<br/>up is not so much bad in itself. The problem is the receptor it binds to:<br/>dressing up is inevitably a substitute for good ideas. It is no coincidence<br/>that technically inept business types are known as "suits."  <br/>  <br/>Nerds don't just happen to dress informally. They do it too consistently.<br/>Consciously or not, they dress informally as a prophylactic measure against<br/>stupidity.  <br/>  <br/> **6\. Nerds**  <br/>  <br/>Clothing is only the most visible battleground in the war against formality.<br/>Nerds tend to eschew formality of any sort. They're not impressed by one's job<br/>title, for example, or any of the other appurtenances of authority.  <br/>  <br/>Indeed, that's practically the definition of a nerd. I found myself talking<br/>recently to someone from Hollywood who was planning a show about nerds. I<br/>thought it would be useful if I explained what a nerd was. What I came up with<br/>was: someone who doesn't expend any effort on marketing himself.  <br/>  <br/>A nerd, in other words, is someone who concentrates on substance. So what's<br/>the connection between nerds and technology? Roughly that you can't fool<br/>mother nature. In technical matters, you have to get the right answers. If<br/>your software miscalculates the path of a space probe, you can't finesse your<br/>way out of trouble by saying that your code is patriotic, or avant-garde, or<br/>any of the other dodges people use in nontechnical fields.  <br/>  <br/>And as technology becomes increasingly important in the economy, nerd culture<br/>is rising with it. Nerds are already a lot cooler than they were when I was a<br/>kid. When I was in college in the mid-1980s, "nerd" was still an insult.<br/>People who majored in computer science generally tried to conceal it. Now<br/>women ask me where they can meet nerds. (The answer that springs to mind is<br/>"Usenix," but that would be like drinking from a firehose.)  <br/>  <br/>I have no illusions about why nerd culture is becoming more accepted. It's not<br/>because people are realizing that substance is more important than marketing.<br/>It's because the nerds are getting rich. But that is not going to change.  <br/>  <br/> **7\. Options**  <br/>  <br/>What makes the nerds rich, usually, is stock options. Now there are moves<br/>afoot to make it harder for companies to grant options. To the extent there's<br/>some genuine accounting abuse going on, by all means correct it. But don't<br/>kill the golden goose. Equity is the fuel that drives technical innovation.  <br/>  <br/>Options are a good idea because (a) they're fair, and (b) they work. Someone<br/>who goes to work for a company is (one hopes) adding to its value, and it's<br/>only fair to give them a share of it. And as a purely practical measure,<br/>people work a _lot_ harder when they have options. I've seen that first hand.  <br/>  <br/>The fact that a few crooks during the Bubble robbed their companies by<br/>granting themselves options doesn't mean options are a bad idea. During the<br/>railroad boom, some executives enriched themselves by selling watered stock—by<br/>issuing more shares than they said were outstanding. But that doesn't make<br/>common stock a bad idea. Crooks just use whatever means are available.  <br/>  <br/>If there is a problem with options, it's that they reward slightly the wrong<br/>thing. Not surprisingly, people do what you pay them to. If you pay them by<br/>the hour, they'll work a lot of hours. If you pay them by the volume of work<br/>done, they'll get a lot of work done (but only as you defined work). And if<br/>you pay them to raise the stock price, which is what options amount to,<br/>they'll raise the stock price.  <br/>  <br/>But that's not quite what you want. What you want is to increase the actual<br/>value of the company, not its market cap. Over time the two inevitably meet,<br/>but not always as quickly as options vest. Which means options tempt<br/>employees, if only unconsciously, to "pump and dump"—to do things that will<br/>make the company _seem_ valuable. I found that when I was at Yahoo, I couldn't<br/>help thinking, "how will this sound to investors?" when I should have been<br/>thinking "is this a good idea?"  <br/>  <br/>So maybe the standard option deal needs to be tweaked slightly. Maybe options<br/>should be replaced with something tied more directly to earnings. It's still<br/>early days.  <br/>  <br/> **8\. Startups**  <br/>  <br/>What made the options valuable, for the most part, is that they were options<br/>on the stock of startups. Startups were not of course a creation of the<br/>Bubble, but they were more visible during the Bubble than ever before.  <br/>  <br/>One thing most people did learn about for the first time during the Bubble was<br/>the startup created with the intention of selling it. Originally a startup<br/>meant a small company that hoped to grow into a big one. But increasingly<br/>startups are evolving into a vehicle for developing technology on spec.  <br/>  <br/>As I wrote in Hackers & Painters, employees seem to be most productive when<br/>they're paid in proportion to the wealth they generate. And the advantage of a<br/>startup—indeed, almost its raison d'etre—is that it offers something otherwise<br/>impossible to obtain: a way of _measuring_ that.  <br/>  <br/>In many businesses, it just makes more sense for companies to get technology<br/>by buying startups rather than developing it in house. You pay more, but there<br/>is less risk, and risk is what big companies don't want. It makes the guys<br/>developing the technology more accountable, because they only get paid if they<br/>build the winner. And you end up with better technology, created faster,<br/>because things are made in the innovative atmosphere of startups instead of<br/>the bureaucratic atmosphere of big companies.  <br/>  <br/>Our startup, Viaweb, was built to be sold. We were open with investors about<br/>that from the start. And we were careful to create something that could slot<br/>easily into a larger company. That is the pattern for the future.  <br/>  <br/> **9\. California**  <br/>  <br/>The Bubble was a California phenomenon. When I showed up in Silicon Valley in<br/>1998, I felt like an immigrant from Eastern Europe arriving in America in<br/>1900. Everyone was so cheerful and healthy and rich. It seemed a new and<br/>improved world.  <br/>  <br/>The press, ever eager to exaggerate small trends, now gives one the impression<br/>that Silicon Valley is a ghost town. Not at all. When I drive down 101 from<br/>the airport, I still feel a buzz of energy, as if there were a giant<br/>transformer nearby. Real estate is still more expensive than just about<br/>anywhere else in the country. The people still look healthy, and the weather<br/>is still fabulous. The future is there. (I say "there" because I moved back to<br/>the East Coast after Yahoo. I still wonder if this was a smart idea.)  <br/>  <br/>What makes the Bay Area superior is the attitude of the people. I notice that<br/>when I come home to Boston. The first thing I see when I walk out of the<br/>airline terminal is the fat, grumpy guy in charge of the taxi line. I brace<br/>myself for rudeness: _remember, you're back on the East Coast now._  <br/>  <br/>The atmosphere varies from city to city, and fragile organisms like startups<br/>are exceedingly sensitive to such variation. If it hadn't already been<br/>hijacked as a new euphemism for liberal, the word to describe the atmosphere<br/>in the Bay Area would be "progressive." People there are trying to build the<br/>future. Boston has MIT and Harvard, but it also has a lot of truculent,<br/>unionized employees like the police who recently held the Democratic National<br/>Convention for ransom, and a lot of people trying to be Thurston Howell. Two<br/>sides of an obsolete coin.  <br/>  <br/>Silicon Valley may not be the next Paris or London, but it is at least the<br/>next Chicago. For the next fifty years, that's where new wealth will come<br/>from.  <br/>  <br/> **10\. Productivity**  <br/>  <br/>During the Bubble, optimistic analysts used to justify high price to earnings<br/>ratios by saying that technology was going to increase productivity<br/>dramatically. They were wrong about the specific companies, but not so wrong<br/>about the underlying principle. I think one of the big trends we'll see in the<br/>coming century is a huge increase in productivity.  <br/>  <br/>Or more precisely, a huge increase in variation in productivity. Technology is<br/>a lever. It doesn't add; it multiplies. If the present range of productivity<br/>is 0 to 100, introducing a multiple of 10 increases the range from 0 to 1000.  <br/>  <br/>One upshot of which is that the companies of the future may be surprisingly<br/>small. I sometimes daydream about how big you could grow a company (in<br/>revenues) without ever having more than ten people. What would happen if you<br/>outsourced everything except product development? If you tried this<br/>experiment, I think you'd be surprised at how far you could get. As Fred<br/>Brooks pointed out, small groups are intrinsically more productive, because<br/>the internal friction in a group grows as the square of its size.  <br/>  <br/>Till quite recently, running a major company meant managing an army of<br/>workers. Our standards about how many employees a company should have are<br/>still influenced by old patterns. Startups are perforce small, because they<br/>can't afford to hire a lot of people. But I think it's a big mistake for<br/>companies to loosen their belts as revenues increase. The question is not<br/>whether you can afford the extra salaries. Can you afford the loss in<br/>productivity that comes from making the company bigger?  <br/>  <br/>The prospect of technological leverage will of course raise the specter of<br/>unemployment. I'm surprised people still worry about this. After centuries of<br/>supposedly job-killing innovations, the number of jobs is within ten percent<br/>of the number of people who want them. This can't be a coincidence. There must<br/>be some kind of balancing mechanism.  <br/>  <br/> **What's New**  <br/>  <br/>When one looks over these trends, is there any overall theme? There does seem<br/>to be: that in the coming century, good ideas will count for more. That 26<br/>year olds with good ideas will increasingly have an edge over 50 year olds<br/>with powerful connections. That doing good work will matter more than dressing<br/>up—or advertising, which is the same thing for companies. That people will be<br/>rewarded a bit more in proportion to the value of what they create.  <br/>  <br/>If so, this is good news indeed. Good ideas always tend to win eventually. The<br/>problem is, it can take a very long time. It took decades for relativity to be<br/>accepted, and the greater part of a century to establish that central planning<br/>didn't work. So even a small increase in the rate at which good ideas win<br/>would be a momentous change—big enough, probably, to justify a name like the<br/>"new economy."  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Actually it's hard to say now. As Jeremy Siegel points out, if the value<br/>of a stock is its future earnings, you can't tell if it was overvalued till<br/>you see what the earnings turn out to be. While certain famous Internet stocks<br/>were almost certainly overvalued in 1999, it is still hard to say for sure<br/>whether, e.g., the Nasdaq index was.  <br/>  <br/>Siegel, Jeremy J. "What Is an Asset Price Bubble? An Operational Definition."<br/>_European Financial Management,_ 9:1, 2003.  <br/>  <br/>[2] The number of users comes from a 6/03 Nielsen study quoted on Google's<br/>site. (You'd think they'd have something more recent.) The revenue estimate is<br/>based on revenues of $1.35 billion for the first half of 2004, as reported in<br/>their IPO filing.  <br/>  <br/> **Thanks** to Chris Anderson, Trevor Blackwell, Sarah Harlin, Jessica<br/>Livingston, and Robert Morris for reading drafts of this.  <br/>  <br/>  <br/><br/>The Long Tail  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>March 2006, rev August 2009  <br/>  <br/>Yesterday one of the founders we funded asked me why we started Y Combinator.<br/>Or more precisely, he asked if we'd started YC mainly for fun.  <br/>  <br/>Kind of, but not quite. It is enormously fun to be able to work with Rtm and<br/>Trevor again. I missed that after we sold Viaweb, and for all the years after<br/>I always had a background process running, looking for something we could do<br/>together. There is definitely an aspect of a band reunion to Y Combinator.<br/>Every couple days I slip and call it "Viaweb."  <br/>  <br/>Viaweb we started very explicitly to make money. I was sick of living from one<br/>freelance project to the next, and decided to just work as hard as I could<br/>till I'd made enough to solve the problem once and for all. Viaweb was<br/>sometimes fun, but it wasn't designed for fun, and mostly it wasn't. I'd be<br/>surprised if any startup is. All startups are mostly schleps.  <br/>  <br/>The real reason we started Y Combinator is neither selfish nor virtuous. We<br/>didn't start it mainly to make money; we have no idea what our average returns<br/>might be, and won't know for years. Nor did we start YC mainly to help out<br/>young would-be founders, though we do like the idea, and comfort ourselves<br/>occasionally with the thought that if all our investments tank, we will thus<br/>have been doing something unselfish. (It's oddly nondeterministic.)  <br/>  <br/>The real reason we started Y Combinator is one probably only a hacker would<br/>understand. We did it because it seems such a great hack. There are thousands<br/>of smart people who could start companies and don't, and with a relatively<br/>small amount of force applied at just the right place, we can spring on the<br/>world a stream of new startups that might otherwise not have existed.  <br/>  <br/>In a way this is virtuous, because I think startups are a good thing. But<br/>really what motivates us is the completely amoral desire that would motivate<br/>any hacker who looked at some complex device and realized that with a tiny<br/>tweak he could make it run more efficiently. In this case, the device is the<br/>world's economy, which fortunately happens to be open source.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>October 2006  <br/>  <br/> _(This essay is derived from a talk at MIT.)_  <br/>  <br/>Till recently graduating seniors had two choices: get a job or go to grad<br/>school. I think there will increasingly be a third option: to start your own<br/>startup. But how common will that be?  <br/>  <br/>I'm sure the default will always be to get a job, but starting a startup could<br/>well become as popular as grad school. In the late 90s my professor friends<br/>used to complain that they couldn't get grad students, because all the<br/>undergrads were going to work for startups. I wouldn't be surprised if that<br/>situation returns, but with one difference: this time they'll be starting<br/>their own instead of going to work for other people's.  <br/>  <br/>The most ambitious students will at this point be asking: Why wait till you<br/>graduate? Why not start a startup while you're in college? In fact, why go to<br/>college at all? Why not start a startup instead?  <br/>  <br/>A year and a half ago I gave a talk where I said that the average age of the<br/>founders of Yahoo, Google, and Microsoft was 24, and that if grad students<br/>could start startups, why not undergrads? I'm glad I phrased that as a<br/>question, because now I can pretend it wasn't merely a rhetorical one. At the<br/>time I couldn't imagine why there should be any lower limit for the age of<br/>startup founders. Graduation is a bureaucratic change, not a biological one.<br/>And certainly there are undergrads as competent technically as most grad<br/>students. So why shouldn't undergrads be able to start startups as well as<br/>grad students?  <br/>  <br/>I now realize that something does change at graduation: you lose a huge excuse<br/>for failing. Regardless of how complex your life is, you'll find that everyone<br/>else, including your family and friends, will discard all the low bits and<br/>regard you as having a single occupation at any given time. If you're in<br/>college and have a summer job writing software, you still read as a student.<br/>Whereas if you graduate and get a job programming, you'll be instantly<br/>regarded by everyone as a programmer.  <br/>  <br/>The problem with starting a startup while you're still in school is that<br/>there's a built-in escape hatch. If you start a startup in the summer between<br/>your junior and senior year, it reads to everyone as a summer job. So if it<br/>goes nowhere, big deal; you return to school in the fall with all the other<br/>seniors; no one regards you as a failure, because your occupation is student,<br/>and you didn't fail at that. Whereas if you start a startup just one year<br/>later, after you graduate, as long as you're not accepted to grad school in<br/>the fall the startup reads to everyone as your occupation. You're now a<br/>startup founder, so you have to do well at that.  <br/>  <br/>For nearly everyone, the opinion of one's peers is the most powerful motivator<br/>of all—more powerful even than the nominal goal of most startup founders,<br/>getting rich. [1] About a month into each funding cycle we have an event<br/>called Prototype Day where each startup presents to the others what they've<br/>got so far. You might think they wouldn't need any more motivation. They're<br/>working on their cool new idea; they have funding for the immediate future;<br/>and they're playing a game with only two outcomes: wealth or failure. You'd<br/>think that would be motivation enough. And yet the prospect of a demo pushes<br/>most of them into a rush of activity.  <br/>  <br/>Even if you start a startup explicitly to get rich, the money you might get<br/>seems pretty theoretical most of the time. What drives you day to day is not<br/>wanting to look bad.  <br/>  <br/>You probably can't change that. Even if you could, I don't think you'd want<br/>to; someone who really, truly doesn't care what his peers think of him is<br/>probably a psychopath. So the best you can do is consider this force like a<br/>wind, and set up your boat accordingly. If you know your peers are going to<br/>push you in some direction, choose good peers, and position yourself so they<br/>push you in a direction you like.  <br/>  <br/>Graduation changes the prevailing winds, and those make a difference. Starting<br/>a startup is so hard that it's a close call even for the ones that succeed.<br/>However high a startup may be flying now, it probably has a few leaves stuck<br/>in the landing gear from those trees it barely cleared at the end of the<br/>runway. In such a close game, the smallest increase in the forces against you<br/>can be enough to flick you over the edge into failure.  <br/>  <br/>When we first started Y Combinator we encouraged people to start startups<br/>while they were still in college. That's partly because Y Combinator began as<br/>a kind of summer program. We've kept the program shape—all of us having dinner<br/>together once a week turns out to be a good idea—but we've decided now that<br/>the party line should be to tell people to wait till they graduate.  <br/>  <br/>Does that mean you can't start a startup in college? Not at all. Sam Altman,<br/>the co-founder of Loopt, had just finished his sophomore year when we funded<br/>them, and Loopt is probably the most promising of all the startups we've<br/>funded so far. But Sam Altman is a very unusual guy. Within about three<br/>minutes of meeting him, I remember thinking "Ah, so this is what Bill Gates<br/>must have been like when he was 19."  <br/>  <br/>If it can work to start a startup during college, why do we tell people not<br/>to? For the same reason that the probably apocryphal violinist, whenever he<br/>was asked to judge someone's playing, would always say they didn't have enough<br/>talent to make it as a pro. Succeeding as a musician takes determination as<br/>well as talent, so this answer works out to be the right advice for everyone.<br/>The ones who are uncertain believe it and give up, and the ones who are<br/>sufficiently determined think "screw that, I'll succeed anyway."  <br/>  <br/>So our official policy now is only to fund undergrads we can't talk out of it.<br/>And frankly, if you're not certain, you _should_ wait. It's not as if all the<br/>opportunities to start companies are going to be gone if you don't do it now.<br/>Maybe the window will close on some idea you're working on, but that won't be<br/>the last idea you'll have. For every idea that times out, new ones become<br/>feasible. Historically the opportunities to start startups have only increased<br/>with time.  <br/>  <br/>In that case, you might ask, why not wait longer? Why not go work for a while,<br/>or go to grad school, and then start a startup? And indeed, that might be a<br/>good idea. If I had to pick the sweet spot for startup founders, based on who<br/>we're most excited to see applications from, I'd say it's probably the mid-<br/>twenties. Why? What advantages does someone in their mid-twenties have over<br/>someone who's 21? And why isn't it older? What can 25 year olds do that 32<br/>year olds can't? Those turn out to be questions worth examining.  <br/>  <br/> **Plus**  <br/>  <br/>If you start a startup soon after college, you'll be a young founder by<br/>present standards, so you should know what the relative advantages of young<br/>founders are. They're not what you might think. As a young founder your<br/>strengths are: stamina, poverty, rootlessness, colleagues, and ignorance.  <br/>  <br/>The importance of stamina shouldn't be surprising. If you've heard anything<br/>about startups you've probably heard about the long hours. As far as I can<br/>tell these are universal. I can't think of any successful startups whose<br/>founders worked 9 to 5. And it's particularly necessary for younger founders<br/>to work long hours because they're probably not as efficient as they'll be<br/>later.  <br/>  <br/>Your second advantage, poverty, might not sound like an advantage, but it is a<br/>huge one. Poverty implies you can live cheaply, and this is critically<br/>important for startups. Nearly every startup that fails, fails by running out<br/>of money. It's a little misleading to put it this way, because there's usually<br/>some other underlying cause. But regardless of the source of your problems, a<br/>low burn rate gives you more opportunity to recover from them. And since most<br/>startups make all kinds of mistakes at first, room to recover from mistakes is<br/>a valuable thing to have.  <br/>  <br/>Most startups end up doing something different than they planned. The way the<br/>successful ones find something that works is by trying things that don't. So<br/>the worst thing you can do in a startup is to have a rigid, pre-ordained plan<br/>and then start spending a lot of money to implement it. Better to operate<br/>cheaply and give your ideas time to evolve.  <br/>  <br/>Recent grads can live on practically nothing, and this gives you an edge over<br/>older founders, because the main cost in software startups is people. The guys<br/>with kids and mortgages are at a real disadvantage. This is one reason I'd bet<br/>on the 25 year old over the 32 year old. The 32 year old probably is a better<br/>programmer, but probably also has a much more expensive life. Whereas a 25<br/>year old has some work experience (more on that later) but can live as cheaply<br/>as an undergrad.  <br/>  <br/>Robert Morris and I were 29 and 30 respectively when we started Viaweb, but<br/>fortunately we still lived like 23 year olds. We both had roughly zero assets.<br/>I would have loved to have a mortgage, since that would have meant I had a<br/>_house_. But in retrospect having nothing turned out to be convenient. I<br/>wasn't tied down and I was used to living cheaply.  <br/>  <br/>Even more important than living cheaply, though, is thinking cheaply. One<br/>reason the Apple II was so popular was that it was cheap. The computer itself<br/>was cheap, and it used cheap, off-the-shelf peripherals like a cassette tape<br/>recorder for data storage and a TV as a monitor. And you know why? Because Woz<br/>designed this computer for himself, and he couldn't afford anything more.  <br/>  <br/>We benefitted from the same phenomenon. Our prices were daringly low for the<br/>time. The top level of service was $300 a month, which was an order of<br/>magnitude below the norm. In retrospect this was a smart move, but we didn't<br/>do it because we were smart. $300 a month seemed like a lot of money to us.<br/>Like Apple, we created something inexpensive, and therefore popular, simply<br/>because we were poor.  <br/>  <br/>A lot of startups have that form: someone comes along and makes something for<br/>a tenth or a hundredth of what it used to cost, and the existing players can't<br/>follow because they don't even want to think about a world in which that's<br/>possible. Traditional long distance carriers, for example, didn't even want to<br/>think about VoIP. (It was coming, all the same.) Being poor helps in this<br/>game, because your own personal bias points in the same direction technology<br/>evolves in.  <br/>  <br/>The advantages of rootlessness are similar to those of poverty. When you're<br/>young you're more mobile—not just because you don't have a house or much<br/>stuff, but also because you're less likely to have serious relationships. This<br/>turns out to be important, because a lot of startups involve someone moving.  <br/>  <br/>The founders of Kiko, for example, are now en route to the Bay Area to start<br/>their next startup. It's a better place for what they want to do. And it was<br/>easy for them to decide to go, because neither as far as I know has a serious<br/>girlfriend, and everything they own will fit in one car—or more precisely,<br/>will either fit in one car or is crappy enough that they don't mind leaving it<br/>behind.  <br/>  <br/>They at least were in Boston. What if they'd been in Nebraska, like Evan<br/>Williams was at their age? Someone wrote recently that the drawback of Y<br/>Combinator was that you had to move to participate. It couldn't be any other<br/>way. The kind of conversations we have with founders, we have to have in<br/>person. We fund a dozen startups at a time, and we can't be in a dozen places<br/>at once. But even if we could somehow magically save people from moving, we<br/>wouldn't. We wouldn't be doing founders a favor by letting them stay in<br/>Nebraska. Places that aren't startup hubs are toxic to startups. You can tell<br/>that from indirect evidence. You can tell how hard it must be to start a<br/>startup in Houston or Chicago or Miami from the microscopically small number,<br/>per capita, that succeed there. I don't know exactly what's suppressing all<br/>the startups in these towns—probably a hundred subtle little things—but<br/>something must be. [2]  <br/>  <br/>Maybe this will change. Maybe the increasing cheapness of startups will mean<br/>they'll be able to survive anywhere, instead of only in the most hospitable<br/>environments. Maybe 37signals is the pattern for the future. But maybe not.<br/>Historically there have always been certain towns that were centers for<br/>certain industries, and if you weren't in one of them you were at a<br/>disadvantage. So my guess is that 37signals is an anomaly. We're looking at a<br/>pattern much older than "Web 2.0" here.  <br/>  <br/>Perhaps the reason more startups per capita happen in the Bay Area than Miami<br/>is simply that there are more founder-type people there. Successful startups<br/>are almost never started by one person. Usually they begin with a conversation<br/>in which someone mentions that something would be a good idea for a company,<br/>and his friend says, "Yeah, that is a good idea, let's try it." If you're<br/>missing that second person who says "let's try it," the startup never happens.<br/>And that is another area where undergrads have an edge. They're surrounded by<br/>people willing to say that. At a good college you're concentrated together<br/>with a lot of other ambitious and technically minded people—probably more<br/>concentrated than you'll ever be again. If your nucleus spits out a neutron,<br/>there's a good chance it will hit another nucleus.  <br/>  <br/>The number one question people ask us at Y Combinator is: Where can I find a<br/>co-founder? That's the biggest problem for someone starting a startup at 30.<br/>When they were in school they knew a lot of good co-founders, but by 30<br/>they've either lost touch with them or these people are tied down by jobs they<br/>don't want to leave.  <br/>  <br/>Viaweb was an anomaly in this respect too. Though we were comparatively old,<br/>we weren't tied down by impressive jobs. I was trying to be an artist, which<br/>is not very constraining, and Robert, though 29, was still in grad school due<br/>to a little interruption in his academic career back in 1988. So arguably the<br/>Worm made Viaweb possible. Otherwise Robert would have been a junior professor<br/>at that age, and he wouldn't have had time to work on crazy speculative<br/>projects with me.  <br/>  <br/>Most of the questions people ask Y Combinator we have some kind of answer for,<br/>but not the co-founder question. There is no good answer. Co-founders really<br/>should be people you already know. And by far the best place to meet them is<br/>school. You have a large sample of smart people; you get to compare how they<br/>all perform on identical tasks; and everyone's life is pretty fluid. A lot of<br/>startups grow out of schools for this reason. Google, Yahoo, and Microsoft,<br/>among others, were all founded by people who met in school. (In Microsoft's<br/>case, it was high school.)  <br/>  <br/>Many students feel they should wait and get a little more experience before<br/>they start a company. All other things being equal, they should. But all other<br/>things are not quite as equal as they look. Most students don't realize how<br/>rich they are in the scarcest ingredient in startups, co-founders. If you wait<br/>too long, you may find that your friends are now involved in some project they<br/>don't want to abandon. The better they are, the more likely this is to happen.  <br/>  <br/>One way to mitigate this problem might be to actively plan your startup while<br/>you're getting those n years of experience. Sure, go off and get jobs or go to<br/>grad school or whatever, but get together regularly to scheme, so the idea of<br/>starting a startup stays alive in everyone's brain. I don't know if this<br/>works, but it can't hurt to try.  <br/>  <br/>It would be helpful just to realize what an advantage you have as students.<br/>Some of your classmates are probably going to be successful startup founders;<br/>at a great technical university, that is a near certainty. So which ones? If I<br/>were you I'd look for the people who are not just smart, but incurable<br/>builders.  Look for the people who keep starting projects, and finish at least<br/>some of them. That's what we look for. Above all else, above academic<br/>credentials and even the idea you apply with, we look for people who build<br/>things.  <br/>  <br/>The other place co-founders meet is at work. Fewer do than at school, but<br/>there are things you can do to improve the odds. The most important,<br/>obviously, is to work somewhere that has a lot of smart, young people. Another<br/>is to work for a company located in a startup hub. It will be easier to talk a<br/>co-worker into quitting with you in a place where startups are happening all<br/>around you.  <br/>  <br/>You might also want to look at the employment agreement you sign when you get<br/>hired. Most will say that any ideas you think of while you're employed by the<br/>company belong to them. In practice it's hard for anyone to prove what ideas<br/>you had when, so the line gets drawn at code. If you're going to start a<br/>startup, don't write any of the code while you're still employed. Or at least<br/>discard any code you wrote while still employed and start over. It's not so<br/>much that your employer will find out and sue you. It won't come to that;<br/>investors or acquirers or (if you're so lucky) underwriters will nail you<br/>first. Between t = 0 and when you buy that yacht, _someone_ is going to ask if<br/>any of your code legally belongs to anyone else, and you need to be able to<br/>say no. [3]  <br/>  <br/>The most overreaching employee agreement I've seen so far is Amazon's. In<br/>addition to the usual clauses about owning your ideas, you also can't be a<br/>founder of a startup that has another founder who worked at Amazon—even if you<br/>didn't know them or even work there at the same time. I suspect they'd have a<br/>hard time enforcing this, but it's a bad sign they even try. There are plenty<br/>of other places to work; you may as well choose one that keeps more of your<br/>options open.  <br/>  <br/>Speaking of cool places to work, there is of course Google. But I notice<br/>something slightly frightening about Google: zero startups come out of there.<br/>In that respect it's a black hole. People seem to like working at Google too<br/>much to leave. So if you hope to start a startup one day, the evidence so far<br/>suggests you shouldn't work there.  <br/>  <br/>I realize this seems odd advice. If they make your life so good that you don't<br/>want to leave, why not work there? Because, in effect, you're probably getting<br/>a local maximum. You need a certain activation energy to start a startup. So<br/>an employer who's fairly pleasant to work for can lull you into staying<br/>indefinitely, even if it would be a net win for you to leave. [4]  <br/>  <br/>The best place to work, if you want to start a startup, is probably a startup.<br/>In addition to being the right sort of experience, one way or another it will<br/>be over quickly. You'll either end up rich, in which case problem solved, or<br/>the startup will get bought, in which case it it will start to suck to work<br/>there and it will be easy to leave, or most likely, the thing will blow up and<br/>you'll be free again.  <br/>  <br/>Your final advantage, ignorance, may not sound very useful. I deliberately<br/>used a controversial word for it; you might equally call it innocence. But it<br/>seems to be a powerful force. My Y Combinator co-founder Jessica Livingston is<br/>just about to publish a book of interviews with startup founders, and I<br/>noticed a remarkable pattern in them. One after another said that if they'd<br/>known how hard it would be, they would have been too intimidated to start.  <br/>  <br/>Ignorance can be useful when it's a counterweight to other forms of stupidity.<br/>It's useful in starting startups because you're capable of more than you<br/>realize. Starting startups is harder than you expect, but you're also capable<br/>of more than you expect, so they balance out.  <br/>  <br/>Most people look at a company like Apple and think, how could I ever make such<br/>a thing? Apple is an institution, and I'm just a person. But every institution<br/>was at one point just a handful of people in a room deciding to start<br/>something. Institutions are made up, and made up by people no different from<br/>you.  <br/>  <br/>I'm not saying everyone could start a startup. I'm sure most people couldn't;<br/>I don't know much about the population at large. When you get to groups I know<br/>well, like hackers, I can say more precisely. At the top schools, I'd guess as<br/>many as a quarter of the CS majors could make it as startup founders if they<br/>wanted.  <br/>  <br/>That "if they wanted" is an important qualification—so important that it's<br/>almost cheating to append it like that—because once you get over a certain<br/>threshold of intelligence, which most CS majors at top schools are past, the<br/>deciding factor in whether you succeed as a founder is how much you want to.<br/>You don't have to be that smart. If you're not a genius, just start a startup<br/>in some unsexy field where you'll have less competition, like software for<br/>human resources departments. I picked that example at random, but I feel safe<br/>in predicting that whatever they have now, it wouldn't take genius to do<br/>better. There are a lot of people out there working on boring stuff who are<br/>desperately in need of better software, so however short you think you fall of<br/>Larry and Sergey, you can ratchet down the coolness of the idea far enough to<br/>compensate.  <br/>  <br/>As well as preventing you from being intimidated, ignorance can sometimes help<br/>you discover new ideas. Steve Wozniak put this very strongly:<br/><br/>> All the best things that I did at Apple came from (a) not having money and<br/>> (b) not having done it before, ever. Every single thing that we came out<br/>> with that was really great, I'd never once done that thing in my life.<br/><br/>When you know nothing, you have to reinvent stuff for yourself, and if you're<br/>smart your reinventions may be better than what preceded them. This is<br/>especially true in fields where the rules change. All our ideas about software<br/>were developed in a time when processors were slow, and memories and disks<br/>were tiny. Who knows what obsolete assumptions are embedded in the<br/>conventional wisdom? And the way these assumptions are going to get fixed is<br/>not by explicitly deallocating them, but by something more akin to garbage<br/>collection. Someone ignorant but smart will come along and reinvent<br/>everything, and in the process simply fail to reproduce certain existing<br/>ideas.  <br/>  <br/> **Minus**  <br/>  <br/>So much for the advantages of young founders. What about the disadvantages?<br/>I'm going to start with what goes wrong and try to trace it back to the root<br/>causes.  <br/>  <br/>What goes wrong with young founders is that they build stuff that looks like<br/>class projects. It was only recently that we figured this out ourselves. We<br/>noticed a lot of similarities between the startups that seemed to be falling<br/>behind, but we couldn't figure out how to put it into words. Then finally we<br/>realized what it was: they were building class projects.  <br/>  <br/>But what does that really mean? What's wrong with class projects? What's the<br/>difference between a class project and a real startup? If we could answer that<br/>question it would be useful not just to would-be startup founders but to<br/>students in general, because we'd be a long way toward explaining the mystery<br/>of the so-called real world.  <br/>  <br/>There seem to be two big things missing in class projects: (1) an iterative<br/>definition of a real problem and (2) intensity.  <br/>  <br/>The first is probably unavoidable. Class projects will inevitably solve fake<br/>problems. For one thing, real problems are rare and valuable. If a professor<br/>wanted to have students solve real problems, he'd face the same paradox as<br/>someone trying to give an example of whatever "paradigm" might succeed the<br/>Standard Model of physics. There may well be something that does, but if you<br/>could think of an example you'd be entitled to the Nobel Prize. Similarly,<br/>good new problems are not to be had for the asking.  <br/>  <br/>In technology the difficulty is compounded by the fact that real startups tend<br/>to discover the problem they're solving by a process of evolution. Someone has<br/>an idea for something; they build it; and in doing so (and probably only by<br/>doing so) they realize the problem they should be solving is another one. Even<br/>if the professor let you change your project description on the fly, there<br/>isn't time enough to do that in a college class, or a market to supply<br/>evolutionary pressures. So class projects are mostly about implementation,<br/>which is the least of your problems in a startup.  <br/>  <br/>It's not just that in a startup you work on the idea as well as<br/>implementation. The very implementation is different. Its main purpose is to<br/>refine the idea. Often the only value of most of the stuff you build in the<br/>first six months is that it proves your initial idea was mistaken. And that's<br/>extremely valuable. If you're free of a misconception that everyone else still<br/>shares, you're in a powerful position. But you're not thinking that way about<br/>a class project. Proving your initial plan was mistaken would just get you a<br/>bad grade. Instead of building stuff to throw away, you tend to want every<br/>line of code to go toward that final goal of showing you did a lot of work.  <br/>  <br/>That leads to our second difference: the way class projects are measured.<br/>Professors will tend to judge you by the distance between the starting point<br/>and where you are now. If someone has achieved a lot, they should get a good<br/>grade. But customers will judge you from the other direction: the distance<br/>remaining between where you are now and the features they need. The market<br/>doesn't give a shit how hard you worked. Users just want your software to do<br/>what they need, and you get a zero otherwise. That is one of the most<br/>distinctive differences between school and the real world: there is no reward<br/>for putting in a good effort. In fact, the whole concept of a "good effort" is<br/>a fake idea adults invented to encourage kids. It is not found in nature.  <br/>  <br/>Such lies seem to be helpful to kids. But unfortunately when you graduate they<br/>don't give you a list of all the lies they told you during your education. You<br/>have to get them beaten out of you by contact with the real world. And this is<br/>why so many jobs want work experience. I couldn't understand that when I was<br/>in college. I knew how to program. In fact, I could tell I knew how to program<br/>better than most people doing it for a living. So what was this mysterious<br/>"work experience" and why did I need it?  <br/>  <br/>Now I know what it is, and part of the confusion is grammatical. Describing it<br/>as "work experience" implies it's like experience operating a certain kind of<br/>machine, or using a certain programming language. But really what work<br/>experience refers to is not some specific expertise, but the elimination of<br/>certain habits left over from childhood.  <br/>  <br/>One of the defining qualities of kids is that they flake. When you're a kid<br/>and you face some hard test, you can cry and say "I can't" and they won't make<br/>you do it. Of course, no one can make you do anything in the grownup world<br/>either. What they do instead is fire you. And when motivated by that you find<br/>you can do a lot more than you realized. So one of the things employers expect<br/>from someone with "work experience" is the elimination of the flake reflex—the<br/>ability to get things done, with no excuses.  <br/>  <br/>The other thing you get from work experience is an understanding of what work<br/>is, and in particular, how intrinsically horrible it is. Fundamentally the<br/>equation is a brutal one: you have to spend most of your waking hours doing<br/>stuff someone else wants, or starve. There are a few places where the work is<br/>so interesting that this is concealed, because what other people want done<br/>happens to coincide with what you want to work on. But you only have to<br/>imagine what would happen if they diverged to see the underlying reality.  <br/>  <br/>It's not so much that adults lie to kids about this as never explain it. They<br/>never explain what the deal is with money. You know from an early age that<br/>you'll have some sort of job, because everyone asks what you're going to "be"<br/>when you grow up. What they don't tell you is that as a kid you're sitting on<br/>the shoulders of someone else who's treading water, and that starting working<br/>means you get thrown into the water on your own, and have to start treading<br/>water yourself or sink. "Being" something is incidental; the immediate problem<br/>is not to drown.  <br/>  <br/>The relationship between work and money tends to dawn on you only gradually.<br/>At least it did for me. One's first thought tends to be simply "This sucks.<br/>I'm in debt. Plus I have to get up on monday and go to work." Gradually you<br/>realize that these two things are as tightly connected as only a market can<br/>make them.  <br/>  <br/>So the most important advantage 24 year old founders have over 20 year old<br/>founders is that they know what they're trying to avoid. To the average<br/>undergrad the idea of getting rich translates into buying Ferraris, or being<br/>admired. To someone who has learned from experience about the relationship<br/>between money and work, it translates to something way more important: it<br/>means you get to opt out of the brutal equation that governs the lives of<br/>99.9% of people. Getting rich means you can stop treading water.  <br/>  <br/>Someone who gets this will work much harder at making a startup succeed—with<br/>the proverbial energy of a drowning man, in fact. But understanding the<br/>relationship between money and work also changes the way you work. You don't<br/>get money just for working, but for doing things other people want. Someone<br/>who's figured that out will automatically focus more on the user. And that<br/>cures the other half of the class-project syndrome. After you've been working<br/>for a while, you yourself tend to measure what you've done the same way the<br/>market does.  <br/>  <br/>Of course, you don't have to spend years working to learn this stuff. If<br/>you're sufficiently perceptive you can grasp these things while you're still<br/>in school. Sam Altman did. He must have, because Loopt is no class project.<br/>And as his example suggests, this can be valuable knowledge. At a minimum, if<br/>you get this stuff, you already have most of what you gain from the "work<br/>experience" employers consider so desirable. But of course if you really get<br/>it, you can use this information in a way that's more valuable to you than<br/>that.  <br/>  <br/> **Now**  <br/>  <br/>So suppose you think you might start a startup at some point, either when you<br/>graduate or a few years after. What should you do now? For both jobs and grad<br/>school, there are ways to prepare while you're in college. If you want to get<br/>a job when you graduate, you should get summer jobs at places you'd like to<br/>work. If you want to go to grad school, it will help to work on research<br/>projects as an undergrad. What's the equivalent for startups? How do you keep<br/>your options maximally open?  <br/>  <br/>One thing you can do while you're still in school is to learn how startups<br/>work. Unfortunately that's not easy. Few if any colleges have classes about<br/>startups. There may be business school classes on entrepreneurship, as they<br/>call it over there, but these are likely to be a waste of time. Business<br/>schools like to talk about startups, but philosophically they're at the<br/>opposite end of the spectrum. Most books on startups also seem to be useless.<br/>I've looked at a few and none get it right. Books in most fields are written<br/>by people who know the subject from experience, but for startups there's a<br/>unique problem: by definition the founders of successful startups don't need<br/>to write books to make money. As a result most books on the subject end up<br/>being written by people who don't understand it.  <br/>  <br/>So I'd be skeptical of classes and books. The way to learn about startups is<br/>by watching them in action, preferably by working at one. How do you do that<br/>as an undergrad? Probably by sneaking in through the back door. Just hang<br/>around a lot and gradually start doing things for them. Most startups are (or<br/>should be) very cautious about hiring. Every hire increases the burn rate, and<br/>bad hires early on are hard to recover from. However, startups usually have a<br/>fairly informal atmosphere, and there's always a lot that needs to be done. If<br/>you just start doing stuff for them, many will be too busy to shoo you away.<br/>You can thus gradually work your way into their confidence, and maybe turn it<br/>into an official job later, or not, whichever you prefer. This won't work for<br/>all startups, but it would work for most I've known.  <br/>  <br/>Number two, make the most of the great advantage of school: the wealth of co-<br/>founders. Look at the people around you and ask yourself which you'd like to<br/>work with. When you apply that test, you may find you get surprising results.<br/>You may find you'd prefer the quiet guy you've mostly ignored to someone who<br/>seems impressive but has an attitude to match. I'm not suggesting you suck up<br/>to people you don't really like because you think one day they'll be<br/>successful. Exactly the opposite, in fact: you should only start a startup<br/>with someone you like, because a startup will put your friendship through a<br/>stress test. I'm just saying you should think about who you really admire and<br/>hang out with them, instead of whoever circumstances throw you together with.  <br/>  <br/>Another thing you can do is learn skills that will be useful to you in a<br/>startup. These may be different from the skills you'd learn to get a job. For<br/>example, thinking about getting a job will make you want to learn programming<br/>languages you think employers want, like Java and C++. Whereas if you start a<br/>startup, you get to pick the language, so you have to think about which will<br/>actually let you get the most done. If you use that test you might end up<br/>learning Ruby or Python instead.  <br/>  <br/>But the most important skill for a startup founder isn't a programming<br/>technique. It's a knack for understanding users and figuring out how to give<br/>them what they want. I know I repeat this, but that's because it's so<br/>important. And it's a skill you can learn, though perhaps habit might be a<br/>better word. Get into the habit of thinking of software as having users. What<br/>do those users want? What would make them say wow?  <br/>  <br/>This is particularly valuable for undergrads, because the concept of users is<br/>missing from most college programming classes. The way you get taught<br/>programming in college would be like teaching writing as grammar, without<br/>mentioning that its purpose is to communicate something to an audience.<br/>Fortunately an audience for software is now only an http request away. So in<br/>addition to the programming you do for your classes, why not build some kind<br/>of website people will find useful? At the very least it will teach you how to<br/>write software with users. In the best case, it might not just be preparation<br/>for a startup, but the startup itself, like it was for Yahoo and Google.  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Even the desire to protect one's children seems weaker, judging from<br/>things people have historically done to their kids rather than risk their<br/>community's disapproval. (I assume we still do things that will be regarded in<br/>the future as barbaric, but historical abuses are easier for us to see.)  <br/>  <br/>[2] Worrying that Y Combinator makes founders move for 3 months also suggests<br/>one underestimates how hard it is to start a startup. You're going to have to<br/>put up with much greater inconveniences than that.  <br/>  <br/>[3] Most employee agreements say that any idea relating to the company's<br/>present or potential future business belongs to them. Often as not the second<br/>clause could include any possible startup, and anyone doing due diligence for<br/>an investor or acquirer will assume the worst.  <br/>  <br/>To be safe either (a) don't use code written while you were still employed in<br/>your previous job, or (b) get your employer to renounce, in writing, any claim<br/>to the code you write for your side project. Many will consent to (b) rather<br/>than lose a prized employee. The downside is that you'll have to tell them<br/>exactly what your project does.  <br/>  <br/>[4] Geshke and Warnock only founded Adobe because Xerox ignored them. If Xerox<br/>had used what they built, they would probably never have left PARC.  <br/>  <br/> **Thanks** to Jessica Livingston and Robert Morris for reading drafts of<br/>this, and to Jeff Arnold and the SIPB for inviting me to speak.  <br/>  <br/>Comment on this essay.  <br/>  <br/><br/>Chinese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>May 2004  <br/>  <br/> _(This essay was originally published inHackers & Painters.) _  <br/>  <br/>If you wanted to get rich, how would you do it? I think your best bet would be<br/>to start or join a startup. That's been a reliable way to get rich for<br/>hundreds of years. The word "startup" dates from the 1960s, but what happens<br/>in one is very similar to the venture-backed trading voyages of the Middle<br/>Ages.  <br/>  <br/>Startups usually involve technology, so much so that the phrase "high-tech<br/>startup" is almost redundant. A startup is a small company that takes on a<br/>hard technical problem.  <br/>  <br/>Lots of people get rich knowing nothing more than that. You don't have to know<br/>physics to be a good pitcher. But I think it could give you an edge to<br/>understand the underlying principles. Why do startups have to be small? Will a<br/>startup inevitably stop being a startup as it grows larger? And why do they so<br/>often work on developing new technology? Why are there so many startups<br/>selling new drugs or computer software, and none selling corn oil or laundry<br/>detergent?  <br/>  <br/> **The Proposition**  <br/>  <br/>Economically, you can think of a startup as a way to compress your whole<br/>working life into a few years. Instead of working at a low intensity for forty<br/>years, you work as hard as you possibly can for four. This pays especially<br/>well in technology, where you earn a premium for working fast.  <br/>  <br/>Here is a brief sketch of the economic proposition. If you're a good hacker in<br/>your mid twenties, you can get a job paying about $80,000 per year. So on<br/>average such a hacker must be able to do at least $80,000 worth of work per<br/>year for the company just to break even. You could probably work twice as many<br/>hours as a corporate employee, and if you focus you can probably get three<br/>times as much done in an hour. [1] You should get another multiple of two, at<br/>least, by eliminating the drag of the pointy-haired middle manager who would<br/>be your boss in a big company. Then there is one more multiple: how much<br/>smarter are you than your job description expects you to be? Suppose another<br/>multiple of three. Combine all these multipliers, and I'm claiming you could<br/>be 36 times more productive than you're expected to be in a random corporate<br/>job. [2] If a fairly good hacker is worth $80,000 a year at a big company,<br/>then a smart hacker working very hard without any corporate bullshit to slow<br/>him down should be able to do work worth about $3 million a year.  <br/>  <br/>Like all back-of-the-envelope calculations, this one has a lot of wiggle room.<br/>I wouldn't try to defend the actual numbers. But I stand by the structure of<br/>the calculation. I'm not claiming the multiplier is precisely 36, but it is<br/>certainly more than 10, and probably rarely as high as 100.  <br/>  <br/>If $3 million a year seems high, remember that we're talking about the limit<br/>case: the case where you not only have zero leisure time but indeed work so<br/>hard that you endanger your health.  <br/>  <br/>Startups are not magic. They don't change the laws of wealth creation. They<br/>just represent a point at the far end of the curve. There is a conservation<br/>law at work here: if you want to make a million dollars, you have to endure a<br/>million dollars' worth of pain. For example, one way to make a million dollars<br/>would be to work for the Post Office your whole life, and save every penny of<br/>your salary. Imagine the stress of working for the Post Office for fifty<br/>years. In a startup you compress all this stress into three or four years. You<br/>do tend to get a certain bulk discount if you buy the economy-size pain, but<br/>you can't evade the fundamental conservation law. If starting a startup were<br/>easy, everyone would do it.  <br/>  <br/> **Millions, not Billions**  <br/>  <br/>If $3 million a year seems high to some people, it will seem low to others.<br/>Three _million?_ How do I get to be a billionaire, like Bill Gates?  <br/>  <br/>So let's get Bill Gates out of the way right now. It's not a good idea to use<br/>famous rich people as examples, because the press only write about the very<br/>richest, and these tend to be outliers. Bill Gates is a smart, determined, and<br/>hardworking man, but you need more than that to make as much money as he has.<br/>You also need to be very lucky.  <br/>  <br/>There is a large random factor in the success of any company. So the guys you<br/>end up reading about in the papers are the ones who are very smart, totally<br/>dedicated, _and_ win the lottery. Certainly Bill is smart and dedicated, but<br/>Microsoft also happens to have been the beneficiary of one of the most<br/>spectacular blunders in the history of business: the licensing deal for DOS.<br/>No doubt Bill did everything he could to steer IBM into making that blunder,<br/>and he has done an excellent job of exploiting it, but if there had been one<br/>person with a brain on IBM's side, Microsoft's future would have been very<br/>different. Microsoft at that stage had little leverage over IBM. They were<br/>effectively a component supplier. If IBM had required an exclusive license, as<br/>they should have, Microsoft would still have signed the deal. It would still<br/>have meant a lot of money for them, and IBM could easily have gotten an<br/>operating system elsewhere.  <br/>  <br/>Instead IBM ended up using all its power in the market to give Microsoft<br/>control of the PC standard. From that point, all Microsoft had to do was<br/>execute. They never had to bet the company on a bold decision. All they had to<br/>do was play hardball with licensees and copy more innovative products<br/>reasonably promptly.  <br/>  <br/>If IBM hadn't made this mistake, Microsoft would still have been a successful<br/>company, but it could not have grown so big so fast. Bill Gates would be rich,<br/>but he'd be somewhere near the bottom of the Forbes 400 with the other guys<br/>his age.  <br/>  <br/>There are a lot of ways to get rich, and this essay is about only one of them.<br/>This essay is about how to make money by creating wealth and getting paid for<br/>it. There are plenty of other ways to get money, including chance,<br/>speculation, marriage, inheritance, theft, extortion, fraud, monopoly, graft,<br/>lobbying, counterfeiting, and prospecting. Most of the greatest fortunes have<br/>probably involved several of these.  <br/>  <br/>The advantage of creating wealth, as a way to get rich, is not just that it's<br/>more legitimate (many of the other methods are now illegal) but that it's more<br/>_straightforward._ You just have to do something people want.  <br/>  <br/> **Money Is Not Wealth**  <br/>  <br/>If you want to create wealth, it will help to understand what it is. Wealth is<br/>not the same thing as money. [3] Wealth is as old as human history. Far older,<br/>in fact; ants have wealth. Money is a comparatively recent invention.  <br/>  <br/>Wealth is the fundamental thing. Wealth is stuff we want: food, clothes,<br/>houses, cars, gadgets, travel to interesting places, and so on. You can have<br/>wealth without having money. If you had a magic machine that could on command<br/>make you a car or cook you dinner or do your laundry, or do anything else you<br/>wanted, you wouldn't need money. Whereas if you were in the middle of<br/>Antarctica, where there is nothing to buy, it wouldn't matter how much money<br/>you had.  <br/>  <br/>Wealth is what you want, not money. But if wealth is the important thing, why<br/>does everyone talk about making money? It is a kind of shorthand: money is a<br/>way of moving wealth, and in practice they are usually interchangeable. But<br/>they are not the same thing, and unless you plan to get rich by<br/>counterfeiting, talking about _making money_ can make it harder to understand<br/>how to make money.  <br/>  <br/>Money is a side effect of specialization. In a specialized society, most of<br/>the things you need, you can't make for yourself. If you want a potato or a<br/>pencil or a place to live, you have to get it from someone else.  <br/>  <br/>How do you get the person who grows the potatoes to give you some? By giving<br/>him something he wants in return. But you can't get very far by trading things<br/>directly with the people who need them. If you make violins, and none of the<br/>local farmers wants one, how will you eat?  <br/>  <br/>The solution societies find, as they get more specialized, is to make the<br/>trade into a two-step process. Instead of trading violins directly for<br/>potatoes, you trade violins for, say, silver, which you can then trade again<br/>for anything else you need. The intermediate stuff-- the _medium of exchange_<br/>\-- can be anything that's rare and portable. Historically metals have been<br/>the most common, but recently we've been using a medium of exchange, called<br/>the _dollar_ , that doesn't physically exist. It works as a medium of<br/>exchange, however, because its rarity is guaranteed by the U.S. Government.  <br/>  <br/>The advantage of a medium of exchange is that it makes trade work. The<br/>disadvantage is that it tends to obscure what trade really means. People think<br/>that what a business does is make money. But money is just the intermediate<br/>stage-- just a shorthand-- for whatever people want. What most businesses<br/>really do is make wealth. They do something people want. [4]  <br/>  <br/> **The Pie Fallacy**  <br/>  <br/>A surprising number of people retain from childhood the idea that there is a<br/>fixed amount of wealth in the world. There is, in any normal family, a fixed<br/>amount of _money_ at any moment. But that's not the same thing.  <br/>  <br/>When wealth is talked about in this context, it is often described as a pie.<br/>"You can't make the pie larger," say politicians. When you're talking about<br/>the amount of money in one family's bank account, or the amount available to a<br/>government from one year's tax revenue, this is true. If one person gets more,<br/>someone else has to get less.  <br/>  <br/>I can remember believing, as a child, that if a few rich people had all the<br/>money, it left less for everyone else. Many people seem to continue to believe<br/>something like this well into adulthood. This fallacy is usually there in the<br/>background when you hear someone talking about how x percent of the population<br/>have y percent of the wealth. If you plan to start a startup, then whether you<br/>realize it or not, you're planning to disprove the Pie Fallacy.  <br/>  <br/>What leads people astray here is the abstraction of money. Money is not<br/>wealth. It's just something we use to move wealth around. So although there<br/>may be, in certain specific moments (like your family, this month) a fixed<br/>amount of money available to trade with other people for things you want,<br/>there is not a fixed amount of wealth in the world. _You can make more<br/>wealth._ Wealth has been getting created and destroyed (but on balance,<br/>created) for all of human history.  <br/>  <br/>Suppose you own a beat-up old car. Instead of sitting on your butt next<br/>summer, you could spend the time restoring your car to pristine condition. In<br/>doing so you create wealth. The world is-- and you specifically are-- one<br/>pristine old car the richer. And not just in some metaphorical way. If you<br/>sell your car, you'll get more for it.  <br/>  <br/>In restoring your old car you have made yourself richer. You haven't made<br/>anyone else poorer. So there is obviously not a fixed pie. And in fact, when<br/>you look at it this way, you wonder why anyone would think there was. [5]  <br/>  <br/>Kids know, without knowing they know, that they can create wealth. If you need<br/>to give someone a present and don't have any money, you make one. But kids are<br/>so bad at making things that they consider home-made presents to be a<br/>distinct, inferior, sort of thing to store-bought ones-- a mere expression of<br/>the proverbial thought that counts. And indeed, the lumpy ashtrays we made for<br/>our parents did not have much of a resale market.  <br/>  <br/> **Craftsmen**  <br/>  <br/>The people most likely to grasp that wealth can be created are the ones who<br/>are good at making things, the craftsmen. Their hand-made objects become<br/>store-bought ones. But with the rise of industrialization there are fewer and<br/>fewer craftsmen. One of the biggest remaining groups is computer programmers.  <br/>  <br/>A programmer can sit down in front of a computer and _create wealth_. A good<br/>piece of software is, in itself, a valuable thing. There is no manufacturing<br/>to confuse the issue. Those characters you type are a complete, finished<br/>product. If someone sat down and wrote a web browser that didn't suck (a fine<br/>idea, by the way), the world would be that much richer. [5b]  <br/>  <br/>Everyone in a company works together to create wealth, in the sense of making<br/>more things people want. Many of the employees (e.g. the people in the<br/>mailroom or the personnel department) work at one remove from the actual<br/>making of stuff. Not the programmers. They literally think the product, one<br/>line at a time. And so it's clearer to programmers that wealth is something<br/>that's made, rather than being distributed, like slices of a pie, by some<br/>imaginary Daddy.  <br/>  <br/>It's also obvious to programmers that there are huge variations in the rate at<br/>which wealth is created. At Viaweb we had one programmer who was a sort of<br/>monster of productivity. I remember watching what he did one long day and<br/>estimating that he had added several hundred thousand dollars to the market<br/>value of the company. A great programmer, on a roll, could create a million<br/>dollars worth of wealth in a couple weeks. A mediocre programmer over the same<br/>period will generate zero or even negative wealth (e.g. by introducing bugs).  <br/>  <br/>This is why so many of the best programmers are libertarians. In our world,<br/>you sink or swim, and there are no excuses. When those far removed from the<br/>creation of wealth-- undergraduates, reporters, politicians-- hear that the<br/>richest 5% of the people have half the total wealth, they tend to think<br/>_injustice!_ An experienced programmer would be more likely to think _is that<br/>all?_ The top 5% of programmers probably write 99% of the good software.  <br/>  <br/>Wealth can be created without being sold. Scientists, till recently at least,<br/>effectively donated the wealth they created. We are all richer for knowing<br/>about penicillin, because we're less likely to die from infections. Wealth is<br/>whatever people want, and not dying is certainly something we want. Hackers<br/>often donate their work by writing open source software that anyone can use<br/>for free. I am much the richer for the operating system FreeBSD, which I'm<br/>running on the computer I'm using now, and so is Yahoo, which runs it on all<br/>their servers.  <br/>  <br/> **What a Job Is**  <br/>  <br/>In industrialized countries, people belong to one institution or another at<br/>least until their twenties. After all those years you get used to the idea of<br/>belonging to a group of people who all get up in the morning, go to some set<br/>of buildings, and do things that they do not, ordinarily, enjoy doing.<br/>Belonging to such a group becomes part of your identity: name, age, role,<br/>institution. If you have to introduce yourself, or someone else describes you,<br/>it will be as something like, John Smith, age 10, a student at such and such<br/>elementary school, or John Smith, age 20, a student at such and such college.  <br/>  <br/>When John Smith finishes school he is expected to get a job. And what getting<br/>a job seems to mean is joining another institution. Superficially it's a lot<br/>like college. You pick the companies you want to work for and apply to join<br/>them. If one likes you, you become a member of this new group. You get up in<br/>the morning and go to a new set of buildings, and do things that you do not,<br/>ordinarily, enjoy doing. There are a few differences: life is not as much fun,<br/>and you get paid, instead of paying, as you did in college. But the<br/>similarities feel greater than the differences. John Smith is now John Smith,<br/>22, a software developer at such and such corporation.  <br/>  <br/>In fact John Smith's life has changed more than he realizes. Socially, a<br/>company looks much like college, but the deeper you go into the underlying<br/>reality, the more different it gets.  <br/>  <br/>What a company does, and has to do if it wants to continue to exist, is earn<br/>money. And the way most companies make money is by creating wealth. Companies<br/>can be so specialized that this similarity is concealed, but it is not only<br/>manufacturing companies that create wealth. A big component of wealth is<br/>location. Remember that magic machine that could make you cars and cook you<br/>dinner and so on? It would not be so useful if it delivered your dinner to a<br/>random location in central Asia. If wealth means what people want, companies<br/>that move things also create wealth. Ditto for many other kinds of companies<br/>that don't make anything physical. Nearly all companies exist to do something<br/>people want.  <br/>  <br/>And that's what you do, as well, when you go to work for a company. But here<br/>there is another layer that tends to obscure the underlying reality. In a<br/>company, the work you do is averaged together with a lot of other people's.<br/>You may not even be aware you're doing something people want. Your<br/>contribution may be indirect. But the company as a whole must be giving people<br/>something they want, or they won't make any money. And if they are paying you<br/>x dollars a year, then on average you must be contributing at least x dollars<br/>a year worth of work, or the company will be spending more than it makes, and<br/>will go out of business.  <br/>  <br/>Someone graduating from college thinks, and is told, that he needs to get a<br/>job, as if the important thing were becoming a member of an institution. A<br/>more direct way to put it would be: you need to start doing something people<br/>want. You don't need to join a company to do that. All a company is is a group<br/>of people working together to do something people want. It's doing something<br/>people want that matters, not joining the group. [6]  <br/>  <br/>For most people the best plan probably is to go to work for some existing<br/>company. But it is a good idea to understand what's happening when you do<br/>this. A job means doing something people want, averaged together with everyone<br/>else in that company.  <br/>  <br/> **Working Harder**  <br/>  <br/>That averaging gets to be a problem. I think the single biggest problem<br/>afflicting large companies is the difficulty of assigning a value to each<br/>person's work. For the most part they punt. In a big company you get paid a<br/>fairly predictable salary for working fairly hard. You're expected not to be<br/>obviously incompetent or lazy, but you're not expected to devote your whole<br/>life to your work.  <br/>  <br/>It turns out, though, that there are economies of scale in how much of your<br/>life you devote to your work. In the right kind of business, someone who<br/>really devoted himself to work could generate ten or even a hundred times as<br/>much wealth as an average employee. A programmer, for example, instead of<br/>chugging along maintaining and updating an existing piece of software, could<br/>write a whole new piece of software, and with it create a new source of<br/>revenue.  <br/>  <br/>Companies are not set up to reward people who want to do this. You can't go to<br/>your boss and say, I'd like to start working ten times as hard, so will you<br/>please pay me ten times as much? For one thing, the official fiction is that<br/>you are already working as hard as you can. But a more serious problem is that<br/>the company has no way of measuring the value of your work.  <br/>  <br/>Salesmen are an exception. It's easy to measure how much revenue they<br/>generate, and they're usually paid a percentage of it. If a salesman wants to<br/>work harder, he can just start doing it, and he will automatically get paid<br/>proportionally more.  <br/>  <br/>There is one other job besides sales where big companies can hire first-rate<br/>people: in the top management jobs. And for the same reason: their performance<br/>can be measured. The top managers are held responsible for the performance of<br/>the entire company. Because an ordinary employee's performance can't usually<br/>be measured, he is not expected to do more than put in a solid effort. Whereas<br/>top management, like salespeople, have to actually come up with the numbers.<br/>The CEO of a company that tanks cannot plead that he put in a solid effort. If<br/>the company does badly, he's done badly.  <br/>  <br/>A company that could pay all its employees so straightforwardly would be<br/>enormously successful. Many employees would work harder if they could get paid<br/>for it. More importantly, such a company would attract people who wanted to<br/>work especially hard. It would crush its competitors.  <br/>  <br/>Unfortunately, companies can't pay everyone like salesmen. Salesmen work<br/>alone. Most employees' work is tangled together. Suppose a company makes some<br/>kind of consumer gadget. The engineers build a reliable gadget with all kinds<br/>of new features; the industrial designers design a beautiful case for it; and<br/>then the marketing people convince everyone that it's something they've got to<br/>have. How do you know how much of the gadget's sales are due to each group's<br/>efforts? Or, for that matter, how much is due to the creators of past gadgets<br/>that gave the company a reputation for quality? There's no way to untangle all<br/>their contributions. Even if you could read the minds of the consumers, you'd<br/>find these factors were all blurred together.  <br/>  <br/>If you want to go faster, it's a problem to have your work tangled together<br/>with a large number of other people's. In a large group, your performance is<br/>not separately measurable-- and the rest of the group slows you down.  <br/>  <br/> **Measurement and Leverage**  <br/>  <br/>To get rich you need to get yourself in a situation with two things,<br/>measurement and leverage. You need to be in a position where your performance<br/>can be measured, or there is no way to get paid more by doing more. And you<br/>have to have leverage, in the sense that the decisions you make have a big<br/>effect.  <br/>  <br/>Measurement alone is not enough. An example of a job with measurement but not<br/>leverage is doing piecework in a sweatshop. Your performance is measured and<br/>you get paid accordingly, but you have no scope for decisions. The only<br/>decision you get to make is how fast you work, and that can probably only<br/>increase your earnings by a factor of two or three.  <br/>  <br/>An example of a job with both measurement and leverage would be lead actor in<br/>a movie. Your performance can be measured in the gross of the movie. And you<br/>have leverage in the sense that your performance can make or break it.  <br/>  <br/>CEOs also have both measurement and leverage. They're measured, in that the<br/>performance of the company is their performance. And they have leverage in<br/>that their decisions set the whole company moving in one direction or another.  <br/>  <br/>I think everyone who gets rich by their own efforts will be found to be in a<br/>situation with measurement and leverage. Everyone I can think of does: CEOs,<br/>movie stars, hedge fund managers, professional athletes. A good hint to the<br/>presence of leverage is the possibility of failure. Upside must be balanced by<br/>downside, so if there is big potential for gain there must also be a<br/>terrifying possibility of loss. CEOs, stars, fund managers, and athletes all<br/>live with the sword hanging over their heads; the moment they start to suck,<br/>they're out. If you're in a job that feels safe, you are not going to get<br/>rich, because if there is no danger there is almost certainly no leverage.  <br/>  <br/>But you don't have to become a CEO or a movie star to be in a situation with<br/>measurement and leverage. All you need to do is be part of a small group<br/>working on a hard problem.  <br/>  <br/> **Smallness = Measurement**  <br/>  <br/>If you can't measure the value of the work done by individual employees, you<br/>can get close. You can measure the value of the work done by small groups.  <br/>  <br/>One level at which you can accurately measure the revenue generated by<br/>employees is at the level of the whole company. When the company is small, you<br/>are thereby fairly close to measuring the contributions of individual<br/>employees. A viable startup might only have ten employees, which puts you<br/>within a factor of ten of measuring individual effort.  <br/>  <br/>Starting or joining a startup is thus as close as most people can get to<br/>saying to one's boss, I want to work ten times as hard, so please pay me ten<br/>times as much. There are two differences: you're not saying it to your boss,<br/>but directly to the customers (for whom your boss is only a proxy after all),<br/>and you're not doing it individually, but along with a small group of other<br/>ambitious people.  <br/>  <br/>It will, ordinarily, be a group. Except in a few unusual kinds of work, like<br/>acting or writing books, you can't be a company of one person. And the people<br/>you work with had better be good, because it's their work that yours is going<br/>to be averaged with.  <br/>  <br/>A big company is like a giant galley driven by a thousand rowers. Two things<br/>keep the speed of the galley down. One is that individual rowers don't see any<br/>result from working harder. The other is that, in a group of a thousand<br/>people, the average rower is likely to be pretty average.  <br/>  <br/>If you took ten people at random out of the big galley and put them in a boat<br/>by themselves, they could probably go faster. They would have both carrot and<br/>stick to motivate them. An energetic rower would be encouraged by the thought<br/>that he could have a visible effect on the speed of the boat. And if someone<br/>was lazy, the others would be more likely to notice and complain.  <br/>  <br/>But the real advantage of the ten-man boat shows when you take the ten _best_<br/>rowers out of the big galley and put them in a boat together. They will have<br/>all the extra motivation that comes from being in a small group. But more<br/>importantly, by selecting that small a group you can get the best rowers. Each<br/>one will be in the top 1%. It's a much better deal for them to average their<br/>work together with a small group of their peers than to average it with<br/>everyone.  <br/>  <br/>That's the real point of startups. Ideally, you are getting together with a<br/>group of other people who also want to work a lot harder, and get paid a lot<br/>more, than they would in a big company. And because startups tend to get<br/>founded by self-selecting groups of ambitious people who already know one<br/>another (at least by reputation), the level of measurement is more precise<br/>than you get from smallness alone. A startup is not merely ten people, but ten<br/>people like you.  <br/>  <br/>Steve Jobs once said that the success or failure of a startup depends on the<br/>first ten employees. I agree. If anything, it's more like the first five.<br/>Being small is not, in itself, what makes startups kick butt, but rather that<br/>small groups can be select. You don't want small in the sense of a village,<br/>but small in the sense of an all-star team.  <br/>  <br/>The larger a group, the closer its average member will be to the average for<br/>the population as a whole. So all other things being equal, a very able person<br/>in a big company is probably getting a bad deal, because his performance is<br/>dragged down by the overall lower performance of the others. Of course, all<br/>other things often are not equal: the able person may not care about money, or<br/>may prefer the stability of a large company. But a very able person who does<br/>care about money will ordinarily do better to go off and work with a small<br/>group of peers.  <br/>  <br/> **Technology = Leverage**  <br/>  <br/>Startups offer anyone a way to be in a situation with measurement and<br/>leverage. They allow measurement because they're small, and they offer<br/>leverage because they make money by inventing new technology.  <br/>  <br/>What is technology? It's _technique_. It's the way we all do things. And when<br/>you discover a new way to do things, its value is multiplied by all the people<br/>who use it. It is the proverbial fishing rod, rather than the fish. That's the<br/>difference between a startup and a restaurant or a barber shop. You fry eggs<br/>or cut hair one customer at a time. Whereas if you solve a technical problem<br/>that a lot of people care about, you help everyone who uses your solution.<br/>That's leverage.  <br/>  <br/>If you look at history, it seems that most people who got rich by creating<br/>wealth did it by developing new technology. You just can't fry eggs or cut<br/>hair fast enough. What made the Florentines rich in 1200 was the discovery of<br/>new techniques for making the high-tech product of the time, fine woven cloth.<br/>What made the Dutch rich in 1600 was the discovery of shipbuilding and<br/>navigation techniques that enabled them to dominate the seas of the Far East.  <br/>  <br/>Fortunately there is a natural fit between smallness and solving hard<br/>problems. The leading edge of technology moves fast. Technology that's<br/>valuable today could be worthless in a couple years. Small companies are more<br/>at home in this world, because they don't have layers of bureaucracy to slow<br/>them down. Also, technical advances tend to come from unorthodox approaches,<br/>and small companies are less constrained by convention.  <br/>  <br/>Big companies can develop technology. They just can't do it quickly. Their<br/>size makes them slow and prevents them from rewarding employees for the<br/>extraordinary effort required. So in practice big companies only get to<br/>develop technology in fields where large capital requirements prevent startups<br/>from competing with them, like microprocessors, power plants, or passenger<br/>aircraft. And even in those fields they depend heavily on startups for<br/>components and ideas.  <br/>  <br/>It's obvious that biotech or software startups exist to solve hard technical<br/>problems, but I think it will also be found to be true in businesses that<br/>don't seem to be about technology. McDonald's, for example, grew big by<br/>designing a system, the McDonald's franchise, that could then be reproduced at<br/>will all over the face of the earth. A McDonald's franchise is controlled by<br/>rules so precise that it is practically a piece of software. Write once, run<br/>everywhere. Ditto for Wal-Mart. Sam Walton got rich not by being a retailer,<br/>but by designing a new kind of store.  <br/>  <br/>Use difficulty as a guide not just in selecting the overall aim of your<br/>company, but also at decision points along the way. At Viaweb one of our rules<br/>of thumb was _run upstairs._ Suppose you are a little, nimble guy being chased<br/>by a big, fat, bully. You open a door and find yourself in a staircase. Do you<br/>go up or down? I say up. The bully can probably run downstairs as fast as you<br/>can. Going upstairs his bulk will be more of a disadvantage. Running upstairs<br/>is hard for you but even harder for him.  <br/>  <br/>What this meant in practice was that we deliberately sought hard problems. If<br/>there were two features we could add to our software, both equally valuable in<br/>proportion to their difficulty, we'd always take the harder one. Not just<br/>because it was more valuable, but _because it was harder._ We delighted in<br/>forcing bigger, slower competitors to follow us over difficult ground. Like<br/>guerillas, startups prefer the difficult terrain of the mountains, where the<br/>troops of the central government can't follow. I can remember times when we<br/>were just exhausted after wrestling all day with some horrible technical<br/>problem. And I'd be delighted, because something that was hard for us would be<br/>impossible for our competitors.  <br/>  <br/>This is not just a good way to run a startup. It's what a startup is. Venture<br/>capitalists know about this and have a phrase for it: _barriers to entry._ If<br/>you go to a VC with a new idea and ask him to invest in it, one of the first<br/>things he'll ask is, how hard would this be for someone else to develop? That<br/>is, how much difficult ground have you put between yourself and potential<br/>pursuers? [7] And you had better have a convincing explanation of why your<br/>technology would be hard to duplicate. Otherwise as soon as some big company<br/>becomes aware of it, they'll make their own, and with their brand name,<br/>capital, and distribution clout, they'll take away your market overnight.<br/>You'd be like guerillas caught in the open field by regular army forces.  <br/>  <br/>One way to put up barriers to entry is through patents. But patents may not<br/>provide much protection. Competitors commonly find ways to work around a<br/>patent. And if they can't, they may simply violate it and invite you to sue<br/>them. A big company is not afraid to be sued; it's an everyday thing for them.<br/>They'll make sure that suing them is expensive and takes a long time. Ever<br/>heard of Philo Farnsworth? He invented television. The reason you've never<br/>heard of him is that his company was not the one to make money from it. [8]<br/>The company that did was RCA, and Farnsworth's reward for his efforts was a<br/>decade of patent litigation.  <br/>  <br/>Here, as so often, the best defense is a good offense. If you can develop<br/>technology that's simply too hard for competitors to duplicate, you don't need<br/>to rely on other defenses. Start by picking a hard problem, and then at every<br/>decision point, take the harder choice. [9]  <br/>  <br/> **The Catch(es)**  <br/>  <br/>If it were simply a matter of working harder than an ordinary employee and<br/>getting paid proportionately, it would obviously be a good deal to start a<br/>startup. Up to a point it would be more fun. I don't think many people like<br/>the slow pace of big companies, the interminable meetings, the water-cooler<br/>conversations, the clueless middle managers, and so on.  <br/>  <br/>Unfortunately there are a couple catches. One is that you can't choose the<br/>point on the curve that you want to inhabit. You can't decide, for example,<br/>that you'd like to work just two or three times as hard, and get paid that<br/>much more. When you're running a startup, your competitors decide how hard you<br/>work. And they pretty much all make the same decision: as hard as you possibly<br/>can.  <br/>  <br/>The other catch is that the payoff is only on average proportionate to your<br/>productivity. There is, as I said before, a large random multiplier in the<br/>success of any company. So in practice the deal is not that you're 30 times as<br/>productive and get paid 30 times as much. It is that you're 30 times as<br/>productive, and get paid between zero and a thousand times as much. If the<br/>mean is 30x, the median is probably zero. Most startups tank, and not just the<br/>dogfood portals we all heard about during the Internet Bubble. It's common for<br/>a startup to be developing a genuinely good product, take slightly too long to<br/>do it, run out of money, and have to shut down.  <br/>  <br/>A startup is like a mosquito. A bear can absorb a hit and a crab is armored<br/>against one, but a mosquito is designed for one thing: to score. No energy is<br/>wasted on defense. The defense of mosquitos, as a species, is that there are a<br/>lot of them, but this is little consolation to the individual mosquito.  <br/>  <br/>Startups, like mosquitos, tend to be an all-or-nothing proposition. And you<br/>don't generally know which of the two you're going to get till the last<br/>minute. Viaweb came close to tanking several times. Our trajectory was like a<br/>sine wave. Fortunately we got bought at the top of the cycle, but it was<br/>damned close. While we were visiting Yahoo in California to talk about selling<br/>the company to them, we had to borrow a conference room to reassure an<br/>investor who was about to back out of a new round of funding that we needed to<br/>stay alive.  <br/>  <br/>The all-or-nothing aspect of startups was not something we wanted. Viaweb's<br/>hackers were all extremely risk-averse. If there had been some way just to<br/>work super hard and get paid for it, without having a lottery mixed in, we<br/>would have been delighted. We would have much preferred a 100% chance of $1<br/>million to a 20% chance of $10 million, even though theoretically the second<br/>is worth twice as much. Unfortunately, there is not currently any space in the<br/>business world where you can get the first deal.  <br/>  <br/>The closest you can get is by selling your startup in the early stages, giving<br/>up upside (and risk) for a smaller but guaranteed payoff. We had a chance to<br/>do this, and stupidly, as we then thought, let it slip by. After that we<br/>became comically eager to sell. For the next year or so, if anyone expressed<br/>the slightest curiosity about Viaweb we would try to sell them the company.<br/>But there were no takers, so we had to keep going.  <br/>  <br/>It would have been a bargain to buy us at an early stage, but companies doing<br/>acquisitions are not looking for bargains. A company big enough to acquire<br/>startups will be big enough to be fairly conservative, and within the company<br/>the people in charge of acquisitions will be among the more conservative,<br/>because they are likely to be business school types who joined the company<br/>late. They would rather overpay for a safe choice. So it is easier to sell an<br/>established startup, even at a large premium, than an early-stage one.  <br/>  <br/> **Get Users**  <br/>  <br/>I think it's a good idea to get bought, if you can. Running a business is<br/>different from growing one. It is just as well to let a big company take over<br/>once you reach cruising altitude. It's also financially wiser, because selling<br/>allows you to diversify. What would you think of a financial advisor who put<br/>all his client's assets into one volatile stock?  <br/>  <br/>How do you get bought? Mostly by doing the same things you'd do if you didn't<br/>intend to sell the company. Being profitable, for example. But getting bought<br/>is also an art in its own right, and one that we spent a lot of time trying to<br/>master.  <br/>  <br/>Potential buyers will always delay if they can. The hard part about getting<br/>bought is getting them to act. For most people, the most powerful motivator is<br/>not the hope of gain, but the fear of loss. For potential acquirers, the most<br/>powerful motivator is the prospect that one of their competitors will buy you.<br/>This, as we found, causes CEOs to take red-eyes. The second biggest is the<br/>worry that, if they don't buy you now, you'll continue to grow rapidly and<br/>will cost more to acquire later, or even become a competitor.  <br/>  <br/>In both cases, what it all comes down to is users. You'd think that a company<br/>about to buy you would do a lot of research and decide for themselves how<br/>valuable your technology was. Not at all. What they go by is the number of<br/>users you have.  <br/>  <br/>In effect, acquirers assume the customers know who has the best technology.<br/>And this is not as stupid as it sounds. Users are the only real proof that<br/>you've created wealth. Wealth is what people want, and if people aren't using<br/>your software, maybe it's not just because you're bad at marketing. Maybe it's<br/>because you haven't made what they want.  <br/>  <br/>Venture capitalists have a list of danger signs to watch out for. Near the top<br/>is the company run by techno-weenies who are obsessed with solving interesting<br/>technical problems, instead of making users happy. In a startup, you're not<br/>just trying to solve problems. You're trying to solve problems _that users<br/>care about._  <br/>  <br/>So I think you should make users the test, just as acquirers do. Treat a<br/>startup as an optimization problem in which performance is measured by number<br/>of users. As anyone who has tried to optimize software knows, the key is<br/>measurement. When you try to guess where your program is slow, and what would<br/>make it faster, you almost always guess wrong.  <br/>  <br/>Number of users may not be the perfect test, but it will be very close. It's<br/>what acquirers care about. It's what revenues depend on. It's what makes<br/>competitors unhappy. It's what impresses reporters, and potential new users.<br/>Certainly it's a better test than your a priori notions of what problems are<br/>important to solve, no matter how technically adept you are.  <br/>  <br/>Among other things, treating a startup as an optimization problem will help<br/>you avoid another pitfall that VCs worry about, and rightly-- taking a long<br/>time to develop a product. Now we can recognize this as something hackers<br/>already know to avoid: premature optimization. Get a version 1.0 out there as<br/>soon as you can. Until you have some users to measure, you're optimizing based<br/>on guesses.  <br/>  <br/>The ball you need to keep your eye on here is the underlying principle that<br/>wealth is what people want. If you plan to get rich by creating wealth, you<br/>have to know what people want. So few businesses really pay attention to<br/>making customers happy. How often do you walk into a store, or call a company<br/>on the phone, with a feeling of dread in the back of your mind? When you hear<br/>"your call is important to us, please stay on the line," do you think, oh<br/>good, now everything will be all right?  <br/>  <br/>A restaurant can afford to serve the occasional burnt dinner. But in<br/>technology, you cook one thing and that's what everyone eats. So any<br/>difference between what people want and what you deliver is multiplied. You<br/>please or annoy customers wholesale. The closer you can get to what they want,<br/>the more wealth you generate.  <br/>  <br/> **Wealth and Power**  <br/>  <br/>Making wealth is not the only way to get rich. For most of human history it<br/>has not even been the most common. Until a few centuries ago, the main sources<br/>of wealth were mines, slaves and serfs, land, and cattle, and the only ways to<br/>acquire these rapidly were by inheritance, marriage, conquest, or<br/>confiscation. Naturally wealth had a bad reputation.  <br/>  <br/>Two things changed. The first was the rule of law. For most of the world's<br/>history, if you did somehow accumulate a fortune, the ruler or his henchmen<br/>would find a way to steal it. But in medieval Europe something new happened. A<br/>new class of merchants and manufacturers began to collect in towns. [10]<br/>Together they were able to withstand the local feudal lord. So for the first<br/>time in our history, the bullies stopped stealing the nerds' lunch money. This<br/>was naturally a great incentive, and possibly indeed the main cause of the<br/>second big change, industrialization.  <br/>  <br/>A great deal has been written about the causes of the Industrial Revolution.<br/>But surely a necessary, if not sufficient, condition was that people who made<br/>fortunes be able to enjoy them in peace. [11] One piece of evidence is what<br/>happened to countries that tried to return to the old model, like the Soviet<br/>Union, and to a lesser extent Britain under the labor governments of the 1960s<br/>and early 1970s. Take away the incentive of wealth, and technical innovation<br/>grinds to a halt.  <br/>  <br/>Remember what a startup is, economically: a way of saying, I want to work<br/>faster. Instead of accumulating money slowly by being paid a regular wage for<br/>fifty years, I want to get it over with as soon as possible. So governments<br/>that forbid you to accumulate wealth are in effect decreeing that you work<br/>slowly. They're willing to let you earn $3 million over fifty years, but<br/>they're not willing to let you work so hard that you can do it in two. They<br/>are like the corporate boss that you can't go to and say, I want to work ten<br/>times as hard, so please pay me ten times a much. Except this is not a boss<br/>you can escape by starting your own company.  <br/>  <br/>The problem with working slowly is not just that technical innovation happens<br/>slowly. It's that it tends not to happen at all. It's only when you're<br/>deliberately looking for hard problems, as a way to use speed to the greatest<br/>advantage, that you take on this kind of project. Developing new technology is<br/>a pain in the ass. It is, as Edison said, one percent inspiration and ninety-<br/>nine percent perspiration. Without the incentive of wealth, no one wants to do<br/>it. Engineers will work on sexy projects like fighter planes and moon rockets<br/>for ordinary salaries, but more mundane technologies like light bulbs or<br/>semiconductors have to be developed by entrepreneurs.  <br/>  <br/>Startups are not just something that happened in Silicon Valley in the last<br/>couple decades. Since it became possible to get rich by creating wealth,<br/>everyone who has done it has used essentially the same recipe: measurement and<br/>leverage, where measurement comes from working with a small group, and<br/>leverage from developing new techniques. The recipe was the same in Florence<br/>in 1200 as it is in Santa Clara today.  <br/>  <br/>Understanding this may help to answer an important question: why Europe grew<br/>so powerful. Was it something about the geography of Europe? Was it that<br/>Europeans are somehow racially superior? Was it their religion? The answer (or<br/>at least the proximate cause) may be that the Europeans rode on the crest of a<br/>powerful new idea: allowing those who made a lot of money to keep it.  <br/>  <br/>Once you're allowed to do that, people who want to get rich can do it by<br/>generating wealth instead of stealing it. The resulting technological growth<br/>translates not only into wealth but into military power. The theory that led<br/>to the stealth plane was developed by a Soviet mathematician. But because the<br/>Soviet Union didn't have a computer industry, it remained for them a theory;<br/>they didn't have hardware capable of executing the calculations fast enough to<br/>design an actual airplane.  <br/>  <br/>In that respect the Cold War teaches the same lesson as World War II and, for<br/>that matter, most wars in recent history. Don't let a ruling class of warriors<br/>and politicians squash the entrepreneurs. The same recipe that makes<br/>individuals rich makes countries powerful. Let the nerds keep their lunch<br/>money, and you rule the world.  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] One valuable thing you tend to get only in startups is<br/>_uninterruptability_. Different kinds of work have different time quanta.<br/>Someone proofreading a manuscript could probably be interrupted every fifteen<br/>minutes with little loss of productivity. But the time quantum for hacking is<br/>very long: it might take an hour just to load a problem into your head. So the<br/>cost of having someone from personnel call you about a form you forgot to fill<br/>out can be huge.  <br/>  <br/>This is why hackers give you such a baleful stare as they turn from their<br/>screen to answer your question. Inside their heads a giant house of cards is<br/>tottering.  <br/>  <br/>The mere possibility of being interrupted deters hackers from starting hard<br/>projects. This is why they tend to work late at night, and why it's next to<br/>impossible to write great software in a cubicle (except late at night).  <br/>  <br/>One great advantage of startups is that they don't yet have any of the people<br/>who interrupt you. There is no personnel department, and thus no form nor<br/>anyone to call you about it.  <br/>  <br/>[2] Faced with the idea that people working for startups might be 20 or 30<br/>times as productive as those working for large companies, executives at large<br/>companies will naturally wonder, how could I get the people working for me to<br/>do that? The answer is simple: pay them to.  <br/>  <br/>Internally most companies are run like Communist states. If you believe in<br/>free markets, why not turn your company into one?  <br/>  <br/>Hypothesis: A company will be maximally profitable when each employee is paid<br/>in proportion to the wealth they generate.  <br/>  <br/>[3] Until recently even governments sometimes didn't grasp the distinction<br/>between money and wealth. Adam Smith ( _Wealth of Nations_ , v:i) mentions<br/>several that tried to preserve their "wealth" by forbidding the export of gold<br/>or silver. But having more of the medium of exchange would not make a country<br/>richer; if you have more money chasing the same amount of material wealth, the<br/>only result is higher prices.  <br/>  <br/>[4] There are many senses of the word "wealth," not all of them material. I'm<br/>not trying to make a deep philosophical point here about which is the true<br/>kind. I'm writing about one specific, rather technical sense of the word<br/>"wealth." What people will give you money for. This is an interesting sort of<br/>wealth to study, because it is the kind that prevents you from starving. And<br/>what people will give you money for depends on them, not you.  <br/>  <br/>When you're starting a business, it's easy to slide into thinking that<br/>customers want what you do. During the Internet Bubble I talked to a woman<br/>who, because she liked the outdoors, was starting an "outdoor portal." You<br/>know what kind of business you should start if you like the outdoors? One to<br/>recover data from crashed hard disks.  <br/>  <br/>What's the connection? None at all. Which is precisely my point. If you want<br/>to create wealth (in the narrow technical sense of not starving) then you<br/>should be especially skeptical about any plan that centers on things you like<br/>doing. That is where your idea of what's valuable is least likely to coincide<br/>with other people's.  <br/>  <br/>[5] In the average car restoration you probably do make everyone else<br/>microscopically poorer, by doing a small amount of damage to the environment.<br/>While environmental costs should be taken into account, they don't make wealth<br/>a zero-sum game. For example, if you repair a machine that's broken because a<br/>part has come unscrewed, you create wealth with no environmental cost.  <br/>  <br/>[5b] This essay was written before Firefox.  <br/>  <br/>[6] Many people feel confused and depressed in their early twenties. Life<br/>seemed so much more fun in college. Well, of course it was. Don't be fooled by<br/>the surface similarities. You've gone from guest to servant. It's possible to<br/>have fun in this new world. Among other things, you now get to go behind the<br/>doors that say "authorized personnel only." But the change is a shock at<br/>first, and all the worse if you're not consciously aware of it.  <br/>  <br/>[7] When VCs asked us how long it would take another startup to duplicate our<br/>software, we used to reply that they probably wouldn't be able to at all. I<br/>think this made us seem naive, or liars.  <br/>  <br/>[8] Few technologies have one clear inventor. So as a rule, if you know the<br/>"inventor" of something (the telephone, the assembly line, the airplane, the<br/>light bulb, the transistor) it is because their company made money from it,<br/>and the company's PR people worked hard to spread the story. If you don't know<br/>who invented something (the automobile, the television, the computer, the jet<br/>engine, the laser), it's because other companies made all the money.  <br/>  <br/>[9] This is a good plan for life in general. If you have two choices, choose<br/>the harder. If you're trying to decide whether to go out running or sit home<br/>and watch TV, go running. Probably the reason this trick works so well is that<br/>when you have two choices and one is harder, the only reason you're even<br/>considering the other is laziness. You know in the back of your mind what's<br/>the right thing to do, and this trick merely forces you to acknowledge it.  <br/>  <br/>[10] It is probably no accident that the middle class first appeared in<br/>northern Italy and the low countries, where there were no strong central<br/>governments. These two regions were the richest of their time and became the<br/>twin centers from which Renaissance civilization radiated. If they no longer<br/>play that role, it is because other places, like the United States, have been<br/>truer to the principles they discovered.  <br/>  <br/>[11] It may indeed be a sufficient condition. But if so, why didn't the<br/>Industrial Revolution happen earlier? Two possible (and not incompatible)<br/>answers: (a) It did. The Industrial Revolution was one in a series. (b)<br/>Because in medieval towns, monopolies and guild regulations initially slowed<br/>the development of new means of production.  <br/>  <br/>Comment on this essay.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>German Translation  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>November 2015  <br/>  <br/>A few months ago an article about Y Combinator said that early on it had been<br/>a "one-man show." It's sadly common to read that sort of thing. But the<br/>problem with that description is not just that it's unfair. It's also<br/>misleading. Much of what's most novel about YC is due to Jessica Livingston.<br/>If you don't understand her, you don't understand YC. So let me tell you a<br/>little about Jessica.  <br/>  <br/>YC had 4 founders. Jessica and I decided one night to start it, and the next<br/>day we recruited my friends Robert Morris and Trevor Blackwell. Jessica and I<br/>ran YC day to day, and Robert and Trevor read applications and did interviews<br/>with us.  <br/>  <br/>Jessica and I were already dating when we started YC. At first we tried to act<br/>"professional" about this, meaning we tried to conceal it. In retrospect that<br/>seems ridiculous, and we soon dropped the pretense. And the fact that Jessica<br/>and I were a couple is a big part of what made YC what it was. YC felt like a<br/>family. The founders early on were mostly young. We all had dinner together<br/>once a week, cooked for the first couple years by me. Our first building had<br/>been a private home. The overall atmosphere was shockingly different from a<br/>VC's office on Sand Hill Road, in a way that was entirely for the better.<br/>There was an authenticity that everyone who walked in could sense. And that<br/>didn't just mean that people trusted us. It was the perfect quality to instill<br/>in startups. Authenticity is one of the most important things YC looks for in<br/>founders, not just because fakers and opportunists are annoying, but because<br/>authenticity is one of the main things that separates the most successful<br/>startups from the rest.  <br/>  <br/>Early YC was a family, and Jessica was its mom. And the culture she defined<br/>was one of YC's most important innovations. Culture is important in any<br/>organization, but at YC culture wasn't just how we behaved when we built the<br/>product. At YC, the culture was the product.  <br/>  <br/>Jessica was also the mom in another sense: she had the last word. Everything<br/>we did as an organization went through her first — who to fund, what to say to<br/>the public, how to deal with other companies, who to hire, everything.  <br/>  <br/>Before we had kids, YC was more or less our life. There was no real<br/>distinction between working hours and not. We talked about YC all the time.<br/>And while there might be some businesses that it would be tedious to let<br/>infect your private life, we liked it. We'd started YC because it was<br/>something we were interested in. And some of the problems we were trying to<br/>solve were endlessly difficult. How do you recognize good founders? You could<br/>talk about that for years, and we did; we still do.  <br/>  <br/>I'm better at some things than Jessica, and she's better at some things than<br/>me. One of the things she's best at is judging people. She's one of those rare<br/>individuals with x-ray vision for character. She can see through any kind of<br/>faker almost immediately. Her nickname within YC was the Social Radar, and<br/>this special power of hers was critical in making YC what it is. The earlier<br/>you pick startups, the more you're picking the founders. Later stage investors<br/>get to try products and look at growth numbers. At the stage where YC invests,<br/>there is often neither a product nor any numbers.  <br/>  <br/>Others thought YC had some special insight about the future of technology.<br/>Mostly we had the same sort of insight Socrates claimed: we at least knew we<br/>knew nothing. What made YC successful was being able to pick good founders. We<br/>thought Airbnb was a bad idea. We funded it because we liked the founders.  <br/>  <br/>During interviews, Robert and Trevor and I would pepper the applicants with<br/>technical questions. Jessica would mostly watch. A lot of the applicants<br/>probably read her as some kind of secretary, especially early on, because she<br/>was the one who'd go out and get each new group and she didn't ask many<br/>questions. She was ok with that. It was easier for her to watch people if they<br/>didn't notice her. But after the interview, the three of us would turn to<br/>Jessica and ask "What does the Social Radar say?" [1]  <br/>  <br/>Having the Social Radar at interviews wasn't just how we picked founders who'd<br/>be successful. It was also how we picked founders who were good people. At<br/>first we did this because we couldn't help it. Imagine what it would feel like<br/>to have x-ray vision for character. Being around bad people would be<br/>intolerable. So we'd refuse to fund founders whose characters we had doubts<br/>about even if we thought they'd be successful.  <br/>  <br/>Though we initially did this out of self-indulgence, it turned out to be very<br/>valuable to YC. We didn't realize it in the beginning, but the people we were<br/>picking would become the YC alumni network. And once we picked them, unless<br/>they did something really egregious, they were going to be part of it for<br/>life. Some now think YC's alumni network is its most valuable feature. I<br/>personally think YC's advice is pretty good too, but the alumni network is<br/>certainly among the most valuable features. The level of trust and helpfulness<br/>is remarkable for a group of such size. And Jessica is the main reason why.  <br/>  <br/>(As we later learned, it probably cost us little to reject people whose<br/>characters we had doubts about, because how good founders are and how well<br/>they do are _not orthogonal_. If bad founders succeed at all, they tend to<br/>sell early. The most successful founders are almost all good.)  <br/>  <br/>If Jessica was so important to YC, why don't more people realize it? Partly<br/>because I'm a writer, and writers always get disproportionate attention. YC's<br/>brand was initially my brand, and our applicants were people who'd read my<br/>essays. But there is another reason: Jessica hates attention. Talking to<br/>reporters makes her nervous. The thought of giving a talk paralyzes her. She<br/>was even uncomfortable at our wedding, because the bride is always the center<br/>of attention. [2]  <br/>  <br/>It's not just because she's shy that she hates attention, but because it<br/>throws off the Social Radar. She can't be herself. You can't watch people when<br/>everyone is watching you.  <br/>  <br/>Another reason attention worries her is that she hates bragging. In anything<br/>she does that's publicly visible, her biggest fear (after the obvious fear<br/>that it will be bad) is that it will seem ostentatious. She says being too<br/>modest is a common problem for women. But in her case it goes beyond that. She<br/>has a horror of ostentation so visceral it's almost a phobia.  <br/>  <br/>She also hates fighting. She can't do it; she just shuts down. And<br/>unfortunately there is a good deal of fighting in being the public face of an<br/>organization.  <br/>  <br/>So although Jessica more than anyone made YC unique, the very qualities that<br/>enabled her to do it mean she tends to get written out of YC's history.<br/>Everyone buys this story that PG started YC and his wife just kind of helped.<br/>Even YC's haters buy it. A couple years ago when people were attacking us for<br/>not funding more female founders (than exist), they all treated YC as<br/>identical with PG. It would have spoiled the narrative to acknowledge<br/>Jessica's central role at YC.  <br/>  <br/>Jessica was boiling mad that people were accusing _her_ company of sexism.<br/>I've never seen her angrier about anything. But she did not contradict them.<br/>Not publicly. In private there was a great deal of profanity. And she wrote<br/>three separate essays about the question of female founders. But she could<br/>never bring herself to publish any of them. She'd seen the level of vitriol in<br/>this debate, and she shrank from engaging. [3]  <br/>  <br/>It wasn't just because she disliked fighting. She's so sensitive to character<br/>that it repels her even to fight with dishonest people. The idea of mixing it<br/>up with linkbait journalists or Twitter trolls would seem to her not merely<br/>frightening, but disgusting.  <br/>  <br/>But Jessica knew her example as a successful female founder would encourage<br/>more women to start companies, so last year she did something YC had never<br/>done before and hired a PR firm to get her some interviews. At one of the<br/>first she did, the reporter brushed aside her insights about startups and<br/>turned it into a sensationalistic story about how some guy had tried to chat<br/>her up as she was waiting outside the bar where they had arranged to meet.<br/>Jessica was mortified, partly because the guy had done nothing wrong, but more<br/>because the story treated her as a victim significant only for being a woman,<br/>rather than one of the most knowledgeable investors in the Valley.  <br/>  <br/>After that she told the PR firm to stop.  <br/>  <br/>You're not going to be hearing in the press about what Jessica has achieved.<br/>So let me tell you what Jessica has achieved. Y Combinator is fundamentally a<br/>nexus of people, like a university. It doesn't make a product. What defines it<br/>is the people. Jessica more than anyone curated and nurtured that collection<br/>of people. In that sense she literally made YC.  <br/>  <br/>Jessica knows more about the qualities of startup founders than anyone else<br/>ever has. Her immense data set and x-ray vision are the perfect storm in that<br/>respect. The qualities of the founders are the best predictor of how a startup<br/>will do. And startups are in turn the most important source of growth in<br/>mature economies.  <br/>  <br/>The person who knows the most about the most important factor in the growth of<br/>mature economies — that is who Jessica Livingston is. Doesn't that sound like<br/>someone who should be better known?  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Harj Taggar reminded me that while Jessica didn't ask many questions, they<br/>tended to be important ones:  <br/>  <br/>"She was always good at sniffing out any red flags about the team or their<br/>determination and disarmingly asking the right question, which usually<br/>revealed more than the founders realized."  <br/>  <br/>[2] Or more precisely, while she likes getting attention in the sense of<br/>getting credit for what she has done, she doesn't like getting attention in<br/>the sense of being watched in real time. Unfortunately, not just for her but<br/>for a lot of people, how much you get of the former depends a lot on how much<br/>you get of the latter.  <br/>  <br/>Incidentally, if you saw Jessica at a public event, you would never guess she<br/>hates attention, because (a) she is very polite and (b) when she's nervous,<br/>she expresses it by smiling more.  <br/>  <br/>[3] The existence of people like Jessica is not just something the mainstream<br/>media needs to learn to acknowledge, but something feminists need to learn to<br/>acknowledge as well. There are successful women who don't like to fight. Which<br/>means if the public conversation about women consists of fighting, their<br/>voices will be silenced.  <br/>  <br/>There's a sort of Gresham's Law of conversations. If a conversation reaches a<br/>certain level of incivility, the more thoughtful people start to leave. No one<br/>understands female founders better than Jessica. But it's unlikely anyone will<br/>ever hear her speak candidly about the topic. She ventured a toe in that water<br/>a while ago, and the reaction was so violent that she decided "never again."  <br/>  <br/>**Thanks** to Sam Altman, Paul Buchheit, Patrick Collison, Daniel Gackle,<br/>Carolynn Levy, Jon Levy, Kirsty Nathoo, Robert Morris, Geoff Ralston, and Harj<br/>Taggar for reading drafts of this. And yes, Jessica Livingston, who made me<br/>cut surprisingly little.  <br/>  <br/>  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>March 2008, rev. June 2008  <br/>  <br/>Technology tends to separate normal from natural. Our bodies weren't designed<br/>to eat the foods that people in rich countries eat, or to get so little<br/>exercise. There may be a similar problem with the way we work: a normal job<br/>may be as bad for us intellectually as white flour or sugar is for us<br/>physically.  <br/>  <br/>I began to suspect this after spending several years working with startup<br/>founders. I've now worked with over 200 of them, and I've noticed a definite<br/>difference between programmers working on their own startups and those working<br/>for large organizations. I wouldn't say founders seem happier, necessarily;<br/>starting a startup can be very stressful. Maybe the best way to put it is to<br/>say that they're happier in the sense that your body is happier during a long<br/>run than sitting on a sofa eating doughnuts.  <br/>  <br/>Though they're statistically abnormal, startup founders seem to be working in<br/>a way that's more natural for humans.  <br/>  <br/>I was in Africa last year and saw a lot of animals in the wild that I'd only<br/>seen in zoos before. It was remarkable how different they seemed. Particularly<br/>lions. Lions in the wild seem about ten times more alive. They're like<br/>different animals. I suspect that working for oneself feels better to humans<br/>in much the same way that living in the wild must feel better to a wide-<br/>ranging predator like a lion. Life in a zoo is easier, but it isn't the life<br/>they were designed for.  <br/>  <br/>**Trees**  <br/>  <br/>What's so unnatural about working for a big company? The root of the problem<br/>is that humans weren't meant to work in such large groups.  <br/>  <br/>Another thing you notice when you see animals in the wild is that each species<br/>thrives in groups of a certain size. A herd of impalas might have 100 adults;<br/>baboons maybe 20; lions rarely 10. Humans also seem designed to work in<br/>groups, and what I've read about hunter-gatherers accords with research on<br/>organizations and my own experience to suggest roughly what the ideal size is:<br/>groups of 8 work well; by 20 they're getting hard to manage; and a group of 50<br/>is really unwieldy. [1]  <br/>  <br/>Whatever the upper limit is, we are clearly not meant to work in groups of<br/>several hundred. And yet—for reasons having more to do with technology than<br/>human nature—a great many people work for companies with hundreds or thousands<br/>of employees.  <br/>  <br/>Companies know groups that large wouldn't work, so they divide themselves into<br/>units small enough to work together. But to coordinate these they have to<br/>introduce something new: bosses.  <br/>  <br/>These smaller groups are always arranged in a tree structure. Your boss is the<br/>point where your group attaches to the tree. But when you use this trick for<br/>dividing a large group into smaller ones, something strange happens that I've<br/>never heard anyone mention explicitly. In the group one level up from yours,<br/>your boss represents your entire group. A group of 10 managers is not merely a<br/>group of 10 people working together in the usual way. It's really a group of<br/>groups. Which means for a group of 10 managers to work together as if they<br/>were simply a group of 10 individuals, the group working for each manager<br/>would have to work as if they were a single person—the workers and manager<br/>would each share only one person's worth of freedom between them.  <br/>  <br/>In practice a group of people are never able to act as if they were one<br/>person. But in a large organization divided into groups in this way, the<br/>pressure is always in that direction. Each group tries its best to work as if<br/>it were the small group of individuals that humans were designed to work in.<br/>That was the point of creating it. And when you propagate that constraint, the<br/>result is that each person gets freedom of action in inverse proportion to the<br/>size of the entire tree. [2]  <br/>  <br/>Anyone who's worked for a large organization has felt this. You can feel the<br/>difference between working for a company with 100 employees and one with<br/>10,000, even if your group has only 10 people.  <br/>  <br/>**Corn Syrup**  <br/>  <br/>A group of 10 people within a large organization is a kind of fake tribe. The<br/>number of people you interact with is about right. But something is missing:<br/>individual initiative. Tribes of hunter-gatherers have much more freedom. The<br/>leaders have a little more power than other members of the tribe, but they<br/>don't generally tell them what to do and when the way a boss can.  <br/>  <br/>It's not your boss's fault. The real problem is that in the group above you in<br/>the hierarchy, your entire group is one virtual person. Your boss is just the<br/>way that constraint is imparted to you.  <br/>  <br/>So working in a group of 10 people within a large organization feels both<br/>right and wrong at the same time. On the surface it feels like the kind of<br/>group you're meant to work in, but something major is missing. A job at a big<br/>company is like high fructose corn syrup: it has some of the qualities of<br/>things you're meant to like, but is disastrously lacking in others.  <br/>  <br/>Indeed, food is an excellent metaphor to explain what's wrong with the usual<br/>sort of job.  <br/>  <br/>For example, working for a big company is the default thing to do, at least<br/>for programmers. How bad could it be? Well, food shows that pretty clearly. If<br/>you were dropped at a random point in America today, nearly all the food<br/>around you would be bad for you. Humans were not designed to eat white flour,<br/>refined sugar, high fructose corn syrup, and hydrogenated vegetable oil. And<br/>yet if you analyzed the contents of the average grocery store you'd probably<br/>find these four ingredients accounted for most of the calories. "Normal" food<br/>is terribly bad for you. The only people who eat what humans were actually<br/>designed to eat are a few Birkenstock-wearing weirdos in Berkeley.  <br/>  <br/>If "normal" food is so bad for us, why is it so common? There are two main<br/>reasons. One is that it has more immediate appeal. You may feel lousy an hour<br/>after eating that pizza, but eating the first couple bites feels great. The<br/>other is economies of scale. Producing junk food scales; producing fresh<br/>vegetables doesn't. Which means (a) junk food can be very cheap, and (b) it's<br/>worth spending a lot to market it.  <br/>  <br/>If people have to choose between something that's cheap, heavily marketed, and<br/>appealing in the short term, and something that's expensive, obscure, and<br/>appealing in the long term, which do you think most will choose?  <br/>  <br/>It's the same with work. The average MIT graduate wants to work at Google or<br/>Microsoft, because it's a recognized brand, it's safe, and they'll get paid a<br/>good salary right away. It's the job equivalent of the pizza they had for<br/>lunch. The drawbacks will only become apparent later, and then only in a vague<br/>sense of malaise.  <br/>  <br/>And founders and early employees of startups, meanwhile, are like the<br/>Birkenstock-wearing weirdos of Berkeley: though a tiny minority of the<br/>population, they're the ones living as humans are meant to. In an artificial<br/>world, only extremists live naturally.  <br/>  <br/>**Programmers**  <br/>  <br/>The restrictiveness of big company jobs is particularly hard on programmers,<br/>because the essence of programming is to build new things. Sales people make<br/>much the same pitches every day; support people answer much the same<br/>questions; but once you've written a piece of code you don't need to write it<br/>again. So a programmer working as programmers are meant to is always making<br/>new things. And when you're part of an organization whose structure gives each<br/>person freedom in inverse proportion to the size of the tree, you're going to<br/>face resistance when you do something new.  <br/>  <br/>This seems an inevitable consequence of bigness. It's true even in the<br/>smartest companies. I was talking recently to a founder who considered<br/>starting a startup right out of college, but went to work for Google instead<br/>because he thought he'd learn more there. He didn't learn as much as he<br/>expected. Programmers learn by doing, and most of the things he wanted to do,<br/>he couldn't—sometimes because the company wouldn't let him, but often because<br/>the company's code wouldn't let him. Between the drag of legacy code, the<br/>overhead of doing development in such a large organization, and the<br/>restrictions imposed by interfaces owned by other groups, he could only try a<br/>fraction of the things he would have liked to. He said he has learned much<br/>more in his own startup, despite the fact that he has to do all the company's<br/>errands as well as programming, because at least when he's programming he can<br/>do whatever he wants.  <br/>  <br/>An obstacle downstream propagates upstream. If you're not allowed to implement<br/>new ideas, you stop having them. And vice versa: when you can do whatever you<br/>want, you have more ideas about what to do. So working for yourself makes your<br/>brain more powerful in the same way a low-restriction exhaust system makes an<br/>engine more powerful.  <br/>  <br/>Working for yourself doesn't have to mean starting a startup, of course. But a<br/>programmer deciding between a regular job at a big company and their own<br/>startup is probably going to learn more doing the startup.  <br/>  <br/>You can adjust the amount of freedom you get by scaling the size of company<br/>you work for. If you start the company, you'll have the most freedom. If you<br/>become one of the first 10 employees you'll have almost as much freedom as the<br/>founders. Even a company with 100 people will feel different from one with<br/>1000.  <br/>  <br/>Working for a small company doesn't ensure freedom. The tree structure of<br/>large organizations sets an upper bound on freedom, not a lower bound. The<br/>head of a small company may still choose to be a tyrant. The point is that a<br/>large organization is compelled by its structure to be one.  <br/>  <br/>**Consequences**  <br/>  <br/>That has real consequences for both organizations and individuals. One is that<br/>companies will inevitably slow down as they grow larger, no matter how hard<br/>they try to keep their startup mojo. It's a consequence of the tree structure<br/>that every large organization is forced to adopt.  <br/>  <br/>Or rather, a large organization could only avoid slowing down if they avoided<br/>tree structure. And since human nature limits the size of group that can work<br/>together, the only way I can imagine for larger groups to avoid tree structure<br/>would be to have no structure: to have each group actually be independent, and<br/>to work together the way components of a market economy do.  <br/>  <br/>That might be worth exploring. I suspect there are already some highly<br/>partitionable businesses that lean this way. But I don't know any technology<br/>companies that have done it.  <br/>  <br/>There is one thing companies can do short of structuring themselves as<br/>sponges: they can stay small. If I'm right, then it really pays to keep a<br/>company as small as it can be at every stage. Particularly a technology<br/>company. Which means it's doubly important to hire the best people. Mediocre<br/>hires hurt you twice: they get less done, but they also make you big, because<br/>you need more of them to solve a given problem.  <br/>  <br/>For individuals the upshot is the same: aim small. It will always suck to work<br/>for large organizations, and the larger the organization, the more it will<br/>suck.  <br/>  <br/>In an essay I wrote a couple years ago I advised graduating seniors to work<br/>for a couple years for another company before starting their own. I'd modify<br/>that now. Work for another company if you want to, but only for a small one,<br/>and if you want to start your own startup, go ahead.  <br/>  <br/>The reason I suggested college graduates not start startups immediately was<br/>that I felt most would fail. And they will. But ambitious programmers are<br/>better off doing their own thing and failing than going to work at a big<br/>company. Certainly they'll learn more. They might even be better off<br/>financially. A lot of people in their early twenties get into debt, because<br/>their expenses grow even faster than the salary that seemed so high when they<br/>left school. At least if you start a startup and fail your net worth will be<br/>zero rather than negative. [3]  <br/>  <br/>We've now funded so many different types of founders that we have enough data<br/>to see patterns, and there seems to be no benefit from working for a big<br/>company. The people who've worked for a few years do seem better than the ones<br/>straight out of college, but only because they're that much older.  <br/>  <br/>The people who come to us from big companies often seem kind of conservative.<br/>It's hard to say how much is because big companies made them that way, and how<br/>much is the natural conservatism that made them work for the big companies in<br/>the first place. But certainly a large part of it is learned. I know because<br/>I've seen it burn off.  <br/>  <br/>Having seen that happen so many times is one of the things that convinces me<br/>that working for oneself, or at least for a small group, is the natural way<br/>for programmers to live. Founders arriving at Y Combinator often have the<br/>downtrodden air of refugees. Three months later they're transformed: they have<br/>so much more confidence that they seem as if they've grown several inches<br/>taller. [4] Strange as this sounds, they seem both more worried and happier at<br/>the same time. Which is exactly how I'd describe the way lions seem in the<br/>wild.  <br/>  <br/>Watching employees get transformed into founders makes it clear that the<br/>difference between the two is due mostly to environment—and in particular that<br/>the environment in big companies is toxic to programmers. In the first couple<br/>weeks of working on their own startup they seem to come to life, because<br/>finally they're working the way people are meant to.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] When I talk about humans being meant or designed to live a certain way, I<br/>mean by evolution.  <br/>  <br/>[2] It's not only the leaves who suffer. The constraint propagates up as well<br/>as down. So managers are constrained too; instead of just doing things, they<br/>have to act through subordinates.  <br/>  <br/>[3] Do not finance your startup with credit cards. Financing a startup with<br/>debt is usually a stupid move, and credit card debt stupidest of all. Credit<br/>card debt is a bad idea, period. It is a trap set by evil companies for the<br/>desperate and the foolish.  <br/>  <br/>[4] The founders we fund used to be younger (initially we encouraged<br/>undergrads to apply), and the first couple times I saw this I used to wonder<br/>if they were actually getting physically taller.  <br/>  <br/> **Thanks** to Trevor Blackwell, Ross Boucher, Aaron Iba, Abby Kirigin, Ivan<br/>Kirigin, Jessica Livingston, and Robert Morris for reading drafts of this.  <br/>  <br/>  <br/><br/>French Translation  <br/><br/>Russian Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>November 2004, corrected June 2006  <br/>  <br/>Occam's razor says we should prefer the simpler of two explanations. I begin<br/>by reminding readers of this principle because I'm about to propose a theory<br/>that will offend both liberals and conservatives. But Occam's razor means, in<br/>effect, that if you want to disagree with it, you have a hell of a coincidence<br/>to explain.  <br/>  <br/>Theory: In US presidential elections, the more charismatic candidate wins.  <br/>  <br/>People who write about politics, whether on the left or the right, have a<br/>consistent bias: they take politics seriously. When one candidate beats<br/>another they look for political explanations. The country is shifting to the<br/>left, or the right. And that sort of shift can certainly be the result of a<br/>presidential election, which makes it easy to believe it was the cause.  <br/>  <br/>But when I think about why I voted for Clinton over the first George Bush, it<br/>wasn't because I was shifting to the left. Clinton just seemed more dynamic.<br/>He seemed to want the job more. Bush seemed old and tired. I suspect it was<br/>the same for a lot of voters.  <br/>  <br/>Clinton didn't represent any national shift leftward. [1] He was just more<br/>charismatic than George Bush or (God help us) Bob Dole. In 2000 we practically<br/>got a controlled experiment to prove it: Gore had Clinton's policies, but not<br/>his charisma, and he suffered proportionally. [2] Same story in 2004. Kerry<br/>was smarter and more articulate than Bush, but rather a stiff. And Kerry lost.  <br/>  <br/>As I looked further back, I kept finding the same pattern. Pundits said Carter<br/>beat Ford because the country distrusted the Republicans after Watergate. And<br/>yet it also happened that Carter was famous for his big grin and folksy ways,<br/>and Ford for being a boring klutz. Four years later, pundits said the country<br/>had lurched to the right. But Reagan, a former actor, also happened to be even<br/>more charismatic than Carter (whose grin was somewhat less cheery after four<br/>stressful years in office). In 1984 the charisma gap between Reagan and<br/>Mondale was like that between Clinton and Dole, with similar results. The<br/>first George Bush managed to win in 1988, though he would later be vanquished<br/>by one of the most charismatic presidents ever, because in 1988 he was up<br/>against the notoriously uncharismatic Michael Dukakis.  <br/>  <br/>These are the elections I remember personally, but apparently the same pattern<br/>played out in 1964 and 1972. The most recent counterexample appears to be<br/>1968, when Nixon beat the more charismatic Hubert Humphrey. But when you<br/>examine that election, it tends to support the charisma theory more than<br/>contradict it. As Joe McGinnis recounts in his famous book _The Selling of the<br/>President 1968_ , Nixon knew he had less charisma than Humphrey, and thus<br/>simply refused to debate him on TV. He knew he couldn't afford to let the two<br/>of them be seen side by side.  <br/>  <br/>Now a candidate probably couldn't get away with refusing to debate. But in<br/>1968 the custom of televised debates was still evolving. In effect, Nixon won<br/>in 1968 because voters were never allowed to see the real Nixon. All they saw<br/>were carefully scripted campaign spots.  <br/>  <br/>Oddly enough, the most recent true counterexample is probably 1960. Though<br/>this election is usually given as an example of the power of TV, Kennedy<br/>apparently would not have won without fraud by party machines in Illinois and<br/>Texas. But TV was still young in 1960; only 87% of households had it. [3]<br/>Undoubtedly TV helped Kennedy, so historians are correct in regarding this<br/>election as a watershed. TV required a new kind of candidate. There would be<br/>no more Calvin Coolidges.  <br/>  <br/>The charisma theory may also explain why Democrats tend to lose presidential<br/>elections. The core of the Democrats' ideology seems to be a belief in<br/>government. Perhaps this tends to attract people who are earnest, but dull.<br/>Dukakis, Gore, and Kerry were so similar in that respect that they might have<br/>been brothers. Good thing for the Democrats that their screen lets through an<br/>occasional Clinton, even if some scandal results. [4]  <br/>  <br/>One would like to believe elections are won and lost on issues, if only fake<br/>ones like Willie Horton. And yet, if they are, we have a remarkable<br/>coincidence to explain. In every presidential election since TV became<br/>widespread, the apparently more charismatic candidate has won. Surprising,<br/>isn't it, that voters' opinions on the issues have lined up with charisma for<br/>11 elections in a row?  <br/>  <br/>The political commentators who come up with shifts to the left or right in<br/>their morning-after analyses are like the financial reporters stuck writing<br/>stories day after day about the random fluctuations of the stock market. Day<br/>ends, market closes up or down, reporter looks for good or bad news<br/>respectively, and writes that the market was up on news of Intel's earnings,<br/>or down on fears of instability in the Middle East. Suppose we could somehow<br/>feed these reporters false information about market closes, but give them all<br/>the other news intact. Does anyone believe they would notice the anomaly, and<br/>not simply write that stocks were up (or down) on whatever good (or bad) news<br/>there was that day? That they would say, hey, wait a minute, how can stocks be<br/>up with all this unrest in the Middle East?  <br/>  <br/>I'm not saying that issues don't matter to voters. Of course they do. But the<br/>major parties know so well which issues matter how much to how many voters,<br/>and adjust their message so precisely in response, that they tend to split the<br/>difference on the issues, leaving the election to be decided by the one factor<br/>they can't control: charisma.  <br/>  <br/>If the Democrats had been running a candidate as charismatic as Clinton in the<br/>2004 election, he'd have won. And we'd be reading that the election was a<br/>referendum on the war in Iraq, instead of that the Democrats are out of touch<br/>with evangelical Christians in middle America.  <br/>  <br/>During the 1992 election, the Clinton campaign staff had a big sign in their<br/>office saying "It's the economy, stupid." Perhaps it was even simpler than<br/>they thought.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Postscript**  <br/>  <br/>Opinions seem to be divided about the charisma theory. Some say it's<br/>impossible, others say it's obvious. This seems a good sign. Perhaps it's in<br/>the sweet spot midway between.  <br/>  <br/>As for it being impossible, I reply: here's the data; here's the theory;<br/>theory explains data 100%. To a scientist, at least, that means it deserves<br/>attention, however implausible it seems.  <br/>  <br/>You can't believe voters are so superficial that they just choose the most<br/>charismatic guy? My theory doesn't require that. I'm not proposing that<br/>charisma is the only factor, just that it's the only one _left_ after the<br/>efforts of the two parties cancel one another out.  <br/>  <br/>As for the theory being obvious, as far as I know, no one has proposed it<br/>before. Election forecasters are proud when they can achieve the same results<br/>with much more complicated models.  <br/>  <br/>Finally, to the people who say that the theory is probably true, but rather<br/>depressing: it's not so bad as it seems. The phenomenon is like a pricing<br/>anomaly; once people realize it's there, it will disappear. Once both parties<br/>realize it's a waste of time to nominate uncharismatic candidates, they'll<br/>tend to nominate only the most charismatic ones. And if the candidates are<br/>equally charismatic, charisma will cancel out, and elections will be decided<br/>on issues, as political commentators like to think they are now.  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] As Clinton himself discovered to his surprise when, in one of his first<br/>acts as president, he tried to shift the military leftward. After a bruising<br/>fight he escaped with a face-saving compromise.  <br/>  <br/>[2] True, Gore won the popular vote. But politicians know the electoral vote<br/>decides the election, so that's what they campaign for. If Bush had been<br/>campaigning for the popular vote he would presumably have got more of it.<br/>(Thanks to judgmentalist for this point.)  <br/>  <br/>[3] Source: Nielsen Media Research. Of the remaining 13%, 11 didn't have TV<br/>because they couldn't afford it. I'd argue that the missing 11% were probably<br/>also the 11% most susceptible to charisma.  <br/>  <br/>[4] One implication of this theory is that parties shouldn't be too quick to<br/>reject candidates with skeletons in their closets. Charismatic candidates will<br/>tend to have more skeletons than squeaky clean dullards, but in practice that<br/>doesn't seem to lose elections. The current Bush, for example, probably did<br/>more drugs in his twenties than any preceding president, and yet managed to<br/>get elected with a base of evangelical Christians. All you have to do is say<br/>you've reformed, and stonewall about the details.  <br/>  <br/> **Thanks** to Trevor Blackwell, Maria Daniels, Jessica Livingston, Jackie<br/>McDonough, and Robert Morris for reading drafts of this, and to Eric Raymond<br/>for pointing out that I was wrong about 1968.  <br/>  <br/>Comment on this essay.  <br/>  <br/>  <br/><br/>What Charisma Is  <br/>  <br/><br/>Politics and the Art of Acting  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>March 2005  <br/>  <br/> _(Parts of this essay began as replies to students who wrote to me with<br/>questions.)_  <br/>  <br/>Recently I've had several emails from computer science undergrads asking what<br/>to do in college. I might not be the best source of advice, because I was a<br/>philosophy major in college. But I took so many CS classes that most CS majors<br/>thought I was one. I was certainly a hacker, at least.  <br/>  <br/> **Hacking**  <br/>  <br/>What should you do in college to become a good hacker? There are two main<br/>things you can do: become very good at programming, and learn a lot about<br/>specific, cool problems. These turn out to be equivalent, because each drives<br/>you to do the other.  <br/>  <br/>The way to be good at programming is to work (a) a lot (b) on hard problems.<br/>And the way to make yourself work on hard problems is to work on some very<br/>engaging project.  <br/>  <br/>Odds are this project won't be a class assignment. My friend Robert learned a<br/>lot by writing network software when he was an undergrad. One of his projects<br/>was to connect Harvard to the Arpanet; it had been one of the original nodes,<br/>but by 1984 the connection had died. [1] Not only was this work not for a<br/>class, but because he spent all his time on it and neglected his studies, he<br/>was kicked out of school for a year. [2] It all evened out in the end, and now<br/>he's a professor at MIT. But you'll probably be happier if you don't go to<br/>that extreme; it caused him a lot of worry at the time.  <br/>  <br/>Another way to be good at programming is to find other people who are good at<br/>it, and learn what they know. Programmers tend to sort themselves into tribes<br/>according to the type of work they do and the tools they use, and some tribes<br/>are smarter than others. Look around you and see what the smart people seem to<br/>be working on; there's usually a reason.  <br/>  <br/>Some of the smartest people around you are professors. So one way to find<br/>interesting work is to volunteer as a research assistant. Professors are<br/>especially interested in people who can solve tedious system-administration<br/>type problems for them, so that is a way to get a foot in the door. What they<br/>fear are flakes and resume padders. It's all too common for an assistant to<br/>result in a net increase in work. So you have to make it clear you'll mean a<br/>net decrease.  <br/>  <br/>Don't be put off if they say no. Rejection is almost always less personal than<br/>the rejectee imagines. Just move on to the next. (This applies to dating too.)  <br/>  <br/>Beware, because although most professors are smart, not all of them work on<br/>interesting stuff. Professors have to publish novel results to advance their<br/>careers, but there is more competition in more interesting areas of research.<br/>So what less ambitious professors do is turn out a series of papers whose<br/>conclusions are novel because no one else cares about them. You're better off<br/>avoiding these.  <br/>  <br/>I never worked as a research assistant, so I feel a bit dishonest recommending<br/>that route. I learned to program by writing stuff of my own, particularly by<br/>trying to reverse-engineer Winograd's SHRDLU. I was as obsessed with that<br/>program as a mother with a new baby.  <br/>  <br/>Whatever the disadvantages of working by yourself, the advantage is that the<br/>project is all your own. You never have to compromise or ask anyone's<br/>permission, and if you have a new idea you can just sit down and start<br/>implementing it.  <br/>  <br/>In your own projects you don't have to worry about novelty (as professors do)<br/>or profitability (as businesses do). All that matters is how hard the project<br/>is technically, and that has no correlation to the nature of the application.<br/>"Serious" applications like databases are often trivial and dull technically<br/>(if you ever suffer from insomnia, try reading the technical literature about<br/>databases) while "frivolous" applications like games are often very<br/>sophisticated. I'm sure there are game companies out there working on products<br/>with more intellectual content than the research at the bottom nine tenths of<br/>university CS departments.  <br/>  <br/>If I were in college now I'd probably work on graphics: a network game, for<br/>example, or a tool for 3D animation. When I was an undergrad there weren't<br/>enough cycles around to make graphics interesting, but it's hard to imagine<br/>anything more fun to work on now.  <br/>  <br/> **Math**  <br/>  <br/>When I was in college, a lot of the professors believed (or at least wished)<br/>that computer science was a branch of math. This idea was strongest at<br/>Harvard, where there wasn't even a CS major till the 1980s; till then one had<br/>to major in applied math. But it was nearly as bad at Cornell. When I told the<br/>fearsome Professor Conway that I was interested in AI (a hot topic then), he<br/>told me I should major in math. I'm still not sure whether he thought AI<br/>required math, or whether he thought AI was nonsense and that majoring in<br/>something rigorous would cure me of such stupid ambitions.  <br/>  <br/>In fact, the amount of math you need as a hacker is a lot less than most<br/>university departments like to admit. I don't think you need much more than<br/>high school math plus a few concepts from the theory of computation. (You have<br/>to know what an n^2 algorithm is if you want to avoid writing them.) Unless<br/>you're planning to write math applications, of course. Robotics, for example,<br/>is all math.  <br/>  <br/>But while you don't literally need math for most kinds of hacking, in the<br/>sense of knowing 1001 tricks for differentiating formulas, math is very much<br/>worth studying for its own sake. It's a valuable source of metaphors for<br/>almost any kind of work.[3] I wish I'd studied more math in college for that<br/>reason.  <br/>  <br/>Like a lot of people, I was mathematically abused as a child. I learned to<br/>think of math as a collection of formulas that were neither beautiful nor had<br/>any relation to my life (despite attempts to translate them into "word<br/>problems"), but had to be memorized in order to do well on tests.  <br/>  <br/>One of the most valuable things you could do in college would be to learn what<br/>math is really about. This may not be easy, because a lot of good<br/>mathematicians are bad teachers. And while there are many popular books on<br/>math, few seem good. The best I can think of are W. W. Sawyer's. And of course<br/>Euclid. [4]  <br/>  <br/> **Everything**  <br/>  <br/>Thomas Huxley said "Try to learn something about everything and everything<br/>about something." Most universities aim at this ideal.  <br/>  <br/>But what's everything? To me it means, all that people learn in the course of<br/>working honestly on hard problems. All such work tends to be related, in that<br/>ideas and techniques from one field can often be transplanted successfully to<br/>others. Even others that seem quite distant. For example, I write essays the<br/>same way I write software: I sit down and blow out a lame version 1 as fast as<br/>I can type, then spend several weeks rewriting it.  <br/>  <br/>Working on hard problems is not, by itself, enough. Medieval alchemists were<br/>working on a hard problem, but their approach was so bogus that there was<br/>little to learn from studying it, except possibly about people's ability to<br/>delude themselves. Unfortunately the sort of AI I was trying to learn in<br/>college had the same flaw: a very hard problem, blithely approached with<br/>hopelessly inadequate techniques. Bold? Closer to fraudulent.  <br/>  <br/>The social sciences are also fairly bogus, because they're so much influenced<br/>by intellectual fashions. If a physicist met a colleague from 100 years ago,<br/>he could teach him some new things; if a psychologist met a colleague from 100<br/>years ago, they'd just get into an ideological argument. Yes, of course,<br/>you'll learn something by taking a psychology class. The point is, you'll<br/>learn more by taking a class in another department.  <br/>  <br/>The worthwhile departments, in my opinion, are math, the hard sciences,<br/>engineering, history (especially economic and social history, and the history<br/>of science), architecture, and the classics. A survey course in art history<br/>may be worthwhile. Modern literature is important, but the way to learn about<br/>it is just to read. I don't know enough about music to say.  <br/>  <br/>You can skip the social sciences, philosophy, and the various departments<br/>created recently in response to political pressures. Many of these fields talk<br/>about important problems, certainly. But the way they talk about them is<br/>useless. For example, philosophy talks, among other things, about our<br/>obligations to one another; but you can learn more about this from a wise<br/>grandmother or E. B. White than from an academic philosopher.  <br/>  <br/>I speak here from experience. I should probably have been offended when people<br/>laughed at Clinton for saying "It depends on what the meaning of the word 'is'<br/>is." I took about five classes in college on what the meaning of "is" is.  <br/>  <br/>Another way to figure out which fields are worth studying is to create the<br/>_dropout graph._ For example, I know many people who switched from math to<br/>computer science because they found math too hard, and no one who did the<br/>opposite. People don't do hard things gratuitously; no one will work on a<br/>harder problem unless it is proportionately (or at least log(n)) more<br/>rewarding. So probably math is more worth studying than computer science. By<br/>similar comparisons you can make a graph of all the departments in a<br/>university. At the bottom you'll find the subjects with least intellectual<br/>content.  <br/>  <br/>If you use this method, you'll get roughly the same answer I just gave.  <br/>  <br/>Language courses are an anomaly. I think they're better considered as<br/>extracurricular activities, like pottery classes. They'd be far more useful<br/>when combined with some time living in a country where the language is spoken.<br/>On a whim I studied Arabic as a freshman. It was a lot of work, and the only<br/>lasting benefits were a weird ability to identify semitic roots and some<br/>insights into how people recognize words.  <br/>  <br/>Studio art and creative writing courses are wildcards. Usually you don't get<br/>taught much: you just work (or don't work) on whatever you want, and then sit<br/>around offering "crits" of one another's creations under the vague supervision<br/>of the teacher. But writing and art are both very hard problems that (some)<br/>people work honestly at, so they're worth doing, especially if you can find a<br/>good teacher.  <br/>  <br/> **Jobs**  <br/>  <br/>Of course college students have to think about more than just learning. There<br/>are also two practical problems to consider: jobs, and graduate school.  <br/>  <br/>In theory a liberal education is not supposed to supply job training. But<br/>everyone knows this is a bit of a fib. Hackers at every college learn<br/>practical skills, and not by accident.  <br/>  <br/>What you should learn to get a job depends on the kind you want. If you want<br/>to work in a big company, learn how to hack Blub on Windows. If you want to<br/>work at a cool little company or research lab, you'll do better to learn Ruby<br/>on Linux. And if you want to start your own company, which I think will be<br/>more and more common, master the most powerful tools you can find, because<br/>you're going to be in a race against your competitors, and they'll be your<br/>horse.  <br/>  <br/>There is not a direct correlation between the skills you should learn in<br/>college and those you'll use in a job. You should aim slightly high in<br/>college.  <br/>  <br/>In workouts a football player may bench press 300 pounds, even though he may<br/>never have to exert anything like that much force in the course of a game.<br/>Likewise, if your professors try to make you learn stuff that's more advanced<br/>than you'll need in a job, it may not just be because they're academics,<br/>detached from the real world. They may be trying to make you lift weights with<br/>your brain.  <br/>  <br/>The programs you write in classes differ in three critical ways from the ones<br/>you'll write in the real world: they're small; you get to start from scratch;<br/>and the problem is usually artificial and predetermined. In the real world,<br/>programs are bigger, tend to involve existing code, and often require you to<br/>figure out what the problem is before you can solve it.  <br/>  <br/>You don't have to wait to leave (or even enter) college to learn these skills.<br/>If you want to learn how to deal with existing code, for example, you can<br/>contribute to open-source projects. The sort of employer you want to work for<br/>will be as impressed by that as good grades on class assignments.  <br/>  <br/>In existing open-source projects you don't get much practice at the third<br/>skill, deciding what problems to solve. But there's nothing to stop you<br/>starting new projects of your own. And good employers will be even more<br/>impressed with that.  <br/>  <br/>What sort of problem should you try to solve? One way to answer that is to ask<br/>what you need as a user. For example, I stumbled on a good algorithm for spam<br/>filtering because I wanted to stop getting spam. Now what I wish I had was a<br/>mail reader that somehow prevented my inbox from filling up. I tend to use my<br/>inbox as a todo list. But that's like using a screwdriver to open bottles;<br/>what one really wants is a bottle opener.  <br/>  <br/> **Grad School**  <br/>  <br/>What about grad school? Should you go? And how do you get into a good one?  <br/>  <br/>In principle, grad school is professional training in research, and you<br/>shouldn't go unless you want to do research as a career. And yet half the<br/>people who get PhDs in CS don't go into research. I didn't go to grad school<br/>to become a professor. I went because I wanted to learn more.  <br/>  <br/>So if you're mainly interested in hacking and you go to grad school, you'll<br/>find a lot of other people who are similarly out of their element. And if half<br/>the people around you are out of their element in the same way you are, are<br/>you really out of your element?  <br/>  <br/>There's a fundamental problem in "computer science," and it surfaces in<br/>situations like this. No one is sure what "research" is supposed to be. A lot<br/>of research is hacking that had to be crammed into the form of an academic<br/>paper to yield one more quantum of publication.  <br/>  <br/>So it's kind of misleading to ask whether you'll be at home in grad school,<br/>because very few people are quite at home in computer science. The whole field<br/>is uncomfortable in its own skin. So the fact that you're mainly interested in<br/>hacking shouldn't deter you from going to grad school. Just be warned you'll<br/>have to do a lot of stuff you don't like.  <br/>  <br/>Number one will be your dissertation. Almost everyone hates their dissertation<br/>by the time they're done with it. The process inherently tends to produce an<br/>unpleasant result, like a cake made out of whole wheat flour and baked for<br/>twelve hours. Few dissertations are read with pleasure, especially by their<br/>authors.  <br/>  <br/>But thousands before you have suffered through writing a dissertation. And<br/>aside from that, grad school is close to paradise. Many people remember it as<br/>the happiest time of their lives. And nearly all the rest, including me,<br/>remember it as a period that would have been, if they hadn't had to write a<br/>dissertation. [5]  <br/>  <br/>The danger with grad school is that you don't see the scary part upfront. PhD<br/>programs start out as college part 2, with several years of classes. So by the<br/>time you face the horror of writing a dissertation, you're already several<br/>years in. If you quit now, you'll be a grad-school dropout, and you probably<br/>won't like that idea. When Robert got kicked out of grad school for writing<br/>the Internet worm of 1988, I envied him enormously for finding a way out<br/>without the stigma of failure.  <br/>  <br/>On the whole, grad school is probably better than most alternatives. You meet<br/>a lot of smart people, and your glum procrastination will at least be a<br/>powerful common bond. And of course you have a PhD at the end. I forgot about<br/>that. I suppose that's worth something.  <br/>  <br/>The greatest advantage of a PhD (besides being the union card of academia, of<br/>course) may be that it gives you some baseline confidence. For example, the<br/>Honeywell thermostats in my house have the most atrocious UI. My mother, who<br/>has the same model, diligently spent a day reading the user's manual to learn<br/>how to operate hers. She assumed the problem was with her. But I can think to<br/>myself "If someone with a PhD in computer science can't understand this<br/>thermostat, it _must_ be badly designed."  <br/>  <br/>If you still want to go to grad school after this equivocal recommendation, I<br/>can give you solid advice about how to get in. A lot of my friends are CS<br/>professors now, so I have the inside story about admissions. It's quite<br/>different from college. At most colleges, admissions officers decide who gets<br/>in. For PhD programs, the professors do. And they try to do it well, because<br/>the people they admit are going to be working for them.  <br/>  <br/>Apparently only recommendations really matter at the best schools.<br/>Standardized tests count for nothing, and grades for little. The essay is<br/>mostly an opportunity to disqualify yourself by saying something stupid. The<br/>only thing professors trust is recommendations, preferably from people they<br/>know. [6]  <br/>  <br/>So if you want to get into a PhD program, the key is to impress your<br/>professors. And from my friends who are professors I know what impresses them:<br/>not merely trying to impress them. They're not impressed by students who get<br/>good grades or want to be their research assistants so they can get into grad<br/>school. They're impressed by students who get good grades and want to be their<br/>research assistants because they're genuinely interested in the topic.  <br/>  <br/>So the best thing you can do in college, whether you want to get into grad<br/>school or just be good at hacking, is figure out what you truly like. It's<br/>hard to trick professors into letting you into grad school, and impossible to<br/>trick problems into letting you solve them. College is where faking stops<br/>working. From this point, unless you want to go work for a big company, which<br/>is like reverting to high school, the only way forward is through doing what<br/>you love.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] No one seems to have minded, which shows how unimportant the Arpanet<br/>(which became the Internet) was as late as 1984.  <br/>  <br/>[2] This is why, when I became an employer, I didn't care about GPAs. In fact,<br/>we actively sought out people who'd failed out of school. We once put up<br/>posters around Harvard saying "Did you just get kicked out for doing badly in<br/>your classes because you spent all your time working on some project of your<br/>own? Come work for us!" We managed to find a kid who had been, and he was a<br/>great hacker.  <br/>  <br/>When Harvard kicks undergrads out for a year, they have to get jobs. The idea<br/>is to show them how awful the real world is, so they'll understand how lucky<br/>they are to be in college. This plan backfired with the guy who came to work<br/>for us, because he had more fun than he'd had in school, and made more that<br/>year from stock options than any of his professors did in salary. So instead<br/>of crawling back repentant at the end of the year, he took another year off<br/>and went to Europe. He did eventually graduate at about 26.  <br/>  <br/>[3] Eric Raymond says the best metaphors for hackers are in set theory,<br/>combinatorics, and graph theory.  <br/>  <br/>Trevor Blackwell reminds you to take math classes intended for math majors.<br/>"'Math for engineers' classes sucked mightily. In fact any 'x for engineers'<br/>sucks, where x includes math, law, writing and visual design."  <br/>  <br/>[4] Other highly recommended books: _What is Mathematics?_ , by Courant and<br/>Robbins; _Geometry and the Imagination_ by Hilbert and Cohn-Vossen. And for<br/>those interested in graphic design, Byrne's Euclid.  <br/>  <br/>[5] If you wanted to have the perfect life, the thing to do would be to go to<br/>grad school, secretly write your dissertation in the first year or two, and<br/>then just enjoy yourself for the next three years, dribbling out a chapter at<br/>a time. This prospect will make grad students' mouths water, but I know of no<br/>one who's had the discipline to pull it off.  <br/>  <br/>[6] One professor friend says that 15-20% of the grad students they admit each<br/>year are "long shots." But what he means by long shots are people whose<br/>applications are perfect in every way, except that no one on the admissions<br/>committee knows the professors who wrote the recommendations.  <br/>  <br/>So if you want to get into grad school in the sciences, you need to go to<br/>college somewhere with real research professors. Otherwise you'll seem a risky<br/>bet to admissions committees, no matter how good you are.  <br/>  <br/>Which implies a surprising but apparently inevitable consequence: little<br/>liberal arts colleges are doomed.  Most smart high school kids at least<br/>consider going into the sciences, even if they ultimately choose not to. Why<br/>go to a college that limits their options?  <br/>  <br/>  <br/>  <br/> **Thanks** to Trevor Blackwell, Alex Lewin, Jessica Livingston, Robert<br/>Morris, Eric Raymond, and several anonymous CS professors for reading drafts<br/>of this, and to the students whose questions began it.  <br/>  <br/>  <br/><br/>More Advice for Undergrads  <br/>  <br/><br/>Joel Spolsky: Advice for Computer Science College Students  <br/>  <br/><br/>Eric Raymond: How to Become a Hacker  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>January 2015  <br/>  <br/>My father is a mathematician. For most of my childhood he worked for<br/>Westinghouse, modelling nuclear reactors.  <br/>  <br/>He was one of those lucky people who know early on what they want to do. When<br/>you talk to him about his childhood, there's a clear watershed at about age<br/>12, when he "got interested in maths."  <br/>  <br/>He grew up in the small Welsh seacoast town of Pwllheli. As we retraced his<br/>walk to school on Google Street View, he said that it had been nice growing up<br/>in the country.  <br/>  <br/>"Didn't it get boring when you got to be about 15?" I asked.  <br/>  <br/>"No," he said, "by then I was interested in maths."  <br/>  <br/>In another conversation he told me that what he really liked was solving<br/>problems. To me the exercises at the end of each chapter in a math textbook<br/>represent work, or at best a way to reinforce what you learned in that<br/>chapter. To him the problems were the reward. The text of each chapter was<br/>just some advice about solving them. He said that as soon as he got a new<br/>textbook he'd immediately work out all the problems — to the slight annoyance<br/>of his teacher, since the class was supposed to work through the book<br/>gradually.  <br/>  <br/>Few people know so early or so certainly what they want to work on. But<br/>talking to my father reminded me of a heuristic the rest of us can use. If<br/>something that seems like work to other people doesn't seem like work to you,<br/>that's something you're well suited for. For example, a lot of programmers I<br/>know, including me, actually like debugging. It's not something people tend to<br/>volunteer; one likes it the way one likes popping zits. But you may have to<br/>like debugging to like programming, considering the degree to which<br/>programming consists of it.  <br/>  <br/>The stranger your tastes seem to other people, the stronger evidence they<br/>probably are of what you should do. When I was in college I used to write<br/>papers for my friends. It was quite interesting to write a paper for a class I<br/>wasn't taking. Plus they were always so relieved.  <br/>  <br/>It seemed curious that the same task could be painful to one person and<br/>pleasant to another, but I didn't realize at the time what this imbalance<br/>implied, because I wasn't looking for it. I didn't realize how hard it can be<br/>to decide what you should work on, and that you sometimes have to figure it<br/>out from subtle clues, like a detective solving a case in a mystery novel. So<br/>I bet it would help a lot of people to ask themselves about this explicitly.<br/>What seems like work to other people that doesn't seem like work to you?  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Thanks** to Sam Altman, Trevor Blackwell, Jessica Livingston, Robert Morris,<br/>and my father for reading drafts of this.  <br/>  <br/><br/>Robert Morris: All About Programming  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>March 2006  <br/>  <br/> _(This essay is derived from a talk at Google.)_  <br/>  <br/>A few weeks ago I found to my surprise that I'd been granted four patents.<br/>This was all the more surprising because I'd only applied for three. The<br/>patents aren't mine, of course. They were assigned to Viaweb, and became<br/>Yahoo's when they bought us. But the news set me thinking about the question<br/>of software patents generally.  <br/>  <br/>Patents are a hard problem. I've had to advise most of the startups we've<br/>funded about them, and despite years of experience I'm still not always sure<br/>I'm giving the right advice.  <br/>  <br/>One thing I do feel pretty certain of is that if you're against software<br/>patents, you're against patents in general. Gradually our machines consist<br/>more and more of software. Things that used to be done with levers and cams<br/>and gears are now done with loops and trees and closures. There's nothing<br/>special about physical embodiments of control systems that should make them<br/>patentable, and the software equivalent not.  <br/>  <br/>Unfortunately, patent law is inconsistent on this point. Patent law in most<br/>countries says that algorithms aren't patentable. This rule is left over from<br/>a time when "algorithm" meant something like the Sieve of Eratosthenes. In<br/>1800, people could not see as readily as we can that a great many patents on<br/>mechanical objects were really patents on the algorithms they embodied.  <br/>  <br/>Patent lawyers still have to pretend that's what they're doing when they<br/>patent algorithms. You must not use the word "algorithm" in the title of a<br/>patent application, just as you must not use the word "essays" in the title of<br/>a book. If you want to patent an algorithm, you have to frame it as a computer<br/>system executing that algorithm. Then it's mechanical; phew. The default<br/>euphemism for algorithm is "system and method." Try a patent search for that<br/>phrase and see how many results you get.  <br/>  <br/>Since software patents are no different from hardware patents, people who say<br/>"software patents are evil" are saying simply "patents are evil." So why do so<br/>many people complain about software patents specifically?  <br/>  <br/>I think the problem is more with the patent office than the concept of<br/>software patents. Whenever software meets government, bad things happen,<br/>because software changes fast and government changes slow. The patent office<br/>has been overwhelmed by both the volume and the novelty of applications for<br/>software patents, and as a result they've made a lot of mistakes.  <br/>  <br/>The most common is to grant patents that shouldn't be granted. To be<br/>patentable, an invention has to be more than new. It also has to be non-<br/>obvious. And this, especially, is where the USPTO has been dropping the ball.<br/>Slashdot has an icon that expresses the problem vividly: a knife and fork with<br/>the words "patent pending" superimposed.  <br/>  <br/>The scary thing is, this is the _only_ icon they have for patent stories.<br/>Slashdot readers now take it for granted that a story about a patent will be<br/>about a bogus patent. That's how bad the problem has become.  <br/>  <br/>The problem with Amazon's notorious one-click patent, for example, is not that<br/>it's a software patent, but that it's obvious. Any online store that kept<br/>people's shipping addresses would have implemented this. The reason Amazon did<br/>it first was not that they were especially smart, but because they were one of<br/>the earliest sites with enough clout to force customers to log in before they<br/>could buy something. [1]  <br/>  <br/>We, as hackers, know the USPTO is letting people patent the knives and forks<br/>of our world. The problem is, the USPTO are not hackers. They're probably good<br/>at judging new inventions for casting steel or grinding lenses, but they don't<br/>understand software yet.  <br/>  <br/>At this point an optimist would be tempted to add "but they will eventually."<br/>Unfortunately that might not be true. The problem with software patents is an<br/>instance of a more general one: the patent office takes a while to understand<br/>new technology. If so, this problem will only get worse, because the rate of<br/>technological change seems to be increasing. In thirty years, the patent<br/>office may understand the sort of things we now patent as software, but there<br/>will be other new types of inventions they understand even less.  <br/>  <br/>Applying for a patent is a negotiation. You generally apply for a broader<br/>patent than you think you'll be granted, and the examiners reply by throwing<br/>out some of your claims and granting others. So I don't really blame Amazon<br/>for applying for the one-click patent. The big mistake was the patent<br/>office's, for not insisting on something narrower, with real technical<br/>content. By granting such an over-broad patent, the USPTO in effect slept with<br/>Amazon on the first date. Was Amazon supposed to say no?  <br/>  <br/>Where Amazon went over to the dark side was not in applying for the patent,<br/>but in enforcing it. A lot of companies (Microsoft, for example) have been<br/>granted large numbers of preposterously over-broad patents, but they keep them<br/>mainly for defensive purposes. Like nuclear weapons, the main role of big<br/>companies' patent portfolios is to threaten anyone who attacks them with a<br/>counter-suit. Amazon's suit against Barnes & Noble was thus the equivalent of<br/>a nuclear first strike.  <br/>  <br/>That suit probably hurt Amazon more than it helped them. Barnes & Noble was a<br/>lame site; Amazon would have crushed them anyway. To attack a rival they could<br/>have ignored, Amazon put a lasting black mark on their own reputation. Even<br/>now I think if you asked hackers to free-associate about Amazon, the one-click<br/>patent would turn up in the first ten topics.  <br/>  <br/>Google clearly doesn't feel that merely holding patents is evil. They've<br/>applied for a lot of them. Are they hypocrites? Are patents evil?  <br/>  <br/>There are really two variants of that question, and people answering it often<br/>aren't clear in their own minds which they're answering. There's a narrow<br/>variant: is it bad, given the current legal system, to apply for patents? and<br/>also a broader one: is it bad that the current legal system allows patents?  <br/>  <br/>These are separate questions. For example, in preindustrial societies like<br/>medieval Europe, when someone attacked you, you didn't call the police. There<br/>were no police. When attacked, you were supposed to fight back, and there were<br/>conventions about how to do it. Was this wrong? That's two questions: was it<br/>wrong to take justice into your own hands, and was it wrong that you had to?<br/>We tend to say yes to the second, but no to the first. If no one else will<br/>defend you, you have to defend yourself. [2]  <br/>  <br/>The situation with patents is similar. Business is a kind of ritualized<br/>warfare. Indeed, it evolved from actual warfare: most early traders switched<br/>on the fly from merchants to pirates depending on how strong you seemed. In<br/>business there are certain rules describing how companies may and may not<br/>compete with one another, and someone deciding that they're going to play by<br/>their own rules is missing the point. Saying "I'm not going to apply for<br/>patents just because everyone else does" is not like saying "I'm not going to<br/>lie just because everyone else does." It's more like saying "I'm not going to<br/>use TCP/IP just because everyone else does." Oh yes you are.  <br/>  <br/>A closer comparison might be someone seeing a hockey game for the first time,<br/>realizing with shock that the players were _deliberately_ bumping into one<br/>another, and deciding that one would on no account be so rude when playing<br/>hockey oneself.  <br/>  <br/>Hockey allows checking. It's part of the game. If your team refuses to do it,<br/>you simply lose. So it is in business. Under the present rules, patents are<br/>part of the game.  <br/>  <br/>What does that mean in practice? We tell the startups we fund not to worry<br/>about infringing patents, because startups rarely get sued for patent<br/>infringement. There are only two reasons someone might sue you: for money, or<br/>to prevent you from competing with them. Startups are too poor to be worth<br/>suing for money. And in practice they don't seem to get sued much by<br/>competitors, either. They don't get sued by other startups because (a) patent<br/>suits are an expensive distraction, and (b) since the other startups are as<br/>young as they are, their patents probably haven't issued yet. [3] Nor do<br/>startups, at least in the software business, seem to get sued much by<br/>established competitors. Despite all the patents Microsoft holds, I don't know<br/>of an instance where they sued a startup for patent infringement. Companies<br/>like Microsoft and Oracle don't win by winning lawsuits. That's too uncertain.<br/>They win by locking competitors out of their sales channels. If you do manage<br/>to threaten them, they're more likely to buy you than sue you.  <br/>  <br/>When you read of big companies filing patent suits against smaller ones, it's<br/>usually a big company on the way down, grasping at straws. For example,<br/>Unisys's attempts to enforce their patent on LZW compression. When you see a<br/>big company threatening patent suits, sell. When a company starts fighting<br/>over IP, it's a sign they've lost the real battle, for users.  <br/>  <br/>A company that sues competitors for patent infringement is like a defender who<br/>has been beaten so thoroughly that he turns to plead with the referee. You<br/>don't do that if you can still reach the ball, even if you genuinely believe<br/>you've been fouled. So a company threatening patent suits is a company in<br/>trouble.  <br/>  <br/>When we were working on Viaweb, a bigger company in the e-commerce business<br/>was granted a patent on online ordering, or something like that. I got a call<br/>from a VP there asking if we'd like to license it. I replied that I thought<br/>the patent was completely bogus, and would never hold up in court. "Ok," he<br/>replied. "So, are you guys hiring?"  <br/>  <br/>If your startup grows big enough, however, you'll start to get sued, no matter<br/>what you do. If you go public, for example, you'll be sued by multiple patent<br/>trolls who hope you'll pay them off to go away. More on them later.  <br/>  <br/>In other words, no one will sue you for patent infringement till you have<br/>money, and once you have money, people will sue you whether they have grounds<br/>to or not. So I advise fatalism. Don't waste your time worrying about patent<br/>infringement. You're probably violating a patent every time you tie your<br/>shoelaces. At the start, at least, just worry about making something great and<br/>getting lots of users. If you grow to the point where anyone considers you<br/>worth attacking, you're doing well.  <br/>  <br/>We do advise the companies we fund to apply for patents, but not so they can<br/>sue competitors. Successful startups either get bought or grow into big<br/>companies. If a startup wants to grow into a big company, they should apply<br/>for patents to build up the patent portfolio they'll need to maintain an armed<br/>truce with other big companies. If they want to get bought, they should apply<br/>for patents because patents are part of the mating dance with acquirers.  <br/>  <br/>Most startups that succeed do it by getting bought, and most acquirers care<br/>about patents. Startup acquisitions are usually a build-vs-buy decision for<br/>the acquirer. Should we buy this little startup or build our own? And two<br/>things, especially, make them decide not to build their own: if you already<br/>have a large and rapidly growing user base, and if you have a fairly solid<br/>patent application on critical parts of your software.  <br/>  <br/>There's a third reason big companies should prefer buying to building: that if<br/>they built their own, they'd screw it up. But few big companies are smart<br/>enough yet to admit this to themselves. It's usually the acquirer's engineers<br/>who are asked how hard it would be for the company to build their own, and<br/>they overestimate their abilities. [4] A patent seems to change the balance.<br/>It gives the acquirer an excuse to admit they couldn't copy what you're doing.<br/>It may also help them to grasp what's special about your technology.  <br/>  <br/>Frankly, it surprises me how small a role patents play in the software<br/>business. It's kind of ironic, considering all the dire things experts say<br/>about software patents stifling innovation, but when one looks closely at the<br/>software business, the most striking thing is how little patents seem to<br/>matter.  <br/>  <br/>In other fields, companies regularly sue competitors for patent infringement.<br/>For example, the airport baggage scanning business was for many years a cozy<br/>duopoly shared between two companies, InVision and L-3. In 2002 a startup<br/>called Reveal appeared, with new technology that let them build scanners a<br/>third the size. They were sued for patent infringement before they'd even<br/>released a product.  <br/>  <br/>You rarely hear that kind of story in our world. The one example I've found<br/>is, embarrassingly enough, Yahoo, which filed a patent suit against a gaming<br/>startup called Xfire in 2005. Xfire doesn't seem to be a very big deal, and<br/>it's hard to say why Yahoo felt threatened. Xfire's VP of engineering had<br/>worked at Yahoo on similar stuff-- in fact, he was listed as an inventor on<br/>the patent Yahoo sued over-- so perhaps there was something personal about it.<br/>My guess is that someone at Yahoo goofed. At any rate they didn't pursue the<br/>suit very vigorously.  <br/>  <br/>Why do patents play so small a role in software? I can think of three possible<br/>reasons.  <br/>  <br/>One is that software is so complicated that patents by themselves are not<br/>worth very much. I may be maligning other fields here, but it seems that in<br/>most types of engineering you can hand the details of some new technique to a<br/>group of medium-high quality people and get the desired result. For example,<br/>if someone develops a new process for smelting ore that gets a better yield,<br/>and you assemble a team of qualified experts and tell them about it, they'll<br/>be able to get the same yield. This doesn't seem to work in software. Software<br/>is so subtle and unpredictable that "qualified experts" don't get you very<br/>far.  <br/>  <br/>That's why we rarely hear phrases like "qualified expert" in the software<br/>business. What that level of ability can get you is, say, to make your<br/>software compatible with some other piece of software-- in eight months, at<br/>enormous cost. To do anything harder you need individual brilliance. If you<br/>assemble a team of qualified experts and tell them to make a new web-based<br/>email program, they'll get their asses kicked by a team of inspired nineteen<br/>year olds.  <br/>  <br/>Experts can implement, but they can't design. Or rather, expertise in<br/>implementation is the only kind most people, including the experts themselves,<br/>can measure. [5]  <br/>  <br/>But design is a definite skill. It's not just an airy intangible. Things<br/>always seem intangible when you don't understand them. Electricity seemed an<br/>airy intangible to most people in 1800. Who knew there was so much to know<br/>about it? So it is with design. Some people are good at it and some people are<br/>bad at it, and there's something very tangible they're good or bad at.  <br/>  <br/>The reason design counts so much in software is probably that there are fewer<br/>constraints than on physical things. Building physical things is expensive and<br/>dangerous. The space of possible choices is smaller; you tend to have to work<br/>as part of a larger group; and you're subject to a lot of regulations. You<br/>don't have any of that if you and a couple friends decide to create a new web-<br/>based application.  <br/>  <br/>Because there's so much scope for design in software, a successful application<br/>tends to be way more than the sum of its patents. What protects little<br/>companies from being copied by bigger competitors is not just their patents,<br/>but the thousand little things the big company will get wrong if they try.  <br/>  <br/>The second reason patents don't count for much in our world is that startups<br/>rarely attack big companies head-on, the way Reveal did. In the software<br/>business, startups beat established companies by transcending them. Startups<br/>don't build desktop word processing programs to compete with Microsoft Word.<br/>[6] They build Writely. If this paradigm is crowded, just wait for the next<br/>one; they run pretty frequently on this route.  <br/>  <br/>Fortunately for startups, big companies are extremely good at denial. If you<br/>take the trouble to attack them from an oblique angle, they'll meet you half-<br/>way and maneuver to keep you in their blind spot. To sue a startup would mean<br/>admitting it was dangerous, and that often means seeing something the big<br/>company doesn't want to see. IBM used to sue its mainframe competitors<br/>regularly, but they didn't bother much about the microcomputer industry<br/>because they didn't want to see the threat it posed. Companies building web<br/>based apps are similarly protected from Microsoft, which even now doesn't want<br/>to imagine a world in which Windows is irrelevant.  <br/>  <br/>The third reason patents don't seem to matter very much in software is public<br/>opinion-- or rather, hacker opinion. In a recent interview, Steve Ballmer<br/>coyly left open the possibility of attacking Linux on patent grounds. But I<br/>doubt Microsoft would ever be so stupid. They'd face the mother of all<br/>boycotts. And not just from the technical community in general; a lot of their<br/>own people would rebel.  <br/>  <br/>Good hackers care a lot about matters of principle, and they are highly<br/>mobile. If a company starts misbehaving, smart people won't work there. For<br/>some reason this seems to be more true in software than other businesses. I<br/>don't think it's because hackers have intrinsically higher principles so much<br/>as that their skills are easily transferrable. Perhaps we can split the<br/>difference and say that mobility gives hackers the luxury of being principled.  <br/>  <br/>Google's "don't be evil" policy may for this reason be the most valuable thing<br/>they've discovered. It's very constraining in some ways. If Google does do<br/>something evil, they get doubly whacked for it: once for whatever they did,<br/>and again for hypocrisy. But I think it's worth it. It helps them to hire the<br/>best people, and it's better, even from a purely selfish point of view, to be<br/>constrained by principles than by stupidity.  <br/>  <br/>(I wish someone would get this point across to the present administration.)  <br/>  <br/>I'm not sure what the proportions are of the preceding three ingredients, but<br/>the custom among the big companies seems to be not to sue the small ones, and<br/>the startups are mostly too busy and too poor to sue one another. So despite<br/>the huge number of software patents there's not a lot of suing going on. With<br/>one exception: patent trolls.  <br/>  <br/>Patent trolls are companies consisting mainly of lawyers whose whole business<br/>is to accumulate patents and threaten to sue companies who actually make<br/>things. Patent trolls, it seems safe to say, are evil. I feel a bit stupid<br/>saying that, because when you're saying something that Richard Stallman and<br/>Bill Gates would both agree with, you must be perilously close to tautologies.  <br/>  <br/>The CEO of Forgent, one of the most notorious patent trolls, says that what<br/>his company does is "the American way." Actually that's not true. The American<br/>way is to make money by creating wealth, not by suing people. [7] What<br/>companies like Forgent do is actually the proto-industrial way. In the period<br/>just before the industrial revolution, some of the greatest fortunes in<br/>countries like England and France were made by courtiers who extracted some<br/>lucrative right from the crown-- like the right to collect taxes on the import<br/>of silk-- and then used this to squeeze money from the merchants in that<br/>business. So when people compare patent trolls to the mafia, they're more<br/>right than they know, because the mafia too are not merely bad, but bad<br/>specifically in the sense of being an obsolete business model.  <br/>  <br/>Patent trolls seem to have caught big companies by surprise. In the last<br/>couple years they've extracted hundreds of millions of dollars from them.<br/>Patent trolls are hard to fight precisely because they create nothing. Big<br/>companies are safe from being sued by other big companies because they can<br/>threaten a counter-suit. But because patent trolls don't make anything,<br/>there's nothing they can be sued for. I predict this loophole will get closed<br/>fairly quickly, at least by legal standards. It's clearly an abuse of the<br/>system, and the victims are powerful. [8]  <br/>  <br/>But evil as patent trolls are, I don't think they hamper innovation much. They<br/>don't sue till a startup has made money, and by that point the innovation that<br/>generated it has already happened. I can't think of a startup that avoided<br/>working on some problem because of patent trolls.  <br/>  <br/>So much for hockey as the game is played now. What about the more theoretical<br/>question of whether hockey would be a better game without checking? Do patents<br/>encourage or discourage innovation?  <br/>  <br/>This is a very hard question to answer in the general case. People write whole<br/>books on the topic. One of my main hobbies is the history of technology, and<br/>even though I've studied the subject for years, it would take me several weeks<br/>of research to be able to say whether patents have in general been a net win.  <br/>  <br/>One thing I can say is that 99.9% of the people who express opinions on the<br/>subject do it not based on such research, but out of a kind of religious<br/>conviction. At least, that's the polite way of putting it; the colloquial<br/>version involves speech coming out of organs not designed for that purpose.  <br/>  <br/>Whether they encourage innovation or not, patents were at least intended to.<br/>You don't get a patent for nothing. In return for the exclusive right to use<br/>an idea, you have to _publish_ it, and it was largely to encourage such<br/>openness that patents were established.  <br/>  <br/>Before patents, people protected ideas by keeping them secret. With patents,<br/>central governments said, in effect, if you tell everyone your idea, we'll<br/>protect it for you. There is a parallel here to the rise of civil order, which<br/>happened at roughly the same time. Before central governments were powerful<br/>enough to enforce order, rich people had private armies. As governments got<br/>more powerful, they gradually compelled magnates to cede most responsibility<br/>for protecting them. (Magnates still have bodyguards, but no longer to protect<br/>them from other magnates.)  <br/>  <br/>Patents, like police, are involved in many abuses. But in both cases the<br/>default is something worse. The choice is not "patents or freedom?" any more<br/>than it is "police or freedom?" The actual questions are respectively "patents<br/>or secrecy?" and "police or gangs?"  <br/>  <br/>As with gangs, we have some idea what secrecy would be like, because that's<br/>how things used to be. The economy of medieval Europe was divided up into<br/>little tribes, each jealously guarding their privileges and secrets. In<br/>Shakespeare's time, "mystery" was synonymous with "craft." Even today we can<br/>see an echo of the secrecy of medieval guilds, in the now pointless secrecy of<br/>the Masons.  <br/>  <br/>The most memorable example of medieval industrial secrecy is probably Venice,<br/>which forbade glassblowers to leave the city, and sent assassins after those<br/>who tried. We might like to think we wouldn't go so far, but the movie<br/>industry has already tried to pass laws prescribing three year prison terms<br/>just for putting movies on public networks. Want to try a frightening thought<br/>experiment? If the movie industry could have any law they wanted, where would<br/>they stop? Short of the death penalty, one assumes, but how close would they<br/>get?  <br/>  <br/>Even worse than the spectacular abuses might be the overall decrease in<br/>efficiency that would accompany increased secrecy. As anyone who has dealt<br/>with organizations that operate on a "need to know" basis can attest, dividing<br/>information up into little cells is terribly inefficient. The flaw in the<br/>"need to know" principle is that you don't _know_ who needs to know something.<br/>An idea from one area might spark a great discovery in another. But the<br/>discoverer doesn't know he needs to know it.  <br/>  <br/>If secrecy were the only protection for ideas, companies wouldn't just have to<br/>be secretive with other companies; they'd have to be secretive internally.<br/>This would encourage what is already the worst trait of big companies.  <br/>  <br/>I'm not saying secrecy would be worse than patents, just that we couldn't<br/>discard patents for free. Businesses would become more secretive to<br/>compensate, and in some fields this might get ugly. Nor am I defending the<br/>current patent system. There is clearly a lot that's broken about it. But the<br/>breakage seems to affect software less than most other fields.  <br/>  <br/>In the software business I know from experience whether patents encourage or<br/>discourage innovation, and the answer is the type that people who like to<br/>argue about public policy least like to hear: they don't affect innovation<br/>much, one way or the other. Most innovation in the software business happens<br/>in startups, and startups should simply ignore other companies' patents. At<br/>least, that's what we advise, and we bet money on that advice.  <br/>  <br/>The only real role of patents, for most startups, is as an element of the<br/>mating dance with acquirers. There patents do help a little. And so they do<br/>encourage innovation indirectly, in that they give more power to startups,<br/>which is where, pound for pound, the most innovation happens. But even in the<br/>mating dance, patents are of secondary importance. It matters more to make<br/>something great and get a lot of users.  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] You have to be careful here, because a great discovery often seems obvious<br/>in retrospect. One-click ordering, however, is not such a discovery.  <br/>  <br/>[2] "Turn the other cheek" skirts the issue; the critical question is not how<br/>to deal with slaps, but sword thrusts.  <br/>  <br/>[3] Applying for a patent is now very slow, but it might actually be bad if<br/>that got fixed. At the moment the time it takes to get a patent is<br/>conveniently just longer than the time it takes a startup to succeed or fail.  <br/>  <br/>[4] Instead of the canonical "could you build this?" maybe the corp dev guys<br/>should be asking "will you build this?" or even "why haven't you already built<br/>this?"  <br/>  <br/>[5] Design ability is so hard to measure that you can't even trust the design<br/>world's internal standards. You can't assume that someone with a degree in<br/>design is any good at design, or that an eminent designer is any better than<br/>his peers. If that worked, any company could build products as good as Apple's<br/>just by hiring sufficiently qualified designers.  <br/>  <br/>[6] If anyone wanted to try, we'd be interested to hear from them. I suspect<br/>it's one of those things that's not as hard as everyone assumes.  <br/>  <br/>[7] Patent trolls can't even claim, like speculators, that they "create"<br/>liquidity.  <br/>  <br/>[8] If big companies don't want to wait for the government to take action,<br/>there is a way to fight back themselves. For a long time I thought there<br/>wasn't, because there was nothing to grab onto. But there is one resource<br/>patent trolls need: lawyers. Big technology companies between them generate a<br/>lot of legal business. If they agreed among themselves never to do business<br/>with any firm employing anyone who had worked for a patent troll, either as an<br/>employee or as outside counsel, they could probably starve the trolls of the<br/>lawyers they need.  <br/>  <br/> **Thanks** to Dan Bloomberg, Paul Buchheit, Sarah Harlin, Jessica Livingston,<br/>and Peter Norvig for reading drafts of this, to Joel Lehrer and Peter Eng for<br/>answering my questions about patents, and to Ankur Pansari for inviting me to<br/>speak.  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>December 2014  <br/>  <br/>If the world were static, we could have monotonically increasing confidence in<br/>our beliefs. The more (and more varied) experience a belief survived, the less<br/>likely it would be false. Most people implicitly believe something like this<br/>about their opinions. And they're justified in doing so with opinions about<br/>things that don't change much, like human nature. But you can't trust your<br/>opinions in the same way about things that change, which could include<br/>practically everything else.  <br/>  <br/>When experts are wrong, it's often because they're experts on an earlier<br/>version of the world.  <br/>  <br/>Is it possible to avoid that? Can you protect yourself against obsolete<br/>beliefs? To some extent, yes. I spent almost a decade investing in early stage<br/>startups, and curiously enough protecting yourself against obsolete beliefs is<br/>exactly what you have to do to succeed as a startup investor. Most really good<br/>startup ideas look like bad ideas at first, and many of those look bad<br/>specifically because some change in the world just switched them from bad to<br/>good. I spent a lot of time learning to recognize such ideas, and the<br/>techniques I used may be applicable to ideas in general.  <br/>  <br/>The first step is to have an explicit belief in change. People who fall victim<br/>to a monotonically increasing confidence in their opinions are implicitly<br/>concluding the world is static. If you consciously remind yourself it isn't,<br/>you start to look for change.  <br/>  <br/>Where should one look for it? Beyond the moderately useful generalization that<br/>human nature doesn't change much, the unfortunate fact is that change is hard<br/>to predict. This is largely a tautology but worth remembering all the same:<br/>change that matters usually comes from an unforeseen quarter.  <br/>  <br/>So I don't even try to predict it. When I get asked in interviews to predict<br/>the future, I always have to struggle to come up with something plausible-<br/>sounding on the fly, like a student who hasn't prepared for an exam. [1] But<br/>it's not out of laziness that I haven't prepared. It seems to me that beliefs<br/>about the future are so rarely correct that they usually aren't worth the<br/>extra rigidity they impose, and that the best strategy is simply to be<br/>aggressively open-minded. Instead of trying to point yourself in the right<br/>direction, admit you have no idea what the right direction is, and try instead<br/>to be super sensitive to the winds of change.  <br/>  <br/>It's ok to have working hypotheses, even though they may constrain you a bit,<br/>because they also motivate you. It's exciting to chase things and exciting to<br/>try to guess answers. But you have to be disciplined about not letting your<br/>hypotheses harden into anything more. [2]  <br/>  <br/>I believe this passive m.o. works not just for evaluating new ideas but also<br/>for having them. The way to come up with new ideas is not to try explicitly<br/>to, but to try to solve problems and simply not discount weird hunches you<br/>have in the process.  <br/>  <br/>The winds of change originate in the unconscious minds of domain experts. If<br/>you're sufficiently expert in a field, any weird idea or apparently irrelevant<br/>question that occurs to you is ipso facto worth exploring. [3] Within Y<br/>Combinator, when an idea is described as crazy, it's a compliment—in fact, on<br/>average probably a higher compliment than when an idea is described as good.  <br/>  <br/>Startup investors have extraordinary incentives for correcting obsolete<br/>beliefs. If they can realize before other investors that some apparently<br/>unpromising startup isn't, they can make a huge amount of money. But the<br/>incentives are more than just financial. Investors' opinions are explicitly<br/>tested: startups come to them and they have to say yes or no, and then, fairly<br/>quickly, they learn whether they guessed right. The investors who say no to a<br/>Google (and there were several) will remember it for the rest of their lives.  <br/>  <br/>Anyone who must in some sense bet on ideas rather than merely commenting on<br/>them has similar incentives. Which means anyone who wants such incentives can<br/>have them, by turning their comments into bets: if you write about a topic in<br/>some fairly durable and public form, you'll find you worry much more about<br/>getting things right than most people would in a casual conversation. [4]  <br/>  <br/>Another trick I've found to protect myself against obsolete beliefs is to<br/>focus initially on people rather than ideas. Though the nature of future<br/>discoveries is hard to predict, I've found I can predict quite well what sort<br/>of people will make them. Good new ideas come from earnest, energetic,<br/>independent-minded people.  <br/>  <br/>Betting on people over ideas saved me countless times as an investor. We<br/>thought Airbnb was a bad idea, for example. But we could tell the founders<br/>were earnest, energetic, and independent-minded. (Indeed, almost<br/>pathologically so.) So we suspended disbelief and funded them.  <br/>  <br/>This too seems a technique that should be generally applicable. Surround<br/>yourself with the sort of people new ideas come from. If you want to notice<br/>quickly when your beliefs become obsolete, you can't do better than to be<br/>friends with the people whose discoveries will make them so.  <br/>  <br/>It's hard enough already not to become the prisoner of your own expertise, but<br/>it will only get harder, because change is accelerating. That's not a recent<br/>trend; change has been accelerating since the paleolithic era. Ideas beget<br/>ideas. I don't expect that to change. But I could be wrong.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] My usual trick is to talk about aspects of the present that most people<br/>haven't noticed yet.  <br/>  <br/>[2] Especially if they become well enough known that people start to identify<br/>them with you. You have to be extra skeptical about things you want to<br/>believe, and once a hypothesis starts to be identified with you, it will<br/>almost certainly start to be in that category.  <br/>  <br/>[3] In practice "sufficiently expert" doesn't require one to be recognized as<br/>an expert—which is a trailing indicator in any case. In many fields a year of<br/>focused work plus caring a lot would be enough.  <br/>  <br/>[4] Though they are public and persist indefinitely, comments on e.g. forums<br/>and places like Twitter seem empirically to work like casual conversation. The<br/>threshold may be whether what you write has a title.  <br/>  <br/>**Thanks** to Sam Altman, Patrick Collison, and Robert Morris for reading<br/>drafts of this.  <br/>  <br/><br/>Spanish Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>December 2008  <br/>  <br/>For nearly all of history the success of a society was proportionate to its<br/>ability to assemble large and disciplined organizations. Those who bet on<br/>economies of scale generally won, which meant the largest organizations were<br/>the most successful ones.  <br/>  <br/>Things have already changed so much that this is hard for us to believe, but<br/>till just a few decades ago the largest organizations tended to be the most<br/>progressive. An ambitious kid graduating from college in 1960 wanted to work<br/>in the huge, gleaming offices of Ford, or General Electric, or NASA. Small<br/>meant small-time. Small in 1960 didn't mean a cool little startup. It meant<br/>uncle Sid's shoe store.  <br/>  <br/>When I grew up in the 1970s, the idea of the "corporate ladder" was still very<br/>much alive. The standard plan was to try to get into a good college, from<br/>which one would be drafted into some organization and then rise to positions<br/>of gradually increasing responsibility. The more ambitious merely hoped to<br/>climb the same ladder faster. [1]  <br/>  <br/>But in the late twentieth century something changed. It turned out that<br/>economies of scale were not the only force at work. Particularly in<br/>technology, the increase in speed one could get from smaller groups started to<br/>trump the advantages of size.  <br/>  <br/>The future turned out to be different from the one we were expecting in 1970.<br/>The domed cities and flying cars we expected have failed to materialize. But<br/>fortunately so have the jumpsuits with badges indicating our specialty and<br/>rank. Instead of being dominated by a few, giant tree-structured<br/>organizations, it's now looking like the economy of the future will be a fluid<br/>network of smaller, independent units.  <br/>  <br/>It's not so much that large organizations stopped working. There's no evidence<br/>that famously successful organizations like the Roman army or the British East<br/>India Company were any less afflicted by protocol and politics than<br/>organizations of the same size today. But they were competing against<br/>opponents who couldn't change the rules on the fly by discovering new<br/>technology. Now it turns out the rule "large and disciplined organizations<br/>win" needs to have a qualification appended: "at games that change slowly." No<br/>one knew till change reached a sufficient speed.  <br/>  <br/>Large organizations _will_ start to do worse now, though, because for the<br/>first time in history they're no longer getting the best people. An ambitious<br/>kid graduating from college now doesn't want to work for a big company. They<br/>want to work for the hot startup that's rapidly growing into one. If they're<br/>really ambitious, they want to start it. [2]  <br/>  <br/>This doesn't mean big companies will disappear. To say that startups will<br/>succeed implies that big companies will exist, because startups that succeed<br/>either become big companies or are acquired by them. [3] But large<br/>organizations will probably never again play the leading role they did up till<br/>the last quarter of the twentieth century.  <br/>  <br/>It's kind of surprising that a trend that lasted so long would ever run out.<br/>How often does it happen that a rule works for thousands of years, then<br/>switches polarity?  <br/>  <br/>The millennia-long run of bigger-is-better left us with a lot of traditions<br/>that are now obsolete, but extremely deeply rooted. Which means the ambitious<br/>can now do arbitrage on them. It will be very valuable to understand precisely<br/>which ideas to keep and which can now be discarded.  <br/>  <br/>The place to look is where the spread of smallness began: in the world of<br/>startups.  <br/>  <br/>There have always been occasional cases, particularly in the US, of ambitious<br/>people who grew the ladder under them instead of climbing it. But till<br/>recently this was an anomalous route that tended to be followed only by<br/>outsiders. It was no coincidence that the great industrialists of the<br/>nineteenth century had so little formal education. As huge as their companies<br/>eventually became, they were all essentially mechanics and shopkeepers at<br/>first. That was a social step no one with a college education would take if<br/>they could avoid it. Till the rise of technology startups, and in particular,<br/>Internet startups, it was very unusual for educated people to start their own<br/>businesses.  <br/>  <br/>The eight men who left Shockley Semiconductor to found Fairchild<br/>Semiconductor, the original Silicon Valley startup, weren't even trying to<br/>start a company at first. They were just looking for a company willing to hire<br/>them as a group. Then one of their parents introduced them to a small<br/>investment bank that offered to find funding for them to start their own, so<br/>they did. But starting a company was an alien idea to them; it was something<br/>they backed into. [4]  <br/>  <br/>Now I would guess that practically every Stanford or Berkeley undergrad who<br/>knows how to program has at least considered the idea of starting a startup.<br/>East Coast universities are not far behind, and British universities only a<br/>little behind them. This pattern suggests that attitudes at Stanford and<br/>Berkeley are not an anomaly, but a leading indicator. This is the way the<br/>world is going.  <br/>  <br/>Of course, Internet startups are still only a fraction of the world's economy.<br/>Could a trend based on them be that powerful?  <br/>  <br/>I think so. There's no reason to suppose there's any limit to the amount of<br/>work that could be done in this area. Like science, wealth seems to expand<br/>fractally. Steam power was a sliver of the British economy when Watt started<br/>working on it. But his work led to more work till that sliver had expanded<br/>into something bigger than the whole economy of which it had initially been a<br/>part.  <br/>  <br/>The same thing could happen with the Internet. If Internet startups offer the<br/>best opportunity for ambitious people, then a lot of ambitious people will<br/>start them, and this bit of the economy will balloon in the usual fractal way.  <br/>  <br/>Even if Internet-related applications only become a tenth of the world's<br/>economy, this component will set the tone for the rest. The most dynamic part<br/>of the economy always does, in everything from salaries to standards of dress.<br/>Not just because of its prestige, but because the principles underlying the<br/>most dynamic part of the economy tend to be ones that work.  <br/>  <br/>For the future, the trend to bet on seems to be networks of small, autonomous<br/>groups whose performance is measured individually. And the societies that win<br/>will be the ones with the least impedance.  <br/>  <br/>As with the original industrial revolution, some societies are going to be<br/>better at this than others. Within a generation of its birth in England, the<br/>Industrial Revolution had spread to continental Europe and North America. But<br/>it didn't spread everywhere. This new way of doing things could only take root<br/>in places that were prepared for it. It could only spread to places that<br/>already had a vigorous middle class.  <br/>  <br/>There is a similar social component to the transformation that began in<br/>Silicon Valley in the 1960s. Two new kinds of techniques were developed there:<br/>techniques for building integrated circuits, and techniques for building a new<br/>type of company designed to grow fast by creating new technology. The<br/>techniques for building integrated circuits spread rapidly to other countries.<br/>But the techniques for building startups didn't. Fifty years later, startups<br/>are ubiquitous in Silicon Valley and common in a handful of other US cities,<br/>but they're still an anomaly in most of the world.  <br/>  <br/>Part of the reason—possibly the main reason—that startups have not spread as<br/>broadly as the Industrial Revolution did is their social disruptiveness.<br/>Though it brought many social changes, the Industrial Revolution was not<br/>fighting the principle that bigger is better. Quite the opposite: the two<br/>dovetailed beautifully. The new industrial companies adapted the customs of<br/>existing large organizations like the military and the civil service, and the<br/>resulting hybrid worked well. "Captains of industry" issued orders to "armies<br/>of workers," and everyone knew what they were supposed to do.  <br/>  <br/>Startups seem to go more against the grain, socially. It's hard for them to<br/>flourish in societies that value hierarchy and stability, just as it was hard<br/>for industrialization to flourish in societies ruled by people who stole at<br/>will from the merchant class. But there were already a handful of countries<br/>past that stage when the Industrial Revolution happened. There do not seem to<br/>be that many ready this time.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] One of the bizarre consequences of this model was that the usual way to<br/>make more money was to become a manager. This is one of the things startups<br/>fix.  <br/>  <br/>[2] There are a lot of reasons American car companies have been doing so much<br/>worse than Japanese car companies, but at least one of them is a cause for<br/>optimism: American graduates have more options.  <br/>  <br/>[3] It's possible that companies will one day be able to grow big in revenues<br/>without growing big in people, but we are not very far along that trend yet.  <br/>  <br/>[4] Lecuyer, Christophe, _Making Silicon Valley_ , MIT Press, 2006.  <br/>  <br/> **Thanks** to Trevor Blackwell, Paul Buchheit, Jessica Livingston, and Robert<br/>Morris for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>February 2007  <br/>  <br/>A few days ago I finally figured out something I've wondered about for 25<br/>years: the relationship between wisdom and intelligence. Anyone can see<br/>they're not the same by the number of people who are smart, but not very wise.<br/>And yet intelligence and wisdom do seem related. How?  <br/>  <br/>What is wisdom? I'd say it's knowing what to do in a lot of situations. I'm<br/>not trying to make a deep point here about the true nature of wisdom, just to<br/>figure out how we use the word. A wise person is someone who usually knows the<br/>right thing to do.  <br/>  <br/>And yet isn't being smart also knowing what to do in certain situations? For<br/>example, knowing what to do when the teacher tells your elementary school<br/>class to add all the numbers from 1 to 100? [1]  <br/>  <br/>Some say wisdom and intelligence apply to different types of problems—wisdom<br/>to human problems and intelligence to abstract ones. But that isn't true. Some<br/>wisdom has nothing to do with people: for example, the wisdom of the engineer<br/>who knows certain structures are less prone to failure than others. And<br/>certainly smart people can find clever solutions to human problems as well as<br/>abstract ones. [2]  <br/>  <br/>Another popular explanation is that wisdom comes from experience while<br/>intelligence is innate. But people are not simply wise in proportion to how<br/>much experience they have. Other things must contribute to wisdom besides<br/>experience, and some may be innate: a reflective disposition, for example.  <br/>  <br/>Neither of the conventional explanations of the difference between wisdom and<br/>intelligence stands up to scrutiny. So what is the difference? If we look at<br/>how people use the words "wise" and "smart," what they seem to mean is<br/>different shapes of performance.  <br/>  <br/> **Curve**  <br/>  <br/>"Wise" and "smart" are both ways of saying someone knows what to do. The<br/>difference is that "wise" means one has a high average outcome across all<br/>situations, and "smart" means one does spectacularly well in a few. That is,<br/>if you had a graph in which the x axis represented situations and the y axis<br/>the outcome, the graph of the wise person would be high overall, and the graph<br/>of the smart person would have high peaks.  <br/>  <br/>The distinction is similar to the rule that one should judge talent at its<br/>best and character at its worst. Except you judge intelligence at its best,<br/>and wisdom by its average. That's how the two are related: they're the two<br/>different senses in which the same curve can be high.  <br/>  <br/>So a wise person knows what to do in most situations, while a smart person<br/>knows what to do in situations where few others could. We need to add one more<br/>qualification: we should ignore cases where someone knows what to do because<br/>they have inside information. [3] But aside from that, I don't think we can<br/>get much more specific without starting to be mistaken.  <br/>  <br/>Nor do we need to. Simple as it is, this explanation predicts, or at least<br/>accords with, both of the conventional stories about the distinction between<br/>wisdom and intelligence. Human problems are the most common type, so being<br/>good at solving those is key in achieving a high average outcome. And it seems<br/>natural that a high average outcome depends mostly on experience, but that<br/>dramatic peaks can only be achieved by people with certain rare, innate<br/>qualities; nearly anyone can learn to be a good swimmer, but to be an Olympic<br/>swimmer you need a certain body type.  <br/>  <br/>This explanation also suggests why wisdom is such an elusive concept: there's<br/>no such thing. "Wise" means something—that one is on average good at making<br/>the right choice. But giving the name "wisdom" to the supposed quality that<br/>enables one to do that doesn't mean such a thing exists. To the extent<br/>"wisdom" means anything, it refers to a grab-bag of qualities as various as<br/>self-discipline, experience, and empathy. [4]  <br/>  <br/>Likewise, though "intelligent" means something, we're asking for trouble if we<br/>insist on looking for a single thing called "intelligence." And whatever its<br/>components, they're not all innate. We use the word "intelligent" as an<br/>indication of ability: a smart person can grasp things few others could. It<br/>does seem likely there's some inborn predisposition to intelligence (and<br/>wisdom too), but this predisposition is not itself intelligence.  <br/>  <br/>One reason we tend to think of intelligence as inborn is that people trying to<br/>measure it have concentrated on the aspects of it that are most measurable. A<br/>quality that's inborn will obviously be more convenient to work with than one<br/>that's influenced by experience, and thus might vary in the course of a study.<br/>The problem comes when we drag the word "intelligence" over onto what they're<br/>measuring. If they're measuring something inborn, they can't be measuring<br/>intelligence. Three year olds aren't smart. When we describe one as smart,<br/>it's shorthand for "smarter than other three year olds."  <br/>  <br/> **Split**  <br/>  <br/>Perhaps it's a technicality to point out that a predisposition to intelligence<br/>is not the same as intelligence. But it's an important technicality, because<br/>it reminds us that we can become smarter, just as we can become wiser.  <br/>  <br/>The alarming thing is that we may have to choose between the two.  <br/>  <br/>If wisdom and intelligence are the average and peaks of the same curve, then<br/>they converge as the number of points on the curve decreases. If there's just<br/>one point, they're identical: the average and maximum are the same. But as the<br/>number of points increases, wisdom and intelligence diverge. And historically<br/>the number of points on the curve seems to have been increasing: our ability<br/>is tested in an ever wider range of situations.  <br/>  <br/>In the time of Confucius and Socrates, people seem to have regarded wisdom,<br/>learning, and intelligence as more closely related than we do. Distinguishing<br/>between "wise" and "smart" is a modern habit. [5] And the reason we do is that<br/>they've been diverging. As knowledge gets more specialized, there are more<br/>points on the curve, and the distinction between the spikes and the average<br/>becomes sharper, like a digital image rendered with more pixels.  <br/>  <br/>One consequence is that some old recipes may have become obsolete. At the very<br/>least we have to go back and figure out if they were really recipes for wisdom<br/>or intelligence. But the really striking change, as intelligence and wisdom<br/>drift apart, is that we may have to decide which we prefer. We may not be able<br/>to optimize for both simultaneously.  <br/>  <br/>Society seems to have voted for intelligence. We no longer admire the sage—not<br/>the way people did two thousand years ago. Now we admire the genius. Because<br/>in fact the distinction we began with has a rather brutal converse: just as<br/>you can be smart without being very wise, you can be wise without being very<br/>smart. That doesn't sound especially admirable. That gets you James Bond, who<br/>knows what to do in a lot of situations, but has to rely on Q for the ones<br/>involving math.  <br/>  <br/>Intelligence and wisdom are obviously not mutually exclusive. In fact, a high<br/>average may help support high peaks. But there are reasons to believe that at<br/>some point you have to choose between them. One is the example of very smart<br/>people, who are so often unwise that in popular culture this now seems to be<br/>regarded as the rule rather than the exception. Perhaps the absent-minded<br/>professor is wise in his way, or wiser than he seems, but he's not wise in the<br/>way Confucius or Socrates wanted people to be. [6]  <br/>  <br/> **New**  <br/>  <br/>For both Confucius and Socrates, wisdom, virtue, and happiness were<br/>necessarily related. The wise man was someone who knew what the right choice<br/>was and always made it; to be the right choice, it had to be morally right; he<br/>was therefore always happy, knowing he'd done the best he could. I can't think<br/>of many ancient philosophers who would have disagreed with that, so far as it<br/>goes.  <br/>  <br/>"The superior man is always happy; the small man sad," said Confucius. [7]  <br/>  <br/>Whereas a few years ago I read an interview with a mathematician who said that<br/>most nights he went to bed discontented, feeling he hadn't made enough<br/>progress. [8] The Chinese and Greek words we translate as "happy" didn't mean<br/>exactly what we do by it, but there's enough overlap that this remark<br/>contradicts them.  <br/>  <br/>Is the mathematician a small man because he's discontented? No; he's just<br/>doing a kind of work that wasn't very common in Confucius's day.  <br/>  <br/>Human knowledge seems to grow fractally. Time after time, something that<br/>seemed a small and uninteresting area—experimental error, even—turns out, when<br/>examined up close, to have as much in it as all knowledge up to that point.<br/>Several of the fractal buds that have exploded since ancient times involve<br/>inventing and discovering new things. Math, for example, used to be something<br/>a handful of people did part-time. Now it's the career of thousands. And in<br/>work that involves making new things, some old rules don't apply.  <br/>  <br/>Recently I've spent some time advising people, and there I find the ancient<br/>rule still works: try to understand the situation as well as you can, give the<br/>best advice you can based on your experience, and then don't worry about it,<br/>knowing you did all you could. But I don't have anything like this serenity<br/>when I'm writing an essay. Then I'm worried. What if I run out of ideas? And<br/>when I'm writing, four nights out of five I go to bed discontented, feeling I<br/>didn't get enough done.  <br/>  <br/>Advising people and writing are fundamentally different types of work. When<br/>people come to you with a problem and you have to figure out the right thing<br/>to do, you don't (usually) have to invent anything. You just weigh the<br/>alternatives and try to judge which is the prudent choice. But _prudence_<br/>can't tell me what sentence to write next. The search space is too big.  <br/>  <br/>Someone like a judge or a military officer can in much of his work be guided<br/>by duty, but duty is no guide in making things. Makers depend on something<br/>more precarious: inspiration. And like most people who lead a precarious<br/>existence, they tend to be worried, not contented. In that respect they're<br/>more like the small man of Confucius's day, always one bad harvest (or ruler)<br/>away from starvation. Except instead of being at the mercy of weather and<br/>officials, they're at the mercy of their own imagination.  <br/>  <br/> **Limits**  <br/>  <br/>To me it was a relief just to realize it might be ok to be discontented. The<br/>idea that a successful person should be happy has thousands of years of<br/>momentum behind it. If I was any good, why didn't I have the easy confidence<br/>winners are supposed to have? But that, I now believe, is like a runner asking<br/>"If I'm such a good athlete, why do I feel so tired?" Good runners still get<br/>tired; they just get tired at higher speeds.  <br/>  <br/>People whose work is to invent or discover things are in the same position as<br/>the runner. There's no way for them to do the best they can, because there's<br/>no limit to what they could do. The closest you can come is to compare<br/>yourself to other people. But the better you do, the less this matters. An<br/>undergrad who gets something published feels like a star. But for someone at<br/>the top of the field, what's the test of doing well? Runners can at least<br/>compare themselves to others doing exactly the same thing; if you win an<br/>Olympic gold medal, you can be fairly content, even if you think you could<br/>have run a bit faster. But what is a novelist to do?  <br/>  <br/>Whereas if you're doing the kind of work in which problems are presented to<br/>you and you have to choose between several alternatives, there's an upper<br/>bound on your performance: choosing the best every time. In ancient societies,<br/>nearly all work seems to have been of this type. The peasant had to decide<br/>whether a garment was worth mending, and the king whether or not to invade his<br/>neighbor, but neither was expected to invent anything. In principle they could<br/>have; the king could have invented firearms, then invaded his neighbor. But in<br/>practice innovations were so rare that they weren't expected of you, any more<br/>than goalkeepers are expected to score goals. [9] In practice, it seemed as if<br/>there was a correct decision in every situation, and if you made it you'd done<br/>your job perfectly, just as a goalkeeper who prevents the other team from<br/>scoring is considered to have played a perfect game.  <br/>  <br/>In this world, wisdom seemed paramount. [10] Even now, most people do work in<br/>which problems are put before them and they have to choose the best<br/>alternative. But as knowledge has grown more specialized, there are more and<br/>more types of work in which people have to make up new things, and in which<br/>performance is therefore unbounded. Intelligence has become increasingly<br/>important relative to wisdom because there is more room for spikes.  <br/>  <br/> **Recipes**  <br/>  <br/>Another sign we may have to choose between intelligence and wisdom is how<br/>different their recipes are. Wisdom seems to come largely from curing childish<br/>qualities, and intelligence largely from cultivating them.  <br/>  <br/>Recipes for wisdom, particularly ancient ones, tend to have a remedial<br/>character. To achieve wisdom one must cut away all the debris that fills one's<br/>head on emergence from childhood, leaving only the important stuff. Both self-<br/>control and experience have this effect: to eliminate the random biases that<br/>come from your own nature and from the circumstances of your upbringing<br/>respectively. That's not all wisdom is, but it's a large part of it. Much of<br/>what's in the sage's head is also in the head of every twelve year old. The<br/>difference is that in the head of the twelve year old it's mixed together with<br/>a lot of random junk.  <br/>  <br/>The path to intelligence seems to be through working on hard problems. You<br/>develop intelligence as you might develop muscles, through exercise. But there<br/>can't be too much compulsion here. No amount of discipline can replace genuine<br/>curiosity. So cultivating intelligence seems to be a matter of identifying<br/>some bias in one's character—some tendency to be interested in certain types<br/>of things—and nurturing it. Instead of obliterating your idiosyncrasies in an<br/>effort to make yourself a neutral vessel for the truth, you select one and try<br/>to grow it from a seedling into a tree.  <br/>  <br/>The wise are all much alike in their wisdom, but very smart people tend to be<br/>smart in distinctive ways.  <br/>  <br/>Most of our educational traditions aim at wisdom. So perhaps one reason<br/>schools work badly is that they're trying to make intelligence using recipes<br/>for wisdom. Most recipes for wisdom have an element of subjection. At the very<br/>least, you're supposed to do what the teacher says. The more extreme recipes<br/>aim to break down your individuality the way basic training does. But that's<br/>not the route to intelligence. Whereas wisdom comes through humility, it may<br/>actually help, in cultivating intelligence, to have a mistakenly high opinion<br/>of your abilities, because that encourages you to keep working. Ideally till<br/>you realize how mistaken you were.  <br/>  <br/>(The reason it's hard to learn new skills late in life is not just that one's<br/>brain is less malleable. Another probably even worse obstacle is that one has<br/>higher standards.)  <br/>  <br/>I realize we're on dangerous ground here. I'm not proposing the primary goal<br/>of education should be to increase students' "self-esteem." That just breeds<br/>laziness. And in any case, it doesn't really fool the kids, not the smart<br/>ones. They can tell at a young age that a contest where everyone wins is a<br/>fraud.  <br/>  <br/>A teacher has to walk a narrow path: you want to encourage kids to come up<br/>with things on their own, but you can't simply applaud everything they<br/>produce. You have to be a good audience: appreciative, but not too easily<br/>impressed. And that's a lot of work. You have to have a good enough grasp of<br/>kids' capacities at different ages to know when to be surprised.  <br/>  <br/>That's the opposite of traditional recipes for education. Traditionally the<br/>student is the audience, not the teacher; the student's job is not to invent,<br/>but to absorb some prescribed body of material. (The use of the term<br/>"recitation" for sections in some colleges is a fossil of this.) The problem<br/>with these old traditions is that they're too much influenced by recipes for<br/>wisdom.  <br/>  <br/> **Different**  <br/>  <br/>I deliberately gave this essay a provocative title; of course it's worth being<br/>wise. But I think it's important to understand the relationship between<br/>intelligence and wisdom, and particularly what seems to be the growing gap<br/>between them. That way we can avoid applying rules and standards to<br/>intelligence that are really meant for wisdom. These two senses of "knowing<br/>what to do" are more different than most people realize. The path to wisdom is<br/>through discipline, and the path to intelligence through carefully selected<br/>self-indulgence. Wisdom is universal, and intelligence idiosyncratic. And<br/>while wisdom yields calmness, intelligence much of the time leads to<br/>discontentment.  <br/>  <br/>That's particularly worth remembering. A physicist friend recently told me<br/>half his department was on Prozac. Perhaps if we acknowledge that some amount<br/>of frustration is inevitable in certain kinds of work, we can mitigate its<br/>effects. Perhaps we can box it up and put it away some of the time, instead of<br/>letting it flow together with everyday sadness to produce what seems an<br/>alarmingly large pool. At the very least, we can avoid being discontented<br/>about being discontented.  <br/>  <br/>If you feel exhausted, it's not necessarily because there's something wrong<br/>with you. Maybe you're just running fast.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Gauss was supposedly asked this when he was 10. Instead of laboriously<br/>adding together the numbers like the other students, he saw that they<br/>consisted of 50 pairs that each summed to 101 (100 \+ 1, 99 + 2, etc), and<br/>that he could just multiply 101 by 50 to get the answer, 5050.  <br/>  <br/>[2] A variant is that intelligence is the ability to solve problems, and<br/>wisdom the judgement to know how to use those solutions. But while this is<br/>certainly an important relationship between wisdom and intelligence, it's not<br/>the _distinction between_ them. Wisdom is useful in solving problems too, and<br/>intelligence can help in deciding what to do with the solutions.  <br/>  <br/>[3] In judging both intelligence and wisdom we have to factor out some<br/>knowledge. People who know the combination of a safe will be better at opening<br/>it than people who don't, but no one would say that was a test of intelligence<br/>or wisdom.  <br/>  <br/>But knowledge overlaps with wisdom and probably also intelligence. A knowledge<br/>of human nature is certainly part of wisdom. So where do we draw the line?  <br/>  <br/>Perhaps the solution is to discount knowledge that at some point has a sharp<br/>drop in utility. For example, understanding French will help you in a large<br/>number of situations, but its value drops sharply as soon as no one else<br/>involved knows French. Whereas the value of understanding vanity would decline<br/>more gradually.  <br/>  <br/>The knowledge whose utility drops sharply is the kind that has little relation<br/>to other knowledge. This includes mere conventions, like languages and safe<br/>combinations, and also what we'd call "random" facts, like movie stars'<br/>birthdays, or how to distinguish 1956 from 1957 Studebakers.  <br/>  <br/>[4] People seeking some single thing called "wisdom" have been fooled by<br/>grammar. Wisdom is just knowing the right thing to do, and there are a hundred<br/>and one different qualities that help in that. Some, like selflessness, might<br/>come from meditating in an empty room, and others, like a knowledge of human<br/>nature, might come from going to drunken parties.  <br/>  <br/>Perhaps realizing this will help dispel the cloud of semi-sacred mystery that<br/>surrounds wisdom in so many people's eyes. The mystery comes mostly from<br/>looking for something that doesn't exist. And the reason there have<br/>historically been so many different schools of thought about how to achieve<br/>wisdom is that they've focused on different components of it.  <br/>  <br/>When I use the word "wisdom" in this essay, I mean no more than whatever<br/>collection of qualities helps people make the right choice in a wide variety<br/>of situations.  <br/>  <br/>[5] Even in English, our sense of the word "intelligence" is surprisingly<br/>recent. Predecessors like "understanding" seem to have had a broader meaning.  <br/>  <br/>[6] There is of course some uncertainty about how closely the remarks<br/>attributed to Confucius and Socrates resemble their actual opinions. I'm using<br/>these names as we use the name "Homer," to mean the hypothetical people who<br/>said the things attributed to them.  <br/>  <br/>[7] _Analects_ VII:36, Fung trans.  <br/>  <br/>Some translators use "calm" instead of "happy." One source of difficulty here<br/>is that present-day English speakers have a different idea of happiness from<br/>many older societies. Every language probably has a word meaning "how one<br/>feels when things are going well," but different cultures react differently<br/>when things go well. We react like children, with smiles and laughter. But in<br/>a more reserved society, or in one where life was tougher, the reaction might<br/>be a quiet contentment.  <br/>  <br/>[8] It may have been Andrew Wiles, but I'm not sure. If anyone remembers such<br/>an interview, I'd appreciate hearing from you.  <br/>  <br/>[9] Confucius claimed proudly that he had never invented anything—that he had<br/>simply passed on an accurate account of ancient traditions. [ _Analects_<br/>VII:1] It's hard for us now to appreciate how important a duty it must have<br/>been in preliterate societies to remember and pass on the group's accumulated<br/>knowledge. Even in Confucius's time it still seems to have been the first duty<br/>of the scholar.  <br/>  <br/>[10] The bias toward wisdom in ancient philosophy may be exaggerated by the<br/>fact that, in both Greece and China, many of the first philosophers (including<br/>Confucius and Plato) saw themselves as teachers of administrators, and so<br/>thought disproportionately about such matters. The few people who did invent<br/>things, like storytellers, must have seemed an outlying data point that could<br/>be ignored.  <br/>  <br/> **Thanks** to Trevor Blackwell, Sarah Harlin, Jessica Livingston, and Robert<br/>Morris for reading drafts of this.  <br/>  <br/><br/>Polish Translation  <br/>  <br/><br/>French Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>October 2010  <br/>  <br/>Silicon Valley proper is mostly suburban sprawl. At first glance it doesn't<br/>seem there's anything to see. It's not the sort of place that has conspicuous<br/>monuments. But if you look, there are subtle signs you're in a place that's<br/>different from other places.  <br/>  <br/> **1.Stanford University**  <br/>  <br/>Stanford is a strange place. Structurally it is to an ordinary university what<br/>suburbia is to a city. It's enormously spread out, and feels surprisingly<br/>empty much of the time. But notice the weather. It's probably perfect. And<br/>notice the beautiful mountains to the west. And though you can't see it,<br/>cosmopolitan San Francisco is 40 minutes to the north. That combination is<br/>much of the reason Silicon Valley grew up around this university and not some<br/>other one.  <br/>  <br/> **2.University Ave**  <br/>  <br/>A surprising amount of the work of the Valley is done in the cafes on or just<br/>off University Ave in Palo Alto. If you visit on a weekday between 10 and 5,<br/>you'll often see founders pitching investors. In case you can't tell, the<br/>founders are the ones leaning forward eagerly, and the investors are the ones<br/>sitting back with slightly pained expressions.  <br/>  <br/> **3.The Lucky Office**  <br/>  <br/>The office at 165 University Ave was Google's first. Then it was Paypal's.<br/>(Now it's Wepay's.) The interesting thing about it is the location. It's a<br/>smart move to put a startup in a place with restaurants and people walking<br/>around instead of in an office park, because then the people who work there<br/>want to stay there, instead of fleeing as soon as conventional working hours<br/>end. They go out for dinner together, talk about ideas, and then come back and<br/>implement them.  <br/>  <br/>It's important to realize that Google's current location in an office park is<br/>not where they started; it's just where they were forced to move when they<br/>needed more space. Facebook was till recently across the street, till they too<br/>had to move because they needed more space.  <br/>  <br/> **4.Old Palo Alto**  <br/>  <br/>Palo Alto was not originally a suburb. For the first 100 years or so of its<br/>existence, it was a college town out in the countryside. Then in the mid 1950s<br/>it was engulfed in a wave of suburbia that raced down the peninsula. But Palo<br/>Alto north of Oregon expressway still feels noticeably different from the area<br/>around it. It's one of the nicest places in the Valley. The buildings are old<br/>(though increasingly they are being torn down and replaced with generic<br/>McMansions) and the trees are tall. But houses are very expensive—around $1000<br/>per square foot. This is post-exit Silicon Valley.  <br/>  <br/>**5.Sand Hill Road**  <br/>  <br/>It's interesting to see the VCs' offices on the north side of Sand Hill Road<br/>precisely because they're so boringly uniform. The buildings are all more or<br/>less the same, their exteriors express very little, and they are arranged in a<br/>confusing maze. (I've been visiting them for years and I still occasionally<br/>get lost.) It's not a coincidence. These buildings are a pretty accurate<br/>reflection of the VC business.  <br/>  <br/>If you go on a weekday you may see groups of founders there to meet VCs. But<br/>mostly you won't see anyone; bustling is the last word you'd use to describe<br/>the atmos. Visiting Sand Hill Road reminds you that the opposite of "down and<br/>dirty" would be "up and clean."  <br/>  <br/> **6.Castro Street**  <br/>  <br/>It's a tossup whether Castro Street or University Ave should be considered the<br/>heart of the Valley now. University Ave would have been 10 years ago. But Palo<br/>Alto is getting expensive. Increasingly startups are located in Mountain View,<br/>and Palo Alto is a place they come to meet investors. Palo Alto has a lot of<br/>different cafes, but there is one that clearly dominates in Mountain View: Red<br/>Rock.  <br/>  <br/> **7.Google**  <br/>  <br/>Google spread out from its first building in Mountain View to a lot of the<br/>surrounding ones. But because the buildings were built at different times by<br/>different people, the place doesn't have the sterile, walled-off feel that a<br/>typical large company's headquarters have. It definitely has a flavor of its<br/>own though. You sense there is something afoot. The general atmos is vaguely<br/>utopian; there are lots of Priuses, and people who look like they drive them.  <br/>  <br/>You can't get into Google unless you know someone there. It's very much worth<br/>seeing inside if you can, though. Ditto for Facebook, at the end of California<br/>Ave in Palo Alto, though there is nothing to see outside.  <br/>  <br/> **8.Skyline Drive**  <br/>  <br/>Skyline Drive runs along the crest of the Santa Cruz mountains. On one side is<br/>the Valley, and on the other is the sea—which because it's cold and foggy and<br/>has few harbors, plays surprisingly little role in the lives of people in the<br/>Valley, considering how close it is. Along some parts of Skyline the dominant<br/>trees are huge redwoods, and in others they're live oaks. Redwoods mean those<br/>are the parts where the fog off the coast comes in at night; redwoods condense<br/>rain out of fog. The MROSD manages a collection of great walking trails off<br/>Skyline.  <br/>  <br/> **9.280**  <br/>  <br/>Silicon Valley has two highways running the length of it: 101, which is pretty<br/>ugly, and 280, which is one of the more beautiful highways in the world. I<br/>always take 280 when I have a choice. Notice the long narrow lake to the west?<br/>That's the San Andreas Fault. It runs along the base of the hills, then heads<br/>uphill through Portola Valley. One of the MROSD trails runs right along the<br/>fault. A string of rich neighborhoods runs along the foothills to the west of<br/>280: Woodside, Portola Valley, Los Altos Hills, Saratoga, Los Gatos.  <br/>  <br/>SLAC goes right under 280 a little bit south of Sand Hill Road. And a couple<br/>miles south of that is the Valley's equivalent of the "Welcome to Las Vegas"<br/>sign: The Dish.  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>I skipped the Computer History Museum because this is a list of where to see<br/>the Valley itself, not where to see artifacts from it. I also skipped San<br/>Jose. San Jose calls itself the capital of Silicon Valley, but when people in<br/>the Valley use the phrase "the city," they mean San Francisco. San Jose is a<br/>dotted line on a map.  <br/>  <br/> **Thanks** to Sam Altman, Paul Buchheit, Patrick Collison, and Jessica<br/>Livingston for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>August 2010  <br/>  <br/>Two years ago I wrote about what I called "a huge, unexploited opportunity in<br/>startup funding<br/><br/>  <br/>  <br/><br/>* * *<br/><br/>April 2007  <br/>  <br/> _(This essay is derived from a keynote talk at the 2007 ASES Summit at<br/>Stanford.)_  <br/>  <br/>The world of investors is a foreign one to most hackers—partly because<br/>investors are so unlike hackers, and partly because they tend to operate in<br/>secret. I've been dealing with this world for many years, both as a founder<br/>and an investor, and I still don't fully understand it.  <br/>  <br/>In this essay I'm going to list some of the more surprising things I've<br/>learned about investors. Some I only learned in the past year.  <br/>  <br/>Teaching hackers how to deal with investors is probably the second most<br/>important thing we do at Y Combinator. The most important thing for a startup<br/>is to make something good. But everyone knows that's important. The dangerous<br/>thing about investors is that hackers don't know how little they know about<br/>this strange world.  <br/>  <br/> **1\. The investors are what make a startup hub.**  <br/>  <br/>About a year ago I tried to figure out what you'd need to reproduce Silicon<br/>Valley. I decided the critical ingredients were rich people and<br/>nerds—investors and founders. People are all you need to make technology, and<br/>all the other people will move.  <br/>  <br/>If I had to narrow that down, I'd say investors are the limiting factor. Not<br/>because they contribute more to the startup, but simply because they're least<br/>willing to move. They're rich. They're not going to move to Albuquerque just<br/>because there are some smart hackers there they could invest in. Whereas<br/>hackers will move to the Bay Area to find investors.  <br/>  <br/> **2\. Angel investors are the most critical.**  <br/>  <br/>There are several types of investors. The two main categories are angels and<br/>VCs: VCs invest other people's money, and angels invest their own.  <br/>  <br/>Though they're less well known, the angel investors are probably the more<br/>critical ingredient in creating a silicon valley. Most companies that VCs<br/>invest in would never have made it that far if angels hadn't invested first.<br/>VCs say between half and three quarters of companies that raise series A<br/>rounds have taken some outside investment already. [1]  <br/>  <br/>Angels are willing to fund riskier projects than VCs. They also give valuable<br/>advice, because (unlike VCs) many have been startup founders themselves.  <br/>  <br/>Google's story shows the key role angels play. A lot of people know Google<br/>raised money from Kleiner and Sequoia. What most don't realize is how late.<br/>That VC round was a series B round; the premoney valuation was $75 million.<br/>Google was already a successful company at that point. Really, Google was<br/>funded with angel money.  <br/>  <br/>It may seem odd that the canonical Silicon Valley startup was funded by<br/>angels, but this is not so surprising. Risk is always proportionate to reward.<br/>So the most successful startup of all is likely to have seemed an extremely<br/>risky bet at first, and that is exactly the kind VCs won't touch.  <br/>  <br/>Where do angel investors come from? From other startups. So startup hubs like<br/>Silicon Valley benefit from something like the marketplace effect, but shifted<br/>in time: startups are there because startups were there.  <br/>  <br/> **3\. Angels don't like publicity.**  <br/>  <br/>If angels are so important, why do we hear more about VCs? Because VCs like<br/>publicity. They need to market themselves to the investors who are their<br/>"customers"—the endowments and pension funds and rich families whose money<br/>they invest—and also to founders who might come to them for funding.  <br/>  <br/>Angels don't need to market themselves to investors because they invest their<br/>own money. Nor do they want to market themselves to founders: they don't want<br/>random people pestering them with business plans. Actually, neither do VCs.<br/>Both angels and VCs get deals almost exclusively through personal<br/>introductions. [2]  <br/>  <br/>The reason VCs want a strong brand is not to draw in more business plans over<br/>the transom, but so they win deals when competing against other VCs. Whereas<br/>angels are rarely in direct competition, because (a) they do fewer deals, (b)<br/>they're happy to split them, and (c) they invest at a point where the stream<br/>is broader.  <br/>  <br/> **4\. Most investors, especially VCs, are not like founders.**  <br/>  <br/>Some angels are, or were, hackers. But most VCs are a different type of<br/>people: they're dealmakers.  <br/>  <br/>If you're a hacker, here's a thought experiment you can run to understand why<br/>there are basically no hacker VCs: How would you like a job where you never<br/>got to make anything, but instead spent all your time listening to other<br/>people pitch (mostly terrible) projects, deciding whether to fund them, and<br/>sitting on their boards if you did? That would not be fun for most hackers.<br/>Hackers like to make things. This would be like being an administrator.  <br/>  <br/>Because most VCs are a different species of people from founders, it's hard to<br/>know what they're thinking. If you're a hacker, the last time you had to deal<br/>with these guys was in high school. Maybe in college you walked past their<br/>fraternity on your way to the lab. But don't underestimate them. They're as<br/>expert in their world as you are in yours. What they're good at is reading<br/>people, and making deals work to their advantage. Think twice before you try<br/>to beat them at that.  <br/>  <br/> **5\. Most investors are momentum investors.**  <br/>  <br/>Because most investors are dealmakers rather than technology people, they<br/>generally don't understand what you're doing. I knew as a founder that most<br/>VCs didn't get technology. I also knew some made a lot of money. And yet it<br/>never occurred to me till recently to put those two ideas together and ask<br/>"How can VCs make money by investing in stuff they don't understand?"  <br/>  <br/>The answer is that they're like momentum investors. You can (or could once)<br/>make a lot of money by noticing sudden changes in stock prices. When a stock<br/>jumps upward, you buy, and when it suddenly drops, you sell. In effect you're<br/>insider trading, without knowing what you know. You just know someone knows<br/>something, and that's making the stock move.  <br/>  <br/>This is how most venture investors operate. They don't try to look at<br/>something and predict whether it will take off. They win by noticing that<br/>something _is_ taking off a little sooner than everyone else. That generates<br/>almost as good returns as actually being able to pick winners. They may have<br/>to pay a little more than they would if they got in at the very beginning, but<br/>only a little.  <br/>  <br/>Investors always say what they really care about is the team. Actually what<br/>they care most about is your traffic, then what other investors think, then<br/>the team. If you don't yet have any traffic, they fall back on number 2, what<br/>other investors think. And this, as you can imagine, produces wild<br/>oscillations in the "stock price" of a startup. One week everyone wants you,<br/>and they're begging not to be cut out of the deal. But all it takes is for one<br/>big investor to cool on you, and the next week no one will return your phone<br/>calls. We regularly have startups go from hot to cold or cold to hot in a<br/>matter of days, and literally nothing has changed.  <br/>  <br/>There are two ways to deal with this phenomenon. If you're feeling really<br/>confident, you can try to ride it. You can start by asking a comparatively<br/>lowly VC for a small amount of money, and then after generating interest<br/>there, ask more prestigious VCs for larger amounts, stirring up a crescendo of<br/>buzz, and then "sell" at the top. This is extremely risky, and takes months<br/>even if you succeed. I wouldn't try it myself. My advice is to err on the side<br/>of safety: when someone offers you a decent deal, just take it and get on with<br/>building the company. Startups win or lose based on the quality of their<br/>product, not the quality of their funding deals.  <br/>  <br/> **6\. Most investors are looking for big hits.**  <br/>  <br/>Venture investors like companies that could go public. That's where the big<br/>returns are. They know the odds of any individual startup going public are<br/>small, but they want to invest in those that at least have a _chance_ of going<br/>public.  <br/>  <br/>Currently the way VCs seem to operate is to invest in a bunch of companies,<br/>most of which fail, and one of which is Google. Those few big wins compensate<br/>for losses on their other investments. What this means is that most VCs will<br/>only invest in you if you're a potential Google. They don't care about<br/>companies that are a safe bet to be acquired for $20 million. There needs to<br/>be a chance, however small, of the company becoming really big.  <br/>  <br/>Angels are different in this respect. They're happy to invest in a company<br/>where the most likely outcome is a $20 million acquisition if they can do it<br/>at a low enough valuation. But of course they like companies that could go<br/>public too. So having an ambitious long-term plan pleases everyone.  <br/>  <br/>If you take VC money, you have to mean it, because the structure of VC deals<br/>prevents early acquisitions. If you take VC money, they won't let you sell<br/>early.  <br/>  <br/> **7\. VCs want to invest large amounts.**  <br/>  <br/>The fact that they're running investment funds makes VCs want to invest large<br/>amounts. A typical VC fund is now hundreds of millions of dollars. If $400<br/>million has to be invested by 10 partners, they have to invest $40 million<br/>each. VCs usually sit on the boards of companies they fund. If the average<br/>deal size was $1 million, each partner would have to sit on 40 boards, which<br/>would not be fun. So they prefer bigger deals, where they can put a lot of<br/>money to work at once.  <br/>  <br/>VCs don't regard you as a bargain if you don't need a lot of money. That may<br/>even make you less attractive, because it means their investment creates less<br/>of a barrier to entry for competitors.  <br/>  <br/>Angels are in a different position because they're investing their own money.<br/>They're happy to invest small amounts—sometimes as little as $20,000—as long<br/>as the potential returns look good enough. So if you're doing something<br/>inexpensive, go to angels.  <br/>  <br/> **8\. Valuations are fiction.**  <br/>  <br/>VCs admit that valuations are an artifact. They decide how much money you need<br/>and how much of the company they want, and those two constraints yield a<br/>valuation.  <br/>  <br/>Valuations increase as the size of the investment does. A company that an<br/>angel is willing to put $50,000 into at a valuation of a million can't take $6<br/>million from VCs at that valuation. That would leave the founders less than a<br/>seventh of the company between them (since the option pool would also come out<br/>of that seventh). Most VCs wouldn't want that, which is why you never hear of<br/>deals where a VC invests $6 million at a premoney valuation of $1 million.  <br/>  <br/>If valuations change depending on the amount invested, that shows how far they<br/>are from reflecting any kind of value of the company.  <br/>  <br/>Since valuations are made up, founders shouldn't care too much about them.<br/>That's not the part to focus on. In fact, a high valuation can be a bad thing.<br/>If you take funding at a premoney valuation of $10 million, you won't be<br/>selling the company for 20. You'll have to sell for over 50 for the VCs to get<br/>even a 5x return, which is low to them. More likely they'll want you to hold<br/>out for 100. But needing to get a high price decreases the chance of getting<br/>bought at all; many companies can buy you for $10 million, but only a handful<br/>for 100. And since a startup is like a pass/fail course for the founders, what<br/>you want to optimize is your chance of a good outcome, not the percentage of<br/>the company you keep.  <br/>  <br/>So why do founders chase high valuations? They're tricked by misplaced<br/>ambition. They feel they've achieved more if they get a higher valuation. They<br/>usually know other founders, and if they get a higher valuation they can say<br/>"mine is bigger than yours." But funding is not the real test. The real test<br/>is the final outcome for the founder, and getting too high a valuation may<br/>just make a good outcome less likely.  <br/>  <br/>The one advantage of a high valuation is that you get less dilution. But there<br/>is another less sexy way to achieve that: just take less money.  <br/>  <br/> **9\. Investors look for founders like the current stars.**  <br/>  <br/>Ten years ago investors were looking for the next Bill Gates. This was a<br/>mistake, because Microsoft was a very anomalous startup. They started almost<br/>as a contract programming operation, and the reason they became huge was that<br/>IBM happened to drop the PC standard in their lap.  <br/>  <br/>Now all the VCs are looking for the next Larry and Sergey. This is a good<br/>trend, because Larry and Sergey are closer to the ideal startup founders.  <br/>  <br/>Historically investors thought it was important for a founder to be an expert<br/>in business. So they were willing to fund teams of MBAs who planned to use the<br/>money to pay programmers to build their product for them. This is like funding<br/>Steve Ballmer in the hope that the programmer he'll hire is Bill Gates—kind of<br/>backward, as the events of the Bubble showed. Now most VCs know they should be<br/>funding technical guys. This is more pronounced among the very top funds; the<br/>lamer ones still want to fund MBAs.  <br/>  <br/>If you're a hacker, it's good news that investors are looking for Larry and<br/>Sergey. The bad news is, the only investors who can do it right are the ones<br/>who knew them when they were a couple of CS grad students, not the confident<br/>media stars they are today. What investors still don't get is how clueless and<br/>tentative great founders can seem at the very beginning.  <br/>  <br/> **10\. The contribution of investors tends to be underestimated.**  <br/>  <br/>Investors do more for startups than give them money. They're helpful in doing<br/>deals and arranging introductions, and some of the smarter ones, particularly<br/>angels, can give good advice about the product.  <br/>  <br/>In fact, I'd say what separates the great investors from the mediocre ones is<br/>the quality of their advice. Most investors give advice, but the top ones give<br/>_good_ advice.  <br/>  <br/>Whatever help investors give a startup tends to be underestimated. It's to<br/>everyone's advantage to let the world think the founders thought of<br/>everything. The goal of the investors is for the company to become valuable,<br/>and the company seems more valuable if it seems like all the good ideas came<br/>from within.  <br/>  <br/>This trend is compounded by the obsession that the press has with founders. In<br/>a company founded by two people, 10% of the ideas might come from the first<br/>guy they hire. Arguably they've done a bad job of hiring otherwise. And yet<br/>this guy will be almost entirely overlooked by the press.  <br/>  <br/>I say this as a founder: the contribution of founders is always overestimated.<br/>The danger here is that new founders, looking at existing founders, will think<br/>that they're supermen that one couldn't possibly equal oneself. Actually they<br/>have a hundred different types of support people just offscreen making the<br/>whole show possible. [3]  <br/>  <br/> **11\. VCs are afraid of looking bad.**  <br/>  <br/>I've been very surprised to discover how timid most VCs are. They seem to be<br/>afraid of looking bad to their partners, and perhaps also to the limited<br/>partners—the people whose money they invest.  <br/>  <br/>You can measure this fear in how much less risk VCs are willing to take. You<br/>can tell they won't make investments for their fund that they might be willing<br/>to make themselves as angels. Though it's not quite accurate to say that VCs<br/>are less willing to take risks. They're less willing to do things that might<br/>look bad. That's not the same thing.  <br/>  <br/>For example, most VCs would be very reluctant to invest in a startup founded<br/>by a pair of 18 year old hackers, no matter how brilliant, because if the<br/>startup failed their partners could turn on them and say "What, you invested<br/>$x million of our money in a pair of 18 year olds?" Whereas if a VC invested<br/>in a startup founded by three former banking executives in their 40s who<br/>planned to outsource their product development—which to my mind is actually a<br/>lot riskier than investing in a pair of really smart 18 year olds—he couldn't<br/>be faulted, if it failed, for making such an apparently prudent investment.  <br/>  <br/>As a friend of mine said, "Most VCs can't do anything that would sound bad to<br/>the kind of doofuses who run pension funds." Angels can take greater risks<br/>because they don't have to answer to anyone.  <br/>  <br/> **12\. Being turned down by investors doesn't mean much.**  <br/>  <br/>Some founders are quite dejected when they get turned down by investors. They<br/>shouldn't take it so much to heart. To start with, investors are often wrong.<br/>It's hard to think of a successful startup that wasn't turned down by<br/>investors at some point. Lots of VCs rejected Google. So obviously the<br/>reaction of investors is not a very meaningful test.  <br/>  <br/>Investors will often reject you for what seem to be superficial reasons. I<br/>read of one VC who turned down a startup simply because they'd given away so<br/>many little bits of stock that the deal required too many signatures to close.<br/>[4] The reason investors can get away with this is that they see so many<br/>deals. It doesn't matter if they underestimate you because of some surface<br/>imperfection, because the next best deal will be almost as good. Imagine<br/>picking out apples at a grocery store. You grab one with a little bruise.<br/>Maybe it's just a surface bruise, but why even bother checking when there are<br/>so many other unbruised apples to choose from?  <br/>  <br/>Investors would be the first to admit they're often wrong. So when you get<br/>rejected by investors, don't think "we suck," but instead ask "do we suck?"<br/>Rejection is a question, not an answer.  <br/>  <br/> **13\. Investors are emotional.**  <br/>  <br/>I've been surprised to discover how emotional investors can be. You'd expect<br/>them to be cold and calculating, or at least businesslike, but often they're<br/>not. I'm not sure if it's their position of power that makes them this way, or<br/>the large sums of money involved, but investment negotiations can easily turn<br/>personal. If you offend investors, they'll leave in a huff.  <br/>  <br/>A while ago an eminent VC firm offered a series A round to a startup we'd seed<br/>funded. Then they heard a rival VC firm was also interested. They were so<br/>afraid that they'd be rejected in favor of this other firm that they gave the<br/>startup what's known as an "exploding termsheet." They had, I think, 24 hours<br/>to say yes or no, or the deal was off. Exploding termsheets are a somewhat<br/>dubious device, but not uncommon. What surprised me was their reaction when I<br/>called to talk about it. I asked if they'd still be interested in the startup<br/>if the rival VC didn't end up making an offer, and they said no. What rational<br/>basis could they have had for saying that? If they thought the startup was<br/>worth investing in, what difference should it make what some other VC thought?<br/>Surely it was their duty to their limited partners simply to invest in the<br/>best opportunities they found; they should be delighted if the other VC said<br/>no, because it would mean they'd overlooked a good opportunity. But of course<br/>there was no rational basis for their decision. They just couldn't stand the<br/>idea of taking this rival firm's rejects.  <br/>  <br/>In this case the exploding termsheet was not (or not only) a tactic to<br/>pressure the startup. It was more like the high school trick of breaking up<br/>with someone before they can break up with you. In an earlier essay I said<br/>that VCs were a lot like high school girls. A few VCs have joked about that<br/>characterization, but none have disputed it.  <br/>  <br/> **14\. The negotiation never stops till the closing.**  <br/>  <br/>Most deals, for investment or acquisition, happen in two phases. There's an<br/>initial phase of negotiation about the big questions. If this succeeds you get<br/>a termsheet, so called because it outlines the key terms of a deal. A<br/>termsheet is not legally binding, but it is a definite step. It's supposed to<br/>mean that a deal is going to happen, once the lawyers work out all the<br/>details. In theory these details are minor ones; by definition all the<br/>important points are supposed to be covered in the termsheet.  <br/>  <br/>Inexperience and wishful thinking combine to make founders feel that when they<br/>have a termsheet, they have a deal. They want there to be a deal; everyone<br/>acts like they have a deal; so there must be a deal. But there isn't and may<br/>not be for several months. A lot can change for a startup in several months.<br/>It's not uncommon for investors and acquirers to get buyer's remorse. So you<br/>have to keep pushing, keep selling, all the way to the close. Otherwise all<br/>the "minor" details left unspecified in the termsheet will be interpreted to<br/>your disadvantage. The other side may even break the deal; if they do that,<br/>they'll usually seize on some technicality or claim you misled them, rather<br/>than admitting they changed their minds.  <br/>  <br/>It can be hard to keep the pressure on an investor or acquirer all the way to<br/>the closing, because the most effective pressure is competition from other<br/>investors or acquirers, and these tend to drop away when you get a termsheet.<br/>You should try to stay as close friends as you can with these rivals, but the<br/>most important thing is just to keep up the momentum in your startup. The<br/>investors or acquirers chose you because you seemed hot. Keep doing whatever<br/>made you seem hot. Keep releasing new features; keep getting new users; keep<br/>getting mentioned in the press and in blogs.  <br/>  <br/> **15\. Investors like to co-invest.**  <br/>  <br/>I've been surprised how willing investors are to split deals. You might think<br/>that if they found a good deal they'd want it all to themselves, but they seem<br/>positively eager to syndicate. This is understandable with angels; they invest<br/>on a smaller scale and don't like to have too much money tied up in any one<br/>deal. But VCs also share deals a lot. Why?  <br/>  <br/>Partly I think this is an artifact of the rule I quoted earlier: after<br/>traffic, VCs care most what other VCs think. A deal that has multiple VCs<br/>interested in it is more likely to close, so of deals that close, more will<br/>have multiple investors.  <br/>  <br/>There is one rational reason to want multiple VCs in a deal: Any investor who<br/>co-invests with you is one less investor who could fund a competitor.<br/>Apparently Kleiner and Sequoia didn't like splitting the Google deal, but it<br/>did at least have the advantage, from each one's point of view, that there<br/>probably wouldn't be a competitor funded by the other. Splitting deals thus<br/>has similar advantages to confusing paternity.  <br/>  <br/>But I think the main reason VCs like splitting deals is the fear of looking<br/>bad. If another firm shares the deal, then in the event of failure it will<br/>seem to have been a prudent choice—a consensus decision, rather than just the<br/>whim of an individual partner.  <br/>  <br/> **16\. Investors collude.**  <br/>  <br/>Investing is not covered by antitrust law. At least, it better not be, because<br/>investors regularly do things that would be illegal otherwise. I know<br/>personally of cases where one investor has talked another out of making a<br/>competitive offer, using the promise of sharing future deals.  <br/>  <br/>In principle investors are all competing for the same deals, but the spirit of<br/>cooperation is stronger than the spirit of competition. The reason, again, is<br/>that there are so many deals. Though a professional investor may have a closer<br/>relationship with a founder he invests in than with other investors, his<br/>relationship with the founder is only going to last a couple years, whereas<br/>his relationship with other firms will last his whole career. There isn't so<br/>much at stake in his interactions with other investors, but there will be a<br/>lot of them. Professional investors are constantly trading little favors.  <br/>  <br/>Another reason investors stick together is to preserve the power of investors<br/>as a whole. So you will not, as of this writing, be able to get investors into<br/>an auction for your series A round. They'd rather lose the deal than establish<br/>a precedent of VCs competitively bidding against one another. An efficient<br/>startup funding market may be coming in the distant future; things tend to<br/>move in that direction; but it's certainly not here now.  <br/>  <br/>**17\. Large-scale investors care about their portfolio, not any individual<br/>company.**  <br/>  <br/>The reason startups work so well is that everyone with power also has equity.<br/>The only way any of them can succeed is if they all do. This makes everyone<br/>naturally pull in the same direction, subject to differences of opinion about<br/>tactics.  <br/>  <br/>The problem is, larger scale investors don't have exactly the same motivation.<br/>Close, but not identical. They don't need any given startup to succeed, like<br/>founders do, just their portfolio as a whole to. So in borderline cases the<br/>rational thing for them to do is to sacrifice unpromising startups.  <br/>  <br/>Large-scale investors tend to put startups in three categories: successes,<br/>failures, and the "living dead"—companies that are plugging along but don't<br/>seem likely in the immediate future to get bought or go public. To the<br/>founders, "living dead" sounds harsh. These companies may be far from failures<br/>by ordinary standards. But they might as well be from a venture investor's<br/>point of view, and they suck up just as much time and attention as the<br/>successes. So if such a company has two possible strategies, a conservative<br/>one that's slightly more likely to work in the end, or a risky one that within<br/>a short time will either yield a giant success or kill the company, VCs will<br/>push for the kill-or-cure option. To them the company is already a write-off.<br/>Better to have resolution, one way or the other, as soon as possible.  <br/>  <br/>If a startup gets into real trouble, instead of trying to save it VCs may just<br/>sell it at a low price to another of their portfolio companies. Philip<br/>Greenspun said in _Founders at Work_ that Ars Digita's VCs did this to them.  <br/>  <br/> **18\. Investors have different risk profiles from founders.**  <br/>  <br/>Most people would rather a 100% chance of $1 million than a 20% chance of $10<br/>million. Investors are rich enough to be rational and prefer the latter. So<br/>they'll always tend to encourage founders to keep rolling the dice. If a<br/>company is doing well, investors will want founders to turn down most<br/>acquisition offers. And indeed, most startups that turn down acquisition<br/>offers ultimately do better. But it's still hair-raising for the founders,<br/>because they might end up with nothing. When someone's offering to buy you for<br/>a price at which your stock is worth $5 million, saying no is equivalent to<br/>having $5 million and betting it all on one spin of the roulette wheel.  <br/>  <br/>Investors will tell you the company is worth more. And they may be right. But<br/>that doesn't mean it's wrong to sell. Any financial advisor who put all his<br/>client's assets in the stock of a single, private company would probably lose<br/>his license for it.  <br/>  <br/>More and more, investors are letting founders cash out partially. That should<br/>correct the problem. Most founders have such low standards that they'll feel<br/>rich with a sum that doesn't seem huge to investors. But this custom is<br/>spreading too slowly, because VCs are afraid of seeming irresponsible. No one<br/>wants to be the first VC to give someone fuck-you money and then actually get<br/>told "fuck you." But until this does start to happen, we know VCs are being<br/>too conservative.  <br/>  <br/> **19\. Investors vary greatly.**  <br/>  <br/>Back when I was a founder I used to think all VCs were the same. And in fact<br/>they do all look the same. They're all what hackers call "suits." But since<br/>I've been dealing with VCs more I've learned that some suits are smarter than<br/>others.  <br/>  <br/>They're also in a business where winners tend to keep winning and losers to<br/>keep losing. When a VC firm has been successful in the past, everyone wants<br/>funding from them, so they get the pick of all the new deals. The self-<br/>reinforcing nature of the venture funding market means that the top ten firms<br/>live in a completely different world from, say, the hundredth. As well as<br/>being smarter, they tend to be calmer and more upstanding; they don't need to<br/>do iffy things to get an edge, and don't want to because they have more brand<br/>to protect.  <br/>  <br/>There are only two kinds of VCs you want to take money from, if you have the<br/>luxury of choosing: the "top tier" VCs, meaning about the top 20 or so firms,<br/>plus a few new ones that are not among the top 20 only because they haven't<br/>been around long enough.  <br/>  <br/>It's particularly important to raise money from a top firm if you're a hacker,<br/>because they're more confident. That means they're less likely to stick you<br/>with a business guy as CEO, like VCs used to do in the 90s. If you seem smart<br/>and want to do it, they'll let you run the company.  <br/>  <br/> **20\. Investors don't realize how much it costs to raise money from them.**  <br/>  <br/>Raising money is a huge time suck at just the point where startups can least<br/>afford it. It's not unusual for it to take five or six months to close a<br/>funding round. Six weeks is fast. And raising money is not just something you<br/>can leave running as a background process. When you're raising money, it's<br/>inevitably the main focus of the company. Which means building the product<br/>isn't.  <br/>  <br/>Suppose a Y Combinator company starts talking to VCs after demo day, and is<br/>successful in raising money from them, closing the deal after a comparatively<br/>short 8 weeks. Since demo day occurs after 10 weeks, the company is now 18<br/>weeks old. Raising money, rather than working on the product, has been the<br/>company's main focus for 44% of its existence. And mind you, this an example<br/>where things turned out _well_.  <br/>  <br/>When a startup does return to working on the product after a funding round<br/>finally closes, it's as if they were returning to work after a months-long<br/>illness. They've lost most of their momentum.  <br/>  <br/>Investors have no idea how much they damage the companies they invest in by<br/>taking so long to do it. But companies do. So there is a big opportunity here<br/>for a new kind of venture fund that invests smaller amounts at lower<br/>valuations, but promises to either close or say no very quickly. If there were<br/>such a firm, I'd recommend it to startups in preference to any other, no<br/>matter how prestigious. Startups live on speed and momentum.  <br/>  <br/> **21\. Investors don't like to say no.**  <br/>  <br/>The reason funding deals take so long to close is mainly that investors can't<br/>make up their minds. VCs are not big companies; they can do a deal in 24 hours<br/>if they need to. But they usually let the initial meetings stretch out over a<br/>couple weeks. The reason is the selection algorithm I mentioned earlier. Most<br/>don't try to predict whether a startup will win, but to notice quickly that it<br/>already is winning. They care what the market thinks of you and what other VCs<br/>think of you, and they can't judge those just from meeting you.  <br/>  <br/>Because they're investing in things that (a) change fast and (b) they don't<br/>understand, a lot of investors will reject you in a way that can later be<br/>claimed not to have been a rejection. Unless you know this world, you may not<br/>even realize you've been rejected. Here's a VC saying no:<br/><br/>> We're really excited about your project, and we want to keep in close touch<br/>> as you develop it further.<br/><br/>Translated into more straightforward language, this means: We're not investing<br/>in you, but we may change our minds if it looks like you're taking off.<br/>Sometimes they're more candid and say explicitly that they need to "see some<br/>traction." They'll invest in you if you start to get lots of users. But so<br/>would any VC. So all they're saying is that you're still at square 1.  <br/>  <br/>Here's a test for deciding whether a VC's response was yes or no. Look down at<br/>your hands. Are you holding a termsheet?  <br/>  <br/> **22\. You need investors.**  <br/>  <br/>Some founders say "Who needs investors?" Empirically the answer seems to be:<br/>everyone who wants to succeed. Practically every successful startup takes<br/>outside investment at some point.  <br/>  <br/>Why? What the people who think they don't need investors forget is that they<br/>will have competitors. The question is not whether you _need_ outside<br/>investment, but whether it could help you at all. If the answer is yes, and<br/>you don't take investment, then competitors who do will have an advantage over<br/>you. And in the startup world a little advantage can expand into a lot.  <br/>  <br/>Mike Moritz famously said that he invested in Yahoo because he thought they<br/>had a few weeks' lead over their competitors. That may not have mattered quite<br/>so much as he thought, because Google came along three years later and kicked<br/>Yahoo's ass. But there is something in what he said. Sometimes a small lead<br/>can grow into the yes half of a binary choice.  <br/>  <br/>Maybe as it gets cheaper to start a startup, it will start to be possible to<br/>succeed in a competitive market without outside funding. There are certainly<br/>costs to raising money. But as of this writing the empirical evidence says<br/>it's a net win.  <br/>  <br/> **23\. Investors like it when you don't need them.**  <br/>  <br/>A lot of founders approach investors as if they needed their permission to<br/>start a company—as if it were like getting into college. But you don't need<br/>investors to start most companies; they just make it easier.  <br/>  <br/>And in fact, investors greatly prefer it if you don't need them. What excites<br/>them, both consciously and unconsciously, is the sort of startup that<br/>approaches them saying "the train's leaving the station; are you in or out?"<br/>not the one saying "please can we have some money to start a company?"  <br/>  <br/>Most investors are "bottoms" in the sense that the startups they like most are<br/>those that are rough with them. When Google stuck Kleiner and Sequoia with a<br/>$75 million premoney valuation, their reaction was probably "Ouch! That feels<br/>so good." And they were right, weren't they? That deal probably made them more<br/>than any other they've done.  <br/>  <br/>The thing is, VCs are pretty good at reading people. So don't try to act tough<br/>with them unless you really are the next Google, or they'll see through you in<br/>a second. Instead of acting tough, what most startups should do is simply<br/>always have a backup plan. Always have some alternative plan for getting<br/>started if any given investor says no. Having one is the best insurance<br/>against needing one.  <br/>  <br/>So you shouldn't start a startup that's expensive to start, because then<br/>you'll be at the mercy of investors. If you ultimately want to do something<br/>that will cost a lot, start by doing a cheaper subset of it, and expand your<br/>ambitions when and if you raise more money.  <br/>  <br/>Apparently the most likely animals to be left alive after a nuclear war are<br/>cockroaches, because they're so hard to kill. That's what you want to be as a<br/>startup, initially. Instead of a beautiful but fragile flower that needs to<br/>have its stem in a plastic tube to support itself, better to be small, ugly,<br/>and indestructible.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] I may be underestimating VCs. They may play some behind the scenes role in<br/>IPOs, which you ultimately need if you want to create a silicon valley.  <br/>  <br/>[2] A few VCs have an email address you can send your business plan to, but<br/>the number of startups that get funded this way is basically zero. You should<br/>always get a personal introduction—and to a partner, not an associate.  <br/>  <br/>[3] Several people have told us that the most valuable thing about startup<br/>school was that they got to see famous startup founders and realized they were<br/>just ordinary guys. Though we're happy to provide this service, this is not<br/>generally the way we pitch startup school to potential speakers.  <br/>  <br/>[4] Actually this sounds to me like a VC who got buyer's remorse, then used a<br/>technicality to get out of the deal. But it's telling that it even seemed a<br/>plausible excuse.  <br/>  <br/> **Thanks** to Sam Altman, Paul Buchheit, Hutch Fishman, and Robert Morris for<br/>reading drafts of this, and to Kenneth King of ASES for inviting me to speak.  <br/>  <br/>Comment on this essay.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>August 2002  <br/>  <br/> _(This article describes the spam-filtering techniques used in the spamproof<br/>web-based mail reader we built to exerciseArc. An improved algorithm is<br/>described in Better Bayesian Filtering.)_  <br/>  <br/>I think it's possible to stop spam, and that content-based filters are the way<br/>to do it. The Achilles heel of the spammers is their message. They can<br/>circumvent any other barrier you set up. They have so far, at least. But they<br/>have to deliver their message, whatever it is. If we can write software that<br/>recognizes their messages, there is no way they can get around that.  <br/>  <br/>_ _ _  <br/>  <br/>To the recipient, spam is easily recognizable. If you hired someone to read<br/>your mail and discard the spam, they would have little trouble doing it. How<br/>much do we have to do, short of AI, to automate this process?  <br/>  <br/>I think we will be able to solve the problem with fairly simple algorithms. In<br/>fact, I've found that you can filter present-day spam acceptably well using<br/>nothing more than a Bayesian combination of the spam probabilities of<br/>individual words. Using a slightly tweaked (as described below) Bayesian<br/>filter, we now miss less than 5 per 1000 spams, with 0 false positives.  <br/>  <br/>The statistical approach is not usually the first one people try when they<br/>write spam filters. Most hackers' first instinct is to try to write software<br/>that recognizes individual properties of spam. You look at spams and you<br/>think, the gall of these guys to try sending me mail that begins "Dear Friend"<br/>or has a subject line that's all uppercase and ends in eight exclamation<br/>points. I can filter out that stuff with about one line of code.  <br/>  <br/>And so you do, and in the beginning it works. A few simple rules will take a<br/>big bite out of your incoming spam. Merely looking for the word "click" will<br/>catch 79.7% of the emails in my spam corpus, with only 1.2% false positives.  <br/>  <br/>I spent about six months writing software that looked for individual spam<br/>features before I tried the statistical approach. What I found was that<br/>recognizing that last few percent of spams got very hard, and that as I made<br/>the filters stricter I got more false positives.  <br/>  <br/>False positives are innocent emails that get mistakenly identified as spams.<br/>For most users, missing legitimate email is an order of magnitude worse than<br/>receiving spam, so a filter that yields false positives is like an acne cure<br/>that carries a risk of death to the patient.  <br/>  <br/>The more spam a user gets, the less likely he'll be to notice one innocent<br/>mail sitting in his spam folder. And strangely enough, the better your spam<br/>filters get, the more dangerous false positives become, because when the<br/>filters are really good, users will be more likely to ignore everything they<br/>catch.  <br/>  <br/>I don't know why I avoided trying the statistical approach for so long. I<br/>think it was because I got addicted to trying to identify spam features<br/>myself, as if I were playing some kind of competitive game with the spammers.<br/>(Nonhackers don't often realize this, but most hackers are very competitive.)<br/>When I did try statistical analysis, I found immediately that it was much<br/>cleverer than I had been. It discovered, of course, that terms like<br/>"virtumundo" and "teens" were good indicators of spam. But it also discovered<br/>that "per" and "FL" and "ff0000" are good indicators of spam. In fact,<br/>"ff0000" (html for bright red) turns out to be as good an indicator of spam as<br/>any pornographic term.  <br/>  <br/>_ _ _  <br/>  <br/>Here's a sketch of how I do statistical filtering. I start with one corpus of<br/>spam and one of nonspam mail. At the moment each one has about 4000 messages<br/>in it. I scan the entire text, including headers and embedded html and<br/>javascript, of each message in each corpus. I currently consider alphanumeric<br/>characters, dashes, apostrophes, and dollar signs to be part of tokens, and<br/>everything else to be a token separator. (There is probably room for<br/>improvement here.) I ignore tokens that are all digits, and I also ignore html<br/>comments, not even considering them as token separators.  <br/>  <br/>I count the number of times each token (ignoring case, currently) occurs in<br/>each corpus. At this stage I end up with two large hash tables, one for each<br/>corpus, mapping tokens to number of occurrences.  <br/>  <br/>Next I create a third hash table, this time mapping each token to the<br/>probability that an email containing it is a spam, which I calculate as<br/>follows [1]:  (let ((g (* 2 (or (gethash word good) 0))) (b (or (gethash word<br/>bad) 0))) (unless (< (+ g b) 5) (max .01 (min .99 (float (/ (min 1 (/ b nbad))<br/>(+ (min 1 (/ g ngood)) (min 1 (/ b nbad)))))))))  where word is the token<br/>whose probability we're calculating, good and bad are the hash tables I<br/>created in the first step, and ngood and nbad are the number of nonspam and<br/>spam messages respectively.  <br/>  <br/>I explained this as code to show a couple of important details. I want to bias<br/>the probabilities slightly to avoid false positives, and by trial and error<br/>I've found that a good way to do it is to double all the numbers in good. This<br/>helps to distinguish between words that occasionally do occur in legitimate<br/>email and words that almost never do. I only consider words that occur more<br/>than five times in total (actually, because of the doubling, occurring three<br/>times in nonspam mail would be enough). And then there is the question of what<br/>probability to assign to words that occur in one corpus but not the other.<br/>Again by trial and error I chose .01 and .99. There may be room for tuning<br/>here, but as the corpus grows such tuning will happen automatically anyway.  <br/>  <br/>The especially observant will notice that while I consider each corpus to be a<br/>single long stream of text for purposes of counting occurrences, I use the<br/>number of emails in each, rather than their combined length, as the divisor in<br/>calculating spam probabilities. This adds another slight bias to protect<br/>against false positives.  <br/>  <br/>When new mail arrives, it is scanned into tokens, and the most interesting<br/>fifteen tokens, where interesting is measured by how far their spam<br/>probability is from a neutral .5, are used to calculate the probability that<br/>the mail is spam. If probs is a list of the fifteen individual probabilities,<br/>you calculate the combined probability thus:  (let ((prod (apply #'* probs)))<br/>(/ prod (+ prod (apply #'* (mapcar #'(lambda (x) (- 1 x)) probs)))))  One<br/>question that arises in practice is what probability to assign to a word<br/>you've never seen, i.e. one that doesn't occur in the hash table of word<br/>probabilities. I've found, again by trial and error, that .4 is a good number<br/>to use. If you've never seen a word before, it is probably fairly innocent;<br/>spam words tend to be all too familiar.  <br/>  <br/>There are examples of this algorithm being applied to actual emails in an<br/>appendix at the end.  <br/>  <br/>I treat mail as spam if the algorithm above gives it a probability of more<br/>than .9 of being spam. But in practice it would not matter much where I put<br/>this threshold, because few probabilities end up in the middle of the range.  <br/>  <br/>_ _ _  <br/>  <br/>One great advantage of the statistical approach is that you don't have to read<br/>so many spams. Over the past six months, I've read literally thousands of<br/>spams, and it is really kind of demoralizing. Norbert Wiener said if you<br/>compete with slaves you become a slave, and there is something similarly<br/>degrading about competing with spammers. To recognize individual spam features<br/>you have to try to get into the mind of the spammer, and frankly I want to<br/>spend as little time inside the minds of spammers as possible.  <br/>  <br/>But the real advantage of the Bayesian approach, of course, is that you know<br/>what you're measuring. Feature-recognizing filters like SpamAssassin assign a<br/>spam "score" to email. The Bayesian approach assigns an actual probability.<br/>The problem with a "score" is that no one knows what it means. The user<br/>doesn't know what it means, but worse still, neither does the developer of the<br/>filter. How many _points_ should an email get for having the word "sex" in it?<br/>A probability can of course be mistaken, but there is little ambiguity about<br/>what it means, or how evidence should be combined to calculate it. Based on my<br/>corpus, "sex" indicates a .97 probability of the containing email being a<br/>spam, whereas "sexy" indicates .99 probability. And Bayes' Rule, equally<br/>unambiguous, says that an email containing both words would, in the (unlikely)<br/>absence of any other evidence, have a 99.97% chance of being a spam.  <br/>  <br/>Because it is measuring probabilities, the Bayesian approach considers all the<br/>evidence in the email, both good and bad. Words that occur disproportionately<br/>_rarely_ in spam (like "though" or "tonight" or "apparently") contribute as<br/>much to decreasing the probability as bad words like "unsubscribe" and "opt-<br/>in" do to increasing it. So an otherwise innocent email that happens to<br/>include the word "sex" is not going to get tagged as spam.  <br/>  <br/>Ideally, of course, the probabilities should be calculated individually for<br/>each user. I get a lot of email containing the word "Lisp", and (so far) no<br/>spam that does. So a word like that is effectively a kind of password for<br/>sending mail to me. In my earlier spam-filtering software, the user could set<br/>up a list of such words and mail containing them would automatically get past<br/>the filters. On my list I put words like "Lisp" and also my zipcode, so that<br/>(otherwise rather spammy-sounding) receipts from online orders would get<br/>through. I thought I was being very clever, but I found that the Bayesian<br/>filter did the same thing for me, and moreover discovered of a lot of words I<br/>hadn't thought of.  <br/>  <br/>When I said at the start that our filters let through less than 5 spams per<br/>1000 with 0 false positives, I'm talking about filtering my mail based on a<br/>corpus of my mail. But these numbers are not misleading, because that is the<br/>approach I'm advocating: filter each user's mail based on the spam and nonspam<br/>mail he receives. Essentially, each user should have two delete buttons,<br/>ordinary delete and delete-as-spam. Anything deleted as spam goes into the<br/>spam corpus, and everything else goes into the nonspam corpus.  <br/>  <br/>You could start users with a seed filter, but ultimately each user should have<br/>his own per-word probabilities based on the actual mail he receives. This (a)<br/>makes the filters more effective, (b) lets each user decide their own precise<br/>definition of spam, and (c) perhaps best of all makes it hard for spammers to<br/>tune mails to get through the filters. If a lot of the brain of the filter is<br/>in the individual databases, then merely tuning spams to get through the seed<br/>filters won't guarantee anything about how well they'll get through individual<br/>users' varying and much more trained filters.  <br/>  <br/>Content-based spam filtering is often combined with a whitelist, a list of<br/>senders whose mail can be accepted with no filtering. One easy way to build<br/>such a whitelist is to keep a list of every address the user has ever sent<br/>mail to. If a mail reader has a delete-as-spam button then you could also add<br/>the from address of every email the user has deleted as ordinary trash.  <br/>  <br/>I'm an advocate of whitelists, but more as a way to save computation than as a<br/>way to improve filtering. I used to think that whitelists would make filtering<br/>easier, because you'd only have to filter email from people you'd never heard<br/>from, and someone sending you mail for the first time is constrained by<br/>convention in what they can say to you. Someone you already know might send<br/>you an email talking about sex, but someone sending you mail for the first<br/>time would not be likely to. The problem is, people can have more than one<br/>email address, so a new from-address doesn't guarantee that the sender is<br/>writing to you for the first time. It is not unusual for an old friend<br/>(especially if he is a hacker) to suddenly send you an email with a new from-<br/>address, so you can't risk false positives by filtering mail from unknown<br/>addresses especially stringently.  <br/>  <br/>In a sense, though, my filters do themselves embody a kind of whitelist (and<br/>blacklist) because they are based on entire messages, including the headers.<br/>So to that extent they "know" the email addresses of trusted senders and even<br/>the routes by which mail gets from them to me. And they know the same about<br/>spam, including the server names, mailer versions, and protocols.  <br/>  <br/>_ _ _  <br/>  <br/>If I thought that I could keep up current rates of spam filtering, I would<br/>consider this problem solved. But it doesn't mean much to be able to filter<br/>out most present-day spam, because spam evolves. Indeed, most antispam<br/>techniques so far have been like pesticides that do nothing more than create a<br/>new, resistant strain of bugs.  <br/>  <br/>I'm more hopeful about Bayesian filters, because they evolve with the spam. So<br/>as spammers start using "c0ck" instead of "cock" to evade simple-minded spam<br/>filters based on individual words, Bayesian filters automatically notice.<br/>Indeed, "c0ck" is far more damning evidence than "cock", and Bayesian filters<br/>know precisely how much more.  <br/>  <br/>Still, anyone who proposes a plan for spam filtering has to be able to answer<br/>the question: if the spammers knew exactly what you were doing, how well could<br/>they get past you? For example, I think that if checksum-based spam filtering<br/>becomes a serious obstacle, the spammers will just switch to mad-lib<br/>techniques for generating message bodies.  <br/>  <br/>To beat Bayesian filters, it would not be enough for spammers to make their<br/>emails unique or to stop using individual naughty words. They'd have to make<br/>their mails indistinguishable from your ordinary mail. And this I think would<br/>severely constrain them. Spam is mostly sales pitches, so unless your regular<br/>mail is all sales pitches, spams will inevitably have a different character.<br/>And the spammers would also, of course, have to change (and keep changing)<br/>their whole infrastructure, because otherwise the headers would look as bad to<br/>the Bayesian filters as ever, no matter what they did to the message body. I<br/>don't know enough about the infrastructure that spammers use to know how hard<br/>it would be to make the headers look innocent, but my guess is that it would<br/>be even harder than making the message look innocent.  <br/>  <br/>Assuming they could solve the problem of the headers, the spam of the future<br/>will probably look something like this:  Hey there. Thought you should check<br/>out the following: http://www.27meg.com/foo  because that is about as much<br/>sales pitch as content-based filtering will leave the spammer room to make.<br/>(Indeed, it will be hard even to get this past filters, because if everything<br/>else in the email is neutral, the spam probability will hinge on the url, and<br/>it will take some effort to make that look neutral.)  <br/>  <br/>Spammers range from businesses running so-called opt-in lists who don't even<br/>try to conceal their identities, to guys who hijack mail servers to send out<br/>spams promoting porn sites. If we use filtering to whittle their options down<br/>to mails like the one above, that should pretty much put the spammers on the<br/>"legitimate" end of the spectrum out of business; they feel obliged by various<br/>state laws to include boilerplate about why their spam is not spam, and how to<br/>cancel your "subscription," and that kind of text is easy to recognize.  <br/>  <br/>(I used to think it was naive to believe that stricter laws would decrease<br/>spam. Now I think that while stricter laws may not decrease the amount of spam<br/>that spammers _send,_ they can certainly help filters to decrease the amount<br/>of spam that recipients actually see.)  <br/>  <br/>All along the spectrum, if you restrict the sales pitches spammers can make,<br/>you will inevitably tend to put them out of business. That word _business_ is<br/>an important one to remember. The spammers are businessmen. They send spam<br/>because it works. It works because although the response rate is abominably<br/>low (at best 15 per million, vs 3000 per million for a catalog mailing), the<br/>cost, to them, is practically nothing. The cost is enormous for the<br/>recipients, about 5 man-weeks for each million recipients who spend a second<br/>to delete the spam, but the spammer doesn't have to pay that.  <br/>  <br/>Sending spam does cost the spammer something, though. [2] So the lower we can<br/>get the response rate-- whether by filtering, or by using filters to force<br/>spammers to dilute their pitches-- the fewer businesses will find it worth<br/>their while to send spam.  <br/>  <br/>The reason the spammers use the kinds of sales pitches that they do is to<br/>increase response rates. This is possibly even more disgusting than getting<br/>inside the mind of a spammer, but let's take a quick look inside the mind of<br/>someone who _responds_ to a spam. This person is either astonishingly<br/>credulous or deeply in denial about their sexual interests. In either case,<br/>repulsive or idiotic as the spam seems to us, it is exciting to them. The<br/>spammers wouldn't say these things if they didn't sound exciting. And "thought<br/>you should check out the following" is just not going to have nearly the pull<br/>with the spam recipient as the kinds of things that spammers say now. Result:<br/>if it can't contain exciting sales pitches, spam becomes less effective as a<br/>marketing vehicle, and fewer businesses want to use it.  <br/>  <br/>That is the big win in the end. I started writing spam filtering software<br/>because I didn't want have to look at the stuff anymore. But if we get good<br/>enough at filtering out spam, it will stop working, and the spammers will<br/>actually stop sending it.  <br/>  <br/>_ _ _  <br/>  <br/>Of all the approaches to fighting spam, from software to laws, I believe<br/>Bayesian filtering will be the single most effective. But I also think that<br/>the more different kinds of antispam efforts we undertake, the better, because<br/>any measure that constrains spammers will tend to make filtering easier. And<br/>even within the world of content-based filtering, I think it will be a good<br/>thing if there are many different kinds of software being used simultaneously.<br/>The more different filters there are, the harder it will be for spammers to<br/>tune spams to get through them.  <br/>  <br/>  <br/>  <br/>**Appendix: Examples of Filtering**  <br/>  <br/>Here is an example of a spam that arrived while I was writing this article.<br/>The fifteen most interesting words in this spam are:  qvp0045 indira mx-05<br/>intimail $7500 freeyankeedom cdo bluefoxmedia jpg unsecured platinum 3d0 qves<br/>7c5 7c266675  The words are a mix of stuff from the headers and from the<br/>message body, which is typical of spam. Also typical of spam is that every one<br/>of these words has a spam probability, in my database, of .99. In fact there<br/>are more than fifteen words with probabilities of .99, and these are just the<br/>first fifteen seen.  <br/>  <br/>Unfortunately that makes this email a boring example of the use of Bayes'<br/>Rule. To see an interesting variety of probabilities we have to look at this<br/>actually quite atypical spam.  <br/>  <br/>The fifteen most interesting words in this spam, with their probabilities,<br/>are:  madam 0.99 promotion 0.99 republic 0.99 shortest 0.047225013 mandatory<br/>0.047225013 standardization 0.07347802 sorry 0.08221981 supported 0.09019077<br/>people's 0.09019077 enter 0.9075001 quality 0.8921298 organization 0.12454646<br/>investment 0.8568143 very 0.14758544 valuable 0.82347786  This time the<br/>evidence is a mix of good and bad. A word like "shortest" is almost as much<br/>evidence for innocence as a word like "madam" or "promotion" is for guilt. But<br/>still the case for guilt is stronger. If you combine these numbers according<br/>to Bayes' Rule, the resulting probability is .9027.  <br/>  <br/>"Madam" is obviously from spams beginning "Dear Sir or Madam." They're not<br/>very common, but the word "madam" _never_ occurs in my legitimate email, and<br/>it's all about the ratio.  <br/>  <br/>"Republic" scores high because it often shows up in Nigerian scam emails, and<br/>also occurs once or twice in spams referring to Korea and South Africa. You<br/>might say that it's an accident that it thus helps identify this spam. But<br/>I've found when examining spam probabilities that there are a lot of these<br/>accidents, and they have an uncanny tendency to push things in the right<br/>direction rather than the wrong one. In this case, it is not entirely a<br/>coincidence that the word "Republic" occurs in Nigerian scam emails and this<br/>spam. There is a whole class of dubious business propositions involving less<br/>developed countries, and these in turn are more likely to have names that<br/>specify explicitly (because they aren't) that they are republics.[3]  <br/>  <br/>On the other hand, "enter" is a genuine miss. It occurs mostly in unsubscribe<br/>instructions, but here is used in a completely innocent way. Fortunately the<br/>statistical approach is fairly robust, and can tolerate quite a lot of misses<br/>before the results start to be thrown off.  <br/>  <br/>For comparison, here is an example of that rare bird, a spam that gets through<br/>the filters. Why? Because by sheer chance it happens to be loaded with words<br/>that occur in my actual email:  perl 0.01 python 0.01 tcl 0.01 scripting 0.01<br/>morris 0.01 graham 0.01491078 guarantee 0.9762507 cgi 0.9734398 paul<br/>0.027040077 quite 0.030676773 pop3 0.042199217 various 0.06080265 prices<br/>0.9359873 managed 0.06451222 difficult 0.071706355  There are a couple pieces<br/>of good news here. First, this mail probably wouldn't get through the filters<br/>of someone who didn't happen to specialize in programming languages and have a<br/>good friend called Morris. For the average user, all the top five words here<br/>would be neutral and would not contribute to the spam probability.  <br/>  <br/>Second, I think filtering based on word pairs (see below) might well catch<br/>this one: "cost effective", "setup fee", "money back" -- pretty incriminating<br/>stuff. And of course if they continued to spam me (or a network I was part<br/>of), "Hostex" itself would be recognized as a spam term.  <br/>  <br/>Finally, here is an innocent email. Its fifteen most interesting words are as<br/>follows:  continuation 0.01 describe 0.01 continuations 0.01 example<br/>0.033600237 programming 0.05214485 i'm 0.055427782 examples 0.07972858 color<br/>0.9189189 localhost 0.09883721 hi 0.116539136 california 0.84421706 same<br/>0.15981844 spot 0.1654587 us-ascii 0.16804294 what 0.19212411  Most of the<br/>words here indicate the mail is an innocent one. There are two bad smelling<br/>words, "color" (spammers love colored fonts) and "California" (which occurs in<br/>testimonials and also in menus in forms), but they are not enough to outweigh<br/>obviously innocent words like "continuation" and "example".  <br/>  <br/>It's interesting that "describe" rates as so thoroughly innocent. It hasn't<br/>occurred in a single one of my 4000 spams. The data turns out to be full of<br/>such surprises. One of the things you learn when you analyze spam texts is how<br/>narrow a subset of the language spammers operate in. It's that fact, together<br/>with the equally characteristic vocabulary of any individual user's mail, that<br/>makes Bayesian filtering a good bet.  <br/>  <br/> **Appendix: More Ideas**  <br/>  <br/>One idea that I haven't tried yet is to filter based on word pairs, or even<br/>triples, rather than individual words. This should yield a much sharper<br/>estimate of the probability. For example, in my current database, the word<br/>"offers" has a probability of .96. If you based the probabilities on word<br/>pairs, you'd end up with "special offers" and "valuable offers" having<br/>probabilities of .99 and, say, "approach offers" (as in "this approach<br/>offers") having a probability of .1 or less.  <br/>  <br/>The reason I haven't done this is that filtering based on individual words<br/>already works so well. But it does mean that there is room to tighten the<br/>filters if spam gets harder to detect. (Curiously, a filter based on word<br/>pairs would be in effect a Markov-chaining text generator running in reverse.)  <br/>  <br/>Specific spam features (e.g. not seeing the recipient's address in the to:<br/>field) do of course have value in recognizing spam. They can be considered in<br/>this algorithm by treating them as virtual words. I'll probably do this in<br/>future versions, at least for a handful of the most egregious spam indicators.<br/>Feature-recognizing spam filters are right in many details; what they lack is<br/>an overall discipline for combining evidence.  <br/>  <br/>Recognizing nonspam features may be more important than recognizing spam<br/>features. False positives are such a worry that they demand extraordinary<br/>measures. I will probably in future versions add a second level of testing<br/>designed specifically to avoid false positives. If a mail triggers this second<br/>level of filters it will be accepted even if its spam probability is above the<br/>threshold.  <br/>  <br/>I don't expect this second level of filtering to be Bayesian. It will<br/>inevitably be not only ad hoc, but based on guesses, because the number of<br/>false positives will not tend to be large enough to notice patterns. (It is<br/>just as well, anyway, if a backup system doesn't rely on the same technology<br/>as the primary system.)  <br/>  <br/>Another thing I may try in the future is to focus extra attention on specific<br/>parts of the email. For example, about 95% of current spam includes the url of<br/>a site they want you to visit. (The remaining 5% want you to call a phone<br/>number, reply by email or to a US mail address, or in a few cases to buy a<br/>certain stock.) The url is in such cases practically enough by itself to<br/>determine whether the email is spam.  <br/>  <br/>Domain names differ from the rest of the text in a (non-German) email in that<br/>they often consist of several words stuck together. Though computationally<br/>expensive in the general case, it might be worth trying to decompose them. If<br/>a filter has never seen the token "xxxporn" before it will have an individual<br/>spam probability of .4, whereas "xxx" and "porn" individually have<br/>probabilities (in my corpus) of .9889 and .99 respectively, and a combined<br/>probability of .9998.  <br/>  <br/>I expect decomposing domain names to become more important as spammers are<br/>gradually forced to stop using incriminating words in the text of their<br/>messages. (A url with an ip address is of course an extremely incriminating<br/>sign, except in the mail of a few sysadmins.)  <br/>  <br/>It might be a good idea to have a cooperatively maintained list of urls<br/>promoted by spammers. We'd need a trust metric of the type studied by Raph<br/>Levien to prevent malicious or incompetent submissions, but if we had such a<br/>thing it would provide a boost to any filtering software. It would also be a<br/>convenient basis for boycotts.  <br/>  <br/>Another way to test dubious urls would be to send out a crawler to look at the<br/>site before the user looked at the email mentioning it. You could use a<br/>Bayesian filter to rate the site just as you would an email, and whatever was<br/>found on the site could be included in calculating the probability of the<br/>email being a spam. A url that led to a redirect would of course be especially<br/>suspicious.  <br/>  <br/>One cooperative project that I think really would be a good idea would be to<br/>accumulate a giant corpus of spam. A large, clean corpus is the key to making<br/>Bayesian filtering work well. Bayesian filters could actually use the corpus<br/>as input. But such a corpus would be useful for other kinds of filters too,<br/>because it could be used to test them.  <br/>  <br/>Creating such a corpus poses some technical problems. We'd need trust metrics<br/>to prevent malicious or incompetent submissions, of course. We'd also need<br/>ways of erasing personal information (not just to-addresses and ccs, but also<br/>e.g. the arguments to unsubscribe urls, which often encode the to-address)<br/>from mails in the corpus. If anyone wants to take on this project, it would be<br/>a good thing for the world.  <br/>  <br/> **Appendix: Defining Spam**  <br/>  <br/>I think there is a rough consensus on what spam is, but it would be useful to<br/>have an explicit definition. We'll need to do this if we want to establish a<br/>central corpus of spam, or even to compare spam filtering rates meaningfully.  <br/>  <br/>To start with, spam is not unsolicited commercial email. If someone in my<br/>neighborhood heard that I was looking for an old Raleigh three-speed in good<br/>condition, and sent me an email offering to sell me one, I'd be delighted, and<br/>yet this email would be both commercial and unsolicited. The defining feature<br/>of spam (in fact, its _raison d'etre_ ) is not that it is unsolicited, but<br/>that it is automated.  <br/>  <br/>It is merely incidental, too, that spam is usually commercial. If someone<br/>started sending mass email to support some political cause, for example, it<br/>would be just as much spam as email promoting a porn site.  <br/>  <br/>I propose we define spam as **unsolicited automated email**. This definition<br/>thus includes some email that many legal definitions of spam don't. Legal<br/>definitions of spam, influenced presumably by lobbyists, tend to exclude mail<br/>sent by companies that have an "existing relationship" with the recipient. But<br/>buying something from a company, for example, does not imply that you have<br/>solicited ongoing email from them. If I order something from an online store,<br/>and they then send me a stream of spam, it's still spam.  <br/>  <br/>Companies sending spam often give you a way to "unsubscribe," or ask you to go<br/>to their site and change your "account preferences" if you want to stop<br/>getting spam. This is not enough to stop the mail from being spam. Not opting<br/>out is not the same as opting in. Unless the recipient explicitly checked a<br/>clearly labelled box (whose default was no) asking to receive the email, then<br/>it is spam.  <br/>  <br/>In some business relationships, you do implicitly solicit certain kinds of<br/>mail. When you order online, I think you implicitly solicit a receipt, and<br/>notification when the order ships. I don't mind when Verisign sends me mail<br/>warning that a domain name is about to expire (at least, if they are the<br/>actual registrar for it). But when Verisign sends me email offering a FREE<br/>Guide to Building My E-Commerce Web Site, that's spam.  <br/>  <br/>**Notes:**  <br/>  <br/>[1] The examples in this article are translated into Common Lisp for, believe<br/>it or not, greater accessibility. The application described here is one that<br/>we wrote in order to test a new Lisp dialect called Arc that is not yet<br/>released.  <br/>  <br/>[2] Currently the lowest rate seems to be about $200 to send a million spams.<br/>That's very cheap, 1/50th of a cent per spam. But filtering out 95% of spam,<br/>for example, would increase the spammers' cost to reach a given audience by a<br/>factor of 20. Few can have margins big enough to absorb that.  <br/>  <br/>[3] As a rule of thumb, the more qualifiers there are before the name of a<br/>country, the more corrupt the rulers. A country called The Socialist People's<br/>Democratic Republic of X is probably the last place in the world you'd want to<br/>live.  <br/>  <br/>**Thanks** to Sarah Harlin for reading drafts of this; Daniel Giffin (who is<br/>also writing the production Arc interpreter) for several good ideas about<br/>filtering and for creating our mail infrastructure; Robert Morris, Trevor<br/>Blackwell and Erann Gat for many discussions about spam; Raph Levien for<br/>advice about trust metrics; and Chip Coldwell and Sam Steingold for advice<br/>about statistics.  <br/>  <br/>  <br/>  <br/>**More Info:**  <br/>  <br/><br/>Plan for Spam FAQ  <br/><br/>Better Bayesian Filtering  <br/><br/>Filters that Fight Back  <br/><br/>Will Filters Kill Spam?  <br/><br/>Japanese Translation  <br/><br/>Spanish Translation  <br/><br/>Chinese Translation  <br/><br/>Probability  <br/><br/>Spam is Different  <br/><br/>Filters vs. Blacklists  <br/><br/>Trust Metrics  <br/><br/>Filtering Research  <br/><br/>Microsoft Patent  <br/><br/>Slashdot Article  <br/><br/>The Wrong Way  <br/><br/>LWN: Filter Comparison  <br/><br/>CRM114 gets 99.87%  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>May 2001<br/><br/>_(These are some notes I made for a panel discussion on programming language<br/>design at MIT on May 10, 2001.)_  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **1\. Programming Languages Are for People.**  <br/>  <br/>Programming languages are how people talk to computers. The computer would be<br/>just as happy speaking any language that was unambiguous. The reason we have<br/>high level languages is because people can't deal with machine language. The<br/>point of programming languages is to prevent our poor frail human brains from<br/>being overwhelmed by a mass of detail.  <br/>  <br/>Architects know that some kinds of design problems are more personal than<br/>others. One of the cleanest, most abstract design problems is designing<br/>bridges. There your job is largely a matter of spanning a given distance with<br/>the least material. The other end of the spectrum is designing chairs. Chair<br/>designers have to spend their time thinking about human butts.  <br/>  <br/>Software varies in the same way. Designing algorithms for routing data through<br/>a network is a nice, abstract problem, like designing bridges. Whereas<br/>designing programming languages is like designing chairs: it's all about<br/>dealing with human weaknesses.  <br/>  <br/>Most of us hate to acknowledge this. Designing systems of great mathematical<br/>elegance sounds a lot more appealing to most of us than pandering to human<br/>weaknesses. And there is a role for mathematical elegance: some kinds of<br/>elegance make programs easier to understand. But elegance is not an end in<br/>itself.  <br/>  <br/>And when I say languages have to be designed to suit human weaknesses, I don't<br/>mean that languages have to be designed for bad programmers. In fact I think<br/>you ought to design for the best programmers, but even the best programmers<br/>have limitations. I don't think anyone would like programming in a language<br/>where all the variables were the letter x with integer subscripts.  <br/>  <br/> **2\. Design for Yourself and Your Friends.**  <br/>  <br/>If you look at the history of programming languages, a lot of the best ones<br/>were languages designed for their own authors to use, and a lot of the worst<br/>ones were designed for other people to use.  <br/>  <br/>When languages are designed for other people, it's always a specific group of<br/>other people: people not as smart as the language designer. So you get a<br/>language that talks down to you. Cobol is the most extreme case, but a lot of<br/>languages are pervaded by this spirit.  <br/>  <br/>It has nothing to do with how abstract the language is. C is pretty low-level,<br/>but it was designed for its authors to use, and that's why hackers like it.  <br/>  <br/>The argument for designing languages for bad programmers is that there are<br/>more bad programmers than good programmers. That may be so. But those few good<br/>programmers write a disproportionately large percentage of the software.  <br/>  <br/>I'm interested in the question, how do you design a language that the very<br/>best hackers will like? I happen to think this is identical to the question,<br/>how do you design a good programming language?, but even if it isn't, it is at<br/>least an interesting question.  <br/>  <br/> **3\. Give the Programmer as Much Control as Possible.**  <br/>  <br/>Many languages (especially the ones designed for other people) have the<br/>attitude of a governess: they try to prevent you from doing things that they<br/>think aren't good for you. I like the opposite approach: give the programmer<br/>as much control as you can.  <br/>  <br/>When I first learned Lisp, what I liked most about it was that it considered<br/>me an equal partner. In the other languages I had learned up till then, there<br/>was the language and there was my program, written in the language, and the<br/>two were very separate. But in Lisp the functions and macros I wrote were just<br/>like those that made up the language itself. I could rewrite the language if I<br/>wanted. It had the same appeal as open-source software.  <br/>  <br/> **4\. Aim for Brevity.**  <br/>  <br/>Brevity is underestimated and even scorned. But if you look into the hearts of<br/>hackers, you'll see that they really love it. How many times have you heard<br/>hackers speak fondly of how in, say, APL, they could do amazing things with<br/>just a couple lines of code? I think anything that really smart people really<br/>love is worth paying attention to.  <br/>  <br/>I think almost anything you can do to make programs shorter is good. There<br/>should be lots of library functions; anything that can be implicit should be;<br/>the syntax should be terse to a fault; even the names of things should be<br/>short.  <br/>  <br/>And it's not only programs that should be short. The manual should be thin as<br/>well. A good part of manuals is taken up with clarifications and reservations<br/>and warnings and special cases. If you force yourself to shorten the manual,<br/>in the best case you do it by fixing the things in the language that required<br/>so much explanation.  <br/>  <br/> **5\. Admit What Hacking Is.**  <br/>  <br/>A lot of people wish that hacking was mathematics, or at least something like<br/>a natural science. I think hacking is more like architecture. Architecture is<br/>related to physics, in the sense that architects have to design buildings that<br/>don't fall down, but the actual goal of architects is to make great buildings,<br/>not to make discoveries about statics.  <br/>  <br/>What hackers like to do is make great programs. And I think, at least in our<br/>own minds, we have to remember that it's an admirable thing to write great<br/>programs, even when this work doesn't translate easily into the conventional<br/>intellectual currency of research papers. Intellectually, it is just as<br/>worthwhile to design a language programmers will love as it is to design a<br/>horrible one that embodies some idea you can publish a paper about.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **1\. How to Organize Big Libraries?**  <br/>  <br/>Libraries are becoming an increasingly important component of programming<br/>languages. They're also getting bigger, and this can be dangerous. If it takes<br/>longer to find the library function that will do what you want than it would<br/>take to write it yourself, then all that code is doing nothing but make your<br/>manual thick. (The Symbolics manuals were a case in point.) So I think we will<br/>have to work on ways to organize libraries. The ideal would be to design them<br/>so that the programmer could guess what library call would do the right thing.  <br/>  <br/> **2\. Are People Really Scared of Prefix Syntax?**  <br/>  <br/>This is an open problem in the sense that I have wondered about it for years<br/>and still don't know the answer. Prefix syntax seems perfectly natural to me,<br/>except possibly for math. But it could be that a lot of Lisp's unpopularity is<br/>simply due to having an unfamiliar syntax. Whether to do anything about it, if<br/>it is true, is another question.<br/><br/>**3\. What Do You Need for Server-Based Software?**<br/><br/>I think a lot of the most exciting new applications that get written in the<br/>next twenty years will be Web-based applications, meaning programs that sit on<br/>the server and talk to you through a Web browser. And to write these kinds of<br/>programs we may need some new things.  <br/>  <br/>One thing we'll need is support for the new way that server-based apps get<br/>released. Instead of having one or two big releases a year, like desktop<br/>software, server-based apps get released as a series of small changes. You may<br/>have as many as five or ten releases a day. And as a rule everyone will always<br/>use the latest version.  <br/>  <br/>You know how you can design programs to be debuggable? Well, server-based<br/>software likewise has to be designed to be changeable. You have to be able to<br/>change it easily, or at least to know what is a small change and what is a<br/>momentous one.  <br/>  <br/>Another thing that might turn out to be useful for server based software,<br/>surprisingly, is continuations. In Web-based software you can use something<br/>like continuation-passing style to get the effect of subroutines in the<br/>inherently stateless world of a Web session. Maybe it would be worthwhile<br/>having actual continuations, if it was not too expensive.  <br/>  <br/> **4\. What New Abstractions Are Left to Discover?**  <br/>  <br/>I'm not sure how reasonable a hope this is, but one thing I would really love<br/>to do, personally, is discover a new abstraction-- something that would make<br/>as much of a difference as having first class functions or recursion or even<br/>keyword parameters. This may be an impossible dream. These things don't get<br/>discovered that often. But I am always looking.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **1\. You Can Use Whatever Language You Want.**  <br/>  <br/>Writing application programs used to mean writing desktop software. And in<br/>desktop software there is a big bias toward writing the application in the<br/>same language as the operating system. And so ten years ago, writing software<br/>pretty much meant writing software in C. Eventually a tradition evolved:<br/>application programs must not be written in unusual languages. And this<br/>tradition had so long to develop that nontechnical people like managers and<br/>venture capitalists also learned it.  <br/>  <br/>Server-based software blows away this whole model. With server-based software<br/>you can use any language you want. Almost nobody understands this yet<br/>(especially not managers and venture capitalists). A few hackers understand<br/>it, and that's why we even hear about new, indy languages like Perl and<br/>Python. We're not hearing about Perl and Python because people are using them<br/>to write Windows apps.  <br/>  <br/>What this means for us, as people interested in designing programming<br/>languages, is that there is now potentially an actual audience for our work.  <br/>  <br/> **2\. Speed Comes from Profilers.**  <br/>  <br/>Language designers, or at least language implementors, like to write compilers<br/>that generate fast code. But I don't think this is what makes languages fast<br/>for users. Knuth pointed out long ago that speed only matters in a few<br/>critical bottlenecks. And anyone who's tried it knows that you can't guess<br/>where these bottlenecks are. Profilers are the answer.  <br/>  <br/>Language designers are solving the wrong problem. Users don't need benchmarks<br/>to run fast. What they need is a language that can show them what parts of<br/>their own programs need to be rewritten. That's where speed comes from in<br/>practice. So maybe it would be a net win if language implementors took half<br/>the time they would have spent doing compiler optimizations and spent it<br/>writing a good profiler instead.  <br/>  <br/> **3\. You Need an Application to Drive the Design of a Language.**  <br/>  <br/>This may not be an absolute rule, but it seems like the best languages all<br/>evolved together with some application they were being used to write. C was<br/>written by people who needed it for systems programming. Lisp was developed<br/>partly to do symbolic differentiation, and McCarthy was so eager to get<br/>started that he was writing differentiation programs even in the first paper<br/>on Lisp, in 1960.  <br/>  <br/>It's especially good if your application solves some new problem. That will<br/>tend to drive your language to have new features that programmers need. I<br/>personally am interested in writing a language that will be good for writing<br/>server-based applications.  <br/>  <br/>[During the panel, Guy Steele also made this point, with the additional<br/>suggestion that the application should not consist of writing the compiler for<br/>your language, unless your language happens to be intended for writing<br/>compilers.]  <br/>  <br/> **4\. A Language Has to Be Good for Writing Throwaway Programs.**  <br/>  <br/>You know what a throwaway program is: something you write quickly for some<br/>limited task. I think if you looked around you'd find that a lot of big,<br/>serious programs started as throwaway programs. I would not be surprised if<br/>_most_ programs started as throwaway programs. And so if you want to make a<br/>language that's good for writing software in general, it has to be good for<br/>writing throwaway programs, because that is the larval stage of most software.  <br/>  <br/> **5\. Syntax Is Connected to Semantics.**  <br/>  <br/>It's traditional to think of syntax and semantics as being completely<br/>separate. This will sound shocking, but it may be that they aren't. I think<br/>that what you want in your language may be related to how you express it.  <br/>  <br/>I was talking recently to Robert Morris, and he pointed out that operator<br/>overloading is a bigger win in languages with infix syntax. In a language with<br/>prefix syntax, any function you define is effectively an operator. If you want<br/>to define a plus for a new type of number you've made up, you can just define<br/>a new function to add them. If you do that in a language with infix syntax,<br/>there's a big difference in appearance between the use of an overloaded<br/>operator and a function call.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **1\. New Programming Languages.**  <br/>  <br/>Back in the 1970s it was fashionable to design new programming languages.<br/>Recently it hasn't been. But I think server-based software will make new<br/>languages fashionable again. With server-based software, you can use any<br/>language you want, so if someone does design a language that actually seems<br/>better than others that are available, there will be people who take a risk<br/>and use it.  <br/>  <br/> **2\. Time-Sharing.**  <br/>  <br/>Richard Kelsey gave this as an idea whose time has come again in the last<br/>panel, and I completely agree with him. My guess (and Microsoft's guess, it<br/>seems) is that much computing will move from the desktop onto remote servers.<br/>In other words, time-sharing is back. And I think there will need to be<br/>support for it at the language level. For example, I know that Richard and<br/>Jonathan Rees have done a lot of work implementing process scheduling within<br/>Scheme 48.  <br/>  <br/> **3\. Efficiency.**  <br/>  <br/>Recently it was starting to seem that computers were finally fast enough. More<br/>and more we were starting to hear about byte code, which implies to me at<br/>least that we feel we have cycles to spare. But I don't think we will, with<br/>server-based software. Someone is going to have to pay for the servers that<br/>the software runs on, and the number of users they can support per machine<br/>will be the divisor of their capital cost.  <br/>  <br/>So I think efficiency will matter, at least in computational bottlenecks. It<br/>will be especially important to do i/o fast, because server-based applications<br/>do a lot of i/o.  <br/>  <br/>It may turn out that byte code is not a win, in the end. Sun and Microsoft<br/>seem to be facing off in a kind of a battle of the byte codes at the moment.<br/>But they're doing it because byte code is a convenient place to insert<br/>themselves into the process, not because byte code is in itself a good idea.<br/>It may turn out that this whole battleground gets bypassed. That would be kind<br/>of amusing.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **1\. Clients.**  <br/>  <br/>This is just a guess, but my guess is that the winning model for most<br/>applications will be purely server-based. Designing software that works on the<br/>assumption that everyone will have your client is like designing a society on<br/>the assumption that everyone will just be honest. It would certainly be<br/>convenient, but you have to assume it will never happen.  <br/>  <br/>I think there will be a proliferation of devices that have some kind of Web<br/>access, and all you'll be able to assume about them is that they can support<br/>simple html and forms. Will you have a browser on your cell phone? Will there<br/>be a phone in your palm pilot? Will your blackberry get a bigger screen? Will<br/>you be able to browse the Web on your gameboy? Your watch? I don't know. And I<br/>don't have to know if I bet on everything just being on the server. It's just<br/>so much more robust to have all the brains on the server.  <br/>  <br/> **2\. Object-Oriented Programming.**  <br/>  <br/>I realize this is a controversial one, but I don't think object-oriented<br/>programming is such a big deal. I think it is a fine model for certain kinds<br/>of applications that need that specific kind of data structure, like window<br/>systems, simulations, and cad programs. But I don't see why it ought to be the<br/>model for all programming.  <br/>  <br/>I think part of the reason people in big companies like object-oriented<br/>programming is because it yields a lot of what looks like work. Something that<br/>might naturally be represented as, say, a list of integers, can now be<br/>represented as a class with all kinds of scaffolding and hustle and bustle.  <br/>  <br/>Another attraction of object-oriented programming is that methods give you<br/>some of the effect of first class functions. But this is old news to Lisp<br/>programmers. When you have actual first class functions, you can just use them<br/>in whatever way is appropriate to the task at hand, instead of forcing<br/>everything into a mold of classes and methods.  <br/>  <br/>What this means for language design, I think, is that you shouldn't build<br/>object-oriented programming in too deeply. Maybe the answer is to offer more<br/>general, underlying stuff, and let people design whatever object systems they<br/>want as libraries.  <br/>  <br/> **3\. Design by Committee.**  <br/>  <br/>Having your language designed by a committee is a big pitfall, and not just<br/>for the reasons everyone knows about. Everyone knows that committees tend to<br/>yield lumpy, inconsistent designs. But I think a greater danger is that they<br/>won't take risks. When one person is in charge he can take risks that a<br/>committee would never agree on.  <br/>  <br/>Is it necessary to take risks to design a good language though? Many people<br/>might suspect that language design is something where you should stick fairly<br/>close to the conventional wisdom. I bet this isn't true. In everything else<br/>people do, reward is proportionate to risk. Why should language design be any<br/>different?  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>May 2007  <br/>  <br/>People who worry about the increasing gap between rich and poor generally look<br/>back on the mid twentieth century as a golden age. In those days we had a<br/>large number of high-paying union manufacturing jobs that boosted the median<br/>income. I wouldn't quite call the high-paying union job a myth, but I think<br/>people who dwell on it are reading too much into it.  <br/>  <br/>Oddly enough, it was working with startups that made me realize where the<br/>high-paying union job came from. In a rapidly growing market, you don't worry<br/>too much about efficiency. It's more important to grow fast. If there's some<br/>mundane problem getting in your way, and there's a simple solution that's<br/>somewhat expensive, just take it and get on with more important things. EBay<br/>didn't win by paying less for servers than their competitors.  <br/>  <br/>Difficult though it may be to imagine now, manufacturing was a growth industry<br/>in the mid twentieth century. This was an era when small firms making<br/>everything from cars to candy were getting consolidated into a new kind of<br/>corporation with national reach and huge economies of scale. You had to grow<br/>fast or die. Workers were for these companies what servers are for an Internet<br/>startup. A reliable supply was more important than low cost.  <br/>  <br/>If you looked in the head of a 1950s auto executive, the attitude must have<br/>been: sure, give 'em whatever they ask for, so long as the new model isn't<br/>delayed.  <br/>  <br/>In other words, those workers were not paid what their work was worth.<br/>Circumstances being what they were, companies would have been stupid to insist<br/>on paying them so little.  <br/>  <br/>If you want a less controversial example of this phenomenon, ask anyone who<br/>worked as a consultant building web sites during the Internet Bubble. In the<br/>late nineties you could get paid huge sums of money for building the most<br/>trivial things. And yet does anyone who was there have any expectation those<br/>days will ever return? I doubt it. Surely everyone realizes that was just a<br/>temporary aberration.  <br/>  <br/>The era of labor unions seems to have been the same kind of aberration, just<br/>spread over a longer period, and mixed together with a lot of ideology that<br/>prevents people from viewing it with as cold an eye as they would something<br/>like consulting during the Bubble.  <br/>  <br/>Basically, unions were just Razorfish.  <br/>  <br/>People who think the labor movement was the creation of heroic union<br/>organizers have a problem to explain: why are unions shrinking now? The best<br/>they can do is fall back on the default explanation of people living in fallen<br/>civilizations. Our ancestors were giants. The workers of the early twentieth<br/>century must have had a moral courage that's lacking today.  <br/>  <br/>In fact there's a simpler explanation. The early twentieth century was just a<br/>fast-growing startup overpaying for infrastructure. And we in the present are<br/>not a fallen people, who have abandoned whatever mysterious high-minded<br/>principles produced the high-paying union job. We simply live in a time when<br/>the fast-growing companies overspend on different things.  <br/>  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>March 2011  <br/>  <br/>Yesterday Fred Wilson published a remarkable post about missing Airbnb. VCs<br/>miss good startups all the time, but it's extraordinarily rare for one to talk<br/>about it publicly till long afterward. So that post is further evidence what a<br/>rare bird Fred is. He's probably the nicest VC I know.  <br/>  <br/>Reading Fred's post made me go back and look at the emails I exchanged with<br/>him at the time, trying to convince him to invest in Airbnb. It was quite<br/>interesting to read. You can see Fred's mind at work as he circles the deal.  <br/>  <br/>Fred and the Airbnb founders have generously agreed to let me publish this<br/>email exchange (with one sentence redacted about something that's<br/>strategically important to Airbnb and not an important part of the<br/>conversation). It's an interesting illustration of an element of the startup<br/>ecosystem that few except the participants ever see: investors trying to<br/>convince one another to invest in their portfolio companies. Hundreds if not<br/>thousands of conversations of this type are happening now, but if one has ever<br/>been published, I haven't seen it. The Airbnbs themselves never even saw these<br/>emails at the time.  <br/>  <br/>We do a lot of this behind the scenes stuff at YC, because we invest in such a<br/>large number of companies, and we invest so early that investors sometimes<br/>need a lot of convincing to see their merits. I don't always try as hard as<br/>this though. Fred must have found me quite annoying.  <br/>  <br/>  <br/>  <br/><br/>* * *<br/>    <br/>    <br/>    from: Paul Graham<br/>    to: Fred Wilson, AirBedAndBreakfast Founders<br/>    date: Fri, Jan 23, 2009 at 11:42 AM<br/>    subject: meet the airbeds  <br/>      <br/>    One of the startups from the batch that just started, AirbedAndBreakfast,<br/>    is in NYC right now meeting their users.  (NYC is their biggest<br/>    market.) I'd recommend meeting them if your schedule allows.  <br/>      <br/>    I'd been thinking to myself that though these guys were going to<br/>    do really well, I should introduce them to angels, because VCs would<br/>    never go for it.  But then I thought maybe I should give you more<br/>    credit.  You'll certainly like meeting them.  Be sure to ask about<br/>    how they funded themselves with breakfast cereal.  <br/>      <br/>    There's no reason this couldn't be as big as Ebay.  And this team<br/>    is the right one to do it.  <br/>      <br/>    --pg  <br/>      <br/>      <br/>      <br/>    from: Brian Chesky<br/>    to: Paul Graham<br/>    cc: Nathan Blecharczyk, Joe Gebbia<br/>    date: Fri, Jan 23, 2009 at 11:40 AM<br/>    subject: Re: meet the airbeds  <br/>      <br/>    PG,  <br/>      <br/>    Thanks for the intro!  <br/>      <br/>    Brian  <br/>      <br/>      <br/>      <br/>    from: Paul Graham<br/>    to: Brian Chesky<br/>    cc: Nathan Blecharczyk, Joe Gebbia<br/>    date: Fri, Jan 23, 2009 at 12:38 PM<br/>    subject: Re: meet the airbeds  <br/>      <br/>    It's a longshot, at this stage, but if there was any VC who'd get<br/>    you guys, it would be Fred.  He is the least suburban-golf-playing<br/>    VC I know.  <br/>      <br/>    He likes to observe startups for a while before acting, so don't<br/>    be bummed if he seems ambivalent.  <br/>      <br/>    --pg  <br/>      <br/>      <br/>      <br/>    from: Fred Wilson<br/>    to: Paul Graham,<br/>    date: Sun, Jan 25, 2009 at 5:28 PM<br/>    subject: Re: meet the airbeds  <br/>      <br/>    Thanks Paul  <br/>      <br/>    We are having a bit of a debate inside our partnership about the<br/>    airbed concept. We'll finish that debate tomorrow in our weekly<br/>    meeting and get back to you with our thoughts  <br/>      <br/>    Thanks  <br/>      <br/>    Fred  <br/>      <br/>      <br/>      <br/>    from: Paul Graham<br/>    to: Fred Wilson<br/>    date: Sun, Jan 25, 2009 at 10:48 PM<br/>    subject: Re: meet the airbeds  <br/>      <br/>    I'd recommend having the debate after meeting them instead of before.<br/>    We had big doubts about this idea, but they vanished on meeting the<br/>    guys.  <br/>      <br/>      <br/>      <br/>    from: Fred Wilson<br/>    to: Paul Graham<br/>    date: Mon, Jan 26, 2009 at 11:08 AM<br/>    subject: RE: meet the airbeds  <br/>      <br/>    We are still very suspect of this idea but will take a meeting as<br/>    you suggest  <br/>      <br/>    Thanks  <br/>      <br/>    fred  <br/>      <br/>      <br/>      <br/>    from: Fred Wilson<br/>    to: Paul Graham, AirBedAndBreakfast Founders<br/>    date: Mon, Jan 26, 2009 at 11:09 AM<br/>    subject: RE: meet the airbeds  <br/>      <br/>    Airbed team -  <br/>      <br/>    Are you still in NYC?  <br/>      <br/>    We'd like to meet if you are  <br/>      <br/>    Thanks  <br/>      <br/>    fred  <br/>      <br/>      <br/>      <br/>    from: Paul Graham<br/>    to: Fred Wilson<br/>    date: Mon, Jan 26, 2009 at 1:42 PM<br/>    subject: Re: meet the airbeds  <br/>      <br/>    Ideas can morph.  Practically every really big startup could say,<br/>    five years later, "believe it or not, we started out doing ___."<br/>    It just seemed a very good sign to me that these guys were actually<br/>    on the ground in NYC hunting down (and understanding) their users.<br/>    On top of several previous good signs.  <br/>      <br/>    --pg  <br/>      <br/>      <br/>      <br/>    from: Fred Wilson<br/>    to: Paul Graham<br/>    date: Sun, Feb 1, 2009 at 7:15 AM<br/>    subject: Re: meet the airbeds  <br/>      <br/>    It's interesting  <br/>      <br/>    Our two junior team members were enthusiastic  <br/>      <br/>    The three "old guys" didn't get it  <br/>      <br/>      <br/>      <br/>    from: Paul Graham<br/>    to: Fred Wilson<br/>    date: Mon, Feb 9, 2009 at 5:58 PM<br/>    subject: airbnb  <br/>      <br/>    The Airbeds just won the first poll among all the YC startups in<br/>    their batch by a landslide.  In the past this has not been a 100%<br/>    indicator of success (if only anything were) but much better than<br/>    random.  <br/>      <br/>    --pg  <br/>      <br/>      <br/>      <br/>    from: Fred Wilson<br/>    to: Paul Graham<br/>    date: Fri, Feb 13, 2009 at 5:29 PM<br/>    subject: Re: airbnb  <br/>      <br/>    I met them today  <br/>      <br/>    They have an interesting business  <br/>      <br/>    I'm just not sure how big it's going to be  <br/>      <br/>    fred  <br/>      <br/>      <br/>      <br/>    from: Paul Graham<br/>    to: Fred Wilson<br/>    date: Sat, Feb 14, 2009 at 9:50 AM<br/>    subject: Re: airbnb  <br/>      <br/>    Did they explain the long-term goal of being the market in accommodation<br/>    the way eBay is in stuff?  That seems like it would be huge.  Hotels<br/>    now are like airlines in the 1970s before they figured out how to<br/>    increase their load factors.  <br/>      <br/>      <br/>      <br/>    from: Fred Wilson<br/>    to: Paul Graham<br/>    date: Tue, Feb 17, 2009 at 2:05 PM<br/>    subject: Re: airbnb  <br/>      <br/>    They did but I am not sure I buy that  <br/>      <br/>    ABNB reminds me of Etsy in that it facilitates real commerce in a<br/>    marketplace model directly between two people  <br/>      <br/>    So I think it can scale all the way to the bed and breakfast market  <br/>      <br/>    But I am not sure they can take on the hotel market  <br/>      <br/>    I could be wrong  <br/>      <br/>    But even so, if you include short term room rental, second home<br/>    rental, bed and breakfast, and other similar classes of accommodations,<br/>    you get to a pretty big opportunity  <br/>      <br/>    fred  <br/>      <br/>      <br/>      <br/>    from: Paul Graham<br/>    to: Fred Wilson<br/>    date: Wed, Feb 18, 2009 at 12:21 AM<br/>    subject: Re: airbnb  <br/>      <br/>    So invest in them!  They're very capital efficient.  They would<br/>    make an investor's money go a long way.  <br/>      <br/>    It's also counter-cyclical.  They just arrived back from NYC, and<br/>    when I asked them what was the most significant thing they'd observed,<br/>    it was how many of their users actually needed to do these rentals<br/>    to pay their rents.  <br/>      <br/>    --pg  <br/>      <br/>      <br/>      <br/>    from: Fred Wilson<br/>    to: Paul Graham<br/>    date: Wed, Feb 18, 2009 at 2:21 AM<br/>    subject: Re: airbnb  <br/>      <br/>    There's a lot to like  <br/>      <br/>    I've done a few things, like intro it to my friends at Foundry who<br/>    were investors in Service Metrics and understand this model  <br/>      <br/>    I am also talking to my friend Mark Pincus who had an idea like<br/>    this a few years ago.  <br/>      <br/>    So we are working on it  <br/>      <br/>    Thanks for the lead  <br/>      <br/>    Fred  <br/>      <br/>      <br/>      <br/>    from: Paul Graham<br/>    to: Fred Wilson<br/>    date: Fri, Feb 20, 2009 at 10:00 PM<br/>    subject: airbnb already spreading to pros  <br/>      <br/>    I know you're skeptical they'll ever get hotels, but there's a<br/>    continuum between private sofas and hotel rooms, and they just moved<br/>    one step further along it.  <br/>      <br/>    [link to an airbnb user]  <br/>      <br/>    This is after only a few months.  I bet you they will get hotels<br/>    eventually.  It will start with small ones.  Just wait till all the<br/>    10-room pensiones in Rome discover this site.  And once it spreads<br/>    to hotels, where is the point (in size of chain) at which it stops?<br/>    Once something becomes a big marketplace, you ignore it at your<br/>    peril.  <br/>      <br/>    --pg  <br/>      <br/>      <br/>      <br/>    from: Fred Wilson<br/>    to: Paul Graham<br/>    date: Sat, Feb 21, 2009 at 4:26 AM<br/>    subject: Re: airbnb already spreading to pros  <br/>      <br/>    That's true. It's also true that there are quite a few marketplaces<br/>    out there that serve this same market  <br/>      <br/>    If you look at many of the people who list at ABNB, they list<br/>    elsewhere too  <br/>      <br/>    I am not negative on this one, I am interested, but we are still<br/>    in the gathering data phase.  <br/>      <br/>    fred<br/>    <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>July 2010  <br/>  <br/>I realized recently that what one thinks about in the shower in the morning is<br/>more important than I'd thought. I knew it was a good time to have ideas. Now<br/>I'd go further: now I'd say it's hard to do a really good job on anything you<br/>don't think about in the shower.  <br/>  <br/>Everyone who's worked on difficult problems is probably familiar with the<br/>phenomenon of working hard to figure something out, failing, and then suddenly<br/>seeing the answer a bit later while doing something else. There's a kind of<br/>thinking you do without trying to. I'm increasingly convinced this type of<br/>thinking is not merely helpful in solving hard problems, but necessary. The<br/>tricky part is, you can only control it indirectly. [1]  <br/>  <br/>I think most people have one top idea in their mind at any given time. That's<br/>the idea their thoughts will drift toward when they're allowed to drift<br/>freely. And this idea will thus tend to get all the benefit of that type of<br/>thinking, while others are starved of it. Which means it's a disaster to let<br/>the wrong idea become the top one in your mind.  <br/>  <br/>What made this clear to me was having an idea I didn't want as the top one in<br/>my mind for two long stretches.  <br/>  <br/>I'd noticed startups got way less done when they started raising money, but it<br/>was not till we ourselves raised money that I understood why. The problem is<br/>not the actual time it takes to meet with investors. The problem is that once<br/>you start raising money, raising money becomes the top idea in your mind. That<br/>becomes what you think about when you take a shower in the morning. And that<br/>means other questions aren't.  <br/>  <br/>I'd hated raising money when I was running Viaweb, but I'd forgotten why I<br/>hated it so much. When we raised money for Y Combinator, I remembered. Money<br/>matters are particularly likely to become the top idea in your mind. The<br/>reason is that they have to be. It's hard to get money. It's not the sort of<br/>thing that happens by default. It's not going to happen unless you let it<br/>become the thing you think about in the shower. And then you'll make little<br/>progress on anything else you'd rather be working on. [2]  <br/>  <br/>(I hear similar complaints from friends who are professors. Professors<br/>nowadays seem to have become professional fundraisers who do a little research<br/>on the side. It may be time to fix that.)  <br/>  <br/>The reason this struck me so forcibly is that for most of the preceding 10<br/>years I'd been able to think about what I wanted. So the contrast when I<br/>couldn't was sharp. But I don't think this problem is unique to me, because<br/>just about every startup I've seen grinds to a halt when they start raising<br/>money  or talking to acquirers.  <br/>  <br/>You can't directly control where your thoughts drift. If you're controlling<br/>them, they're not drifting. But you can control them indirectly, by<br/>controlling what situations you let yourself get into. That has been the<br/>lesson for me: be careful what you let become critical to you. Try to get<br/>yourself into situations where the most urgent problems are ones you want to<br/>think about.  <br/>  <br/>You don't have complete control, of course. An emergency could push other<br/>thoughts out of your head. But barring emergencies you have a good deal of<br/>indirect control over what becomes the top idea in your mind.  <br/>  <br/>I've found there are two types of thoughts especially worth avoiding <br/>thoughts like the Nile Perch in the way they push out more interesting ideas.<br/>One I've already mentioned: thoughts about money. Getting money is almost by<br/>definition an attention sink. The other is disputes. These too are engaging in<br/>the wrong way: they have the same velcro-like shape as genuinely interesting<br/>ideas, but without the substance. So avoid disputes if you want to get real<br/>work done. [3]  <br/>  <br/>Even Newton fell into this trap. After publishing his theory of colors in 1672<br/>he found himself distracted by disputes for years, finally concluding that the<br/>only solution was to stop publishing:<br/><br/>> I see I have made myself a slave to Philosophy, but if I get free of Mr<br/>> Linus's business I will resolutely bid adew to it eternally, excepting what<br/>> I do for my privat satisfaction or leave to come out after me. For I see a<br/>> man must either resolve to put out nothing new or become a slave to defend<br/>> it. [4]<br/><br/>Linus and his students at Liege were among the more tenacious critics.<br/>Newton's biographer Westfall seems to feel he was overreacting:<br/><br/>> Recall that at the time he wrote, Newton's "slavery" consisted of five<br/>> replies to Liege, totalling fourteen printed pages, over the course of a<br/>> year.<br/><br/>I'm more sympathetic to Newton. The problem was not the 14 pages, but the pain<br/>of having this stupid controversy constantly reintroduced as the top idea in a<br/>mind that wanted so eagerly to think about other things.  <br/>  <br/>Turning the other cheek turns out to have selfish advantages. Someone who does<br/>you an injury hurts you twice: first by the injury itself, and second by<br/>taking up your time afterward thinking about it. If you learn to ignore<br/>injuries you can at least avoid the second half. I've found I can to some<br/>extent avoid thinking about nasty things people have done to me by telling<br/>myself: this doesn't deserve space in my head. I'm always delighted to find<br/>I've forgotten the details of disputes, because that means I hadn't been<br/>thinking about them. My wife thinks I'm more forgiving than she is, but my<br/>motives are purely selfish.  <br/>  <br/>I suspect a lot of people aren't sure what's the top idea in their mind at any<br/>given time. I'm often mistaken about it. I tend to think it's the idea I'd<br/>want to be the top one, rather than the one that is. But it's easy to figure<br/>this out: just take a shower. What topic do your thoughts keep returning to?<br/>If it's not what you want to be thinking about, you may want to change<br/>something.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] No doubt there are already names for this type of thinking, but I call it<br/>"ambient thought."  <br/>  <br/>[2] This was made particularly clear in our case, because neither of the funds<br/>we raised was difficult, and yet in both cases the process dragged on for<br/>months. Moving large amounts of money around is never something people treat<br/>casually. The attention required increases with the amount—maybe not linearly,<br/>but definitely monotonically.  <br/>  <br/>[3] Corollary: Avoid becoming an administrator, or your job will consist of<br/>dealing with money and disputes.  <br/>  <br/>[4] Letter to Oldenburg, quoted in Westfall, Richard, _Life of Isaac Newton_ ,<br/>p. 107.  <br/>  <br/> **Thanks** to Sam Altman, Patrick Collison, Jessica Livingston, and Robert<br/>Morris for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>December 2006  <br/>  <br/>I grew up believing that taste is just a matter of personal preference. Each<br/>person has things they like, but no one's preferences are any better than<br/>anyone else's. There is no such thing as _good_ taste.  <br/>  <br/>Like a lot of things I grew up believing, this turns out to be false, and I'm<br/>going to try to explain why.  <br/>  <br/>One problem with saying there's no such thing as good taste is that it also<br/>means there's no such thing as good art. If there were good art, then people<br/>who liked it would have better taste than people who didn't. So if you discard<br/>taste, you also have to discard the idea of art being good, and artists being<br/>good at making it.  <br/>  <br/>It was pulling on that thread that unravelled my childhood faith in<br/>relativism. When you're trying to make things, taste becomes a practical<br/>matter. You have to decide what to do next. Would it make the painting better<br/>if I changed that part? If there's no such thing as better, it doesn't matter<br/>what you do. In fact, it doesn't matter if you paint at all. You could just go<br/>out and buy a ready-made blank canvas. If there's no such thing as good, that<br/>would be just as great an achievement as the ceiling of the Sistine Chapel.<br/>Less laborious, certainly, but if you can achieve the same level of<br/>performance with less effort, surely that's more impressive, not less.  <br/>  <br/>Yet that doesn't seem quite right, does it?  <br/>  <br/> **Audience**  <br/>  <br/>I think the key to this puzzle is to remember that art has an audience. Art<br/>has a purpose, which is to interest its audience. Good art (like good<br/>anything) is art that achieves its purpose particularly well. The meaning of<br/>"interest" can vary. Some works of art are meant to shock, and others to<br/>please; some are meant to jump out at you, and others to sit quietly in the<br/>background. But all art has to work on an audience, and—here's the critical<br/>point—members of the audience share things in common.  <br/>  <br/>For example, nearly all humans find human faces engaging. It seems to be wired<br/>into us. Babies can recognize faces practically from birth. In fact, faces<br/>seem to have co-evolved with our interest in them; the face is the body's<br/>billboard. So all other things being equal, a painting with faces in it will<br/>interest people more than one without. [1]  <br/>  <br/>One reason it's easy to believe that taste is merely personal preference is<br/>that, if it isn't, how do you pick out the people with better taste? There are<br/>billions of people, each with their own opinion; on what grounds can you<br/>prefer one to another? [2]  <br/>  <br/>But if audiences have a lot in common, you're not in a position of having to<br/>choose one out of a random set of individual biases, because the set isn't<br/>random. All humans find faces engaging—practically by definition: face<br/>recognition is in our DNA. And so having a notion of good art, in the sense of<br/>art that does its job well, doesn't require you to pick out a few individuals<br/>and label their opinions as correct. No matter who you pick, they'll find<br/>faces engaging.  <br/>  <br/>Of course, space aliens probably wouldn't find human faces engaging. But there<br/>might be other things they shared in common with us. The most likely source of<br/>examples is math. I expect space aliens would agree with us most of the time<br/>about which of two proofs was better. Erdos thought so. He called a maximally<br/>elegant proof one out of God's book, and presumably God's book is universal.<br/>[3]  <br/>  <br/>Once you start talking about audiences, you don't have to argue simply that<br/>there are or aren't standards of taste. Instead tastes are a series of<br/>concentric rings, like ripples in a pond. There are some things that will<br/>appeal to you and your friends, others that will appeal to most people your<br/>age, others that will appeal to most humans, and perhaps others that would<br/>appeal to most sentient beings (whatever that means).  <br/>  <br/>The picture is slightly more complicated than that, because in the middle of<br/>the pond there are overlapping sets of ripples. For example, there might be<br/>things that appealed particularly to men, or to people from a certain culture.  <br/>  <br/>If good art is art that interests its audience, then when you talk about art<br/>being good, you also have to say for what audience. So is it meaningless to<br/>talk about art simply being good or bad? No, because one audience is the set<br/>of all possible humans. I think that's the audience people are implicitly<br/>talking about when they say a work of art is good: they mean it would engage<br/>any human. [4]  <br/>  <br/>And that is a meaningful test, because although, like any everyday concept,<br/>"human" is fuzzy around the edges, there are a lot of things practically all<br/>humans have in common. In addition to our interest in faces, there's something<br/>special about primary colors for nearly all of us, because it's an artifact of<br/>the way our eyes work. Most humans will also find images of 3D objects<br/>engaging, because that also seems to be built into our visual perception. [5]<br/>And beneath that there's edge-finding, which makes images with definite shapes<br/>more engaging than mere blur.  <br/>  <br/>Humans have a lot more in common than this, of course. My goal is not to<br/>compile a complete list, just to show that there's some solid ground here.<br/>People's preferences aren't random. So an artist working on a painting and<br/>trying to decide whether to change some part of it doesn't have to think "Why<br/>bother? I might as well flip a coin." Instead he can ask "What would make the<br/>painting more interesting to people?" And the reason you can't equal<br/>Michelangelo by going out and buying a blank canvas is that the ceiling of the<br/>Sistine Chapel is more interesting to people.  <br/>  <br/>A lot of philosophers have had a hard time believing it was possible for there<br/>to be objective standards for art. It seemed obvious that beauty, for example,<br/>was something that happened in the head of the observer, not something that<br/>was a property of objects. It was thus "subjective" rather than "objective."<br/>But in fact if you narrow the definition of beauty to something that works a<br/>certain way on humans, and you observe how much humans have in common, it<br/>turns out to be a property of objects after all. You don't have to choose<br/>between something being a property of the subject or the object if subjects<br/>all react similarly. Being good art is thus a property of objects as much as,<br/>say, being toxic to humans is: it's good art if it consistently affects humans<br/>in a certain way.  <br/>  <br/>**Error**  <br/>  <br/>So could we figure out what the best art is by taking a vote? After all, if<br/>appealing to humans is the test, we should be able to just ask them, right?  <br/>  <br/>Well, not quite. For products of nature that might work. I'd be willing to eat<br/>the apple the world's population had voted most delicious, and I'd probably be<br/>willing to visit the beach they voted most beautiful, but having to look at<br/>the painting they voted the best would be a crapshoot.  <br/>  <br/>Man-made stuff is different. For one thing, artists, unlike apple trees, often<br/>deliberately try to trick us. Some tricks are quite subtle. For example, any<br/>work of art sets expectations by its level of finish. You don't expect<br/>photographic accuracy in something that looks like a quick sketch. So one<br/>widely used trick, especially among illustrators, is to intentionally make a<br/>painting or drawing look like it was done faster than it was. The average<br/>person looks at it and thinks: how amazingly skillful. It's like saying<br/>something clever in a conversation as if you'd thought of it on the spur of<br/>the moment, when in fact you'd worked it out the day before.  <br/>  <br/>Another much less subtle influence is brand. If you go to see the Mona Lisa,<br/>you'll probably be disappointed, because it's hidden behind a thick glass wall<br/>and surrounded by a frenzied crowd taking pictures of themselves in front of<br/>it. At best you can see it the way you see a friend across the room at a<br/>crowded party. The Louvre might as well replace it with copy; no one would be<br/>able to tell. And yet the Mona Lisa is a small, dark painting. If you found<br/>people who'd never seen an image of it and sent them to a museum in which it<br/>was hanging among other paintings with a tag labelling it as a portrait by an<br/>unknown fifteenth century artist, most would walk by without giving it a<br/>second look.  <br/>  <br/>For the average person, brand dominates all other factors in the judgement of<br/>art. Seeing a painting they recognize from reproductions is so overwhelming<br/>that their response to it as a painting is drowned out.  <br/>  <br/>And then of course there are the tricks people play on themselves. Most adults<br/>looking at art worry that if they don't like what they're supposed to, they'll<br/>be thought uncultured. This doesn't just affect what they claim to like; they<br/>actually make themselves like things they're supposed to.  <br/>  <br/>That's why you can't just take a vote. Though appeal to people is a meaningful<br/>test, in practice you can't measure it, just as you can't find north using a<br/>compass with a magnet sitting next to it. There are sources of error so<br/>powerful that if you take a vote, all you're measuring is the error.  <br/>  <br/>We can, however, approach our goal from another direction, by using ourselves<br/>as guinea pigs. You're human. If you want to know what the basic human<br/>reaction to a piece of art would be, you can at least approach that by getting<br/>rid of the sources of error in your own judgements.  <br/>  <br/>For example, while anyone's reaction to a famous painting will be warped at<br/>first by its fame, there are ways to decrease its effects. One is to come back<br/>to the painting over and over. After a few days the fame wears off, and you<br/>can start to see it as a painting. Another is to stand close. A painting<br/>familiar from reproductions looks more familiar from ten feet away; close in<br/>you see details that get lost in reproductions, and which you're therefore<br/>seeing for the first time.  <br/>  <br/>There are two main kinds of error that get in the way of seeing a work of art:<br/>biases you bring from your own circumstances, and tricks played by the artist.<br/>Tricks are straightforward to correct for. Merely being aware of them usually<br/>prevents them from working. For example, when I was ten I used to be very<br/>impressed by airbrushed lettering that looked like shiny metal. But once you<br/>study how it's done, you see that it's a pretty cheesy trick—one of the sort<br/>that relies on pushing a few visual buttons really hard to temporarily<br/>overwhelm the viewer. It's like trying to convince someone by shouting at<br/>them.  <br/>  <br/>The way not to be vulnerable to tricks is to explicitly seek out and catalog<br/>them. When you notice a whiff of dishonesty coming from some kind of art, stop<br/>and figure out what's going on. When someone is obviously pandering to an<br/>audience that's easily fooled, whether it's someone making shiny stuff to<br/>impress ten year olds, or someone making conspicuously avant-garde stuff to<br/>impress would-be intellectuals, learn how they do it. Once you've seen enough<br/>examples of specific types of tricks, you start to become a connoisseur of<br/>trickery in general, just as professional magicians are.  <br/>  <br/>What counts as a trick? Roughly, it's something done with contempt for the<br/>audience. For example, the guys designing Ferraris in the 1950s were probably<br/>designing cars that they themselves admired. Whereas I suspect over at General<br/>Motors the marketing people are telling the designers, "Most people who buy<br/>SUVs do it to seem manly, not to drive off-road. So don't worry about the<br/>suspension; just make that sucker as big and tough-looking as you can." [6]  <br/>  <br/>I think with some effort you can make yourself nearly immune to tricks. It's<br/>harder to escape the influence of your own circumstances, but you can at least<br/>move in that direction. The way to do it is to travel widely, in both time and<br/>space. If you go and see all the different kinds of things people like in<br/>other cultures, and learn about all the different things people have liked in<br/>the past, you'll probably find it changes what you like. I doubt you could<br/>ever make yourself into a completely universal person, if only because you can<br/>only travel in one direction in time. But if you find a work of art that would<br/>appeal equally to your friends, to people in Nepal, and to the ancient Greeks,<br/>you're probably onto something.  <br/>  <br/>My main point here is not how to have good taste, but that there can even be<br/>such a thing. And I think I've shown that. There is such a thing as good art.<br/>It's art that interests its human audience, and since humans have a lot in<br/>common, what interests them is not random. Since there's such a thing as good<br/>art, there's also such a thing as good taste, which is the ability to<br/>recognize it.  <br/>  <br/>If we were talking about the taste of apples, I'd agree that taste is just<br/>personal preference. Some people like certain kinds of apples and others like<br/>other kinds, but how can you say that one is right and the other wrong? [7]  <br/>  <br/>The thing is, art isn't apples. Art is man-made. It comes with a lot of<br/>cultural baggage, and in addition the people who make it often try to trick<br/>us. Most people's judgement of art is dominated by these extraneous factors;<br/>they're like someone trying to judge the taste of apples in a dish made of<br/>equal parts apples and jalapeno peppers. All they're tasting is the peppers.<br/>So it turns out you can pick out some people and say that they have better<br/>taste than others: they're the ones who actually taste art like apples.  <br/>  <br/>Or to put it more prosaically, they're the people who (a) are hard to trick,<br/>and (b) don't just like whatever they grew up with. If you could find people<br/>who'd eliminated all such influences on their judgement, you'd probably still<br/>see variation in what they liked. But because humans have so much in common,<br/>you'd also find they agreed on a lot. They'd nearly all prefer the ceiling of<br/>the Sistine Chapel to a blank canvas.  <br/>  <br/> **Making It**  <br/>  <br/>I wrote this essay because I was tired of hearing "taste is subjective" and<br/>wanted to kill it once and for all. Anyone who makes things knows intuitively<br/>that's not true. When you're trying to make art, the temptation to be lazy is<br/>as great as in any other kind of work. Of course it matters to do a good job.<br/>And yet you can see how great a hold "taste is subjective" has even in the art<br/>world by how nervous it makes people to talk about art being good or bad.<br/>Those whose jobs require them to judge art, like curators, mostly resort to<br/>euphemisms like "significant" or "important" or (getting dangerously close)<br/>"realized." [8]  <br/>  <br/>I don't have any illusions that being able to talk about art being good or bad<br/>will cause the people who talk about it to have anything more useful to say.<br/>Indeed, one of the reasons "taste is subjective" found such a receptive<br/>audience is that, historically, the things people have said about good taste<br/>have generally been such nonsense.  <br/>  <br/>It's not for the people who talk about art that I want to free the idea of<br/>good art, but for those who make it. Right now, ambitious kids going to art<br/>school run smack into a brick wall. They arrive hoping one day to be as good<br/>as the famous artists they've seen in books, and the first thing they learn is<br/>that the concept of good has been retired. Instead everyone is just supposed<br/>to explore their own personal vision. [9]  <br/>  <br/>When I was in art school, we were looking one day at a slide of some great<br/>fifteenth century painting, and one of the students asked "Why don't artists<br/>paint like that now?" The room suddenly got quiet. Though rarely asked out<br/>loud, this question lurks uncomfortably in the back of every art student's<br/>mind. It was as if someone had brought up the topic of lung cancer in a<br/>meeting within Philip Morris.  <br/>  <br/>"Well," the professor replied, "we're interested in different questions now."<br/>He was a pretty nice guy, but at the time I couldn't help wishing I could send<br/>him back to fifteenth century Florence to explain in person to Leonardo & Co.<br/>how we had moved beyond their early, limited concept of art. Just imagine that<br/>conversation.  <br/>  <br/>In fact, one of the reasons artists in fifteenth century Florence made such<br/>great things was that they believed you could make great things. [10] They<br/>were intensely competitive and were always trying to outdo one another, like<br/>mathematicians or physicists today—maybe like anyone who has ever done<br/>anything really well.  <br/>  <br/>The idea that you could make great things was not just a useful illusion. They<br/>were actually right. So the most important consequence of realizing there can<br/>be good art is that it frees artists to try to make it. To the ambitious kids<br/>arriving at art school this year hoping one day to make great things, I say:<br/>don't believe it when they tell you this is a naive and outdated ambition.<br/>There is such a thing as good art, and if you try to make it, there are people<br/>who will notice.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] This is not to say, of course, that good paintings must have faces in<br/>them, just that everyone's visual piano has that key on it. There are<br/>situations in which you want to avoid faces, precisely because they attract so<br/>much attention. But you can see how universally faces work by their prevalence<br/>in advertising.  <br/>  <br/>[2] The other reason it's easy to believe is that it makes people feel good.<br/>To a kid, this idea is crack. In every other respect they're constantly being<br/>told that they have a lot to learn. But in this they're perfect. Their opinion<br/>carries the same weight as any adult's. You should probably question anything<br/>you believed as a kid that you'd want to believe this much.  <br/>  <br/>[3] It's conceivable that the elegance of proofs is quantifiable, in the sense<br/>that there may be some formal measure that turns out to coincide with<br/>mathematicians' judgements. Perhaps it would be worth trying to make a formal<br/>language for proofs in which those considered more elegant consistently came<br/>out shorter (perhaps after being macroexpanded or compiled).  <br/>  <br/>[4] Maybe it would be possible to make art that would appeal to space aliens,<br/>but I'm not going to get into that because (a) it's too hard to answer, and<br/>(b) I'm satisfied if I can establish that good art is a meaningful idea for<br/>human audiences.  <br/>  <br/>[5] If early abstract paintings seem more interesting than later ones, it may<br/>be because the first abstract painters were trained to paint from life, and<br/>their hands thus tended to make the kind of gestures you use in representing<br/>physical things. In effect they were saying "scaramara" instead of "uebfgbsb."  <br/>  <br/>[6] It's a bit more complicated, because sometimes artists unconsciously use<br/>tricks by imitating art that does.  <br/>  <br/>[7] I phrased this in terms of the taste of apples because if people can see<br/>the apples, they can be fooled. When I was a kid most apples were a variety<br/>called Red Delicious that had been bred to look appealing in stores, but which<br/>didn't taste very good.  <br/>  <br/>[8] To be fair, curators are in a difficult position. If they're dealing with<br/>recent art, they have to include things in shows that they think are bad.<br/>That's because the test for what gets included in shows is basically the<br/>market price, and for recent art that is largely determined by successful<br/>businessmen and their wives. So it's not always intellectual dishonesty that<br/>makes curators and dealers use neutral-sounding language.  <br/>  <br/>[9] What happens in practice is that everyone gets really good at _talking_<br/>about art. As the art itself gets more random, the effort that would have gone<br/>into the work goes instead into the intellectual sounding theory behind it.<br/>"My work represents an exploration of gender and sexuality in an urban<br/>context," etc. Different people win at that game.  <br/>  <br/>[10] There were several other reasons, including that Florence was then the<br/>richest and most sophisticated city in the world, and that they lived in a<br/>time before photography had (a) killed portraiture as a source of income and<br/>(b) made brand the dominant factor in the sale of art.  <br/>  <br/>Incidentally, I'm not saying that good art = fifteenth century European art.<br/>I'm not saying we should make what they made, but that we should work like<br/>they worked. There are fields now in which many people work with the same<br/>energy and honesty that fifteenth century artists did, but art is not one of<br/>them.  <br/>  <br/> **Thanks** to Trevor Blackwell, Jessica Livingston, and Robert Morris for<br/>reading drafts of this, and to Paul Watson for permission to use the image at<br/>the top.  <br/>  <br/>Comment on this essay.  <br/>  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>November 2005  <br/>  <br/>Does "Web 2.0" mean anything? Till recently I thought it didn't, but the truth<br/>turns out to be more complicated. Originally, yes, it was meaningless. Now it<br/>seems to have acquired a meaning. And yet those who dislike the term are<br/>probably right, because if it means what I think it does, we don't need it.  <br/>  <br/>I first heard the phrase "Web 2.0" in the name of the Web 2.0 conference in<br/>2004. At the time it was supposed to mean using "the web as a platform," which<br/>I took to refer to web-based applications. [1]  <br/>  <br/>So I was surprised at a conference this summer when Tim O'Reilly led a session<br/>intended to figure out a definition of "Web 2.0." Didn't it already mean using<br/>the web as a platform? And if it didn't already mean something, why did we<br/>need the phrase at all?  <br/>  <br/> **Origins**  <br/>  <br/>Tim says the phrase "Web 2.0" first arose in "a brainstorming session between<br/>O'Reilly and Medialive International." What is Medialive International?<br/>"Producers of technology tradeshows and conferences," according to their site.<br/>So presumably that's what this brainstorming session was about. O'Reilly<br/>wanted to organize a conference about the web, and they were wondering what to<br/>call it.  <br/>  <br/>I don't think there was any deliberate plan to suggest there was a new<br/>_version_ of the web. They just wanted to make the point that the web mattered<br/>again. It was a kind of semantic deficit spending: they knew new things were<br/>coming, and the "2.0" referred to whatever those might turn out to be.  <br/>  <br/>And they were right. New things were coming. But the new version number led to<br/>some awkwardness in the short term. In the process of developing the pitch for<br/>the first conference, someone must have decided they'd better take a stab at<br/>explaining what that "2.0" referred to. Whatever it meant, "the web as a<br/>platform" was at least not too constricting.  <br/>  <br/>The story about "Web 2.0" meaning the web as a platform didn't live much past<br/>the first conference. By the second conference, what "Web 2.0" seemed to mean<br/>was something about democracy. At least, it did when people wrote about it<br/>online. The conference itself didn't seem very grassroots. It cost $2800, so<br/>the only people who could afford to go were VCs and people from big companies.  <br/>  <br/>And yet, oddly enough, Ryan Singel's article about the conference in _Wired<br/>News_ spoke of "throngs of geeks." When a friend of mine asked Ryan about<br/>this, it was news to him. He said he'd originally written something like<br/>"throngs of VCs and biz dev guys" but had later shortened it just to<br/>"throngs," and that this must have in turn been expanded by the editors into<br/>"throngs of geeks." After all, a Web 2.0 conference would presumably be full<br/>of geeks, right?  <br/>  <br/>Well, no. There were about 7. Even Tim O'Reilly was wearing a suit, a sight so<br/>alien I couldn't parse it at first. I saw him walk by and said to one of the<br/>O'Reilly people "that guy looks just like Tim."  <br/>  <br/>"Oh, that's Tim. He bought a suit." I ran after him, and sure enough, it was.<br/>He explained that he'd just bought it in Thailand.  <br/>  <br/>The 2005 Web 2.0 conference reminded me of Internet trade shows during the<br/>Bubble, full of prowling VCs looking for the next hot startup. There was that<br/>same odd atmosphere created by a large number of people determined not to miss<br/>out. Miss out on what? They didn't know. Whatever was going to happen—whatever<br/>Web 2.0 turned out to be.  <br/>  <br/>I wouldn't quite call it "Bubble 2.0" just because VCs are eager to invest<br/>again. The Internet is a genuinely big deal. The bust was as much an<br/>overreaction as the boom. It's to be expected that once we started to pull out<br/>of the bust, there would be a lot of growth in this area, just as there was in<br/>the industries that spiked the sharpest before the Depression.  <br/>  <br/>The reason this won't turn into a second Bubble is that the IPO market is<br/>gone. Venture investors are driven by exit strategies. The reason they were<br/>funding all those laughable startups during the late 90s was that they hoped<br/>to sell them to gullible retail investors; they hoped to be laughing all the<br/>way to the bank. Now that route is closed. Now the default exit strategy is to<br/>get bought, and acquirers are less prone to irrational exuberance than IPO<br/>investors. The closest you'll get to Bubble valuations is Rupert Murdoch<br/>paying $580 million for Myspace. That's only off by a factor of 10 or so.  <br/>  <br/> **1\. Ajax**  <br/>  <br/>Does "Web 2.0" mean anything more than the name of a conference yet? I don't<br/>like to admit it, but it's starting to. When people say "Web 2.0" now, I have<br/>some idea what they mean. And the fact that I both despise the phrase and<br/>understand it is the surest proof that it has started to mean something.  <br/>  <br/>One ingredient of its meaning is certainly Ajax, which I can still only just<br/>bear to use without scare quotes. Basically, what "Ajax" means is "Javascript<br/>now works." And that in turn means that web-based applications can now be made<br/>to work much more like desktop ones.  <br/>  <br/>As you read this, a whole new generation of software is being written to take<br/>advantage of Ajax. There hasn't been such a wave of new applications since<br/>microcomputers first appeared. Even Microsoft sees it, but it's too late for<br/>them to do anything more than leak "internal" documents designed to give the<br/>impression they're on top of this new trend.  <br/>  <br/>In fact the new generation of software is being written way too fast for<br/>Microsoft even to channel it, let alone write their own in house. Their only<br/>hope now is to buy all the best Ajax startups before Google does. And even<br/>that's going to be hard, because Google has as big a head start in buying<br/>microstartups as it did in search a few years ago. After all, Google Maps, the<br/>canonical Ajax application, was the result of a startup they bought.  <br/>  <br/>So ironically the original description of the Web 2.0 conference turned out to<br/>be partially right: web-based applications are a big component of Web 2.0. But<br/>I'm convinced they got this right by accident. The Ajax boom didn't start till<br/>early 2005, when Google Maps appeared and the term "Ajax" was coined.  <br/>  <br/> **2\. Democracy**  <br/>  <br/>The second big element of Web 2.0 is democracy. We now have several examples<br/>to prove that amateurs can surpass professionals, when they have the right<br/>kind of system to channel their efforts. Wikipedia may be the most famous.<br/>Experts have given Wikipedia middling reviews, but they miss the critical<br/>point: it's good enough. And it's free, which means people actually read it.<br/>On the web, articles you have to pay for might as well not exist. Even if you<br/>were willing to pay to read them yourself, you can't link to them. They're not<br/>part of the conversation.  <br/>  <br/>Another place democracy seems to win is in deciding what counts as news. I<br/>never look at any news site now except Reddit. [2] I know if something major<br/>happens, or someone writes a particularly interesting article, it will show up<br/>there. Why bother checking the front page of any specific paper or magazine?<br/>Reddit's like an RSS feed for the whole web, with a filter for quality.<br/>Similar sites include Digg, a technology news site that's rapidly approaching<br/>Slashdot in popularity, and del.icio.us, the collaborative bookmarking network<br/>that set off the "tagging" movement. And whereas Wikipedia's main appeal is<br/>that it's good enough and free, these sites suggest that voters do a<br/>significantly better job than human editors.  <br/>  <br/>The most dramatic example of Web 2.0 democracy is not in the selection of<br/>ideas, but their production.  I've noticed for a while that the stuff I read<br/>on individual people's sites is as good as or better than the stuff I read in<br/>newspapers and magazines. And now I have independent evidence: the top links<br/>on Reddit are generally links to individual people's sites rather than to<br/>magazine articles or news stories.  <br/>  <br/>My experience of writing for magazines suggests an explanation. Editors. They<br/>control the topics you can write about, and they can generally rewrite<br/>whatever you produce. The result is to damp extremes. Editing yields 95th<br/>percentile writing—95% of articles are improved by it, but 5% are dragged<br/>down. 5% of the time you get "throngs of geeks."  <br/>  <br/>On the web, people can publish whatever they want. Nearly all of it falls<br/>short of the editor-damped writing in print publications. But the pool of<br/>writers is very, very large. If it's large enough, the lack of damping means<br/>the best writing online should surpass the best in print. [3] And now that the<br/>web has evolved mechanisms for selecting good stuff, the web wins net.<br/>Selection beats damping, for the same reason market economies beat centrally<br/>planned ones.  <br/>  <br/>Even the startups are different this time around. They are to the startups of<br/>the Bubble what bloggers are to the print media. During the Bubble, a startup<br/>meant a company headed by an MBA that was blowing through several million<br/>dollars of VC money to "get big fast" in the most literal sense. Now it means<br/>a smaller, younger, more technical group that just decided to make something<br/>great. They'll decide later if they want to raise VC-scale funding, and if<br/>they take it, they'll take it on their terms.  <br/>  <br/> **3\. Don't Maltreat Users**  <br/>  <br/>I think everyone would agree that democracy and Ajax are elements of "Web<br/>2.0." I also see a third: not to maltreat users. During the Bubble a lot of<br/>popular sites were quite high-handed with users. And not just in obvious ways,<br/>like making them register, or subjecting them to annoying ads. The very design<br/>of the average site in the late 90s was an abuse. Many of the most popular<br/>sites were loaded with obtrusive branding that made them slow to load and sent<br/>the user the message: this is our site, not yours. (There's a physical analog<br/>in the Intel and Microsoft stickers that come on some laptops.)  <br/>  <br/>I think the root of the problem was that sites felt they were giving something<br/>away for free, and till recently a company giving anything away for free could<br/>be pretty high-handed about it. Sometimes it reached the point of economic<br/>sadism: site owners assumed that the more pain they caused the user, the more<br/>benefit it must be to them. The most dramatic remnant of this model may be at<br/>salon.com, where you can read the beginning of a story, but to get the rest<br/>you have sit through a _movie_.  <br/>  <br/>At Y Combinator we advise all the startups we fund never to lord it over<br/>users. Never make users register, unless you need to in order to store<br/>something for them. If you do make users register, never make them wait for a<br/>confirmation link in an email; in fact, don't even ask for their email address<br/>unless you need it for some reason. Don't ask them any unnecessary questions.<br/>Never send them email unless they explicitly ask for it. Never frame pages you<br/>link to, or open them in new windows. If you have a free version and a pay<br/>version, don't make the free version too restricted. And if you find yourself<br/>asking "should we allow users to do x?" just answer "yes" whenever you're<br/>unsure. Err on the side of generosity.  <br/>  <br/>In How to Start a Startup I advised startups never to let anyone fly under<br/>them, meaning never to let any other company offer a cheaper, easier solution.<br/>Another way to fly low is to give users more power. Let users do what they<br/>want. If you don't and a competitor does, you're in trouble.  <br/>  <br/>iTunes is Web 2.0ish in this sense. Finally you can buy individual songs<br/>instead of having to buy whole albums. The recording industry hated the idea<br/>and resisted it as long as possible. But it was obvious what users wanted, so<br/>Apple flew under the labels. [4] Though really it might be better to describe<br/>iTunes as Web 1.5. Web 2.0 applied to music would probably mean individual<br/>bands giving away DRMless songs for free.  <br/>  <br/>The ultimate way to be nice to users is to give them something for free that<br/>competitors charge for. During the 90s a lot of people probably thought we'd<br/>have some working system for micropayments by now. In fact things have gone in<br/>the other direction. The most successful sites are the ones that figure out<br/>new ways to give stuff away for free. Craigslist has largely destroyed the<br/>classified ad sites of the 90s, and OkCupid looks likely to do the same to the<br/>previous generation of dating sites.  <br/>  <br/>Serving web pages is very, very cheap. If you can make even a fraction of a<br/>cent per page view, you can make a profit. And technology for targeting ads<br/>continues to improve. I wouldn't be surprised if ten years from now eBay had<br/>been supplanted by an ad-supported freeBay (or, more likely, gBay).  <br/>  <br/>Odd as it might sound, we tell startups that they should try to make as little<br/>money as possible. If you can figure out a way to turn a billion dollar<br/>industry into a fifty million dollar industry, so much the better, if all<br/>fifty million go to you. Though indeed, making things cheaper often turns out<br/>to generate more money in the end, just as automating things often turns out<br/>to generate more jobs.  <br/>  <br/>The ultimate target is Microsoft. What a bang that balloon is going to make<br/>when someone pops it by offering a free web-based alternative to MS Office.<br/>[5] Who will? Google? They seem to be taking their time. I suspect the pin<br/>will be wielded by a couple of 20 year old hackers who are too naive to be<br/>intimidated by the idea. (How hard can it be?)  <br/>  <br/> **The Common Thread**  <br/>  <br/>Ajax, democracy, and not dissing users. What do they all have in common? I<br/>didn't realize they had anything in common till recently, which is one of the<br/>reasons I disliked the term "Web 2.0" so much. It seemed that it was being<br/>used as a label for whatever happened to be new—that it didn't predict<br/>anything.  <br/>  <br/>But there is a common thread. Web 2.0 means using the web the way it's meant<br/>to be used. The "trends" we're seeing now are simply the inherent nature of<br/>the web emerging from under the broken models that got imposed on it during<br/>the Bubble.  <br/>  <br/>I realized this when I read an  interview with Joe Kraus, the co-founder of<br/>Excite. [6]<br/><br/>> Excite really never got the business model right at all. We fell into the<br/>> classic problem of how when a new medium comes out it adopts the practices,<br/>> the content, the business models of the old medium—which fails, and then the<br/>> more appropriate models get figured out.<br/><br/>It may have seemed as if not much was happening during the years after the<br/>Bubble burst. But in retrospect, something was happening: the web was finding<br/>its natural angle of repose. The democracy component, for example—that's not<br/>an innovation, in the sense of something someone made happen. That's what the<br/>web naturally tends to produce.  <br/>  <br/>Ditto for the idea of delivering desktop-like applications over the web. That<br/>idea is almost as old as the web. But the first time around it was co-opted by<br/>Sun, and we got Java applets. Java has since been remade into a generic<br/>replacement for C++, but in 1996 the story about Java was that it represented<br/>a new model of software. Instead of desktop applications, you'd run Java<br/>"applets" delivered from a server.  <br/>  <br/>This plan collapsed under its own weight. Microsoft helped kill it, but it<br/>would have died anyway. There was no uptake among hackers. When you find PR<br/>firms promoting something as the next development platform, you can be sure<br/>it's not. If it were, you wouldn't need PR firms to tell you, because hackers<br/>would already be writing stuff on top of it, the way sites like Busmonster<br/>used Google Maps as a platform before Google even meant it to be one.  <br/>  <br/>The proof that Ajax is the next hot platform is that thousands of hackers have<br/>spontaneously started building things on top of it. Mikey likes it.  <br/>  <br/>There's another thing all three components of Web 2.0 have in common. Here's a<br/>clue. Suppose you approached investors with the following idea for a Web 2.0<br/>startup:<br/><br/>> Sites like del.icio.us and flickr allow users to "tag" content with<br/>> descriptive tokens. But there is also huge source of _implicit_ tags that<br/>> they ignore: the text within web links. Moreover, these links represent a<br/>> social network connecting the individuals and organizations who created the<br/>> pages, and by using graph theory we can compute from this network an<br/>> estimate of the reputation of each member. We plan to mine the web for these<br/>> implicit tags, and use them together with the reputation hierarchy they<br/>> embody to enhance web searches.<br/><br/>How long do you think it would take them on average to realize that it was a<br/>description of Google?  <br/>  <br/>Google was a pioneer in all three components of Web 2.0: their core business<br/>sounds crushingly hip when described in Web 2.0 terms, "Don't maltreat users"<br/>is a subset of "Don't be evil," and of course Google set off the whole Ajax<br/>boom with Google Maps.  <br/>  <br/>Web 2.0 means using the web as it was meant to be used, and Google does.<br/>That's their secret.  They're sailing with the wind, instead of sitting<br/>becalmed praying for a business model, like the print media, or trying to tack<br/>upwind by suing their customers, like Microsoft and the record labels. [7]  <br/>  <br/>Google doesn't try to force things to happen their way. They try to figure out<br/>what's going to happen, and arrange to be standing there when it does. That's<br/>the way to approach technology—and as business includes an ever larger<br/>technological component, the right way to do business.  <br/>  <br/>The fact that Google is a "Web 2.0" company shows that, while meaningful, the<br/>term is also rather bogus. It's like the word "allopathic." It just means<br/>doing things right, and it's a bad sign when you have a special word for that.  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] From the conference site, June 2004: "While the first wave of the Web was<br/>closely tied to the browser, the second wave extends applications across the<br/>web and enables a new generation of services and business opportunities." To<br/>the extent this means anything, it seems to be about web-based applications.  <br/>  <br/>[2] Disclosure: Reddit was funded by Y Combinator. But although I started<br/>using it out of loyalty to the home team, I've become a genuine addict. While<br/>we're at it, I'm also an investor in !MSFT, having sold all my shares earlier<br/>this year.  <br/>  <br/>[3] I'm not against editing. I spend more time editing than writing, and I<br/>have a group of picky friends who proofread almost everything I write. What I<br/>dislike is editing done after the fact by someone else.  <br/>  <br/>[4] Obvious is an understatement. Users had been climbing in through the<br/>window for years before Apple finally moved the door.  <br/>  <br/>[5] Hint: the way to create a web-based alternative to Office may not be to<br/>write every component yourself, but to establish a protocol for web-based apps<br/>to share a virtual home directory spread across multiple servers. Or it may be<br/>to write it all yourself.  <br/>  <br/>[6] In Jessica Livingston's _Founders at Work_.  <br/>  <br/>[7] Microsoft didn't sue their customers directly, but they seem to have done<br/>all they could to help SCO sue them.  <br/>  <br/> **Thanks** to Trevor Blackwell, Sarah Harlin, Jessica Livingston, Peter<br/>Norvig, Aaron Swartz, and Jeff Weiner for reading drafts of this, and to the<br/>guys at O'Reilly and Adaptive Path for answering my questions.  <br/>  <br/>  <br/>  <br/><br/>Interview About Web 2.0  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>German Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>October 2006  <br/>  <br/>In the Q & A period after a recent talk, someone asked what made startups<br/>fail. After standing there gaping for a few seconds I realized this was kind<br/>of a trick question. It's equivalent to asking how to make a startup succeed —<br/>if you avoid every cause of failure, you succeed — and that's too big a<br/>question to answer on the fly.  <br/>  <br/>Afterwards I realized it could be helpful to look at the problem from this<br/>direction. If you have a list of all the things you shouldn't do, you can turn<br/>that into a recipe for succeeding just by negating. And this form of list may<br/>be more useful in practice. It's easier to catch yourself doing something you<br/>shouldn't than always to remember to do something you should. [1]  <br/>  <br/>In a sense there's just one mistake that kills startups: not making something<br/>users want. If you make something users want, you'll probably be fine,<br/>whatever else you do or don't do. And if you don't make something users want,<br/>then you're dead, whatever else you do or don't do. So really this is a list<br/>of 18 things that cause startups not to make something users want. Nearly all<br/>failure funnels through that.  <br/>  <br/> **1\. Single Founder**  <br/>  <br/>Have you ever noticed how few successful startups were founded by just one<br/>person? Even companies you think of as having one founder, like Oracle,<br/>usually turn out to have more. It seems unlikely this is a coincidence.  <br/>  <br/>What's wrong with having one founder? To start with, it's a vote of no<br/>confidence. It probably means the founder couldn't talk any of his friends<br/>into starting the company with him. That's pretty alarming, because his<br/>friends are the ones who know him best.  <br/>  <br/>But even if the founder's friends were all wrong and the company is a good<br/>bet, he's still at a disadvantage. Starting a startup is too hard for one<br/>person. Even if you could do all the work yourself, you need colleagues to<br/>brainstorm with, to talk you out of stupid decisions, and to cheer you up when<br/>things go wrong.  <br/>  <br/>The last one might be the most important. The low points in a startup are so<br/>low that few could bear them alone. When you have multiple founders, esprit de<br/>corps binds them together in a way that seems to violate conservation laws.<br/>Each thinks "I can't let my friends down." This is one of the most powerful<br/>forces in human nature, and it's missing when there's just one founder.  <br/>  <br/> **2\. Bad Location**  <br/>  <br/>Startups prosper in some places and not others. Silicon Valley dominates, then<br/>Boston, then Seattle, Austin, Denver, and New York. After that there's not<br/>much. Even in New York the number of startups per capita is probably a 20th of<br/>what it is in Silicon Valley. In towns like Houston and Chicago and Detroit<br/>it's too small to measure.  <br/>  <br/>Why is the falloff so sharp? Probably for the same reason it is in other<br/>industries. What's the sixth largest fashion center in the US? The sixth<br/>largest center for oil, or finance, or publishing? Whatever they are they're<br/>probably so far from the top that it would be misleading even to call them<br/>centers.  <br/>  <br/>It's an interesting question why cities become startup hubs, but the reason<br/>startups prosper in them is probably the same as it is for any industry:<br/>that's where the experts are. Standards are higher; people are more<br/>sympathetic to what you're doing; the kind of people you want to hire want to<br/>live there; supporting industries are there; the people you run into in chance<br/>meetings are in the same business. Who knows exactly how these factors combine<br/>to boost startups in Silicon Valley and squish them in Detroit, but it's clear<br/>they do from the number of startups per capita in each.  <br/>  <br/> **3\. Marginal Niche**  <br/>  <br/>Most of the groups that apply to Y Combinator suffer from a common problem:<br/>choosing a small, obscure niche in the hope of avoiding competition.  <br/>  <br/>If you watch little kids playing sports, you notice that below a certain age<br/>they're afraid of the ball. When the ball comes near them their instinct is to<br/>avoid it. I didn't make a lot of catches as an eight year old outfielder,<br/>because whenever a fly ball came my way, I used to close my eyes and hold my<br/>glove up more for protection than in the hope of catching it.  <br/>  <br/>Choosing a marginal project is the startup equivalent of my eight year old<br/>strategy for dealing with fly balls. If you make anything good, you're going<br/>to have competitors, so you may as well face that. You can only avoid<br/>competition by avoiding good ideas.  <br/>  <br/>I think this shrinking from big problems is mostly unconscious. It's not that<br/>people think of grand ideas but decide to pursue smaller ones because they<br/>seem safer. Your unconscious won't even let you think of grand ideas. So the<br/>solution may be to think about ideas without involving yourself. What would be<br/>a great idea for _someone else_ to do as a startup?  <br/>  <br/> **4\. Derivative Idea**  <br/>  <br/>Many of the applications we get are imitations of some existing company.<br/>That's one source of ideas, but not the best. If you look at the origins of<br/>successful startups, few were started in imitation of some other startup.<br/>Where did they get their ideas? Usually from some specific, unsolved problem<br/>the founders identified.  <br/>  <br/>Our startup made software for making online stores. When we started it, there<br/>wasn't any; the few sites you could order from were hand-made at great expense<br/>by web consultants. We knew that if online shopping ever took off, these sites<br/>would have to be generated by software, so we wrote some. Pretty<br/>straightforward.  <br/>  <br/>It seems like the best problems to solve are ones that affect you personally.<br/>Apple happened because Steve Wozniak wanted a computer, Google because Larry<br/>and Sergey couldn't find stuff online, Hotmail because Sabeer Bhatia and Jack<br/>Smith couldn't exchange email at work.  <br/>  <br/>So instead of copying the Facebook, with some variation that the Facebook<br/>rightly ignored, look for ideas from the other direction. Instead of starting<br/>from companies and working back to the problems they solved, look for problems<br/>and imagine the company that might solve them. [2] What do people complain<br/>about? What do you wish there was?  <br/>  <br/> **5\. Obstinacy**  <br/>  <br/>In some fields the way to succeed is to have a vision of what you want to<br/>achieve, and to hold true to it no matter what setbacks you encounter.<br/>Starting startups is not one of them. The stick-to-your-vision approach works<br/>for something like winning an Olympic gold medal, where the problem is well-<br/>defined. Startups are more like science, where you need to follow the trail<br/>wherever it leads.  <br/>  <br/>So don't get too attached to your original plan, because it's probably wrong.<br/>Most successful startups end up doing something different than they originally<br/>intended — often so different that it doesn't even seem like the same company.<br/>You have to be prepared to see the better idea when it arrives. And the<br/>hardest part of that is often discarding your old idea.  <br/>  <br/>But openness to new ideas has to be tuned just right. Switching to a new idea<br/>every week will be equally fatal. Is there some kind of external test you can<br/>use? One is to ask whether the ideas represent some kind of progression. If in<br/>each new idea you're able to re-use most of what you built for the previous<br/>ones, then you're probably in a process that converges. Whereas if you keep<br/>restarting from scratch, that's a bad sign.  <br/>  <br/>Fortunately there's someone you can ask for advice: your users. If you're<br/>thinking about turning in some new direction and your users seem excited about<br/>it, it's probably a good bet.  <br/>  <br/> **6\. Hiring Bad Programmers**  <br/>  <br/>I forgot to include this in the early versions of the list, because nearly all<br/>the founders I know are programmers. This is not a serious problem for them.<br/>They might accidentally hire someone bad, but it's not going to kill the<br/>company. In a pinch they can do whatever's required themselves.  <br/>  <br/>But when I think about what killed most of the startups in the e-commerce<br/>business back in the 90s, it was bad programmers. A lot of those companies<br/>were started by business guys who thought the way startups worked was that you<br/>had some clever idea and then hired programmers to implement it. That's<br/>actually much harder than it sounds — almost impossibly hard in fact — because<br/>business guys can't tell which are the good programmers. They don't even get a<br/>shot at the best ones, because no one really good wants a job implementing the<br/>vision of a business guy.  <br/>  <br/>In practice what happens is that the business guys choose people they think<br/>are good programmers (it says here on his resume that he's a Microsoft<br/>Certified Developer) but who aren't. Then they're mystified to find that their<br/>startup lumbers along like a World War II bomber while their competitors<br/>scream past like jet fighters. This kind of startup is in the same position as<br/>a big company, but without the advantages.  <br/>  <br/>So how do you pick good programmers if you're not a programmer? I don't think<br/>there's an answer. I was about to say you'd have to find a good programmer to<br/>help you hire people. But if you can't recognize good programmers, how would<br/>you even do that?  <br/>  <br/> **7\. Choosing the Wrong Platform**  <br/>  <br/>A related problem (since it tends to be done by bad programmers) is choosing<br/>the wrong platform. For example, I think a lot of startups during the Bubble<br/>killed themselves by deciding to build server-based applications on Windows.<br/>Hotmail was still running on FreeBSD for years after Microsoft bought it,<br/>presumably because Windows couldn't handle the load. If Hotmail's founders had<br/>chosen to use Windows, they would have been swamped.  <br/>  <br/>PayPal only just dodged this bullet. After they merged with X.com, the new CEO<br/>wanted to switch to Windows — even after PayPal cofounder Max Levchin showed<br/>that their software scaled only 1% as well on Windows as Unix. Fortunately for<br/>PayPal they switched CEOs instead.  <br/>  <br/>Platform is a vague word. It could mean an operating system, or a programming<br/>language, or a "framework" built on top of a programming language. It implies<br/>something that both supports and limits, like the foundation of a house.  <br/>  <br/>The scary thing about platforms is that there are always some that seem to<br/>outsiders to be fine, responsible choices and yet, like Windows in the 90s,<br/>will destroy you if you choose them. Java applets were probably the most<br/>spectacular example. This was supposed to be the new way of delivering<br/>applications. Presumably it killed just about 100% of the startups who<br/>believed that.  <br/>  <br/>How do you pick the right platforms? The usual way is to hire good programmers<br/>and let them choose. But there is a trick you could use if you're not a<br/>programmer: visit a top computer science department and see what they use in<br/>research projects.  <br/>  <br/> **8\. Slowness in Launching**  <br/>  <br/>Companies of all sizes have a hard time getting software done. It's intrinsic<br/>to the medium; software is always 85% done. It takes an effort of will to push<br/>through this and get something released to users. [3]  <br/>  <br/>Startups make all kinds of excuses for delaying their launch. Most are<br/>equivalent to the ones people use for procrastinating in everyday life.<br/>There's something that needs to happen first. Maybe. But if the software were<br/>100% finished and ready to launch at the push of a button, would they still be<br/>waiting?  <br/>  <br/>One reason to launch quickly is that it forces you to actually _finish_ some<br/>quantum of work. Nothing is truly finished till it's released; you can see<br/>that from the rush of work that's always involved in releasing anything, no<br/>matter how finished you thought it was. The other reason you need to launch is<br/>that it's only by bouncing your idea off users that you fully understand it.  <br/>  <br/>Several distinct problems manifest themselves as delays in launching: working<br/>too slowly; not truly understanding the problem; fear of having to deal with<br/>users; fear of being judged; working on too many different things; excessive<br/>perfectionism. Fortunately you can combat all of them by the simple expedient<br/>of forcing yourself to launch _something_ fairly quickly.  <br/>  <br/> **9\. Launching Too Early**  <br/>  <br/>Launching too slowly has probably killed a hundred times more startups than<br/>launching too fast, but it is possible to launch too fast. The danger here is<br/>that you ruin your reputation. You launch something, the early adopters try it<br/>out, and if it's no good they may never come back.  <br/>  <br/>So what's the minimum you need to launch? We suggest startups think about what<br/>they plan to do, identify a core that's both (a) useful on its own and (b)<br/>something that can be incrementally expanded into the whole project, and then<br/>get that done as soon as possible.  <br/>  <br/>This is the same approach I (and many other programmers) use for writing<br/>software. Think about the overall goal, then start by writing the smallest<br/>subset of it that does anything useful. If it's a subset, you'll have to write<br/>it anyway, so in the worst case you won't be wasting your time. But more<br/>likely you'll find that implementing a working subset is both good for morale<br/>and helps you see more clearly what the rest should do.  <br/>  <br/>The early adopters you need to impress are fairly tolerant. They don't expect<br/>a newly launched product to do everything; it just has to do _something_.  <br/>  <br/> **10\. Having No Specific User in Mind**  <br/>  <br/>You can't build things users like without understanding them. I mentioned<br/>earlier that the most successful startups seem to have begun by trying to<br/>solve a problem their founders had. Perhaps there's a rule here: perhaps you<br/>create wealth in proportion to how well you understand the problem you're<br/>solving, and the problems you understand best are your own. [4]  <br/>  <br/>That's just a theory. What's not a theory is the converse: if you're trying to<br/>solve problems you don't understand, you're hosed.  <br/>  <br/>And yet a surprising number of founders seem willing to assume that someone,<br/>they're not sure exactly who, will want what they're building. Do the founders<br/>want it? No, they're not the target market. Who is? Teenagers. People<br/>interested in local events (that one is a perennial tarpit). Or "business"<br/>users. What business users? Gas stations? Movie studios? Defense contractors?  <br/>  <br/>You can of course build something for users other than yourself. We did. But<br/>you should realize you're stepping into dangerous territory. You're flying on<br/>instruments, in effect, so you should (a) consciously shift gears, instead of<br/>assuming you can rely on your intuitions as you ordinarily would, and (b) look<br/>at the instruments.  <br/>  <br/>In this case the instruments are the users. When designing for other people<br/>you have to be empirical. You can no longer guess what will work; you have to<br/>find users and measure their responses. So if you're going to make something<br/>for teenagers or "business" users or some other group that doesn't include<br/>you, you have to be able to talk some specific ones into using what you're<br/>making. If you can't, you're on the wrong track.  <br/>  <br/> **11\. Raising Too Little Money**  <br/>  <br/>Most successful startups take funding at some point. Like having more than one<br/>founder, it seems a good bet statistically. How much should you take, though?  <br/>  <br/>Startup funding is measured in time. Every startup that isn't profitable<br/>(meaning nearly all of them, initially) has a certain amount of time left<br/>before the money runs out and they have to stop. This is sometimes referred to<br/>as runway, as in "How much runway do you have left?" It's a good metaphor<br/>because it reminds you that when the money runs out you're going to be<br/>airborne or dead.  <br/>  <br/>Too little money means not enough to get airborne. What airborne means depends<br/>on the situation. Usually you have to advance to a visibly higher level: if<br/>all you have is an idea, a working prototype; if you have a prototype,<br/>launching; if you're launched, significant growth. It depends on investors,<br/>because until you're profitable that's who you have to convince.  <br/>  <br/>So if you take money from investors, you have to take enough to get to the<br/>next step, whatever that is. [5] Fortunately you have some control over both<br/>how much you spend and what the next step is. We advise startups to set both<br/>low, initially: spend practically nothing, and make your initial goal simply<br/>to build a solid prototype. This gives you maximum flexibility.  <br/>  <br/> **12\. Spending Too Much**  <br/>  <br/>It's hard to distinguish spending too much from raising too little. If you run<br/>out of money, you could say either was the cause. The only way to decide which<br/>to call it is by comparison with other startups. If you raised five million<br/>and ran out of money, you probably spent too much.  <br/>  <br/>Burning through too much money is not as common as it used to be. Founders<br/>seem to have learned that lesson. Plus it keeps getting cheaper to start a<br/>startup. So as of this writing few startups spend too much. None of the ones<br/>we've funded have. (And not just because we make small investments; many have<br/>gone on to raise further rounds.)  <br/>  <br/>The classic way to burn through cash is by hiring a lot of people. This bites<br/>you twice: in addition to increasing your costs, it slows you down—so money<br/>that's getting consumed faster has to last longer. Most hackers understand why<br/>that happens; Fred Brooks explained it in The Mythical Man-Month.  <br/>  <br/>We have three general suggestions about hiring: (a) don't do it if you can<br/>avoid it, (b) pay people with equity rather than salary, not just to save<br/>money, but because you want the kind of people who are committed enough to<br/>prefer that, and (c) only hire people who are either going to write code or go<br/>out and get users, because those are the only things you need at first.  <br/>  <br/> **13\. Raising Too Much Money**  <br/>  <br/>It's obvious how too little money could kill you, but is there such a thing as<br/>having too much?  <br/>  <br/>Yes and no. The problem is not so much the money itself as what comes with it.<br/>As one VC who spoke at Y Combinator said, "Once you take several million<br/>dollars of my money, the clock is ticking." If VCs fund you, they're not going<br/>to let you just put the money in the bank and keep operating as two guys<br/>living on ramen. They want that money to go to work. [6] At the very least<br/>you'll move into proper office space and hire more people. That will change<br/>the atmosphere, and not entirely for the better. Now most of your people will<br/>be employees rather than founders. They won't be as committed; they'll need to<br/>be told what to do; they'll start to engage in office politics.  <br/>  <br/>When you raise a lot of money, your company moves to the suburbs and has kids.  <br/>  <br/>Perhaps more dangerously, once you take a lot of money it gets harder to<br/>change direction. Suppose your initial plan was to sell something to<br/>companies. After taking VC money you hire a sales force to do that. What<br/>happens now if you realize you should be making this for consumers instead of<br/>businesses? That's a completely different kind of selling. What happens, in<br/>practice, is that you don't realize that. The more people you have, the more<br/>you stay pointed in the same direction.  <br/>  <br/>Another drawback of large investments is the time they take. The time required<br/>to raise money grows with the amount. [7] When the amount rises into the<br/>millions, investors get very cautious. VCs never quite say yes or no; they<br/>just engage you in an apparently endless conversation. Raising VC scale<br/>investments is thus a huge time sink — more work, probably, than the startup<br/>itself. And you don't want to be spending all your time talking to investors<br/>while your competitors are spending theirs building things.  <br/>  <br/>We advise founders who go on to seek VC money to take the first reasonable<br/>deal they get. If you get an offer from a reputable firm at a reasonable<br/>valuation with no unusually onerous terms, just take it and get on with<br/>building the company. [8] Who cares if you could get a 30% better deal<br/>elsewhere? Economically, startups are an all-or-nothing game. Bargain-hunting<br/>among investors is a waste of time.  <br/>  <br/> **14\. Poor Investor Management**  <br/>  <br/>As a founder, you have to manage your investors. You shouldn't ignore them,<br/>because they may have useful insights. But neither should you let them run the<br/>company. That's supposed to be your job. If investors had sufficient vision to<br/>run the companies they fund, why didn't they start them?  <br/>  <br/>Pissing off investors by ignoring them is probably less dangerous than caving<br/>in to them. In our startup, we erred on the ignoring side. A lot of our energy<br/>got drained away in disputes with investors instead of going into the product.<br/>But this was less costly than giving in, which would probably have destroyed<br/>the company. If the founders know what they're doing, it's better to have half<br/>their attention focused on the product than the full attention of investors<br/>who don't.  <br/>  <br/>How hard you have to work on managing investors usually depends on how much<br/>money you've taken. When you raise VC-scale money, the investors get a great<br/>deal of control. If they have a board majority, they're literally your bosses.<br/>In the more common case, where founders and investors are equally represented<br/>and the deciding vote is cast by neutral outside directors, all the investors<br/>have to do is convince the outside directors and they control the company.  <br/>  <br/>If things go well, this shouldn't matter. So long as you seem to be advancing<br/>rapidly, most investors will leave you alone. But things don't always go<br/>smoothly in startups. Investors have made trouble even for the most successful<br/>companies. One of the most famous examples is Apple, whose board made a nearly<br/>fatal blunder in firing Steve Jobs. Apparently even Google got a lot of grief<br/>from their investors early on.  <br/>  <br/> **15\. Sacrificing Users to (Supposed) Profit**  <br/>  <br/>When I said at the beginning that if you make something users want, you'll be<br/>fine, you may have noticed I didn't mention anything about having the right<br/>business model. That's not because making money is unimportant. I'm not<br/>suggesting that founders start companies with no chance of making money in the<br/>hope of unloading them before they tank. The reason we tell founders not to<br/>worry about the business model initially is that making something people want<br/>is so much harder.  <br/>  <br/>I don't know why it's so hard to make something people want. It seems like it<br/>should be straightforward. But you can tell it must be hard by how few<br/>startups do it.  <br/>  <br/>Because making something people want is so much harder than making money from<br/>it, you should leave business models for later, just as you'd leave some<br/>trivial but messy feature for version 2. In version 1, solve the core problem.<br/>And the core problem in a startup is how to create wealth (= how much people<br/>want something x the number who want it), not how to convert that wealth into<br/>money.  <br/>  <br/>The companies that win are the ones that put users first. Google, for example.<br/>They made search work, then worried about how to make money from it. And yet<br/>some startup founders still think it's irresponsible not to focus on the<br/>business model from the beginning. They're often encouraged in this by<br/>investors whose experience comes from less malleable industries.  <br/>  <br/>It _is_ irresponsible not to think about business models. It's just ten times<br/>more irresponsible not to think about the product.  <br/>  <br/> **16\. Not Wanting to Get Your Hands Dirty**  <br/>  <br/>Nearly all programmers would rather spend their time writing code and have<br/>someone else handle the messy business of extracting money from it. And not<br/>just the lazy ones. Larry and Sergey apparently felt this way too at first.<br/>After developing their new search algorithm, the first thing they tried was to<br/>get some other company to buy it.  <br/>  <br/>Start a company? Yech. Most hackers would rather just have ideas. But as Larry<br/>and Sergey found, there's not much of a market for ideas. No one trusts an<br/>idea till you embody it in a product and use that to grow a user base. Then<br/>they'll pay big time.  <br/>  <br/>Maybe this will change, but I doubt it will change much. There's nothing like<br/>users for convincing acquirers. It's not just that the risk is decreased. The<br/>acquirers are human, and they have a hard time paying a bunch of young guys<br/>millions of dollars just for being clever. When the idea is embodied in a<br/>company with a lot of users, they can tell themselves they're buying the users<br/>rather than the cleverness, and this is easier for them to swallow. [9]  <br/>  <br/>If you're going to attract users, you'll probably have to get up from your<br/>computer and go find some. It's unpleasant work, but if you can make yourself<br/>do it you have a much greater chance of succeeding. In the first batch of<br/>startups we funded, in the summer of 2005, most of the founders spent all<br/>their time building their applications. But there was one who was away half<br/>the time talking to executives at cell phone companies, trying to arrange<br/>deals. Can you imagine anything more painful for a hacker? [10] But it paid<br/>off, because this startup seems the most successful of that group by an order<br/>of magnitude.  <br/>  <br/>If you want to start a startup, you have to face the fact that you can't just<br/>hack. At least one hacker will have to spend some of the time doing business<br/>stuff.  <br/>  <br/> **17\. Fights Between Founders**  <br/>  <br/>Fights between founders are surprisingly common. About 20% of the startups<br/>we've funded have had a founder leave. It happens so often that we've reversed<br/>our attitude to vesting. We still don't require it, but now we advise founders<br/>to vest so there will be an orderly way for people to quit.  <br/>  <br/>A founder leaving doesn't necessarily kill a startup, though. Plenty of<br/>successful startups have had that happen. [11] Fortunately it's usually the<br/>least committed founder who leaves. If there are three founders and one who<br/>was lukewarm leaves, big deal. If you have two and one leaves, or a guy with<br/>critical technical skills leaves, that's more of a problem. But even that is<br/>survivable. Blogger got down to one person, and they bounced back.  <br/>  <br/>Most of the disputes I've seen between founders could have been avoided if<br/>they'd been more careful about who they started a company with. Most disputes<br/>are not due to the situation but the people. Which means they're inevitable.<br/>And most founders who've been burned by such disputes probably had misgivings,<br/>which they suppressed, when they started the company. Don't suppress<br/>misgivings. It's much easier to fix problems before the company is started<br/>than after. So don't include your housemate in your startup because he'd feel<br/>left out otherwise. Don't start a company with someone you dislike because<br/>they have some skill you need and you worry you won't find anyone else. The<br/>people are the most important ingredient in a startup, so don't compromise<br/>there.  <br/>  <br/> **18\. A Half-Hearted Effort**  <br/>  <br/>The failed startups you hear most about are the spectacular flameouts. Those<br/>are actually the elite of failures. The most common type is not the one that<br/>makes spectacular mistakes, but the one that doesn't do much of anything — the<br/>one we never even hear about, because it was some project a couple guys<br/>started on the side while working on their day jobs, but which never got<br/>anywhere and was gradually abandoned.  <br/>  <br/>Statistically, if you want to avoid failure, it would seem like the most<br/>important thing is to quit your day job. Most founders of failed startups<br/>don't quit their day jobs, and most founders of successful ones do. If startup<br/>failure were a disease, the CDC would be issuing bulletins warning people to<br/>avoid day jobs.  <br/>  <br/>Does that mean you should quit your day job? Not necessarily. I'm guessing<br/>here, but I'd guess that many of these would-be founders may not have the kind<br/>of determination it takes to start a company, and that in the back of their<br/>minds, they know it. The reason they don't invest more time in their startup<br/>is that they know it's a bad investment. [12]  <br/>  <br/>I'd also guess there's some band of people who could have succeeded if they'd<br/>taken the leap and done it full-time, but didn't. I have no idea how wide this<br/>band is, but if the winner/borderline/hopeless progression has the sort of<br/>distribution you'd expect, the number of people who could have made it, if<br/>they'd quit their day job, is probably an order of magnitude larger than the<br/>number who do make it. [13]  <br/>  <br/>If that's true, most startups that could succeed fail because the founders<br/>don't devote their whole efforts to them. That certainly accords with what I<br/>see out in the world. Most startups fail because they don't make something<br/>people want, and the reason most don't is that they don't try hard enough.  <br/>  <br/>In other words, starting startups is just like everything else. The biggest<br/>mistake you can make is not to try hard enough. To the extent there's a secret<br/>to success, it's not to be in denial about that.  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] This is not a complete list of the causes of failure, just those you can<br/>control. There are also several you can't, notably ineptitude and bad luck.  <br/>  <br/>[2] Ironically, one variant of the Facebook that might work is a facebook<br/>exclusively for college students.  <br/>  <br/>[3] Steve Jobs tried to motivate people by saying "Real artists ship." This is<br/>a fine sentence, but unfortunately not true. Many famous works of art are<br/>unfinished. It's true in fields that have hard deadlines, like architecture<br/>and filmmaking, but even there people tend to be tweaking stuff till it's<br/>yanked out of their hands.  <br/>  <br/>[4] There's probably also a second factor: startup founders tend to be at the<br/>leading edge of technology, so problems they face are probably especially<br/>valuable.  <br/>  <br/>[5] You should take more than you think you'll need, maybe 50% to 100% more,<br/>because software takes longer to write and deals longer to close than you<br/>expect.  <br/>  <br/>[6] Since people sometimes call us VCs, I should add that we're not. VCs<br/>invest large amounts of other people's money. We invest small amounts of our<br/>own, like angel investors.  <br/>  <br/>[7] Not linearly of course, or it would take forever to raise five million<br/>dollars. In practice it just feels like it takes forever.  <br/>  <br/>Though if you include the cases where VCs don't invest, it would literally<br/>take forever in the median case. And maybe we should, because the danger of<br/>chasing large investments is not just that they take a long time. That's the<br/>_best_ case. The real danger is that you'll expend a lot of time and get<br/>nothing.  <br/>  <br/>[8] Some VCs will offer you an artificially low valuation to see if you have<br/>the balls to ask for more. It's lame that VCs play such games, but some do. If<br/>you're dealing with one of those you should push back on the valuation a bit.  <br/>  <br/>[9] Suppose YouTube's founders had gone to Google in 2005 and told them<br/>"Google Video is badly designed. Give us $10 million and we'll tell you all<br/>the mistakes you made." They would have gotten the royal raspberry. Eighteen<br/>months later Google paid $1.6 billion for the same lesson, partly because they<br/>could then tell themselves that they were buying a phenomenon, or a community,<br/>or some vague thing like that.  <br/>  <br/>I don't mean to be hard on Google. They did better than their competitors, who<br/>may have now missed the video boat entirely.  <br/>  <br/>[10] Yes, actually: dealing with the government. But phone companies are up<br/>there.  <br/>  <br/>[11] Many more than most people realize, because companies don't advertise<br/>this. Did you know Apple originally had three founders?  <br/>  <br/>[12] I'm not dissing these people. I don't have the determination myself. I've<br/>twice come close to starting startups since Viaweb, and both times I bailed<br/>because I realized that without the spur of poverty I just wasn't willing to<br/>endure the stress of a startup.  <br/>  <br/>[13] So how do you know whether you're in the category of people who should<br/>quit their day job, or the presumably larger one who shouldn't? I got to the<br/>point of saying that this was hard to judge for yourself and that you should<br/>seek outside advice, before realizing that that's what we do. We think of<br/>ourselves as investors, but viewed from the other direction Y Combinator is a<br/>service for advising people whether or not to quit their day job. We could be<br/>mistaken, and no doubt often are, but we do at least bet money on our<br/>conclusions.  <br/>  <br/> **Thanks** to Sam Altman, Jessica Livingston, Greg McAdoo, and Robert Morris<br/>for reading drafts of this.  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>Romanian Translation  <br/>  <br/><br/>Chinese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>September 2007  <br/>  <br/>A few weeks ago I had a thought so heretical that it really surprised me. It<br/>may not matter all that much where you go to college.  <br/>  <br/>For me, as for a lot of middle class kids, getting into a good college was<br/>more or less the meaning of life when I was growing up. What was I? A student.<br/>To do that well meant to get good grades. Why did one have to get good grades?<br/>To get into a good college. And why did one want to do that? There seemed to<br/>be several reasons: you'd learn more, get better jobs, make more money. But it<br/>didn't matter exactly what the benefits would be. College was a bottleneck<br/>through which all your future prospects passed; everything would be better if<br/>you went to a better college.  <br/>  <br/>A few weeks ago I realized that somewhere along the line I had stopped<br/>believing that.  <br/>  <br/>What first set me thinking about this was the new trend of worrying<br/>obsessively about what kindergarten your kids go to. It seemed to me this<br/>couldn't possibly matter. Either it won't help your kid get into Harvard, or<br/>if it does, getting into Harvard won't mean much anymore. And then I thought:<br/>how much does it mean even now?  <br/>  <br/>It turns out I have a lot of data about that. My three partners and I run a<br/>seed stage investment firm called Y Combinator. We invest when the company is<br/>just a couple guys and an idea. The idea doesn't matter much; it will change<br/>anyway. Most of our decision is based on the founders. The average founder is<br/>three years out of college. Many have just graduated; a few are still in<br/>school. So we're in much the same position as a graduate program, or a company<br/>hiring people right out of college. Except our choices are immediately and<br/>visibly tested. There are two possible outcomes for a startup: success or<br/>failure—and usually you know within a year which it will be.  <br/>  <br/>The test applied to a startup is among the purest of real world tests. A<br/>startup succeeds or fails depending almost entirely on the efforts of the<br/>founders. Success is decided by the market: you only succeed if users like<br/>what you've built. And users don't care where you went to college.  <br/>  <br/>As well as having precisely measurable results, we have a lot of them. Instead<br/>of doing a small number of large deals like a traditional venture capital<br/>fund, we do a large number of small ones. We currently fund about 40 companies<br/>a year, selected from about 900 applications representing a total of about<br/>2000 people. [1]  <br/>  <br/>Between the volume of people we judge and the rapid, unequivocal test that's<br/>applied to our choices, Y Combinator has been an unprecedented opportunity for<br/>learning how to pick winners. One of the most surprising things we've learned<br/>is how little it matters where people went to college.  <br/>  <br/>I thought I'd already been cured of caring about that. There's nothing like<br/>going to grad school at Harvard to cure you of any illusions you might have<br/>about the average Harvard undergrad. And yet Y Combinator showed us we were<br/>still overestimating people who'd been to elite colleges. We'd interview<br/>people from MIT or Harvard or Stanford and sometimes find ourselves thinking:<br/>they _must_ be smarter than they seem. It took us a few iterations to learn to<br/>trust our senses.  <br/>  <br/>Practically everyone thinks that someone who went to MIT or Harvard or<br/>Stanford must be smart. Even people who hate you for it believe it.  <br/>  <br/>But when you think about what it means to have gone to an elite college, how<br/>could this be true? We're talking about a decision made by admissions<br/>officers—basically, HR people—based on a cursory examination of a huge pile of<br/>depressingly similar applications submitted by seventeen year olds. And what<br/>do they have to go on? An easily gamed standardized test; a short essay<br/>telling you what the kid thinks you want to hear; an interview with a random<br/>alum; a high school record that's largely an index of obedience. Who would<br/>rely on such a test?  <br/>  <br/>And yet a lot of companies do. A lot of companies are very much influenced by<br/>where applicants went to college. How could they be? I think I know the answer<br/>to that.  <br/>  <br/>There used to be a saying in the corporate world: "No one ever got fired for<br/>buying IBM." You no longer hear this about IBM specifically, but the idea is<br/>very much alive; there is a whole category of "enterprise" software companies<br/>that exist to take advantage of it. People buying technology for large<br/>organizations don't care if they pay a fortune for mediocre software. It's not<br/>their money. They just want to buy from a supplier who seems safe—a company<br/>with an established name, confident salesmen, impressive offices, and software<br/>that conforms to all the current fashions. Not necessarily a company that will<br/>deliver so much as one that, if they do let you down, will still seem to have<br/>been a prudent choice. So companies have evolved to fill that niche.  <br/>  <br/>A recruiter at a big company is in much the same position as someone buying<br/>technology for one. If someone went to Stanford and is not obviously insane,<br/>they're probably a safe bet. And a safe bet is enough. No one ever measures<br/>recruiters by the later performance of people they turn down. [2]  <br/>  <br/>I'm not saying, of course, that elite colleges have evolved to prey upon the<br/>weaknesses of large organizations the way enterprise software companies have.<br/>But they work as if they had. In addition to the power of the brand name,<br/>graduates of elite colleges have two critical qualities that plug right into<br/>the way large organizations work. They're good at doing what they're asked,<br/>since that's what it takes to please the adults who judge you at seventeen.<br/>And having been to an elite college makes them more confident.  <br/>  <br/>Back in the days when people might spend their whole career at one big<br/>company, these qualities must have been very valuable. Graduates of elite<br/>colleges would have been capable, yet amenable to authority. And since<br/>individual performance is so hard to measure in large organizations, their own<br/>confidence would have been the starting point for their reputation.  <br/>  <br/>Things are very different in the new world of startups. We couldn't save<br/>someone from the market's judgement even if we wanted to. And being charming<br/>and confident counts for nothing with users. All users care about is whether<br/>you make something they like. If you don't, you're dead.  <br/>  <br/>Knowing that test is coming makes us work a lot harder to get the right<br/>answers than anyone would if they were merely hiring people. We can't afford<br/>to have any illusions about the predictors of success. And what we've found is<br/>that the variation between schools is so much smaller than the variation<br/>between individuals that it's negligible by comparison. We can learn more<br/>about someone in the first minute of talking to them than by knowing where<br/>they went to school.  <br/>  <br/>It seems obvious when you put it that way. Look at the individual, not where<br/>they went to college. But that's a weaker statement than the idea I began<br/>with, that it doesn't matter much where a given individual goes to college.<br/>Don't you learn things at the best schools that you wouldn't learn at lesser<br/>places?  <br/>  <br/>Apparently not. Obviously you can't prove this in the case of a single<br/>individual, but you can tell from aggregate evidence: you can't, without<br/>asking them, distinguish people who went to one school from those who went to<br/>another three times as far down the _US News_ list. [3] Try it and see.  <br/>  <br/>How can this be? Because how much you learn in college depends a lot more on<br/>you than the college. A determined party animal can get through the best<br/>school without learning anything. And someone with a real thirst for knowledge<br/>will be able to find a few smart people to learn from at a school that isn't<br/>prestigious at all.  <br/>  <br/>The other students are the biggest advantage of going to an elite college; you<br/>learn more from them than the professors. But you should be able to reproduce<br/>this at most colleges if you make a conscious effort to find smart friends. At<br/>most colleges you can find at least a handful of other smart students, and<br/>most people have only a handful of close friends in college anyway. [4] The<br/>odds of finding smart professors are even better. The curve for faculty is a<br/>lot flatter than for students, especially in math and the hard sciences; you<br/>have to go pretty far down the list of colleges before you stop finding smart<br/>professors in the math department.  <br/>  <br/>So it's not surprising that we've found the relative prestige of different<br/>colleges useless in judging individuals. There's a lot of randomness in how<br/>colleges select people, and what they learn there depends much more on them<br/>than the college. Between these two sources of variation, the college someone<br/>went to doesn't mean a lot. It is to some degree a predictor of ability, but<br/>so weak that we regard it mainly as a source of error and try consciously to<br/>ignore it.  <br/>  <br/>I doubt what we've discovered is an anomaly specific to startups. Probably<br/>people have always overestimated the importance of where one goes to college.<br/>We're just finally able to measure it.  <br/>  <br/>The unfortunate thing is not just that people are judged by such a superficial<br/>test, but that so many judge themselves by it. A lot of people, probably the<br/>majority of people in America, have some amount of insecurity about where, or<br/>whether, they went to college. The tragedy of the situation is that by far the<br/>greatest liability of not having gone to the college you'd have liked is your<br/>own feeling that you're thereby lacking something. Colleges are a bit like<br/>exclusive clubs in this respect. There is only one real advantage to being a<br/>member of most exclusive clubs: you know you wouldn't be missing much if you<br/>weren't. When you're excluded, you can only imagine the advantages of being an<br/>insider. But invariably they're larger in your imagination than in real life.  <br/>  <br/>So it is with colleges. Colleges differ, but they're nothing like the stamp of<br/>destiny so many imagine them to be. People aren't what some admissions officer<br/>decides about them at seventeen. They're what they make themselves.  <br/>  <br/>Indeed, the great advantage of not caring where people went to college is not<br/>just that you can stop judging them (and yourself) by superficial measures,<br/>but that you can focus instead on what really matters. What matters is what<br/>you make of yourself. I think that's what we should tell kids. Their job isn't<br/>to get good grades so they can get into a good college, but to learn and do.<br/>And not just because that's more rewarding than worldly success. That will<br/>increasingly _be_ the route to worldly success.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] Is what we measure worth measuring? I think so. You can get rich simply by<br/>being energetic and unscrupulous, but getting rich from a technology startup<br/>takes some amount of brains. It is just the kind of work the upper middle<br/>class values; it has about the same intellectual component as being a doctor.  <br/>  <br/>[2] Actually, someone did, once. Mitch Kapor's wife Freada was in charge of HR<br/>at Lotus in the early years. (As he is at pains to point out, they did not<br/>become romantically involved till afterward.) At one point they worried Lotus<br/>was losing its startup edge and turning into a big company. So as an<br/>experiment she sent their recruiters the resumes of the first 40 employees,<br/>with identifying details changed. These were the people who had made Lotus<br/>into the star it was. Not one got an interview.  <br/>  <br/>[3] The _US News_ list? Surely no one trusts that. Even if the statistics they<br/>consider are useful, how do they decide on the relative weights? The reason<br/>the _US News_ list is meaningful is precisely because they are so<br/>intellectually dishonest in that respect. There is no external source they can<br/>use to calibrate the weighting of the statistics they use; if there were, we<br/>could just use that instead. What they must do is adjust the weights till the<br/>top schools are the usual suspects in about the right order. So in effect what<br/>the _US News_ list tells us is what the editors think the top schools are,<br/>which is probably not far from the conventional wisdom on the matter. The<br/>amusing thing is, because some schools work hard to game the system, the<br/>editors will have to keep tweaking their algorithm to get the rankings they<br/>want.  <br/>  <br/>[4] Possible doesn't mean easy, of course. A smart student at a party school<br/>will inevitably be something of an outcast, just as he or she would be in most<br/>high schools.  <br/>  <br/>**Thanks** to Trevor Blackwell, Sarah Harlin, Jessica Livingston, Jackie<br/>McDonough, Peter Norvig, and Robert Morris for reading drafts of this.  <br/>  <br/><br/>French Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>January 2012  <br/>  <br/>A few hours before the Yahoo acquisition was announced in June 1998 I took a<br/>snapshot of Viaweb's site. I thought it might be interesting to look at one<br/>day.  <br/>  <br/>The first thing one notices is is how tiny the pages are. Screens were a lot<br/>smaller in 1998. If I remember correctly, our frontpage used to just fit in<br/>the size window people typically used then.  <br/>  <br/>Browsers then (IE 6 was still 3 years in the future) had few fonts and they<br/>weren't antialiased. If you wanted to make pages that looked good, you had to<br/>render display text as images.  <br/>  <br/>You may notice a certain similarity between the Viaweb and Y Combinator logos.<br/>We did that as an inside joke when we started YC. Considering how basic a red<br/>circle is, it seemed surprising to me when we started Viaweb how few other<br/>companies used one as their logo. A bit later I realized why.  <br/>  <br/>On the Company page you'll notice a mysterious individual called John<br/>McArtyem. Robert Morris (aka Rtm) was so publicity averse after the Worm that<br/>he didn't want his name on the site. I managed to get him to agree to a<br/>compromise: we could use his bio but not his name. He has since relaxed a bit<br/>on that point.  <br/>  <br/>Trevor graduated at about the same time the acquisition closed, so in the<br/>course of 4 days he went from impecunious grad student to millionaire PhD. The<br/>culmination of my career as a writer of press releases was one celebrating his<br/>graduation, illustrated with a drawing I did of him during a meeting.  <br/>  <br/>(Trevor also appears as Trevino Bagwell in our directory of web designers<br/>merchants could hire to build stores for them. We inserted him as a ringer in<br/>case some competitor tried to spam our web designers. We assumed his logo<br/>would deter any actual customers, but it did not.)  <br/>  <br/>Back in the 90s, to get users you had to get mentioned in magazines and<br/>newspapers. There were not the same ways to get found online that there are<br/>today. So we used to pay a PR firm $16,000 a month to get us mentioned in the<br/>press. Fortunately reporters liked us.  <br/>  <br/>In our advice about getting traffic from search engines (I don't think the<br/>term SEO had been coined yet), we say there are only 7 that matter: Yahoo,<br/>AltaVista, Excite, WebCrawler, InfoSeek, Lycos, and HotBot. Notice anything<br/>missing? Google was incorporated that September.  <br/>  <br/>We supported online transactions via a company called Cybercash, since if we<br/>lacked that feature we'd have gotten beaten up in product comparisons. But<br/>Cybercash was so bad and most stores' order volumes were so low that it was<br/>better if merchants processed orders like phone orders. We had a page in our<br/>site trying to talk merchants out of doing real time authorizations.  <br/>  <br/>The whole site was organized like a funnel, directing people to the test<br/>drive. It was a novel thing to be able to try out software online. We put cgi-<br/>bin in our dynamic urls to fool competitors about how our software worked.  <br/>  <br/>We had some well known users. Needless to say, Frederick's of Hollywood got<br/>the most traffic. We charged a flat fee of $300/month for big stores, so it<br/>was a little alarming to have users who got lots of traffic. I once calculated<br/>how much Frederick's was costing us in bandwidth, and it was about $300/month.  <br/>  <br/>Since we hosted all the stores, which together were getting just over 10<br/>million page views per month in June 1998, we consumed what at the time seemed<br/>a lot of bandwidth. We had 2 T1s (3 Mb/sec) coming into our offices. In those<br/>days there was no AWS. Even colocating servers seemed too risky, considering<br/>how often things went wrong with them. So we had our servers in our offices.<br/>Or more precisely, in Trevor's office. In return for the unique privilege of<br/>sharing his office with no other humans, he had to share it with 6 shrieking<br/>tower servers. His office was nicknamed the Hot Tub on account of the heat<br/>they generated. Most days his stack of window air conditioners could keep up.  <br/>  <br/>For describing pages, we had a template language called RTML, which supposedly<br/>stood for something, but which in fact I named after Rtm. RTML was Common Lisp<br/>augmented by some macros and libraries, and concealed under a structure editor<br/>that made it look like it had syntax.  <br/>  <br/>Since we did continuous releases, our software didn't actually have versions.<br/>But in those days the trade press expected versions, so we made them up. If we<br/>wanted to get lots of attention, we made the version number an integer. That<br/>"version 4.0" icon was generated by our own button generator, incidentally.<br/>The whole Viaweb site was made with our software, even though it wasn't an<br/>online store, because we wanted to experience what our users did.  <br/>  <br/>At the end of 1997, we released a general purpose shopping search engine<br/>called Shopfind. It was pretty advanced for the time. It had a programmable<br/>crawler that could crawl most of the different stores online and pick out the<br/>products.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>September 2010  <br/>  <br/>The reason startups have been using more convertible notes in angel rounds is<br/>that they make deals close faster. By making it easier for startups to give<br/>different prices to different investors, they help them break the sort of<br/>deadlock that happens when investors all wait to see who else is going to<br/>invest.  <br/>  <br/>By far the biggest influence on investors' opinions of a startup is the<br/>opinion of other investors. There are very, very few who simply decide for<br/>themselves. Any startup founder can tell you the most common question they<br/>hear from investors is not about the founders or the product, but "who else is<br/>investing?"  <br/>  <br/>That tends to produce deadlocks. Raising an old-fashioned fixed-size equity<br/>round can take weeks, because all the angels sit around waiting for the others<br/>to commit, like competitors in a bicycle sprint who deliberately ride slowly<br/>at the start so they can follow whoever breaks first.  <br/>  <br/>Convertible notes let startups beat such deadlocks by rewarding investors<br/>willing to move first with lower (effective) valuations. Which they deserve<br/>because they're taking more risk. It's much safer to invest in a startup Ron<br/>Conway has already invested in; someone who comes after him should pay a<br/>higher price.  <br/>  <br/>The reason convertible notes allow more flexibility in price is that valuation<br/>caps aren't actual valuations, and notes are cheap and easy to do. So you can<br/>do high-resolution fundraising: if you wanted you could have a separate note<br/>with a different cap for each investor.  <br/>  <br/>That cap need not simply rise monotonically. A startup could also give better<br/>deals to investors they expected to help them most. The point is simply that<br/>different investors, whether because of the help they offer or their<br/>willingness to commit, have different values for startups, and their terms<br/>should reflect that.  <br/>  <br/>Different terms for different investors is clearly the way of the future.<br/>Markets always evolve toward higher resolution. You may not need to use<br/>convertible notes to do it. With sufficiently lightweight standardized equity<br/>terms (and some changes in investors' and lawyers' expectations about equity<br/>rounds) you might be able to do the same thing with equity instead of debt.<br/>Either would be fine with startups, so long as they can easily change their<br/>valuation.  <br/>  <br/>Deadlocks weren't the only problem with fixed-size equity rounds. Another was<br/>that startups had to decide in advance how much to raise. I think it's a<br/>mistake for a startup to fix upon a specific number. If investors are easily<br/>convinced, the startup should raise more now, and if investors are skeptical,<br/>the startup should take a smaller amount and use that to get the company to<br/>the point where it's more convincing.  <br/>  <br/>It's just not reasonable to expect startups to pick an optimal round size in<br/>advance, because that depends on the reactions of investors, and those are<br/>impossible to predict.  <br/>  <br/>Fixed-size, multi-investor angel rounds are such a bad idea for startups that<br/>one wonders why things were ever done that way. One possibility is that this<br/>custom reflects the way investors like to collude when they can get away with<br/>it. But I think the actual explanation is less sinister. I think angels (and<br/>their lawyers) organized rounds this way in unthinking imitation of VC series<br/>A rounds. In a series A, a fixed-size equity round with a lead makes sense,<br/>because there is usually just one big investor, who is unequivocally the lead.<br/>Fixed-size series A rounds already are high res. But the more investors you<br/>have in a round, the less sense it makes for everyone to get the same price.  <br/>  <br/>The most interesting question here may be what high res fundraising will do to<br/>the world of investors. Bolder investors will now get rewarded with lower<br/>prices. But more important, in a hits-driven business, is that they'll be able<br/>to get into the deals they want. Whereas the "who else is investing?" type of<br/>investors will not only pay higher prices, but may not be able to get into the<br/>best deals at all.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Thanks** to Immad Akhund, Sam Altman, John Bautista, Pete Koomen, Jessica<br/>Livingston, Dan Siroker, Harj Taggar, and Fred Wilson for reading drafts of<br/>this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>May 2001  <br/>  <br/> _(This article was written as a kind of business plan for anew language. So<br/>it is missing (because it takes for granted) the most important feature of a<br/>good programming language: very powerful abstractions.)_  <br/>  <br/>A friend of mine once told an eminent operating systems expert that he wanted<br/>to design a really good programming language. The expert told him that it<br/>would be a waste of time, that programming languages don't become popular or<br/>unpopular based on their merits, and so no matter how good his language was,<br/>no one would use it. At least, that was what had happened to the language _he_<br/>had designed.  <br/>  <br/>What does make a language popular? Do popular languages deserve their<br/>popularity? Is it worth trying to define a good programming language? How<br/>would you do it?  <br/>  <br/>I think the answers to these questions can be found by looking at hackers, and<br/>learning what they want. Programming languages are _for_ hackers, and a<br/>programming language is good as a programming language (rather than, say, an<br/>exercise in denotational semantics or compiler design) if and only if hackers<br/>like it.  <br/>  <br/> **1 The Mechanics of Popularity**  <br/>  <br/>It's true, certainly, that most people don't choose programming languages<br/>simply based on their merits. Most programmers are told what language to use<br/>by someone else. And yet I think the effect of such external factors on the<br/>popularity of programming languages is not as great as it's sometimes thought<br/>to be. I think a bigger problem is that a hacker's idea of a good programming<br/>language is not the same as most language designers'.  <br/>  <br/>Between the two, the hacker's opinion is the one that matters. Programming<br/>languages are not theorems. They're tools, designed for people, and they have<br/>to be designed to suit human strengths and weaknesses as much as shoes have to<br/>be designed for human feet. If a shoe pinches when you put it on, it's a bad<br/>shoe, however elegant it may be as a piece of sculpture.  <br/>  <br/>It may be that the majority of programmers can't tell a good language from a<br/>bad one. But that's no different with any other tool. It doesn't mean that<br/>it's a waste of time to try designing a good language. Expert hackers can tell<br/>a good language when they see one, and they'll use it. Expert hackers are a<br/>tiny minority, admittedly, but that tiny minority write all the good software,<br/>and their influence is such that the rest of the programmers will tend to use<br/>whatever language they use. Often, indeed, it is not merely influence but<br/>command: often the expert hackers are the very people who, as their bosses or<br/>faculty advisors, tell the other programmers what language to use.  <br/>  <br/>The opinion of expert hackers is not the only force that determines the<br/>relative popularity of programming languages — legacy software (Cobol) and<br/>hype (Ada, Java) also play a role — but I think it is the most powerful force<br/>over the long term. Given an initial critical mass and enough time, a<br/>programming language probably becomes about as popular as it deserves to be.<br/>And popularity further separates good languages from bad ones, because<br/>feedback from real live users always leads to improvements. Look at how much<br/>any popular language has changed during its life. Perl and Fortran are extreme<br/>cases, but even Lisp has changed a lot. Lisp 1.5 didn't have macros, for<br/>example; these evolved later, after hackers at MIT had spent a couple years<br/>using Lisp to write real programs. [1]  <br/>  <br/>So whether or not a language has to be good to be popular, I think a language<br/>has to be popular to be good. And it has to stay popular to stay good. The<br/>state of the art in programming languages doesn't stand still. And yet the<br/>Lisps we have today are still pretty much what they had at MIT in the<br/>mid-1980s, because that's the last time Lisp had a sufficiently large and<br/>demanding user base.  <br/>  <br/>Of course, hackers have to know about a language before they can use it. How<br/>are they to hear? From other hackers. But there has to be some initial group<br/>of hackers using the language for others even to hear about it. I wonder how<br/>large this group has to be; how many users make a critical mass? Off the top<br/>of my head, I'd say twenty. If a language had twenty separate users, meaning<br/>twenty users who decided on their own to use it, I'd consider it to be real.  <br/>  <br/>Getting there can't be easy. I would not be surprised if it is harder to get<br/>from zero to twenty than from twenty to a thousand. The best way to get those<br/>initial twenty users is probably to use a trojan horse: to give people an<br/>application they want, which happens to be written in the new language.  <br/>  <br/> **2 External Factors**  <br/>  <br/>Let's start by acknowledging one external factor that does affect the<br/>popularity of a programming language. To become popular, a programming<br/>language has to be the scripting language of a popular system. Fortran and<br/>Cobol were the scripting languages of early IBM mainframes. C was the<br/>scripting language of Unix, and so, later, was Perl. Tcl is the scripting<br/>language of Tk. Java and Javascript are intended to be the scripting languages<br/>of web browsers.  <br/>  <br/>Lisp is not a massively popular language because it is not the scripting<br/>language of a massively popular system. What popularity it retains dates back<br/>to the 1960s and 1970s, when it was the scripting language of MIT. A lot of<br/>the great programmers of the day were associated with MIT at some point. And<br/>in the early 1970s, before C, MIT's dialect of Lisp, called MacLisp, was one<br/>of the only programming languages a serious hacker would want to use.  <br/>  <br/>Today Lisp is the scripting language of two moderately popular systems, Emacs<br/>and Autocad, and for that reason I suspect that most of the Lisp programming<br/>done today is done in Emacs Lisp or AutoLisp.  <br/>  <br/>Programming languages don't exist in isolation. To hack is a transitive verb —<br/>hackers are usually hacking something — and in practice languages are judged<br/>relative to whatever they're used to hack. So if you want to design a popular<br/>language, you either have to supply more than a language, or you have to<br/>design your language to replace the scripting language of some existing<br/>system.  <br/>  <br/>Common Lisp is unpopular partly because it's an orphan. It did originally come<br/>with a system to hack: the Lisp Machine. But Lisp Machines (along with<br/>parallel computers) were steamrollered by the increasing power of general<br/>purpose processors in the 1980s. Common Lisp might have remained popular if it<br/>had been a good scripting language for Unix. It is, alas, an atrociously bad<br/>one.  <br/>  <br/>One way to describe this situation is to say that a language isn't judged on<br/>its own merits. Another view is that a programming language really isn't a<br/>programming language unless it's also the scripting language of something.<br/>This only seems unfair if it comes as a surprise. I think it's no more unfair<br/>than expecting a programming language to have, say, an implementation. It's<br/>just part of what a programming language is.  <br/>  <br/>A programming language does need a good implementation, of course, and this<br/>must be free. Companies will pay for software, but individual hackers won't,<br/>and it's the hackers you need to attract.  <br/>  <br/>A language also needs to have a book about it. The book should be thin, well-<br/>written, and full of good examples. K&R is the ideal here. At the moment I'd<br/>almost say that a language has to have a book published by O'Reilly. That's<br/>becoming the test of mattering to hackers.  <br/>  <br/>There should be online documentation as well. In fact, the book can start as<br/>online documentation. But I don't think that physical books are outmoded yet.<br/>Their format is convenient, and the de facto censorship imposed by publishers<br/>is a useful if imperfect filter. Bookstores are one of the most important<br/>places for learning about new languages.  <br/>  <br/> **3 Brevity**  <br/>  <br/>Given that you can supply the three things any language needs — a free<br/>implementation, a book, and something to hack — how do you make a language<br/>that hackers will like?  <br/>  <br/>One thing hackers like is brevity. Hackers are lazy, in the same way that<br/>mathematicians and modernist architects are lazy: they hate anything<br/>extraneous. It would not be far from the truth to say that a hacker about to<br/>write a program decides what language to use, at least subconsciously, based<br/>on the total number of characters he'll have to type. If this isn't precisely<br/>how hackers think, a language designer would do well to act as if it were.  <br/>  <br/>It is a mistake to try to baby the user with long-winded expressions that are<br/>meant to resemble English. Cobol is notorious for this flaw. A hacker would<br/>consider being asked to write  <br/>  <br/>add x to y giving z  <br/>  <br/>instead of  <br/>  <br/>z = x+y  <br/>  <br/>as something between an insult to his intelligence and a sin against God.  <br/>  <br/>It has sometimes been said that Lisp should use first and rest instead of car<br/>and cdr, because it would make programs easier to read. Maybe for the first<br/>couple hours. But a hacker can learn quickly enough that car means the first<br/>element of a list and cdr means the rest. Using first and rest means 50% more<br/>typing. And they are also different lengths, meaning that the arguments won't<br/>line up when they're called, as car and cdr often are, in successive lines.<br/>I've found that it matters a lot how code lines up on the page. I can barely<br/>read Lisp code when it is set in a variable-width font, and friends say this<br/>is true for other languages too.  <br/>  <br/>Brevity is one place where strongly typed languages lose. All other things<br/>being equal, no one wants to begin a program with a bunch of declarations.<br/>Anything that can be implicit, should be.  <br/>  <br/>The individual tokens should be short as well. Perl and Common Lisp occupy<br/>opposite poles on this question. Perl programs can be almost cryptically<br/>dense, while the names of built-in Common Lisp operators are comically long.<br/>The designers of Common Lisp probably expected users to have text editors that<br/>would type these long names for them. But the cost of a long name is not just<br/>the cost of typing it. There is also the cost of reading it, and the cost of<br/>the space it takes up on your screen.  <br/>  <br/> **4 Hackability**  <br/>  <br/>There is one thing more important than brevity to a hacker: being able to do<br/>what you want. In the history of programming languages a surprising amount of<br/>effort has gone into preventing programmers from doing things considered to be<br/>improper. This is a dangerously presumptuous plan. How can the language<br/>designer know what the programmer is going to need to do? I think language<br/>designers would do better to consider their target user to be a genius who<br/>will need to do things they never anticipated, rather than a bumbler who needs<br/>to be protected from himself. The bumbler will shoot himself in the foot<br/>anyway. You may save him from referring to variables in another package, but<br/>you can't save him from writing a badly designed program to solve the wrong<br/>problem, and taking forever to do it.  <br/>  <br/>Good programmers often want to do dangerous and unsavory things. By unsavory I<br/>mean things that go behind whatever semantic facade the language is trying to<br/>present: getting hold of the internal representation of some high-level<br/>abstraction, for example. Hackers like to hack, and hacking means getting<br/>inside things and second guessing the original designer.  <br/>  <br/> _Let yourself be second guessed._ When you make any tool, people use it in<br/>ways you didn't intend, and this is especially true of a highly articulated<br/>tool like a programming language. Many a hacker will want to tweak your<br/>semantic model in a way that you never imagined. I say, let them; give the<br/>programmer access to as much internal stuff as you can without endangering<br/>runtime systems like the garbage collector.  <br/>  <br/>In Common Lisp I have often wanted to iterate through the fields of a struct —<br/>to comb out references to a deleted object, for example, or find fields that<br/>are uninitialized. I know the structs are just vectors underneath. And yet I<br/>can't write a general purpose function that I can call on any struct. I can<br/>only access the fields by name, because that's what a struct is supposed to<br/>mean.  <br/>  <br/>A hacker may only want to subvert the intended model of things once or twice<br/>in a big program. But what a difference it makes to be able to. And it may be<br/>more than a question of just solving a problem. There is a kind of pleasure<br/>here too. Hackers share the surgeon's secret pleasure in poking about in gross<br/>innards, the teenager's secret pleasure in popping zits. [2] For boys, at<br/>least, certain kinds of horrors are fascinating. Maxim magazine publishes an<br/>annual volume of photographs, containing a mix of pin-ups and grisly<br/>accidents. They know their audience.  <br/>  <br/>Historically, Lisp has been good at letting hackers have their way. The<br/>political correctness of Common Lisp is an aberration. Early Lisps let you get<br/>your hands on everything. A good deal of that spirit is, fortunately,<br/>preserved in macros. What a wonderful thing, to be able to make arbitrary<br/>transformations on the source code.  <br/>  <br/>Classic macros are a real hacker's tool — simple, powerful, and dangerous.<br/>It's so easy to understand what they do: you call a function on the macro's<br/>arguments, and whatever it returns gets inserted in place of the macro call.<br/>Hygienic macros embody the opposite principle. They try to protect you from<br/>understanding what they're doing. I have never heard hygienic macros explained<br/>in one sentence. And they are a classic example of the dangers of deciding<br/>what programmers are allowed to want. Hygienic macros are intended to protect<br/>me from variable capture, among other things, but variable capture is exactly<br/>what I want in some macros.  <br/>  <br/>A really good language should be both clean and dirty: cleanly designed, with<br/>a small core of well understood and highly orthogonal operators, but dirty in<br/>the sense that it lets hackers have their way with it. C is like this. So were<br/>the early Lisps. A real hacker's language will always have a slightly raffish<br/>character.  <br/>  <br/>A good programming language should have features that make the kind of people<br/>who use the phrase "software engineering" shake their heads disapprovingly. At<br/>the other end of the continuum are languages like Ada and Pascal, models of<br/>propriety that are good for teaching and not much else.  <br/>  <br/> **5 Throwaway Programs**  <br/>  <br/>To be attractive to hackers, a language must be good for writing the kinds of<br/>programs they want to write. And that means, perhaps surprisingly, that it has<br/>to be good for writing throwaway programs.  <br/>  <br/>A throwaway program is a program you write quickly for some limited task: a<br/>program to automate some system administration task, or generate test data for<br/>a simulation, or convert data from one format to another. The surprising thing<br/>about throwaway programs is that, like the "temporary" buildings built at so<br/>many American universities during World War II, they often don't get thrown<br/>away. Many evolve into real programs, with real features and real users.  <br/>  <br/>I have a hunch that the best big programs begin life this way, rather than<br/>being designed big from the start, like the Hoover Dam. It's terrifying to<br/>build something big from scratch. When people take on a project that's too<br/>big, they become overwhelmed. The project either gets bogged down, or the<br/>result is sterile and wooden: a shopping mall rather than a real downtown,<br/>Brasilia rather than Rome, Ada rather than C.  <br/>  <br/>Another way to get a big program is to start with a throwaway program and keep<br/>improving it. This approach is less daunting, and the design of the program<br/>benefits from evolution. I think, if one looked, that this would turn out to<br/>be the way most big programs were developed. And those that did evolve this<br/>way are probably still written in whatever language they were first written<br/>in, because it's rare for a program to be ported, except for political<br/>reasons. And so, paradoxically, if you want to make a language that is used<br/>for big systems, you have to make it good for writing throwaway programs,<br/>because that's where big systems come from.  <br/>  <br/>Perl is a striking example of this idea. It was not only designed for writing<br/>throwaway programs, but was pretty much a throwaway program itself. Perl began<br/>life as a collection of utilities for generating reports, and only evolved<br/>into a programming language as the throwaway programs people wrote in it grew<br/>larger. It was not until Perl 5 (if then) that the language was suitable for<br/>writing serious programs, and yet it was already massively popular.  <br/>  <br/>What makes a language good for throwaway programs? To start with, it must be<br/>readily available. A throwaway program is something that you expect to write<br/>in an hour. So the language probably must already be installed on the computer<br/>you're using. It can't be something you have to install before you use it. It<br/>has to be there. C was there because it came with the operating system. Perl<br/>was there because it was originally a tool for system administrators, and<br/>yours had already installed it.  <br/>  <br/>Being available means more than being installed, though. An interactive<br/>language, with a command-line interface, is more available than one that you<br/>have to compile and run separately. A popular programming language should be<br/>interactive, and start up fast.  <br/>  <br/>Another thing you want in a throwaway program is brevity. Brevity is always<br/>attractive to hackers, and never more so than in a program they expect to turn<br/>out in an hour.  <br/>  <br/> **6 Libraries**  <br/>  <br/>Of course the ultimate in brevity is to have the program already written for<br/>you, and merely to call it. And this brings us to what I think will be an<br/>increasingly important feature of programming languages: library functions.<br/>Perl wins because it has large libraries for manipulating strings. This class<br/>of library functions are especially important for throwaway programs, which<br/>are often originally written for converting or extracting data. Many Perl<br/>programs probably begin as just a couple library calls stuck together.  <br/>  <br/>I think a lot of the advances that happen in programming languages in the next<br/>fifty years will have to do with library functions. I think future programming<br/>languages will have libraries that are as carefully designed as the core<br/>language. Programming language design will not be about whether to make your<br/>language strongly or weakly typed, or object oriented, or functional, or<br/>whatever, but about how to design great libraries. The kind of language<br/>designers who like to think about how to design type systems may shudder at<br/>this. It's almost like writing applications! Too bad. Languages are for<br/>programmers, and libraries are what programmers need.  <br/>  <br/>It's hard to design good libraries. It's not simply a matter of writing a lot<br/>of code. Once the libraries get too big, it can sometimes take longer to find<br/>the function you need than to write the code yourself. Libraries need to be<br/>designed using a small set of orthogonal operators, just like the core<br/>language. It ought to be possible for the programmer to guess what library<br/>call will do what he needs.  <br/>  <br/>Libraries are one place Common Lisp falls short. There are only rudimentary<br/>libraries for manipulating strings, and almost none for talking to the<br/>operating system. For historical reasons, Common Lisp tries to pretend that<br/>the OS doesn't exist. And because you can't talk to the OS, you're unlikely to<br/>be able to write a serious program using only the built-in operators in Common<br/>Lisp. You have to use some implementation-specific hacks as well, and in<br/>practice these tend not to give you everything you want. Hackers would think a<br/>lot more highly of Lisp if Common Lisp had powerful string libraries and good<br/>OS support.  <br/>  <br/> **7 Syntax**  <br/>  <br/>Could a language with Lisp's syntax, or more precisely, lack of syntax, ever<br/>become popular? I don't know the answer to this question. I do think that<br/>syntax is not the main reason Lisp isn't currently popular. Common Lisp has<br/>worse problems than unfamiliar syntax. I know several programmers who are<br/>comfortable with prefix syntax and yet use Perl by default, because it has<br/>powerful string libraries and can talk to the os.  <br/>  <br/>There are two possible problems with prefix notation: that it is unfamiliar to<br/>programmers, and that it is not dense enough. The conventional wisdom in the<br/>Lisp world is that the first problem is the real one. I'm not so sure. Yes,<br/>prefix notation makes ordinary programmers panic. But I don't think ordinary<br/>programmers' opinions matter. Languages become popular or unpopular based on<br/>what expert hackers think of them, and I think expert hackers might be able to<br/>deal with prefix notation. Perl syntax can be pretty incomprehensible, but<br/>that has not stood in the way of Perl's popularity. If anything it may have<br/>helped foster a Perl cult.  <br/>  <br/>A more serious problem is the diffuseness of prefix notation. For expert<br/>hackers, that really is a problem. No one wants to write (aref a x y) when<br/>they could write a[x,y].  <br/>  <br/>In this particular case there is a way to finesse our way out of the problem.<br/>If we treat data structures as if they were functions on indexes, we could<br/>write (a x y) instead, which is even shorter than the Perl form. Similar<br/>tricks may shorten other types of expressions.  <br/>  <br/>We can get rid of (or make optional) a lot of parentheses by making<br/>indentation significant. That's how programmers read code anyway: when<br/>indentation says one thing and delimiters say another, we go by the<br/>indentation. Treating indentation as significant would eliminate this common<br/>source of bugs as well as making programs shorter.  <br/>  <br/>Sometimes infix syntax is easier to read. This is especially true for math<br/>expressions. I've used Lisp my whole programming life and I still don't find<br/>prefix math expressions natural. And yet it is convenient, especially when<br/>you're generating code, to have operators that take any number of arguments.<br/>So if we do have infix syntax, it should probably be implemented as some kind<br/>of read-macro.  <br/>  <br/>I don't think we should be religiously opposed to introducing syntax into<br/>Lisp, as long as it translates in a well-understood way into underlying<br/>s-expressions. There is already a good deal of syntax in Lisp. It's not<br/>necessarily bad to introduce more, as long as no one is forced to use it. In<br/>Common Lisp, some delimiters are reserved for the language, suggesting that at<br/>least some of the designers intended to have more syntax in the future.  <br/>  <br/>One of the most egregiously unlispy pieces of syntax in Common Lisp occurs in<br/>format strings; format is a language in its own right, and that language is<br/>not Lisp. If there were a plan for introducing more syntax into Lisp, format<br/>specifiers might be able to be included in it. It would be a good thing if<br/>macros could generate format specifiers the way they generate any other kind<br/>of code.  <br/>  <br/>An eminent Lisp hacker told me that his copy of CLTL falls open to the section<br/>format. Mine too. This probably indicates room for improvement. It may also<br/>mean that programs do a lot of I/O.  <br/>  <br/> **8 Efficiency**  <br/>  <br/>A good language, as everyone knows, should generate fast code. But in practice<br/>I don't think fast code comes primarily from things you do in the design of<br/>the language. As Knuth pointed out long ago, speed only matters in certain<br/>critical bottlenecks. And as many programmers have observed since, one is very<br/>often mistaken about where these bottlenecks are.  <br/>  <br/>So, in practice, the way to get fast code is to have a very good profiler,<br/>rather than by, say, making the language strongly typed. You don't need to<br/>know the type of every argument in every call in the program. You do need to<br/>be able to declare the types of arguments in the bottlenecks. And even more,<br/>you need to be able to find out where the bottlenecks are.  <br/>  <br/>One complaint people have had with Lisp is that it's hard to tell what's<br/>expensive. This might be true. It might also be inevitable, if you want to<br/>have a very abstract language. And in any case I think good profiling would go<br/>a long way toward fixing the problem: you'd soon learn what was expensive.  <br/>  <br/>Part of the problem here is social. Language designers like to write fast<br/>compilers. That's how they measure their skill. They think of the profiler as<br/>an add-on, at best. But in practice a good profiler may do more to improve the<br/>speed of actual programs written in the language than a compiler that<br/>generates fast code. Here, again, language designers are somewhat out of touch<br/>with their users. They do a really good job of solving slightly the wrong<br/>problem.  <br/>  <br/>It might be a good idea to have an active profiler — to push performance data<br/>to the programmer instead of waiting for him to come asking for it. For<br/>example, the editor could display bottlenecks in red when the programmer edits<br/>the source code. Another approach would be to somehow represent what's<br/>happening in running programs. This would be an especially big win in server-<br/>based applications, where you have lots of running programs to look at. An<br/>active profiler could show graphically what's happening in memory as a<br/>program's running, or even make sounds that tell what's happening.  <br/>  <br/>Sound is a good cue to problems. In one place I worked, we had a big board of<br/>dials showing what was happening to our web servers. The hands were moved by<br/>little servomotors that made a slight noise when they turned. I couldn't see<br/>the board from my desk, but I found that I could tell immediately, by the<br/>sound, when there was a problem with a server.  <br/>  <br/>It might even be possible to write a profiler that would automatically detect<br/>inefficient algorithms. I would not be surprised if certain patterns of memory<br/>access turned out to be sure signs of bad algorithms. If there were a little<br/>guy running around inside the computer executing our programs, he would<br/>probably have as long and plaintive a tale to tell about his job as a federal<br/>government employee. I often have a feeling that I'm sending the processor on<br/>a lot of wild goose chases, but I've never had a good way to look at what it's<br/>doing.  <br/>  <br/>A number of Lisps now compile into byte code, which is then executed by an<br/>interpreter. This is usually done to make the implementation easier to port,<br/>but it could be a useful language feature. It might be a good idea to make the<br/>byte code an official part of the language, and to allow programmers to use<br/>inline byte code in bottlenecks. Then such optimizations would be portable<br/>too.  <br/>  <br/>The nature of speed, as perceived by the end-user, may be changing. With the<br/>rise of server-based applications, more and more programs may turn out to be<br/>i/o-bound. It will be worth making i/o fast. The language can help with<br/>straightforward measures like simple, fast, formatted output functions, and<br/>also with deep structural changes like caching and persistent objects.  <br/>  <br/>Users are interested in response time. But another kind of efficiency will be<br/>increasingly important: the number of simultaneous users you can support per<br/>processor. Many of the interesting applications written in the near future<br/>will be server-based, and the number of users per server is the critical<br/>question for anyone hosting such applications. In the capital cost of a<br/>business offering a server-based application, this is the divisor.  <br/>  <br/>For years, efficiency hasn't mattered much in most end-user applications.<br/>Developers have been able to assume that each user would have an increasingly<br/>powerful processor sitting on their desk. And by Parkinson's Law, software has<br/>expanded to use the resources available. That will change with server-based<br/>applications. In that world, the hardware and software will be supplied<br/>together. For companies that offer server-based applications, it will make a<br/>very big difference to the bottom line how many users they can support per<br/>server.  <br/>  <br/>In some applications, the processor will be the limiting factor, and execution<br/>speed will be the most important thing to optimize. But often memory will be<br/>the limit; the number of simultaneous users will be determined by the amount<br/>of memory you need for each user's data. The language can help here too. Good<br/>support for threads will enable all the users to share a single heap. It may<br/>also help to have persistent objects and/or language level support for lazy<br/>loading.  <br/>  <br/> **9 Time**  <br/>  <br/>The last ingredient a popular language needs is time. No one wants to write<br/>programs in a language that might go away, as so many programming languages<br/>do. So most hackers will tend to wait until a language has been around for a<br/>couple years before even considering using it.  <br/>  <br/>Inventors of wonderful new things are often surprised to discover this, but<br/>you need time to get any message through to people. A friend of mine rarely<br/>does anything the first time someone asks him. He knows that people sometimes<br/>ask for things that they turn out not to want. To avoid wasting his time, he<br/>waits till the third or fourth time he's asked to do something; by then,<br/>whoever's asking him may be fairly annoyed, but at least they probably really<br/>do want whatever they're asking for.  <br/>  <br/>Most people have learned to do a similar sort of filtering on new things they<br/>hear about. They don't even start paying attention until they've heard about<br/>something ten times. They're perfectly justified: the majority of hot new<br/>whatevers do turn out to be a waste of time, and eventually go away. By<br/>delaying learning VRML, I avoided having to learn it at all.  <br/>  <br/>So anyone who invents something new has to expect to keep repeating their<br/>message for years before people will start to get it. We wrote what was, as<br/>far as I know, the first web-server based application, and it took us years to<br/>get it through to people that it didn't have to be downloaded. It wasn't that<br/>they were stupid. They just had us tuned out.  <br/>  <br/>The good news is, simple repetition solves the problem. All you have to do is<br/>keep telling your story, and eventually people will start to hear. It's not<br/>when people notice you're there that they pay attention; it's when they notice<br/>you're still there.  <br/>  <br/>It's just as well that it usually takes a while to gain momentum. Most<br/>technologies evolve a good deal even after they're first launched —<br/>programming languages especially. Nothing could be better, for a new<br/>techology, than a few years of being used only by a small number of early<br/>adopters. Early adopters are sophisticated and demanding, and quickly flush<br/>out whatever flaws remain in your technology. When you only have a few users<br/>you can be in close contact with all of them. And early adopters are forgiving<br/>when you improve your system, even if this causes some breakage.  <br/>  <br/>There are two ways new technology gets introduced: the organic growth method,<br/>and the big bang method. The organic growth method is exemplified by the<br/>classic seat-of-the-pants underfunded garage startup. A couple guys, working<br/>in obscurity, develop some new technology. They launch it with no marketing<br/>and initially have only a few (fanatically devoted) users. They continue to<br/>improve the technology, and meanwhile their user base grows by word of mouth.<br/>Before they know it, they're big.  <br/>  <br/>The other approach, the big bang method, is exemplified by the VC-backed,<br/>heavily marketed startup. They rush to develop a product, launch it with great<br/>publicity, and immediately (they hope) have a large user base.  <br/>  <br/>Generally, the garage guys envy the big bang guys. The big bang guys are<br/>smooth and confident and respected by the VCs. They can afford the best of<br/>everything, and the PR campaign surrounding the launch has the side effect of<br/>making them celebrities. The organic growth guys, sitting in their garage,<br/>feel poor and unloved. And yet I think they are often mistaken to feel sorry<br/>for themselves. Organic growth seems to yield better technology and richer<br/>founders than the big bang method. If you look at the dominant technologies<br/>today, you'll find that most of them grew organically.  <br/>  <br/>This pattern doesn't only apply to companies. You see it in sponsored research<br/>too. Multics and Common Lisp were big-bang projects, and Unix and MacLisp were<br/>organic growth projects.  <br/>  <br/> **10 Redesign**  <br/>  <br/>"The best writing is rewriting," wrote E. B. White. Every good writer knows<br/>this, and it's true for software too. The most important part of design is<br/>redesign. Programming languages, especially, don't get redesigned enough.  <br/>  <br/>To write good software you must simultaneously keep two opposing ideas in your<br/>head. You need the young hacker's naive faith in his abilities, and at the<br/>same time the veteran's skepticism. You have to be able to think how hard can<br/>it be? with one half of your brain while thinking it will never work with the<br/>other.  <br/>  <br/>The trick is to realize that there's no real contradiction here. You want to<br/>be optimistic and skeptical about two different things. You have to be<br/>optimistic about the possibility of solving the problem, but skeptical about<br/>the value of whatever solution you've got so far.  <br/>  <br/>People who do good work often think that whatever they're working on is no<br/>good. Others see what they've done and are full of wonder, but the creator is<br/>full of worry. This pattern is no coincidence: it is the worry that made the<br/>work good.  <br/>  <br/>If you can keep hope and worry balanced, they will drive a project forward the<br/>same way your two legs drive a bicycle forward. In the first phase of the two-<br/>cycle innovation engine, you work furiously on some problem, inspired by your<br/>confidence that you'll be able to solve it. In the second phase, you look at<br/>what you've done in the cold light of morning, and see all its flaws very<br/>clearly. But as long as your critical spirit doesn't outweigh your hope,<br/>you'll be able to look at your admittedly incomplete system, and think, how<br/>hard can it be to get the rest of the way?, thereby continuing the cycle.  <br/>  <br/>It's tricky to keep the two forces balanced. In young hackers, optimism<br/>predominates. They produce something, are convinced it's great, and never<br/>improve it. In old hackers, skepticism predominates, and they won't even dare<br/>to take on ambitious projects.  <br/>  <br/>Anything you can do to keep the redesign cycle going is good. Prose can be<br/>rewritten over and over until you're happy with it. But software, as a rule,<br/>doesn't get redesigned enough. Prose has readers, but software has _users._ If<br/>a writer rewrites an essay, people who read the old version are unlikely to<br/>complain that their thoughts have been broken by some newly introduced<br/>incompatibility.  <br/>  <br/>Users are a double-edged sword. They can help you improve your language, but<br/>they can also deter you from improving it. So choose your users carefully, and<br/>be slow to grow their number. Having users is like optimization: the wise<br/>course is to delay it. Also, as a general rule, you can at any given time get<br/>away with changing more than you think. Introducing change is like pulling off<br/>a bandage: the pain is a memory almost as soon as you feel it.  <br/>  <br/>Everyone knows that it's not a good idea to have a language designed by a<br/>committee. Committees yield bad design. But I think the worst danger of<br/>committees is that they interfere with redesign. It is so much work to<br/>introduce changes that no one wants to bother. Whatever a committee decides<br/>tends to stay that way, even if most of the members don't like it.  <br/>  <br/>Even a committee of two gets in the way of redesign. This happens particularly<br/>in the interfaces between pieces of software written by two different people.<br/>To change the interface both have to agree to change it at once. And so<br/>interfaces tend not to change at all, which is a problem because they tend to<br/>be one of the most ad hoc parts of any system.  <br/>  <br/>One solution here might be to design systems so that interfaces are horizontal<br/>instead of vertical — so that modules are always vertically stacked strata of<br/>abstraction. Then the interface will tend to be owned by one of them. The<br/>lower of two levels will either be a language in which the upper is written,<br/>in which case the lower level will own the interface, or it will be a slave,<br/>in which case the interface can be dictated by the upper level.  <br/>  <br/> **11 Lisp**  <br/>  <br/>What all this implies is that there is hope for a new Lisp. There is hope for<br/>any language that gives hackers what they want, including Lisp. I think we may<br/>have made a mistake in thinking that hackers are turned off by Lisp's<br/>strangeness. This comforting illusion may have prevented us from seeing the<br/>real problem with Lisp, or at least Common Lisp, which is that it sucks for<br/>doing what hackers want to do. A hacker's language needs powerful libraries<br/>and something to hack. Common Lisp has neither. A hacker's language is terse<br/>and hackable. Common Lisp is not.  <br/>  <br/>The good news is, it's not Lisp that sucks, but Common Lisp. If we can develop<br/>a new Lisp that is a real hacker's language, I think hackers will use it. They<br/>will use whatever language does the job. All we have to do is make sure this<br/>new Lisp does some important job better than other languages.  <br/>  <br/>History offers some encouragement. Over time, successive new programming<br/>languages have taken more and more features from Lisp. There is no longer much<br/>left to copy before the language you've made is Lisp. The latest hot language,<br/>Python, is a watered-down Lisp with infix syntax and no macros. A new Lisp<br/>would be a natural step in this progression.  <br/>  <br/>I sometimes think that it would be a good marketing trick to call it an<br/>improved version of Python. That sounds hipper than Lisp. To many people, Lisp<br/>is a slow AI language with a lot of parentheses. Fritz Kunze's official<br/>biography carefully avoids mentioning the L-word. But my guess is that we<br/>shouldn't be afraid to call the new Lisp Lisp. Lisp still has a lot of latent<br/>respect among the very best hackers — the ones who took 6.001 and understood<br/>it, for example. And those are the users you need to win.  <br/>  <br/>In "How to Become a Hacker," Eric Raymond describes Lisp as something like<br/>Latin or Greek — a language you should learn as an intellectual exercise, even<br/>though you won't actually use it:<br/><br/>> Lisp is worth learning for the profound enlightenment experience you will<br/>> have when you finally get it; that experience will make you a better<br/>> programmer for the rest of your days, even if you never actually use Lisp<br/>> itself a lot.<br/><br/>If I didn't know Lisp, reading this would set me asking questions. A language<br/>that would make me a better programmer, if it means anything at all, means a<br/>language that would be better for programming. And that is in fact the<br/>implication of what Eric is saying.  <br/>  <br/>As long as that idea is still floating around, I think hackers will be<br/>receptive enough to a new Lisp, even if it is called Lisp. But this Lisp must<br/>be a hacker's language, like the classic Lisps of the 1970s. It must be terse,<br/>simple, and hackable. And it must have powerful libraries for doing what<br/>hackers want to do now.  <br/>  <br/>In the matter of libraries I think there is room to beat languages like Perl<br/>and Python at their own game. A lot of the new applications that will need to<br/>be written in the coming years will be server-based applications. There's no<br/>reason a new Lisp shouldn't have string libraries as good as Perl, and if this<br/>new Lisp also had powerful libraries for server-based applications, it could<br/>be very popular. Real hackers won't turn up their noses at a new tool that<br/>will let them solve hard problems with a few library calls. Remember, hackers<br/>are lazy.  <br/>  <br/>It could be an even bigger win to have core language support for server-based<br/>applications. For example, explicit support for programs with multiple users,<br/>or data ownership at the level of type tags.  <br/>  <br/>Server-based applications also give us the answer to the question of what this<br/>new Lisp will be used to hack. It would not hurt to make Lisp better as a<br/>scripting language for Unix. (It would be hard to make it worse.) But I think<br/>there are areas where existing languages would be easier to beat. I think it<br/>might be better to follow the model of Tcl, and supply the Lisp together with<br/>a complete system for supporting server-based applications. Lisp is a natural<br/>fit for server-based applications. Lexical closures provide a way to get the<br/>effect of subroutines when the ui is just a series of web pages. S-expressions<br/>map nicely onto html, and macros are good at generating it. There need to be<br/>better tools for writing server-based applications, and there needs to be a<br/>new Lisp, and the two would work very well together.  <br/>  <br/> **12 The Dream Language**  <br/>  <br/>By way of summary, let's try describing the hacker's dream language. The dream<br/>language is beautiful, clean, and terse. It has an interactive toplevel that<br/>starts up fast. You can write programs to solve common problems with very<br/>little code. Nearly all the code in any program you write is code that's<br/>specific to your application. Everything else has been done for you.  <br/>  <br/>The syntax of the language is brief to a fault. You never have to type an<br/>unnecessary character, or even to use the shift key much.  <br/>  <br/>Using big abstractions you can write the first version of a program very<br/>quickly. Later, when you want to optimize, there's a really good profiler that<br/>tells you where to focus your attention. You can make inner loops blindingly<br/>fast, even writing inline byte code if you need to.  <br/>  <br/>There are lots of good examples to learn from, and the language is intuitive<br/>enough that you can learn how to use it from examples in a couple minutes. You<br/>don't need to look in the manual much. The manual is thin, and has few<br/>warnings and qualifications.  <br/>  <br/>The language has a small core, and powerful, highly orthogonal libraries that<br/>are as carefully designed as the core language. The libraries all work well<br/>together; everything in the language fits together like the parts in a fine<br/>camera. Nothing is deprecated, or retained for compatibility. The source code<br/>of all the libraries is readily available. It's easy to talk to the operating<br/>system and to applications written in other languages.  <br/>  <br/>The language is built in layers. The higher-level abstractions are built in a<br/>very transparent way out of lower-level abstractions, which you can get hold<br/>of if you want.  <br/>  <br/>Nothing is hidden from you that doesn't absolutely have to be. The language<br/>offers abstractions only as a way of saving you work, rather than as a way of<br/>telling you what to do. In fact, the language encourages you to be an equal<br/>participant in its design. You can change everything about it, including even<br/>its syntax, and anything you write has, as much as possible, the same status<br/>as what comes predefined.  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Macros very close to the modern idea were proposed by Timothy Hart in<br/>1964, two years after Lisp 1.5 was released. What was missing, initially, were<br/>ways to avoid variable capture and multiple evaluation; Hart's examples are<br/>subject to both.  <br/>  <br/>[2] In _When the Air Hits Your Brain,_ neurosurgeon Frank Vertosick recounts a<br/>conversation in which his chief resident, Gary, talks about the difference<br/>between surgeons and internists ("fleas"):<br/><br/>> Gary and I ordered a large pizza and found an open booth. The chief lit a<br/>> cigarette. "Look at those goddamn fleas, jabbering about some disease<br/>> they'll see once in their lifetimes. That's the trouble with fleas, they<br/>> only like the bizarre stuff. They hate their bread and butter cases. That's<br/>> the difference between us and the fucking fleas. See, we love big juicy<br/>> lumbar disc herniations, but they hate hypertension...."<br/><br/>It's hard to think of a lumbar disc herniation as juicy (except literally).<br/>And yet I think I know what they mean. I've often had a juicy bug to track<br/>down. Someone who's not a programmer would find it hard to imagine that there<br/>could be pleasure in a bug. Surely it's better if everything just works. In<br/>one way, it is. And yet there is undeniably a grim satisfaction in hunting<br/>down certain sorts of bugs.  <br/>  <br/><br/>Postscript Version  <br/>  <br/><br/>Arc  <br/>  <br/><br/>Five Questions about Language Design  <br/>  <br/><br/>How to Become a Hacker  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>January 2003  <br/>  <br/> _(This article was given as a talk at the 2003 Spam Conference. It describes<br/>the work I've done to improve the performance of the algorithm described inA<br/>Plan for Spam, and what I plan to do in the future.)_  <br/>  <br/>The first discovery I'd like to present here is an algorithm for lazy<br/>evaluation of research papers. Just write whatever you want and don't cite any<br/>previous work, and indignant readers will send you references to all the<br/>papers you should have cited. I discovered this algorithm after ``A Plan for<br/>Spam'' [1] was on Slashdot.  <br/>  <br/>Spam filtering is a subset of text classification, which is a well established<br/>field, but the first papers about Bayesian spam filtering per se seem to have<br/>been two given at the same conference in 1998, one by Pantel and Lin [2], and<br/>another by a group from Microsoft Research [3].  <br/>  <br/>When I heard about this work I was a bit surprised. If people had been onto<br/>Bayesian filtering four years ago, why wasn't everyone using it? When I read<br/>the papers I found out why. Pantel and Lin's filter was the more effective of<br/>the two, but it only caught 92% of spam, with 1.16% false positives.  <br/>  <br/>When I tried writing a Bayesian spam filter, it caught 99.5% of spam with less<br/>than .03% false positives [4]. It's always alarming when two people trying the<br/>same experiment get widely divergent results. It's especially alarming here<br/>because those two sets of numbers might yield opposite conclusions. Different<br/>users have different requirements, but I think for many people a filtering<br/>rate of 92% with 1.16% false positives means that filtering is not an<br/>acceptable solution, whereas 99.5% with less than .03% false positives means<br/>that it is.  <br/>  <br/>So why did we get such different numbers? I haven't tried to reproduce Pantel<br/>and Lin's results, but from reading the paper I see five things that probably<br/>account for the difference.  <br/>  <br/>One is simply that they trained their filter on very little data: 160 spam and<br/>466 nonspam mails. Filter performance should still be climbing with data sets<br/>that small. So their numbers may not even be an accurate measure of the<br/>performance of their algorithm, let alone of Bayesian spam filtering in<br/>general.  <br/>  <br/>But I think the most important difference is probably that they ignored<br/>message headers. To anyone who has worked on spam filters, this will seem a<br/>perverse decision. And yet in the very first filters I tried writing, I<br/>ignored the headers too. Why? Because I wanted to keep the problem neat. I<br/>didn't know much about mail headers then, and they seemed to me full of random<br/>stuff. There is a lesson here for filter writers: don't ignore data. You'd<br/>think this lesson would be too obvious to mention, but I've had to learn it<br/>several times.  <br/>  <br/>Third, Pantel and Lin stemmed the tokens, meaning they reduced e.g. both<br/>``mailing'' and ``mailed'' to the root ``mail''. They may have felt they were<br/>forced to do this by the small size of their corpus, but if so this is a kind<br/>of premature optimization.  <br/>  <br/>Fourth, they calculated probabilities differently. They used all the tokens,<br/>whereas I only use the 15 most significant. If you use all the tokens you'll<br/>tend to miss longer spams, the type where someone tells you their life story<br/>up to the point where they got rich from some multilevel marketing scheme. And<br/>such an algorithm would be easy for spammers to spoof: just add a big chunk of<br/>random text to counterbalance the spam terms.  <br/>  <br/>Finally, they didn't bias against false positives. I think any spam filtering<br/>algorithm ought to have a convenient knob you can twist to decrease the false<br/>positive rate at the expense of the filtering rate. I do this by counting the<br/>occurrences of tokens in the nonspam corpus double.  <br/>  <br/>I don't think it's a good idea to treat spam filtering as a straight text<br/>classification problem. You can use text classification techniques, but<br/>solutions can and should reflect the fact that the text is email, and spam in<br/>particular. Email is not just text; it has structure. Spam filtering is not<br/>just classification, because false positives are so much worse than false<br/>negatives that you should treat them as a different kind of error. And the<br/>source of error is not just random variation, but a live human spammer working<br/>actively to defeat your filter.  <br/>  <br/> **Tokens**  <br/>  <br/>Another project I heard about after the Slashdot article was Bill Yerazunis'<br/>CRM114 [5]. This is the counterexample to the design principle I just<br/>mentioned. It's a straight text classifier, but such a stunningly effective<br/>one that it manages to filter spam almost perfectly without even knowing<br/>that's what it's doing.  <br/>  <br/>Once I understood how CRM114 worked, it seemed inevitable that I would<br/>eventually have to move from filtering based on single words to an approach<br/>like this. But first, I thought, I'll see how far I can get with single words.<br/>And the answer is, surprisingly far.  <br/>  <br/>Mostly I've been working on smarter tokenization. On current spam, I've been<br/>able to achieve filtering rates that approach CRM114's. These techniques are<br/>mostly orthogonal to Bill's; an optimal solution might incorporate both.  <br/>  <br/>``A Plan for Spam'' uses a very simple definition of a token. Letters, digits,<br/>dashes, apostrophes, and dollar signs are constituent characters, and<br/>everything else is a token separator. I also ignored case.  <br/>  <br/>Now I have a more complicated definition of a token:<br/><br/>  1. Case is preserved.  <br/>  <br/><br/>  2. Exclamation points are constituent characters.  <br/>  <br/><br/>  3. Periods and commas are constituents if they occur between two digits. This lets me get ip addresses and prices intact.  <br/>  <br/><br/>  4. A price range like $20-25 yields two tokens, $20 and $25.  <br/>  <br/><br/>  5. Tokens that occur within the To, From, Subject, and Return-Path lines, or within urls, get marked accordingly. E.g. ``foo'' in the Subject line becomes ``Subject*foo''. (The asterisk could be any character you don't allow as a constituent.) <br/><br/>Such measures increase the filter's vocabulary, which makes it more<br/>discriminating. For example, in the current filter, ``free'' in the Subject<br/>line has a spam probability of 98%, whereas the same token in the body has a<br/>spam probability of only 65%.  <br/>  <br/>Here are some of the current probabilities [6]:  <br/>  <br/><br/>    <br/>    <br/>    Subject*FREE      0.9999<br/>    free!!            0.9999<br/>    To*free           0.9998<br/>    Subject*free      0.9782<br/>    free!             0.9199<br/>    Free              0.9198<br/>    Url*free          0.9091<br/>    FREE              0.8747<br/>    From*free         0.7636<br/>    free              0.6546<br/>    <br/><br/>In the Plan for Spam filter, all these tokens would have had the same<br/>probability, .7602. That filter recognized about 23,000 tokens. The current<br/>one recognizes about 187,000.  <br/>  <br/>The disadvantage of having a larger universe of tokens is that there is more<br/>chance of misses. Spreading your corpus out over more tokens has the same<br/>effect as making it smaller. If you consider exclamation points as<br/>constituents, for example, then you could end up not having a spam probability<br/>for free with seven exclamation points, even though you know that free with<br/>just two exclamation points has a probability of 99.99%.  <br/>  <br/>One solution to this is what I call degeneration. If you can't find an exact<br/>match for a token, treat it as if it were a less specific version. I consider<br/>terminal exclamation points, uppercase letters, and occurring in one of the<br/>five marked contexts as making a token more specific. For example, if I don't<br/>find a probability for ``Subject*free!'', I look for probabilities for<br/>``Subject*free'', ``free!'', and ``free'', and take whichever one is farthest<br/>from .5.  <br/>  <br/>Here are the alternatives [7] considered if the filter sees ``FREE!!!'' in the<br/>Subject line and doesn't have a probability for it.  <br/>  <br/><br/>    <br/>    <br/>    Subject*Free!!!<br/>    Subject*free!!!<br/>    Subject*FREE!<br/>    Subject*Free!<br/>    Subject*free!<br/>    Subject*FREE<br/>    Subject*Free<br/>    Subject*free<br/>    FREE!!!<br/>    Free!!!<br/>    free!!!<br/>    FREE!<br/>    Free!<br/>    free!<br/>    FREE<br/>    Free<br/>    free              <br/>    <br/><br/>If you do this, be sure to consider versions with initial caps as well as all<br/>uppercase and all lowercase. Spams tend to have more sentences in imperative<br/>mood, and in those the first word is a verb. So verbs with initial caps have<br/>higher spam probabilities than they would in all lowercase. In my filter, the<br/>spam probability of ``Act'' is 98% and for ``act'' only 62%.  <br/>  <br/>If you increase your filter's vocabulary, you can end up counting the same<br/>word multiple times, according to your old definition of ``same''. Logically,<br/>they're not the same token anymore. But if this still bothers you, let me add<br/>from experience that the words you seem to be counting multiple times tend to<br/>be exactly the ones you'd want to.  <br/>  <br/>Another effect of a larger vocabulary is that when you look at an incoming<br/>mail you find more interesting tokens, meaning those with probabilities far<br/>from .5. I use the 15 most interesting to decide if mail is spam. But you can<br/>run into a problem when you use a fixed number like this. If you find a lot of<br/>maximally interesting tokens, the result can end up being decided by whatever<br/>random factor determines the ordering of equally interesting tokens. One way<br/>to deal with this is to treat some as more interesting than others.  <br/>  <br/>For example, the token ``dalco'' occurs 3 times in my spam corpus and never in<br/>my legitimate corpus. The token ``Url*optmails'' (meaning ``optmails'' within<br/>a url) occurs 1223 times. And yet, as I used to calculate probabilities for<br/>tokens, both would have the same spam probability, the threshold of .99.  <br/>  <br/>That doesn't feel right. There are theoretical arguments for giving these two<br/>tokens substantially different probabilities (Pantel and Lin do), but I<br/>haven't tried that yet. It does seem at least that if we find more than 15<br/>tokens that only occur in one corpus or the other, we ought to give priority<br/>to the ones that occur a lot. So now there are two threshold values. For<br/>tokens that occur only in the spam corpus, the probability is .9999 if they<br/>occur more than 10 times and .9998 otherwise. Ditto at the other end of the<br/>scale for tokens found only in the legitimate corpus.  <br/>  <br/>I may later scale token probabilities substantially, but this tiny amount of<br/>scaling at least ensures that tokens get sorted the right way.  <br/>  <br/>Another possibility would be to consider not just 15 tokens, but all the<br/>tokens over a certain threshold of interestingness. Steven Hauser does this in<br/>his statistical spam filter [8]. If you use a threshold, make it very high, or<br/>spammers could spoof you by packing messages with more innocent words.  <br/>  <br/>Finally, what should one do about html? I've tried the whole spectrum of<br/>options, from ignoring it to parsing it all. Ignoring html is a bad idea,<br/>because it's full of useful spam signs. But if you parse it all, your filter<br/>might degenerate into a mere html recognizer. The most effective approach<br/>seems to be the middle course, to notice some tokens but not others. I look at<br/>a, img, and font tags, and ignore the rest. Links and images you should<br/>certainly look at, because they contain urls.  <br/>  <br/>I could probably be smarter about dealing with html, but I don't think it's<br/>worth putting a lot of time into this. Spams full of html are easy to filter.<br/>The smarter spammers already avoid it. So performance in the future should not<br/>depend much on how you deal with html.  <br/>  <br/> **Performance**  <br/>  <br/>Between December 10 2002 and January 10 2003 I got about 1750 spams. Of these,<br/>4 got through. That's a filtering rate of about 99.75%.  <br/>  <br/>Two of the four spams I missed got through because they happened to use words<br/>that occur often in my legitimate email.  <br/>  <br/>The third was one of those that exploit an insecure cgi script to send mail to<br/>third parties. They're hard to filter based just on the content because the<br/>headers are innocent and they're careful about the words they use. Even so I<br/>can usually catch them. This one squeaked by with a probability of .88, just<br/>under the threshold of .9.  <br/>  <br/>Of course, looking at multiple token sequences would catch it easily. ``Below<br/>is the result of your feedback form'' is an instant giveaway.  <br/>  <br/>The fourth spam was what I call a spam-of-the-future, because this is what I<br/>expect spam to evolve into: some completely neutral text followed by a url. In<br/>this case it was was from someone saying they had finally finished their<br/>homepage and would I go look at it. (The page was of course an ad for a porn<br/>site.)  <br/>  <br/>If the spammers are careful about the headers and use a fresh url, there is<br/>nothing in spam-of-the-future for filters to notice. We can of course counter<br/>by sending a crawler to look at the page. But that might not be necessary. The<br/>response rate for spam-of-the-future must be low, or everyone would be doing<br/>it. If it's low enough, it won't pay for spammers to send it, and we won't<br/>have to work too hard on filtering it.  <br/>  <br/>Now for the really shocking news: during that same one-month period I got<br/>_three_ false positives.  <br/>  <br/>In a way it's a relief to get some false positives. When I wrote ``A Plan for<br/>Spam'' I hadn't had any, and I didn't know what they'd be like. Now that I've<br/>had a few, I'm relieved to find they're not as bad as I feared. False<br/>positives yielded by statistical filters turn out to be mails that sound a lot<br/>like spam, and these tend to be the ones you would least mind missing [9].  <br/>  <br/>Two of the false positives were newsletters from companies I've bought things<br/>from. I never asked to receive them, so arguably they were spams, but I count<br/>them as false positives because I hadn't been deleting them as spams before.<br/>The reason the filters caught them was that both companies in January switched<br/>to commercial email senders instead of sending the mails from their own<br/>servers, and both the headers and the bodies became much spammier.  <br/>  <br/>The third false positive was a bad one, though. It was from someone in Egypt<br/>and written in all uppercase. This was a direct result of making tokens case<br/>sensitive; the Plan for Spam filter wouldn't have caught it.  <br/>  <br/>It's hard to say what the overall false positive rate is, because we're up in<br/>the noise, statistically. Anyone who has worked on filters (at least,<br/>effective filters) will be aware of this problem. With some emails it's hard<br/>to say whether they're spam or not, and these are the ones you end up looking<br/>at when you get filters really tight. For example, so far the filter has<br/>caught two emails that were sent to my address because of a typo, and one sent<br/>to me in the belief that I was someone else. Arguably, these are neither my<br/>spam nor my nonspam mail.  <br/>  <br/>Another false positive was from a vice president at Virtumundo. I wrote to<br/>them pretending to be a customer, and since the reply came back through<br/>Virtumundo's mail servers it had the most incriminating headers imaginable.<br/>Arguably this isn't a real false positive either, but a sort of Heisenberg<br/>uncertainty effect: I only got it because I was writing about spam filtering.  <br/>  <br/>Not counting these, I've had a total of five false positives so far, out of<br/>about 7740 legitimate emails, a rate of .06%. The other two were a notice that<br/>something I bought was back-ordered, and a party reminder from Evite.  <br/>  <br/>I don't think this number can be trusted, partly because the sample is so<br/>small, and partly because I think I can fix the filter not to catch some of<br/>these.  <br/>  <br/>False positives seem to me a different kind of error from false negatives.<br/>Filtering rate is a measure of performance. False positives I consider more<br/>like bugs. I approach improving the filtering rate as optimization, and<br/>decreasing false positives as debugging.  <br/>  <br/>So these five false positives are my bug list. For example, the mail from<br/>Egypt got nailed because the uppercase text made it look to the filter like a<br/>Nigerian spam. This really is kind of a bug. As with html, the email being all<br/>uppercase is really conceptually _one_ feature, not one for each word. I need<br/>to handle case in a more sophisticated way.  <br/>  <br/>So what to make of this .06%? Not much, I think. You could treat it as an<br/>upper bound, bearing in mind the small sample size. But at this stage it is<br/>more a measure of the bugs in my implementation than some intrinsic false<br/>positive rate of Bayesian filtering.  <br/>  <br/> **Future**  <br/>  <br/>What next? Filtering is an optimization problem, and the key to optimization<br/>is profiling. Don't try to guess where your code is slow, because you'll guess<br/>wrong. _Look_ at where your code is slow, and fix that. In filtering, this<br/>translates to: look at the spams you miss, and figure out what you could have<br/>done to catch them.  <br/>  <br/>For example, spammers are now working aggressively to evade filters, and one<br/>of the things they're doing is breaking up and misspelling words to prevent<br/>filters from recognizing them. But working on this is not my first priority,<br/>because I still have no trouble catching these spams [10].  <br/>  <br/>There are two kinds of spams I currently do have trouble with. One is the type<br/>that pretends to be an email from a woman inviting you to go chat with her or<br/>see her profile on a dating site. These get through because they're the one<br/>type of sales pitch you can make without using sales talk. They use the same<br/>vocabulary as ordinary email.  <br/>  <br/>The other kind of spams I have trouble filtering are those from companies in<br/>e.g. Bulgaria offering contract programming services. These get through<br/>because I'm a programmer too, and the spams are full of the same words as my<br/>real mail.  <br/>  <br/>I'll probably focus on the personal ad type first. I think if I look closer<br/>I'll be able to find statistical differences between these and my real mail.<br/>The style of writing is certainly different, though it may take multiword<br/>filtering to catch that. Also, I notice they tend to repeat the url, and<br/>someone including a url in a legitimate mail wouldn't do that [11].  <br/>  <br/>The outsourcing type are going to be hard to catch. Even if you sent a crawler<br/>to the site, you wouldn't find a smoking statistical gun. Maybe the only<br/>answer is a central list of domains advertised in spams [12]. But there can't<br/>be that many of this type of mail. If the only spams left were unsolicited<br/>offers of contract programming services from Bulgaria, we could all probably<br/>move on to working on something else.  <br/>  <br/>Will statistical filtering actually get us to that point? I don't know. Right<br/>now, for me personally, spam is not a problem. But spammers haven't yet made a<br/>serious effort to spoof statistical filters. What will happen when they do?  <br/>  <br/>I'm not optimistic about filters that work at the network level [13]. When<br/>there is a static obstacle worth getting past, spammers are pretty efficient<br/>at getting past it. There is already a company called Assurance Systems that<br/>will run your mail through Spamassassin and tell you whether it will get<br/>filtered out.  <br/>  <br/>Network-level filters won't be completely useless. They may be enough to kill<br/>all the "opt-in" spam, meaning spam from companies like Virtumundo and<br/>Equalamail who claim that they're really running opt-in lists. You can filter<br/>those based just on the headers, no matter what they say in the body. But<br/>anyone willing to falsify headers or use open relays, presumably including<br/>most porn spammers, should be able to get some message past network-level<br/>filters if they want to. (By no means the message they'd like to send though,<br/>which is something.)  <br/>  <br/>The kind of filters I'm optimistic about are ones that calculate probabilities<br/>based on each individual user's mail. These can be much more effective, not<br/>only in avoiding false positives, but in filtering too: for example, finding<br/>the recipient's email address base-64 encoded anywhere in a message is a very<br/>good spam indicator.  <br/>  <br/>But the real advantage of individual filters is that they'll all be different.<br/>If everyone's filters have different probabilities, it will make the spammers'<br/>optimization loop, what programmers would call their edit-compile-test cycle,<br/>appallingly slow. Instead of just tweaking a spam till it gets through a copy<br/>of some filter they have on their desktop, they'll have to do a test mailing<br/>for each tweak. It would be like programming in a language without an<br/>interactive toplevel, and I wouldn't wish that on anyone.  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Paul Graham. ``A Plan for Spam.'' August 2002.<br/>http://paulgraham.com/spam.html.  <br/>  <br/>Probabilities in this algorithm are calculated using a degenerate case of<br/>Bayes' Rule. There are two simplifying assumptions: that the probabilities of<br/>features (i.e. words) are independent, and that we know nothing about the<br/>prior probability of an email being spam.  <br/>  <br/>The first assumption is widespread in text classification. Algorithms that use<br/>it are called ``naive Bayesian.''  <br/>  <br/>The second assumption I made because the proportion of spam in my incoming<br/>mail fluctuated so much from day to day (indeed, from hour to hour) that the<br/>overall prior ratio seemed worthless as a predictor. If you assume that<br/>P(spam) and P(nonspam) are both .5, they cancel out and you can remove them<br/>from the formula.  <br/>  <br/>If you were doing Bayesian filtering in a situation where the ratio of spam to<br/>nonspam was consistently very high or (especially) very low, you could<br/>probably improve filter performance by incorporating prior probabilities. To<br/>do this right you'd have to track ratios by time of day, because spam and<br/>legitimate mail volume both have distinct daily patterns.  <br/>  <br/>[2] Patrick Pantel and Dekang Lin. ``SpamCop-- A Spam Classification &<br/>Organization Program.'' Proceedings of AAAI-98 Workshop on Learning for Text<br/>Categorization.  <br/>  <br/>[3] Mehran Sahami, Susan Dumais, David Heckerman and Eric Horvitz. ``A<br/>Bayesian Approach to Filtering Junk E-Mail.'' Proceedings of AAAI-98 Workshop<br/>on Learning for Text Categorization.  <br/>  <br/>[4] At the time I had zero false positives out of about 4,000 legitimate<br/>emails. If the next legitimate email was a false positive, this would give us<br/>.03%. These false positive rates are untrustworthy, as I explain later. I<br/>quote a number here only to emphasize that whatever the false positive rate<br/>is, it is less than 1.16%.  <br/>  <br/>[5] Bill Yerazunis. ``Sparse Binary Polynomial Hash Message Filtering and The<br/>CRM114 Discriminator.'' Proceedings of 2003 Spam Conference.  <br/>  <br/>[6] In ``A Plan for Spam'' I used thresholds of .99 and .01. It seems<br/>justifiable to use thresholds proportionate to the size of the corpora. Since<br/>I now have on the order of 10,000 of each type of mail, I use .9999 and .0001.  <br/>  <br/>[7] There is a flaw here I should probably fix. Currently, when<br/>``Subject*foo'' degenerates to just ``foo'', what that means is you're getting<br/>the stats for occurrences of ``foo'' in the body or header lines other than<br/>those I mark. What I should do is keep track of statistics for ``foo'' overall<br/>as well as specific versions, and degenerate from ``Subject*foo'' not to<br/>``foo'' but to ``Anywhere*foo''. Ditto for case: I should degenerate from<br/>uppercase to any-case, not lowercase.  <br/>  <br/>It would probably be a win to do this with prices too, e.g. to degenerate from<br/>``$129.99'' to ``$--9.99'', ``$--.99'', and ``$--''.  <br/>  <br/>You could also degenerate from words to their stems, but this would probably<br/>only improve filtering rates early on when you had small corpora.  <br/>  <br/>[8] Steven Hauser. ``Statistical Spam Filter Works for Me.''<br/>http://www.sofbot.com.  <br/>  <br/>[9] False positives are not all equal, and we should remember this when<br/>comparing techniques for stopping spam. Whereas many of the false positives<br/>caused by filters will be near-spams that you wouldn't mind missing, false<br/>positives caused by blacklists, for example, will be just mail from people who<br/>chose the wrong ISP. In both cases you catch mail that's near spam, but for<br/>blacklists nearness is physical, and for filters it's textual.  <br/>  <br/>[10] If spammers get good enough at obscuring tokens for this to be a problem,<br/>we can respond by simply removing whitespace, periods, commas, etc. and using<br/>a dictionary to pick the words out of the resulting sequence. And of course<br/>finding words this way that weren't visible in the original text would in<br/>itself be evidence of spam.  <br/>  <br/>Picking out the words won't be trivial. It will require more than just<br/>reconstructing word boundaries; spammers both add (``xHot nPorn cSite'') and<br/>omit (``P#rn'') letters. Vision research may be useful here, since human<br/>vision is the limit that such tricks will approach.  <br/>  <br/>[11] In general, spams are more repetitive than regular email. They want to<br/>pound that message home. I currently don't allow duplicates in the top 15<br/>tokens, because you could get a false positive if the sender happens to use<br/>some bad word multiple times. (In my current filter, ``dick'' has a spam<br/>probabilty of .9999, but it's also a name.) It seems we should at least notice<br/>duplication though, so I may try allowing up to two of each token, as Brian<br/>Burton does in SpamProbe.  <br/>  <br/>[12] This is what approaches like Brightmail's will degenerate into once<br/>spammers are pushed into using mad-lib techniques to generate everything else<br/>in the message.  <br/>  <br/>[13] It's sometimes argued that we should be working on filtering at the<br/>network level, because it is more efficient. What people usually mean when<br/>they say this is: we currently filter at the network level, and we don't want<br/>to start over from scratch. But you can't dictate the problem to fit your<br/>solution.  <br/>  <br/>Historically, scarce-resource arguments have been the losing side in debates<br/>about software design. People only tend to use them to justify choices<br/>(inaction in particular) made for other reasons.  <br/>  <br/> **Thanks** to Sarah Harlin, Trevor Blackwell, and Dan Giffin for reading<br/>drafts of this paper, and to Dan again for most of the infrastructure that<br/>this filter runs on.  <br/>  <br/>  <br/>  <br/> **Related:**  <br/>  <br/><br/>A Plan for Spam  <br/>  <br/><br/>Plan for Spam FAQ  <br/>  <br/><br/>2003 Spam Conference Proceedings  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Chinese Translation  <br/>  <br/><br/>Test of These Suggestions  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>August 2005  <br/>  <br/>Thirty years ago, one was supposed to work one's way up the corporate ladder.<br/>That's less the rule now. Our generation wants to get paid up front. Instead<br/>of developing a product for some big company in the expectation of getting job<br/>security in return, we develop the product ourselves, in a startup, and sell<br/>it to the big company. At the very least we want options.  <br/>  <br/>Among other things, this shift has created the appearance of a rapid increase<br/>in economic inequality. But really the two cases are not as different as they<br/>look in economic statistics.  <br/>  <br/>Economic statistics are misleading because they ignore the value of safe jobs.<br/>An easy job from which one can't be fired is worth money; exchanging the two<br/>is one of the commonest forms of corruption. A sinecure is, in effect, an<br/>annuity. Except sinecures don't appear in economic statistics. If they did, it<br/>would be clear that in practice socialist countries have nontrivial<br/>disparities of wealth, because they usually have a class of powerful<br/>bureaucrats who are paid mostly by seniority and can never be fired.  <br/>  <br/>While not a sinecure, a position on the corporate ladder was genuinely<br/>valuable, because big companies tried not to fire people, and promoted from<br/>within based largely on seniority. A position on the corporate ladder had a<br/>value analogous to the "goodwill" that is a very real element in the valuation<br/>of companies. It meant one could expect future high paying jobs.  <br/>  <br/>One of main causes of the decay of the corporate ladder is the trend for<br/>takeovers that began in the 1980s. Why waste your time climbing a ladder that<br/>might disappear before you reach the top?  <br/>  <br/>And, by no coincidence, the corporate ladder was one of the reasons the early<br/>corporate raiders were so successful. It's not only economic statistics that<br/>ignore the value of safe jobs. Corporate balance sheets do too. One reason it<br/>was profitable to carve up 1980s companies and sell them for parts was that<br/>they hadn't formally acknowledged their implicit debt to employees who had<br/>done good work and expected to be rewarded with high-paying executive jobs<br/>when their time came.  <br/>  <br/>In the movie _Wall Street_ , Gordon Gekko ridicules a company overloaded with<br/>vice presidents. But the company may not be as corrupt as it seems; those VPs'<br/>cushy jobs were probably payment for work done earlier.  <br/>  <br/>I like the new model better. For one thing, it seems a bad plan to treat jobs<br/>as rewards. Plenty of good engineers got made into bad managers that way. And<br/>the old system meant people had to deal with a lot more corporate politics, in<br/>order to protect the work they'd invested in a position on the ladder.  <br/>  <br/>The big disadvantage of the new system is that it involves more risk. If you<br/>develop ideas in a startup instead of within a big company, any number of<br/>random factors could sink you before you can finish. But maybe the older<br/>generation would laugh at me for saying that the way we do things is riskier.<br/>After all, projects within big companies were always getting cancelled as a<br/>result of arbitrary decisions from higher up. My father's entire industry<br/>(breeder reactors) disappeared that way.  <br/>  <br/>For better or worse, the idea of the corporate ladder is probably gone for<br/>good. The new model seems more liquid, and more efficient. But it is less of a<br/>change, financially, than one might think. Our fathers weren't _that_ stupid.  <br/>  <br/>  <br/>  <br/>  <br/><br/>Romanian Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>July 2007  <br/>  <br/>An investor wants to give you money for a certain percentage of your startup.<br/>Should you take it? You're about to hire your first employee. How much stock<br/>should you give him?  <br/>  <br/>These are some of the hardest questions founders face. And yet both have the<br/>same answer:  <br/>  <br/>1/(1 - n)  <br/>  <br/>Whenever you're trading stock in your company for anything, whether it's money<br/>or an employee or a deal with another company, the test for whether to do it<br/>is the same. You should give up n% of your company if what you trade it for<br/>improves your average outcome enough that the (100 - n)% you have left is<br/>worth more than the whole company was before.  <br/>  <br/>For example, if an investor wants to buy half your company, how much does that<br/>investment have to improve your average outcome for you to break even?<br/>Obviously it has to double: if you trade half your company for something that<br/>more than doubles the company's average outcome, you're net ahead. You have<br/>half as big a share of something worth more than twice as much.  <br/>  <br/>In the general case, if n is the fraction of the company you're giving up, the<br/>deal is a good one if it makes the company worth more than 1/(1 - n).  <br/>  <br/>For example, suppose Y Combinator offers to fund you in return for 6% of your<br/>company. In this case, n is .06 and 1/(1 - n) is 1.064. So you should take the<br/>deal if you believe we can improve your average outcome by more than 6.4%. If<br/>we improve your outcome by 10%, you're net ahead, because the remaining .94<br/>you hold is worth .94 x 1.1 = 1.034. [1]  <br/>  <br/>One of the things the equity equation shows us is that, financially at least,<br/>taking money from a top VC firm can be a really good deal. Greg Mcadoo from<br/>Sequoia recently said at a YC dinner that when Sequoia invests alone they like<br/>to take about 30% of a company. 1/.7 = 1.43, meaning that deal is worth taking<br/>if they can improve your outcome by more than 43%. For the average startup,<br/>that would be an extraordinary bargain. It would improve the average startup's<br/>prospects by more than 43% just to be able to _say_ they were funded by<br/>Sequoia, even if they never actually got the money.  <br/>  <br/>The reason Sequoia is such a good deal is that the percentage of the company<br/>they take is artificially low. They don't even try to get market price for<br/>their investment; they limit their holdings to leave the founders enough stock<br/>to feel the company is still theirs.  <br/>  <br/>The catch is that Sequoia gets about 6000 business plans a year and funds<br/>about 20 of them, so the odds of getting this great deal are 1 in 300. The<br/>companies that make it through are not average startups.  <br/>  <br/>Of course, there are other factors to consider in a VC deal. It's never just a<br/>straight trade of money for stock. But if it were, taking money from a top<br/>firm would generally be a bargain.  <br/>  <br/>You can use the same formula when giving stock to employees, but it works in<br/>the other direction. If i is the average outcome for the company with the<br/>addition of some new person, then they're worth n such that i = 1/(1 - n).<br/>Which means n = (i - 1)/i.  <br/>  <br/>For example, suppose you're just two founders and you want to hire an<br/>additional hacker who's so good you feel he'll increase the average outcome of<br/>the whole company by 20%. n = (1.2 - 1)/1.2 = .167. So you'll break even if<br/>you trade 16.7% of the company for him.  <br/>  <br/>That doesn't mean 16.7% is the right amount of stock to give him. Stock is not<br/>the only cost of hiring someone: there's usually salary and overhead as well.<br/>And if the company merely breaks even on the deal, there's no reason to do it.  <br/>  <br/>I think to translate salary and overhead into stock you should multiply the<br/>annual rate by about 1.5. Most startups grow fast or die; if you die you don't<br/>have to pay the guy, and if you grow fast you'll be paying next year's salary<br/>out of next year's valuation, which should be 3x this year's. If your<br/>valuation grows 3x a year, the total cost in stock of a new hire's salary and<br/>overhead is 1.5 years' cost at the present valuation. [2]  <br/>  <br/>How much of an additional margin should the company need as the "activation<br/>energy" for the deal? Since this is in effect the company's profit on a hire,<br/>the market will determine that: if you're a hot opportunity, you can charge<br/>more.  <br/>  <br/>Let's run through an example. Suppose the company wants to make a "profit" of<br/>50% on the new hire mentioned above. So subtract a third from 16.7% and we<br/>have 11.1% as his "retail" price. Suppose further that he's going to cost $60k<br/>a year in salary and overhead, x 1.5 = $90k total. If the company's valuation<br/>is $2 million, $90k is 4.5%. 11.1% - 4.5% = an offer of 6.6%.  <br/>  <br/>Incidentally, notice how important it is for early employees to take little<br/>salary. It comes right out of stock that could otherwise be given to them.  <br/>  <br/>Obviously there is a great deal of play in these numbers. I'm not claiming<br/>that stock grants can now be reduced to a formula. Ultimately you always have<br/>to guess. But at least know what you're guessing. If you choose a number based<br/>on your gut feel, or a table of typical grant sizes supplied by a VC firm,<br/>understand what those are estimates of.  <br/>  <br/>And more generally, when you make any decision involving equity, run it<br/>through 1/(1 - n) to see if it makes sense. You should always feel richer<br/>after trading equity. If the trade didn't increase the value of your remaining<br/>shares enough to put you net ahead, you wouldn't have (or shouldn't have) done<br/>it.  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] This is why we can't believe anyone would think Y Combinator was a bad<br/>deal. Does anyone really think we're so useless that in three months we can't<br/>improve a startup's prospects by 6.4%?  <br/>  <br/>[2] The obvious choice for your present valuation is the post-money valuation<br/>of your last funding round. This probably undervalues the company, though,<br/>because (a) unless your last round just happened, the company is presumably<br/>worth more, and (b) the valuation of an early funding round usually reflects<br/>some other contribution by the investors.  <br/>  <br/> **Thanks** to Sam Altman, Trevor Blackwell, Paul Buchheit, Hutch Fishman,<br/>David Hornik, Paul Kedrosky, Jessica Livingston, Gary Sabot, and Joshua<br/>Schachter for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>October 2015  <br/>  <br/>This will come as a surprise to a lot of people, but in some cases it's<br/>possible to detect bias in a selection process without knowing anything about<br/>the applicant pool. Which is exciting because among other things it means<br/>third parties can use this technique to detect bias whether those doing the<br/>selecting want them to or not.  <br/>  <br/>You can use this technique whenever (a) you have at least a random sample of<br/>the applicants that were selected, (b) their subsequent performance is<br/>measured, and (c) the groups of applicants you're comparing have roughly equal<br/>distribution of ability.  <br/>  <br/>How does it work? Think about what it means to be biased. What it means for a<br/>selection process to be biased against applicants of type x is that it's<br/>harder for them to make it through. Which means applicants of type x have to<br/>be better to get selected than applicants not of type x. [1] Which means<br/>applicants of type x who do make it through the selection process will<br/>outperform other successful applicants. And if the performance of all the<br/>successful applicants is measured, you'll know if they do.  <br/>  <br/>Of course, the test you use to measure performance must be a valid one. And in<br/>particular it must not be invalidated by the bias you're trying to measure.<br/>But there are some domains where performance can be measured, and in those<br/>detecting bias is straightforward. Want to know if the selection process was<br/>biased against some type of applicant? Check whether they outperform the<br/>others. This is not just a heuristic for detecting bias. It's what bias means.  <br/>  <br/>For example, many suspect that venture capital firms are biased against female<br/>founders. This would be easy to detect: among their portfolio companies, do<br/>startups with female founders outperform those without? A couple months ago,<br/>one VC firm (almost certainly unintentionally) published a study showing bias<br/>of this type. First Round Capital found that among its portfolio companies,<br/>startups with female founders _outperformed_ those without by 63%. [2]  <br/>  <br/>The reason I began by saying that this technique would come as a surprise to<br/>many people is that we so rarely see analyses of this type. I'm sure it will<br/>come as a surprise to First Round that they performed one. I doubt anyone<br/>there realized that by limiting their sample to their own portfolio, they were<br/>producing a study not of startup trends but of their own biases when selecting<br/>companies.  <br/>  <br/>I predict we'll see this technique used more in the future. The information<br/>needed to conduct such studies is increasingly available. Data about who<br/>applies for things is usually closely guarded by the organizations selecting<br/>them, but nowadays data about who gets selected is often publicly available to<br/>anyone who takes the trouble to aggregate it.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] This technique wouldn't work if the selection process looked for different<br/>things from different types of applicants—for example, if an employer hired<br/>men based on their ability but women based on their appearance.  <br/>  <br/>[2] As Paul Buchheit points out, First Round excluded their most successful<br/>investment, Uber, from the study. And while it makes sense to exclude outliers<br/>from some types of studies, studies of returns from startup investing, which<br/>is all about hitting outliers, are not one of them.  <br/>  <br/>**Thanks** to Sam Altman, Jessica Livingston, and Geoff Ralston for reading<br/>drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>March 2012  <br/>  <br/>I'm not a very good speaker. I say "um" a lot. Sometimes I have to pause when<br/>I lose my train of thought. I wish I were a better speaker. But I don't wish I<br/>were a better speaker like I wish I were a better writer. What I really want<br/>is to have good ideas, and that's a much bigger part of being a good writer<br/>than being a good speaker.  <br/>  <br/>Having good ideas is most of writing well. If you know what you're talking<br/>about, you can say it in the plainest words and you'll be perceived as having<br/>a good style. With speaking it's the opposite: having good ideas is an<br/>alarmingly small component of being a good speaker.  <br/>  <br/>I first noticed this at a conference several years ago. There was another<br/>speaker who was much better than me. He had all of us roaring with laughter. I<br/>seemed awkward and halting by comparison. Afterward I put my talk online like<br/>I usually do. As I was doing it I tried to imagine what a transcript of the<br/>other guy's talk would be like, and it was only then I realized he hadn't said<br/>very much.  <br/>  <br/>Maybe this would have been obvious to someone who knew more about speaking,<br/>but it was a revelation to me how much less ideas mattered in speaking than<br/>writing. [1]  <br/>  <br/>A few years later I heard a talk by someone who was not merely a better<br/>speaker than me, but a famous speaker. Boy was he good. So I decided I'd pay<br/>close attention to what he said, to learn how he did it. After about ten<br/>sentences I found myself thinking "I don't want to be a good speaker."  <br/>  <br/>Being a really good speaker is not merely orthogonal to having good ideas, but<br/>in many ways pushes you in the opposite direction. For example, when I give a<br/>talk, I usually write it out beforehand. I know that's a mistake; I know<br/>delivering a prewritten<br/><br/>  <br/>  <br/><br/>* * *<br/><br/>May 2003  <br/>  <br/>If Lisp is so great, why don't more people use it? I was asked this question<br/>by a student in the audience at a talk I gave recently. Not for the first<br/>time, either.  <br/>  <br/>In languages, as in so many things, there's not much correlation between<br/>popularity and quality. Why does John Grisham ( _King of Torts_ sales rank,<br/>44) outsell Jane Austen ( _Pride and Prejudice_ sales rank, 6191)? Would even<br/>Grisham claim that it's because he's a better writer?  <br/>  <br/>Here's the first sentence of _Pride and Prejudice:_<br/><br/>> It is a truth universally acknowledged, that a single man in possession of a<br/>> good fortune must be in want of a wife.<br/><br/>"It is a truth universally acknowledged?" Long words for the first sentence of<br/>a love story.  <br/>  <br/>Like Jane Austen, Lisp looks hard. Its syntax, or lack of syntax, makes it<br/>look completely unlike the languages most people are used to. Before I learned<br/>Lisp, I was afraid of it too. I recently came across a notebook from 1983 in<br/>which I'd written:<br/><br/>> I suppose I should learn Lisp, but it seems so foreign.<br/><br/>Fortunately, I was 19 at the time and not too resistant to learning new<br/>things. I was so ignorant that learning almost anything meant learning new<br/>things.  <br/>  <br/>People frightened by Lisp make up other reasons for not using it. The standard<br/>excuse, back when C was the default language, was that Lisp was too slow. Now<br/>that Lisp dialects are among the faster languages available, that excuse has<br/>gone away. Now the standard excuse is openly circular: that other languages<br/>are more popular.  <br/>  <br/>(Beware of such reasoning. It gets you Windows.)  <br/>  <br/>Popularity is always self-perpetuating, but it's especially so in programming<br/>languages. More libraries get written for popular languages, which makes them<br/>still more popular. Programs often have to work with existing programs, and<br/>this is easier if they're written in the same language, so languages spread<br/>from program to program like a virus. And managers prefer popular languages,<br/>because they give them more leverage over developers, who can more easily be<br/>replaced.  <br/>  <br/>Indeed, if programming languages were all more or less equivalent, there would<br/>be little justification for using any but the most popular. But they aren't<br/>all equivalent, not by a long shot. And that's why less popular languages,<br/>like Jane Austen's novels, continue to survive at all. When everyone else is<br/>reading the latest John Grisham novel, there will always be a few people<br/>reading Jane Austen instead.  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Romanian Translation  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>August 2013  <br/>  <br/>When people hurt themselves lifting heavy things, it's usually because they<br/>try to lift with their back. The right way to lift heavy things is to let your<br/>legs do the work. Inexperienced founders make the same mistake when trying to<br/>convince investors. They try to convince with their pitch. Most would be<br/>better off if they let their startup do the work — if they started by<br/>understanding why their startup is worth investing in, then simply explained<br/>this well to investors.  <br/>  <br/>Investors are looking for startups that will be very successful. But that test<br/>is not as simple as it sounds. In startups, as in a lot of other domains, the<br/>distribution of outcomes follows a power law, but in startups the curve is<br/>startlingly steep. The big successes are so big they dwarf the rest. And since<br/>there are only a handful each year (the conventional wisdom is 15), investors<br/>treat "big success" as if it were binary. Most are interested in you if you<br/>seem like you have a chance, however small, of being one of the 15 big<br/>successes, and otherwise not. [1]  <br/>  <br/>(There are a handful of angels who'd be interested in a company with a high<br/>probability of being moderately successful. But angel investors like big<br/>successes too.)  <br/>  <br/>How do you seem like you'll be one of the big successes? You need three<br/>things: formidable founders, a promising market, and (usually) some evidence<br/>of success so far.  <br/>  <br/> **Formidable**  <br/>  <br/>The most important ingredient is formidable founders. Most investors decide in<br/>the first few minutes whether you seem like a winner or a loser, and once<br/>their opinion is set it's hard to change. [2] Every startup has reasons both<br/>to invest and not to invest. If investors think you're a winner they focus on<br/>the former, and if not they focus on the latter. For example, it might be a<br/>rich market, but with a slow sales cycle. If investors are impressed with you<br/>as founders, they say they want to invest because it's a rich market, and if<br/>not, they say they can't invest because of the slow sales cycle.  <br/>  <br/>They're not necessarily trying to mislead you. Most investors are genuinely<br/>unclear in their own minds why they like or dislike startups. If you seem like<br/>a winner, they'll like your idea more. But don't be too smug about this<br/>weakness of theirs, because you have it too; almost everyone does.  <br/>  <br/>There is a role for ideas of course. They're fuel for the fire that starts<br/>with liking the founders. Once investors like you, you'll see them reaching<br/>for ideas: they'll be saying "yes, and you could also do x." (Whereas when<br/>they don't like you, they'll be saying "but what about y?")  <br/>  <br/>But the foundation of convincing investors is to seem formidable, and since<br/>this isn't a word most people use in conversation much, I should explain what<br/>it means. A formidable person is one who seems like they'll get what they<br/>want, regardless of whatever obstacles are in the way. Formidable is close to<br/>confident, except that someone could be confident and mistaken. Formidable is<br/>roughly justifiably confident.  <br/>  <br/>There are a handful of people who are really good at seeming formidable — some<br/>because they actually are very formidable and just let it show, and others<br/>because they are more or less con artists. [3] But most founders, including<br/>many who will go on to start very successful companies, are not that good at<br/>seeming formidable the first time they try fundraising. What should they do?<br/>[4]  <br/>  <br/>What they should not do is try to imitate the swagger of more experienced<br/>founders. Investors are not always that good at judging technology, but<br/>they're good at judging confidence. If you try to act like something you're<br/>not, you'll just end up in an uncanny valley. You'll depart from sincere, but<br/>never arrive at convincing.  <br/>  <br/> **Truth**  <br/>  <br/>The way to seem most formidable as an inexperienced founder is to stick to the<br/>truth. How formidable you seem isn't a constant. It varies depending on what<br/>you're saying. Most people can seem confident when they're saying "one plus<br/>one is two," because they know it's true. The most diffident person would be<br/>puzzled and even slightly contemptuous if they told a VC "one plus one is two"<br/>and the VC reacted with skepticism. The magic ability of people who are good<br/>at seeming formidable is that they can do this with the sentence "we're going<br/>to make a billion dollars a year." But you can do the same, if not with that<br/>sentence with some fairly impressive ones, so long as you convince yourself<br/>first.  <br/>  <br/>That's the secret. Convince yourself that your startup is worth investing in,<br/>and then when you explain this to investors they'll believe you. And by<br/>convince yourself, I don't mean play mind games with yourself to boost your<br/>confidence. I mean truly evaluate whether your startup is worth investing in.<br/>If it isn't, don't try to raise money. [5] But if it is, you'll be telling the<br/>truth when you tell investors it's worth investing in, and they'll sense that.<br/>You don't have to be a smooth presenter if you understand something well and<br/>tell the truth about it.  <br/>  <br/>To evaluate whether your startup is worth investing in, you have to be a<br/>domain expert. If you're not a domain expert, you can be as convinced as you<br/>like about your idea, and it will seem to investors no more than an instance<br/>of the Dunning-Kruger effect. Which in fact it will usually be. And investors<br/>can tell fairly quickly whether you're a domain expert by how well you answer<br/>their questions. Know everything about your market. [6]  <br/>  <br/>Why do founders persist in trying to convince investors of things they're not<br/>convinced of themselves? Partly because we've all been trained to.  <br/>  <br/>When my friends Robert Morris and Trevor Blackwell were in grad school, one of<br/>their fellow students was on the receiving end of a question from their<br/>faculty advisor that we still quote today. When the unfortunate fellow got to<br/>his last slide, the professor burst out:<br/><br/>> Which one of these conclusions do you actually believe?<br/><br/>One of the artifacts of the way schools are organized is that we all get<br/>trained to talk even when we have nothing to say. If you have a ten page paper<br/>due, then ten pages you must write, even if you only have one page of ideas.<br/>Even if you have no ideas. You have to produce something. And all too many<br/>startups go into fundraising in the same spirit. When they think it's time to<br/>raise money, they try gamely to make the best case they can for their startup.<br/>Most never think of pausing beforehand to ask whether what they're saying is<br/>actually convincing, because they've all been trained to treat the need to<br/>present as a given — as an area of fixed size, over which however much truth<br/>they have must needs be spread, however thinly.  <br/>  <br/>The time to raise money is not when you need it, or when you reach some<br/>artificial deadline like a Demo Day. It's when you can convince investors, and<br/>not before. [7]  <br/>  <br/>And unless you're a good con artist, you'll never convince investors if you're<br/>not convinced yourself. They're far better at detecting bullshit than you are<br/>at producing it, even if you're producing it unknowingly. If you try to<br/>convince investors before you've convinced yourself, you'll be wasting both<br/>your time.  <br/>  <br/>But pausing first to convince yourself will do more than save you from wasting<br/>your time. It will force you to organize your thoughts. To convince yourself<br/>that your startup is worth investing in, you'll have to figure out why it's<br/>worth investing in. And if you can do that you'll end up with more than added<br/>confidence. You'll also have a provisional roadmap of how to succeed.  <br/>  <br/> **Market**  <br/>  <br/>Notice I've been careful to talk about whether a startup is worth investing<br/>in, rather than whether it's going to succeed. No one knows whether a startup<br/>is going to succeed. And it's a good thing for investors that this is so,<br/>because if you could know in advance whether a startup would succeed, the<br/>stock price would already be the future price, and there would be no room for<br/>investors to make money. Startup investors know that every investment is a<br/>bet, and against pretty long odds.  <br/>  <br/>So to prove you're worth investing in, you don't have to prove you're going to<br/>succeed, just that you're a sufficiently good bet. What makes a startup a<br/>sufficiently good bet? In addition to formidable founders, you need a<br/>plausible path to owning a big piece of a big market. Founders think of<br/>startups as ideas, but investors think of them as markets. If there are x<br/>number of customers who'd pay an average of $y per year for what you're<br/>making, then the total addressable market, or TAM, of your company is $xy.<br/>Investors don't expect you to collect all that money, but it's an upper bound<br/>on how big you can get.  <br/>  <br/>Your target market has to be big, and it also has to be capturable by you. But<br/>the market doesn't have to be big yet, nor do you necessarily have to be in it<br/>yet. Indeed, it's often better to start in a small market that will either<br/>turn into a big one or from which you can move into a big one. There just has<br/>to be some plausible sequence of hops that leads to dominating a big market a<br/>few years down the line.  <br/>  <br/>The standard of plausibility varies dramatically depending on the age of the<br/>startup. A three month old company at Demo Day only needs to be a promising<br/>experiment that's worth funding to see how it turns out. Whereas a two year<br/>old company raising a series A round needs to be able to show the experiment<br/>worked. [8]  <br/>  <br/>But every company that gets really big is "lucky" in the sense that their<br/>growth is due mostly to some external wave they're riding, so to make a<br/>convincing case for becoming huge, you have to identify some specific trend<br/>you'll benefit from. Usually you can find this by asking "why now?" If this is<br/>such a great idea, why hasn't someone else already done it? Ideally the answer<br/>is that it only recently became a good idea, because something changed, and no<br/>one else has noticed yet.  <br/>  <br/>Microsoft for example was not going to grow huge selling Basic interpreters.<br/>But by starting there they were perfectly poised to expand up the stack of<br/>microcomputer software as microcomputers grew powerful enough to support one.<br/>And microcomputers turned out to be a really huge wave, bigger than even the<br/>most optimistic observers would have predicted in 1975.  <br/>  <br/>But while Microsoft did really well and there is thus a temptation to think<br/>they would have seemed a great bet a few months in, they probably didn't.<br/>Good, but not great. No company, however successful, ever looks more than a<br/>pretty good bet a few months in. Microcomputers turned out to be a big deal,<br/>and Microsoft both executed well and got lucky. But it was by no means obvious<br/>that this was how things would play out. Plenty of companies seem as good a<br/>bet a few months in. I don't know about startups in general, but at least half<br/>the startups we fund could make as good a case as Microsoft could have for<br/>being on a path to dominating a large market. And who can reasonably expect<br/>more of a startup than that?  <br/>  <br/> **Rejection**  <br/>  <br/>If you can make as good a case as Microsoft could have, will you convince<br/>investors? Not always. A lot of VCs would have rejected Microsoft. [9]<br/>Certainly some rejected Google. And getting rejected will put you in a<br/>slightly awkward position, because as you'll see when you start fundraising,<br/>the most common question you'll get from investors will be "who else is<br/>investing?" What do you say if you've been fundraising for a while and no one<br/>has committed yet? [10]  <br/>  <br/>The people who are really good at acting formidable often solve this problem<br/>by giving investors the impression that while no investors have committed yet,<br/>several are about to. This is arguably a permissible tactic. It's slightly<br/>dickish of investors to care more about who else is investing than any other<br/>aspect of your startup, and misleading them about how far along you are with<br/>other investors seems the complementary countermove. It's arguably an instance<br/>of scamming a scammer. But I don't recommend this approach to most founders,<br/>because most founders wouldn't be able to carry it off. This is the single<br/>most common lie told to investors, and you have to be really good at lying to<br/>tell members of some profession the most common lie they're told.  <br/>  <br/>If you're not a master of negotiation (and perhaps even if you are) the best<br/>solution is to tackle the problem head-on, and to explain why investors have<br/>turned you down and why they're mistaken. If you know you're on the right<br/>track, then you also know why investors were wrong to reject you. Experienced<br/>investors are well aware that the best ideas are also the scariest. They all<br/>know about the VCs who rejected Google. If instead of seeming evasive and<br/>ashamed about having been turned down (and thereby implicitly agreeing with<br/>the verdict) you talk candidly about what scared investors about you, you'll<br/>seem more confident, which they like, and you'll probably also do a better job<br/>of presenting that aspect of your startup. At the very least, that worry will<br/>now be out in the open instead of being a gotcha left to be discovered by the<br/>investors you're currently talking to, who will be proud of and thus attached<br/>to their discovery. [11]  <br/>  <br/>This strategy will work best with the best investors, who are both hard to<br/>bluff and who already believe most other investors are conventional-minded<br/>drones doomed always to miss the big outliers. Raising money is not like<br/>applying to college, where you can assume that if you can get into MIT, you<br/>can also get into Foobar State. Because the best investors are much smarter<br/>than the rest, and the best startup ideas look initially like bad ideas, it's<br/>not uncommon for a startup to be rejected by all the VCs except the best ones.<br/>That's what happened to Dropbox. Y Combinator started in Boston, and for the<br/>first 3 years we ran alternating batches in Boston and Silicon Valley. Because<br/>Boston investors were so few and so timid, we used to ship Boston batches out<br/>for a second Demo Day in Silicon Valley. Dropbox was part of a Boston batch,<br/>which means all those Boston investors got the first look at Dropbox, and none<br/>of them closed the deal. Yet another backup and syncing thing, they all<br/>thought. A couple weeks later, Dropbox raised a series A round from Sequoia.<br/>[12]  <br/>  <br/> **Different**  <br/>  <br/>Not understanding that investors view investments as bets combines with the<br/>ten page paper mentality to prevent founders from even considering the<br/>possibility of being certain of what they're saying. They think they're trying<br/>to convince investors of something very uncertain — that their startup will be<br/>huge — and convincing anyone of something like that must obviously entail some<br/>wild feat of salesmanship. But in fact when you raise money you're trying to<br/>convince investors of something so much less speculative — whether the company<br/>has all the elements of a good bet — that you can approach the problem in a<br/>qualitatively different way. You can convince yourself, then convince them.  <br/>  <br/>And when you convince them, use the same matter-of-fact language you used to<br/>convince yourself. You wouldn't use vague, grandiose marketing-speak among<br/>yourselves. Don't use it with investors either. It not only doesn't work on<br/>them, but seems a mark of incompetence. Just be concise. Many investors<br/>explicitly use that as a test, reasoning (correctly) that if you can't explain<br/>your plans concisely, you don't really understand them. But even investors who<br/>don't have a rule about this will be bored and frustrated by unclear<br/>explanations. [13]  <br/>  <br/>So here's the recipe for impressing investors when you're not already good at<br/>seeming formidable:<br/><br/>  1. Make something worth investing in.  <br/>  <br/><br/>  2. Understand why it's worth investing in.  <br/>  <br/><br/>  3. Explain that clearly to investors. <br/><br/>If you're saying something you know is true, you'll seem confident when you're<br/>saying it. Conversely, never let pitching draw you into bullshitting. As long<br/>as you stay on the territory of truth, you're strong. Make the truth good,<br/>then just tell it.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] There's no reason to believe this number is a constant. In fact it's our<br/>explicit goal at Y Combinator to increase it, by encouraging people to start<br/>startups who otherwise wouldn't have.  <br/>  <br/>[2] Or more precisely, investors decide whether you're a loser or possibly a<br/>winner. If you seem like a winner, they may then, depending on how much you're<br/>raising, have several more meetings with you to test whether that initial<br/>impression holds up.  <br/>  <br/>But if you seem like a loser they're done, at least for the next year or so.<br/>And when they decide you're a loser they usually decide in way less than the<br/>50 minutes they may have allotted for the first meeting. Which explains the<br/>astonished stories one always hears about VC inattentiveness. How could these<br/>people make investment decisions well when they're checking their messages<br/>during startups' presentations? The solution to that mystery is that they've<br/>already made the decision.  <br/>  <br/>[3] The two are not mutually exclusive. There are people who are both<br/>genuinely formidable, and also really good at acting that way.  <br/>  <br/>[4] How can people who will go on to create giant companies not seem<br/>formidable early on? I think the main reason is that their experience so far<br/>has trained them to keep their wings folded, as it were. Family, school, and<br/>jobs encourage cooperation, not conquest. And it's just as well they do,<br/>because even being Genghis Khan is probably 99% cooperation. But the result is<br/>that most people emerge from the tube of their upbringing in their early<br/>twenties compressed into the shape of the tube. Some find they have wings and<br/>start to spread them. But this takes a few years. In the beginning even they<br/>don't know yet what they're capable of.  <br/>  <br/>[5] In fact, change what you're doing. You're investing your own time in your<br/>startup. If you're not convinced that what you're working on is a sufficiently<br/>good bet, why are you even working on that?  <br/>  <br/>[6] When investors ask you a question you don't know the answer to, the best<br/>response is neither to bluff nor give up, but instead to explain how you'd<br/>figure out the answer. If you can work out a preliminary answer on the spot,<br/>so much the better, but explain that's what you're doing.  <br/>  <br/>[7] At YC we try to ensure startups are ready to raise money on Demo Day by<br/>encouraging them to ignore investors and instead focus on their companies till<br/>about a week before. That way most reach the stage where they're sufficiently<br/>convincing well before Demo Day. But not all do, so we also give any startup<br/>that wants to the option of deferring to a later Demo Day.  <br/>  <br/>[8] Founders are often surprised by how much harder it is to raise the next<br/>round. There is a qualitative difference in investors' attitudes. It's like<br/>the difference between being judged as a kid and as an adult. The next time<br/>you raise money, it's not enough to be promising. You have to be delivering<br/>results.  <br/>  <br/>So although it works well to show growth graphs at either stage, investors<br/>treat them differently. At three months, a growth graph is mostly evidence<br/>that the founders are effective. At two years, it has to be evidence of a<br/>promising market and a company tuned to exploit it.  <br/>  <br/>[9] By this I mean that if the present day equivalent of the 3 month old<br/>Microsoft presented at a Demo Day, there would be investors who turned them<br/>down. Microsoft itself didn't raise outside money, and indeed the venture<br/>business barely existed when they got started in 1975.  <br/>  <br/>[10] The best investors rarely care who else is investing, but mediocre<br/>investors almost all do. So you can use this question as a test of investor<br/>quality.  <br/>  <br/>[11] To use this technique, you'll have to find out why investors who rejected<br/>you did so, or at least what they claim was the reason. That may require<br/>asking, because investors don't always volunteer a lot of detail. Make it<br/>clear when you ask that you're not trying to dispute their decision — just<br/>that if there is some weakness in your plans, you need to know about it. You<br/>won't always get a real reason out of them, but you should at least try.  <br/>  <br/>[12] Dropbox wasn't rejected by all the East Coast VCs. There was one firm<br/>that wanted to invest but tried to lowball them.  <br/>  <br/>[13] Alfred Lin points out that it's doubly important for the explanation of a<br/>startup to be clear and concise, because it has to convince at one remove: it<br/>has to work not just on the partner you talk to, but when that partner re-<br/>tells it to colleagues.  <br/>  <br/>We consciously optimize for this at YC. When we work with founders create a<br/>Demo Day pitch, the last step is to imagine how an investor would sell it to<br/>colleagues.  <br/>  <br/>**Thanks** to Marc Andreessen, Sam Altman, Patrick Collison, Ron Conway, Chris<br/>Dixon, Alfred Lin, Ben Horowitz, Steve Huffman, Jessica Livingston, Greg<br/>Mcadoo, Andrew Mason, Geoff Ralston, Yuri Sagalov, Emmett Shear, Rajat Suri,<br/>Garry Tan, Albert Wenger, Fred Wilson, and Qasar Younis for reading drafts of<br/>this.  <br/>  <br/>  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>January 2016  <br/>  <br/>Life is short, as everyone knows. When I was a kid I used to wonder about<br/>this. Is life actually short, or are we really complaining about its<br/>finiteness? Would we be just as likely to feel life was short if we lived 10<br/>times as long?  <br/>  <br/>Since there didn't seem any way to answer this question, I stopped wondering<br/>about it. Then I had kids. That gave me a way to answer the question, and the<br/>answer is that life actually is short.  <br/>  <br/>Having kids showed me how to convert a continuous quantity, time, into<br/>discrete quantities. You only get 52 weekends with your 2 year old. If<br/>Christmas-as-magic lasts from say ages 3 to 10, you only get to watch your<br/>child experience it 8 times. And while it's impossible to say what is a lot or<br/>a little of a continuous quantity like time, 8 is not a lot of something. If<br/>you had a handful of 8 peanuts, or a shelf of 8 books to choose from, the<br/>quantity would definitely seem limited, no matter what your lifespan was.  <br/>  <br/>Ok, so life actually is short. Does it make any difference to know that?  <br/>  <br/>It has for me. It means arguments of the form "Life is too short for x" have<br/>great force. It's not just a figure of speech to say that life is too short<br/>for something. It's not just a synonym for annoying. If you find yourself<br/>thinking that life is too short for something, you should try to eliminate it<br/>if you can.  <br/>  <br/>When I ask myself what I've found life is too short for, the word that pops<br/>into my head is "bullshit." I realize that answer is somewhat tautological.<br/>It's almost the definition of bullshit that it's the stuff that life is too<br/>short for. And yet bullshit does have a distinctive character. There's<br/>something fake about it. It's the junk food of experience. [1]  <br/>  <br/>If you ask yourself what you spend your time on that's bullshit, you probably<br/>already know the answer. Unnecessary meetings, pointless disputes,<br/>bureaucracy, posturing, dealing with other people's mistakes, traffic jams,<br/>addictive but unrewarding pastimes.  <br/>  <br/>There are two ways this kind of thing gets into your life: it's either forced<br/>on you, or it tricks you. To some extent you have to put up with the bullshit<br/>forced on you by circumstances. You need to make money, and making money<br/>consists mostly of errands. Indeed, the law of supply and demand insures that:<br/>the more rewarding some kind of work is, the cheaper people will do it. It may<br/>be that less bullshit is forced on you than you think, though. There has<br/>always been a stream of people who opt out of the default grind and go live<br/>somewhere where opportunities are fewer in the conventional sense, but life<br/>feels more authentic. This could become more common.  <br/>  <br/>You can do it on a smaller scale without moving. The amount of time you have<br/>to spend on bullshit varies between employers. Most large organizations (and<br/>many small ones) are steeped in it. But if you consciously prioritize bullshit<br/>avoidance over other factors like money and prestige, you can probably find<br/>employers that will waste less of your time.  <br/>  <br/>If you're a freelancer or a small company, you can do this at the level of<br/>individual customers. If you fire or avoid toxic customers, you can decrease<br/>the amount of bullshit in your life by more than you decrease your income.  <br/>  <br/>But while some amount of bullshit is inevitably forced on you, the bullshit<br/>that sneaks into your life by tricking you is no one's fault but your own. And<br/>yet the bullshit you choose may be harder to eliminate than the bullshit<br/>that's forced on you. Things that lure you into wasting your time have to be<br/>really good at tricking you. An example that will be familiar to a lot of<br/>people is arguing online. When someone contradicts you, they're in a sense<br/>attacking you. Sometimes pretty overtly. Your instinct when attacked is to<br/>defend yourself. But like a lot of instincts, this one wasn't designed for the<br/>world we now live in. Counterintuitive as it feels, it's better most of the<br/>time not to defend yourself. Otherwise these people are literally taking your<br/>life. [2]  <br/>  <br/>Arguing online is only incidentally addictive. There are more dangerous things<br/>than that. As I've written before, one byproduct of technical progress is that<br/>things we like tend to become _more addictive_. Which means we will<br/>increasingly have to make a conscious effort to avoid addictions  to stand<br/>outside ourselves and ask "is this how I want to be spending my time?"  <br/>  <br/>As well as avoiding bullshit, one should actively seek out things that matter.<br/>But different things matter to different people, and most have to learn what<br/>matters to them. A few are lucky and realize early on that they love math or<br/>taking care of animals or writing, and then figure out a way to spend a lot of<br/>time doing it. But most people start out with a life that's a mix of things<br/>that matter and things that don't, and only gradually learn to distinguish<br/>between them.  <br/>  <br/>For the young especially, much of this confusion is induced by the artificial<br/>situations they find themselves in. In middle school and high school, what the<br/>other kids think of you seems the most important thing in the world. But when<br/>you ask adults what they got wrong at that age, nearly all say they cared too<br/>much what other kids thought of them.  <br/>  <br/>One heuristic for distinguishing stuff that matters is to ask yourself whether<br/>you'll care about it in the future. Fake stuff that matters usually has a<br/>sharp peak of seeming to matter. That's how it tricks you. The area under the<br/>curve is small, but its shape jabs into your consciousness like a pin.  <br/>  <br/>The things that matter aren't necessarily the ones people would call<br/>"important." Having coffee with a friend matters. You won't feel later like<br/>that was a waste of time.  <br/>  <br/>One great thing about having small children is that they make you spend time<br/>on things that matter: them. They grab your sleeve as you're staring at your<br/>phone and say "will you play with me?" And odds are that is in fact the<br/>bullshit-minimizing option.  <br/>  <br/>If life is short, we should expect its shortness to take us by surprise. And<br/>that is just what tends to happen. You take things for granted, and then<br/>they're gone. You think you can always write that book, or climb that<br/>mountain, or whatever, and then you realize the window has closed. The saddest<br/>windows close when other people die. Their lives are short too. After my<br/>mother died, I wished I'd spent more time with her. I lived as if she'd always<br/>be there. And in her typical quiet way she encouraged that illusion. But an<br/>illusion it was. I think a lot of people make the same mistake I did.  <br/>  <br/>The usual way to avoid being taken by surprise by something is to be<br/>consciously aware of it. Back when life was more precarious, people used to be<br/>aware of death to a degree that would now seem a bit morbid. I'm not sure why,<br/>but it doesn't seem the right answer to be constantly reminding oneself of the<br/>grim reaper hovering at everyone's shoulder. Perhaps a better solution is to<br/>look at the problem from the other end. Cultivate a habit of impatience about<br/>the things you most want to do. Don't wait before climbing that mountain or<br/>writing that book or visiting your mother. You don't need to be constantly<br/>reminding yourself why you shouldn't wait. Just don't wait.  <br/>  <br/>I can think of two more things one does when one doesn't have much of<br/>something: try to get more of it, and savor what one has. Both make sense<br/>here.  <br/>  <br/>How you live affects how long you live. Most people could do better. Me among<br/>them.  <br/>  <br/>But you can probably get even more effect by paying closer attention to the<br/>time you have. It's easy to let the days rush by. The "flow" that imaginative<br/>people love so much has a darker cousin that prevents you from pausing to<br/>savor life amid the daily slurry of errands and alarms. One of the most<br/>striking things I've read was not in a book, but the title of one: James<br/>Salter's _Burning the Days_.  <br/>  <br/>It is possible to slow time somewhat. I've gotten better at it. Kids help.<br/>When you have small children, there are a lot of moments so perfect that you<br/>can't help noticing.  <br/>  <br/>It does help too to feel that you've squeezed everything out of some<br/>experience. The reason I'm sad about my mother is not just that I miss her but<br/>that I think of all the things we could have done that we didn't. My oldest<br/>son will be 7 soon. And while I miss the 3 year old version of him, I at least<br/>don't have any regrets over what might have been. We had the best time a daddy<br/>and a 3 year old ever had.  <br/>  <br/>Relentlessly prune bullshit, don't wait to do things that matter, and savor<br/>the time you have. That's what you do when life is short.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] At first I didn't like it that the word that came to mind was one that had<br/>other meanings. But then I realized the other meanings are fairly closely<br/>related. Bullshit in the sense of things you waste your time on is a lot like<br/>intellectual bullshit.  <br/>  <br/>[2] I chose this example deliberately as a note to self. I get attacked a lot<br/>online. People tell the craziest lies about me. And I have so far done a<br/>pretty mediocre job of suppressing the natural human inclination to say "Hey,<br/>that's not true!"  <br/>  <br/> **Thanks** to Jessica Livingston and Geoff Ralston for reading drafts of<br/>this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>September 2004  <br/>  <br/>Remember the essays you had to write in high school? Topic sentence,<br/>introductory paragraph, supporting paragraphs, conclusion. The conclusion<br/>being, say, that Ahab in _Moby Dick_ was a Christ-like figure.  <br/>  <br/>Oy. So I'm going to try to give the other side of the story: what an essay<br/>really is, and how you write one. Or at least, how I write one.  <br/>  <br/> **Mods**  <br/>  <br/>The most obvious difference between real essays and the things one has to<br/>write in school is that real essays are not exclusively about English<br/>literature. Certainly schools should teach students how to write. But due to a<br/>series of historical accidents the teaching of writing has gotten mixed<br/>together with the study of literature. And so all over the country students<br/>are writing not about how a baseball team with a small budget might compete<br/>with the Yankees, or the role of color in fashion, or what constitutes a good<br/>dessert, but about symbolism in Dickens.  <br/>  <br/>With the result that writing is made to seem boring and pointless. Who cares<br/>about symbolism in Dickens? Dickens himself would be more interested in an<br/>essay about color or baseball.  <br/>  <br/>How did things get this way? To answer that we have to go back almost a<br/>thousand years. Around 1100, Europe at last began to catch its breath after<br/>centuries of chaos, and once they had the luxury of curiosity they<br/>rediscovered what we call "the classics." The effect was rather as if we were<br/>visited by beings from another solar system. These earlier civilizations were<br/>so much more sophisticated that for the next several centuries the main work<br/>of European scholars, in almost every field, was to assimilate what they knew.  <br/>  <br/>During this period the study of ancient texts acquired great prestige. It<br/>seemed the essence of what scholars did. As European scholarship gained<br/>momentum it became less and less important; by 1350 someone who wanted to<br/>learn about science could find better teachers than Aristotle in his own era.<br/>[1] But schools change slower than scholarship. In the 19th century the study<br/>of ancient texts was still the backbone of the curriculum.  <br/>  <br/>The time was then ripe for the question: if the study of ancient texts is a<br/>valid field for scholarship, why not modern texts? The answer, of course, is<br/>that the original raison d'etre of classical scholarship was a kind of<br/>intellectual archaeology that does not need to be done in the case of<br/>contemporary authors. But for obvious reasons no one wanted to give that<br/>answer. The archaeological work being mostly done, it implied that those<br/>studying the classics were, if not wasting their time, at least working on<br/>problems of minor importance.  <br/>  <br/>And so began the study of modern literature. There was a good deal of<br/>resistance at first. The first courses in English literature seem to have been<br/>offered by the newer colleges, particularly American ones. Dartmouth, the<br/>University of Vermont, Amherst, and University College, London taught English<br/>literature in the 1820s.  But Harvard didn't have a professor of English<br/>literature until 1876, and Oxford not till 1885. (Oxford had a chair of<br/>Chinese before it had one of English.) [2]  <br/>  <br/>What tipped the scales, at least in the US, seems to have been the idea that<br/>professors should do research as well as teach. This idea (along with the PhD,<br/>the department, and indeed the whole concept of the modern university) was<br/>imported from Germany in the late 19th century. Beginning at Johns Hopkins in<br/>1876, the new model spread rapidly.  <br/>  <br/>Writing was one of the casualties. Colleges had long taught English<br/>composition. But how do you do research on composition? The professors who<br/>taught math could be required to do original math, the professors who taught<br/>history could be required to write scholarly articles about history, but what<br/>about the professors who taught rhetoric or composition? What should they do<br/>research on? The closest thing seemed to be English literature. [3]  <br/>  <br/>And so in the late 19th century the teaching of writing was inherited by<br/>English professors. This had two drawbacks: (a) an expert on literature need<br/>not himself be a good writer, any more than an art historian has to be a good<br/>painter, and (b) the subject of writing now tends to be literature, since<br/>that's what the professor is interested in.  <br/>  <br/>High schools imitate universities. The seeds of our miserable high school<br/>experiences were sown in 1892, when the National Education Association<br/>"formally recommended that literature and composition be unified in the high<br/>school course." [4] The 'riting component of the 3 Rs then morphed into<br/>English, with the bizarre consequence that high school students now had to<br/>write about English literature-- to write, without even realizing it,<br/>imitations of whatever English professors had been publishing in their<br/>journals a few decades before.  <br/>  <br/>It's no wonder if this seems to the student a pointless exercise, because<br/>we're now three steps removed from real work: the students are imitating<br/>English professors, who are imitating classical scholars, who are merely the<br/>inheritors of a tradition growing out of what was, 700 years ago, fascinating<br/>and urgently needed work.  <br/>  <br/> **No Defense**  <br/>  <br/>The other big difference between a real essay and the things they make you<br/>write in school is that a real essay doesn't take a position and then defend<br/>it. That principle, like the idea that we ought to be writing about<br/>literature, turns out to be another intellectual hangover of long forgotten<br/>origins.  <br/>  <br/>It's often mistakenly believed that medieval universities were mostly<br/>seminaries. In fact they were more law schools. And at least in our tradition<br/>lawyers are advocates, trained to take either side of an argument and make as<br/>good a case for it as they can. Whether cause or effect, this spirit pervaded<br/>early universities. The study of rhetoric, the art of arguing persuasively,<br/>was a third of the undergraduate curriculum. [5] And after the lecture the<br/>most common form of discussion was the disputation. This is at least nominally<br/>preserved in our present-day thesis defense: most people treat the words<br/>thesis and dissertation as interchangeable, but originally, at least, a thesis<br/>was a position one took and the dissertation was the argument by which one<br/>defended it.  <br/>  <br/>Defending a position may be a necessary evil in a legal dispute, but it's not<br/>the best way to get at the truth, as I think lawyers would be the first to<br/>admit. It's not just that you miss subtleties this way. The real problem is<br/>that you can't change the question.  <br/>  <br/>And yet this principle is built into the very structure of the things they<br/>teach you to write in high school. The topic sentence is your thesis, chosen<br/>in advance, the supporting paragraphs the blows you strike in the conflict,<br/>and the conclusion-- uh, what is the conclusion? I was never sure about that<br/>in high school. It seemed as if we were just supposed to restate what we said<br/>in the first paragraph, but in different enough words that no one could tell.<br/>Why bother? But when you understand the origins of this sort of "essay," you<br/>can see where the conclusion comes from. It's the concluding remarks to the<br/>jury.  <br/>  <br/>Good writing should be convincing, certainly, but it should be convincing<br/>because you got the right answers, not because you did a good job of arguing.<br/>When I give a draft of an essay to friends, there are two things I want to<br/>know: which parts bore them, and which seem unconvincing. The boring bits can<br/>usually be fixed by cutting. But I don't try to fix the unconvincing bits by<br/>arguing more cleverly. I need to talk the matter over.  <br/>  <br/>At the very least I must have explained something badly. In that case, in the<br/>course of the conversation I'll be forced to come up a with a clearer<br/>explanation, which I can just incorporate in the essay. More often than not I<br/>have to change what I was saying as well. But the aim is never to be<br/>convincing per se. As the reader gets smarter, convincing and true become<br/>identical, so if I can convince smart readers I must be near the truth.  <br/>  <br/>The sort of writing that attempts to persuade may be a valid (or at least<br/>inevitable) form, but it's historically inaccurate to call it an essay. An<br/>essay is something else.  <br/>  <br/> **Trying**  <br/>  <br/>To understand what a real essay is, we have to reach back into history again,<br/>though this time not so far. To Michel de Montaigne, who in 1580 published a<br/>book of what he called "essais." He was doing something quite different from<br/>what lawyers do, and the difference is embodied in the name. _Essayer_ is the<br/>French verb meaning "to try" and an _essai_ is an attempt. An essay is<br/>something you write to try to figure something out.  <br/>  <br/>Figure out what? You don't know yet. And so you can't begin with a thesis,<br/>because you don't have one, and may never have one. An essay doesn't begin<br/>with a statement, but with a question. In a real essay, you don't take a<br/>position and defend it. You notice a door that's ajar, and you open it and<br/>walk in to see what's inside.  <br/>  <br/>If all you want to do is figure things out, why do you need to write anything,<br/>though? Why not just sit and think? Well, there precisely is Montaigne's great<br/>discovery. Expressing ideas helps to form them. Indeed, helps is far too weak<br/>a word. Most of what ends up in my essays I only thought of when I sat down to<br/>write them. That's why I write them.  <br/>  <br/>In the things you write in school you are, in theory, merely explaining<br/>yourself to the reader. In a real essay you're writing for yourself. You're<br/>thinking out loud.  <br/>  <br/>But not quite. Just as inviting people over forces you to clean up your<br/>apartment, writing something that other people will read forces you to think<br/>well. So it does matter to have an audience. The things I've written just for<br/>myself are no good. They tend to peter out. When I run into difficulties, I<br/>find I conclude with a few vague questions and then drift off to get a cup of<br/>tea.  <br/>  <br/>Many published essays peter out in the same way. Particularly the sort written<br/>by the staff writers of newsmagazines. Outside writers tend to supply<br/>editorials of the defend-a-position variety, which make a beeline toward a<br/>rousing (and foreordained) conclusion. But the staff writers feel obliged to<br/>write something "balanced." Since they're writing for a popular magazine, they<br/>start with the most radioactively controversial questions, from which--<br/>because they're writing for a popular magazine-- they then proceed to recoil<br/>in terror. Abortion, for or against? This group says one thing. That group<br/>says another. One thing is certain: the question is a complex one. (But don't<br/>get mad at us. We didn't draw any conclusions.)  <br/>  <br/> **The River**  <br/>  <br/>Questions aren't enough. An essay has to come up with answers. They don't<br/>always, of course. Sometimes you start with a promising question and get<br/>nowhere. But those you don't publish. Those are like experiments that get<br/>inconclusive results. An essay you publish ought to tell the reader something<br/>he didn't already know.  <br/>  <br/>But _what_ you tell him doesn't matter, so long as it's interesting. I'm<br/>sometimes accused of meandering. In defend-a-position writing that would be a<br/>flaw. There you're not concerned with truth. You already know where you're<br/>going, and you want to go straight there, blustering through obstacles, and<br/>hand-waving your way across swampy ground. But that's not what you're trying<br/>to do in an essay. An essay is supposed to be a search for truth. It would be<br/>suspicious if it didn't meander.  <br/>  <br/>The Meander (aka Menderes) is a river in Turkey. As you might expect, it winds<br/>all over the place. But it doesn't do this out of frivolity. The path it has<br/>discovered is the most economical route to the sea. [6]  <br/>  <br/>The river's algorithm is simple. At each step, flow down. For the essayist<br/>this translates to: flow interesting. Of all the places to go next, choose the<br/>most interesting. One can't have quite as little foresight as a river. I<br/>always know generally what I want to write about. But not the specific<br/>conclusions I want to reach; from paragraph to paragraph I let the ideas take<br/>their course.  <br/>  <br/>This doesn't always work. Sometimes, like a river, one runs up against a wall.<br/>Then I do the same thing the river does: backtrack. At one point in this essay<br/>I found that after following a certain thread I ran out of ideas. I had to go<br/>back seven paragraphs and start over in another direction.  <br/>  <br/>Fundamentally an essay is a train of thought-- but a cleaned-up train of<br/>thought, as dialogue is cleaned-up conversation. Real thought, like real<br/>conversation, is full of false starts. It would be exhausting to read. You<br/>need to cut and fill to emphasize the central thread, like an illustrator<br/>inking over a pencil drawing. But don't change so much that you lose the<br/>spontaneity of the original.  <br/>  <br/>Err on the side of the river. An essay is not a reference work. It's not<br/>something you read looking for a specific answer, and feel cheated if you<br/>don't find it. I'd much rather read an essay that went off in an unexpected<br/>but interesting direction than one that plodded dutifully along a prescribed<br/>course.  <br/>  <br/> **Surprise**  <br/>  <br/>So what's interesting? For me, interesting means surprise. Interfaces, as<br/>Geoffrey James has said, should follow the principle of least astonishment. A<br/>button that looks like it will make a machine stop should make it stop, not<br/>speed up. Essays should do the opposite. Essays should aim for maximum<br/>surprise.  <br/>  <br/>I was afraid of flying for a long time and could only travel vicariously. When<br/>friends came back from faraway places, it wasn't just out of politeness that I<br/>asked what they saw. I really wanted to know. And I found the best way to get<br/>information out of them was to ask what surprised them. How was the place<br/>different from what they expected? This is an extremely useful question. You<br/>can ask it of the most unobservant people, and it will extract information<br/>they didn't even know they were recording.  <br/>  <br/>Surprises are things that you not only didn't know, but that contradict things<br/>you thought you knew. And so they're the most valuable sort of fact you can<br/>get. They're like a food that's not merely healthy, but counteracts the<br/>unhealthy effects of things you've already eaten.  <br/>  <br/>How do you find surprises? Well, therein lies half the work of essay writing.<br/>(The other half is expressing yourself well.) The trick is to use yourself as<br/>a proxy for the reader. You should only write about things you've thought<br/>about a lot. And anything you come across that surprises you, who've thought<br/>about the topic a lot, will probably surprise most readers.  <br/>  <br/>For example, in a recent essay I pointed out that because you can only judge<br/>computer programmers by working with them, no one knows who the best<br/>programmers are overall. I didn't realize this when I began that essay, and<br/>even now I find it kind of weird. That's what you're looking for.  <br/>  <br/>So if you want to write essays, you need two ingredients: a few topics you've<br/>thought about a lot, and some ability to ferret out the unexpected.  <br/>  <br/>What should you think about? My guess is that it doesn't matter-- that<br/>anything can be interesting if you get deeply enough into it. One possible<br/>exception might be things that have deliberately had all the variation sucked<br/>out of them, like working in fast food. In retrospect, was there anything<br/>interesting about working at Baskin-Robbins? Well, it was interesting how<br/>important color was to the customers. Kids a certain age would point into the<br/>case and say that they wanted yellow. Did they want French Vanilla or Lemon?<br/>They would just look at you blankly. They wanted yellow. And then there was<br/>the mystery of why the perennial favorite Pralines 'n' Cream was so appealing.<br/>(I think now it was the salt.)  And the difference in the way fathers and<br/>mothers bought ice cream for their kids: the fathers like benevolent kings<br/>bestowing largesse, the mothers harried, giving in to pressure. So, yes, there<br/>does seem to be some material even in fast food.  <br/>  <br/>I didn't notice those things at the time, though. At sixteen I was about as<br/>observant as a lump of rock. I can see more now in the fragments of memory I<br/>preserve of that age than I could see at the time from having it all happening<br/>live, right in front of me.  <br/>  <br/> **Observation**  <br/>  <br/>So the ability to ferret out the unexpected must not merely be an inborn one.<br/>It must be something you can learn. How do you learn it?  <br/>  <br/>To some extent it's like learning history. When you first read history, it's<br/>just a whirl of names and dates. Nothing seems to stick. But the more you<br/>learn, the more hooks you have for new facts to stick onto-- which means you<br/>accumulate knowledge at an exponential rate. Once you remember that Normans<br/>conquered England in 1066, it will catch your attention when you hear that<br/>other Normans conquered southern Italy at about the same time. Which will make<br/>you wonder about Normandy, and take note when a third book mentions that<br/>Normans were not, like most of what is now called France, tribes that flowed<br/>in as the Roman empire collapsed, but Vikings (norman = north man) who arrived<br/>four centuries later in 911. Which makes it easier to remember that Dublin was<br/>also established by Vikings in the 840s. Etc, etc squared.  <br/>  <br/>Collecting surprises is a similar process. The more anomalies you've seen, the<br/>more easily you'll notice new ones. Which means, oddly enough, that as you<br/>grow older, life should become more and more surprising. When I was a kid, I<br/>used to think adults had it all figured out. I had it backwards. Kids are the<br/>ones who have it all figured out. They're just mistaken.  <br/>  <br/>When it comes to surprises, the rich get richer. But (as with wealth) there<br/>may be habits of mind that will help the process along. It's good to have a<br/>habit of asking questions, especially questions beginning with Why. But not in<br/>the random way that three year olds ask why. There are an infinite number of<br/>questions. How do you find the fruitful ones?  <br/>  <br/>I find it especially useful to ask why about things that seem wrong. For<br/>example, why should there be a connection between humor and misfortune? Why do<br/>we find it funny when a character, even one we like, slips on a banana peel?<br/>There's a whole essay's worth of surprises there for sure.  <br/>  <br/>If you want to notice things that seem wrong, you'll find a degree of<br/>skepticism helpful. I take it as an axiom that we're only achieving 1% of what<br/>we could. This helps counteract the rule that gets beaten into our heads as<br/>children: that things are the way they are because that is how things have to<br/>be. For example, everyone I've talked to while writing this essay felt the<br/>same about English classes-- that the whole process seemed pointless. But none<br/>of us had the balls at the time to hypothesize that it was, in fact, all a<br/>mistake. We all thought there was just something we weren't getting.  <br/>  <br/>I have a hunch you want to pay attention not just to things that seem wrong,<br/>but things that seem wrong in a humorous way. I'm always pleased when I see<br/>someone laugh as they read a draft of an essay. But why should I be? I'm<br/>aiming for good ideas. Why should good ideas be funny? The connection may be<br/>surprise. Surprises make us laugh, and surprises are what one wants to<br/>deliver.  <br/>  <br/>I write down things that surprise me in notebooks. I never actually get around<br/>to reading them and using what I've written, but I do tend to reproduce the<br/>same thoughts later. So the main value of notebooks may be what writing things<br/>down leaves in your head.  <br/>  <br/>People trying to be cool will find themselves at a disadvantage when<br/>collecting surprises. To be surprised is to be mistaken. And the essence of<br/>cool, as any fourteen year old could tell you, is _nil admirari._ When you're<br/>mistaken, don't dwell on it; just act like nothing's wrong and maybe no one<br/>will notice.  <br/>  <br/>One of the keys to coolness is to avoid situations where inexperience may make<br/>you look foolish. If you want to find surprises you should do the opposite.<br/>Study lots of different things, because some of the most interesting surprises<br/>are unexpected connections between different fields. For example, jam, bacon,<br/>pickles, and cheese, which are among the most pleasing of foods, were all<br/>originally intended as methods of preservation. And so were books and<br/>paintings.  <br/>  <br/>Whatever you study, include history-- but social and economic history, not<br/>political history. History seems to me so important that it's misleading to<br/>treat it as a mere field of study. Another way to describe it is _all the data<br/>we have so far._  <br/>  <br/>Among other things, studying history gives one confidence that there are good<br/>ideas waiting to be discovered right under our noses. Swords evolved during<br/>the Bronze Age out of daggers, which (like their flint predecessors) had a<br/>hilt separate from the blade. Because swords are longer the hilts kept<br/>breaking off. But it took five hundred years before someone thought of casting<br/>hilt and blade as one piece.  <br/>  <br/> **Disobedience**  <br/>  <br/>Above all, make a habit of paying attention to things you're not supposed to,<br/>either because they're "inappropriate," or not important, or not what you're<br/>supposed to be working on. If you're curious about something, trust your<br/>instincts. Follow the threads that attract your attention. If there's<br/>something you're really interested in, you'll find they have an uncanny way of<br/>leading back to it anyway, just as the conversation of people who are<br/>especially proud of something always tends to lead back to it.  <br/>  <br/>For example, I've always been fascinated by comb-overs, especially the extreme<br/>sort that make a man look as if he's wearing a beret made of his own hair.<br/>Surely this is a lowly sort of thing to be interested in-- the sort of<br/>superficial quizzing best left to teenage girls. And yet there is something<br/>underneath. The key question, I realized, is how does the comber-over not see<br/>how odd he looks? And the answer is that he got to look that way<br/>_incrementally._ What began as combing his hair a little carefully over a thin<br/>patch has gradually, over 20 years, grown into a monstrosity. Gradualness is<br/>very powerful. And that power can be used for constructive purposes too: just<br/>as you can trick yourself into looking like a freak, you can trick yourself<br/>into creating something so grand that you would never have dared to _plan_<br/>such a thing. Indeed, this is just how most good software gets created. You<br/>start by writing a stripped-down kernel (how hard can it be?) and gradually it<br/>grows into a complete operating system. Hence the next leap: could you do the<br/>same thing in painting, or in a novel?  <br/>  <br/>See what you can extract from a frivolous question? If there's one piece of<br/>advice I would give about writing essays, it would be: don't do as you're<br/>told. Don't believe what you're supposed to. Don't write the essay readers<br/>expect; one learns nothing from what one expects. And don't write the way they<br/>taught you to in school.  <br/>  <br/>The most important sort of disobedience is to write essays at all.<br/>Fortunately, this sort of disobedience shows signs of becoming rampant. It<br/>used to be that only a tiny number of officially approved writers were allowed<br/>to write essays. Magazines published few of them, and judged them less by what<br/>they said than who wrote them; a magazine might publish a story by an unknown<br/>writer if it was good enough, but if they published an essay on x it had to be<br/>by someone who was at least forty and whose job title had x in it. Which is a<br/>problem, because there are a lot of things insiders can't say precisely<br/>because they're insiders.  <br/>  <br/>The Internet is changing that. Anyone can publish an essay on the Web, and it<br/>gets judged, as any writing should, by what it says, not who wrote it. Who are<br/>you to write about x? You are whatever you wrote.  <br/>  <br/>Popular magazines made the period between the spread of literacy and the<br/>arrival of TV the golden age of the short story. The Web may well make this<br/>the golden age of the essay. And that's certainly not something I realized<br/>when I started writing this.  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] I'm thinking of Oresme (c. 1323-82). But it's hard to pick a date, because<br/>there was a sudden drop-off in scholarship just as Europeans finished<br/>assimilating classical science. The cause may have been the plague of 1347;<br/>the trend in scientific progress matches the population curve.  <br/>  <br/>[2] Parker, William R. "Where Do College English Departments Come From?"<br/>_College English_ 28 (1966-67), pp. 339-351. Reprinted in Gray, Donald J.<br/>(ed). _The Department of English at Indiana University Bloomington 1868-1970._<br/>Indiana University Publications.  <br/>  <br/>Daniels, Robert V. _The University of Vermont: The First Two Hundred Years._<br/>University of Vermont, 1991.  <br/>  <br/>Mueller, Friedrich M. Letter to the _Pall Mall Gazette._ 1886/87. Reprinted in<br/>Bacon, Alan (ed). _The Nineteenth-Century History of English Studies._<br/>Ashgate, 1998.  <br/>  <br/>[3] I'm compressing the story a bit. At first literature took a back seat to<br/>philology, which (a) seemed more serious and (b) was popular in Germany, where<br/>many of the leading scholars of that generation had been trained.  <br/>  <br/>In some cases the writing teachers were transformed _in situ_ into English<br/>professors. Francis James Child, who had been Boylston Professor of Rhetoric<br/>at Harvard since 1851, became in 1876 the university's first professor of<br/>English.  <br/>  <br/>[4] Parker, _op. cit._ , p. 25.  <br/>  <br/>[5] The undergraduate curriculum or _trivium_ (whence "trivial") consisted of<br/>Latin grammar, rhetoric, and logic. Candidates for masters' degrees went on to<br/>study the _quadrivium_ of arithmetic, geometry, music, and astronomy. Together<br/>these were the seven liberal arts.  <br/>  <br/>The study of rhetoric was inherited directly from Rome, where it was<br/>considered the most important subject. It would not be far from the truth to<br/>say that education in the classical world meant training landowners' sons to<br/>speak well enough to defend their interests in political and legal disputes.  <br/>  <br/>[6] Trevor Blackwell points out that this isn't strictly true, because the<br/>outside edges of curves erode faster.  <br/>  <br/>**Thanks** to Ken Anderson, Trevor Blackwell, Sarah Harlin, Jessica<br/>Livingston, Jackie McDonough, and Robert Morris for reading drafts of this.  <br/>  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Hungarian Translation  <br/>  <br/><br/>Traditional Chinese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>June 2013  <br/>  <br/> _(This talk was written for an audience of investors.)_  <br/>  <br/>Y Combinator has now funded 564 startups including the current batch, which<br/>has 53. The total valuation of the 287 that have valuations (either by raising<br/>an equity round, getting acquired, or dying) is about $11.7 billion, and the<br/>511 prior to the current batch have collectively raised about $1.7 billion.<br/>[1]  <br/>  <br/>As usual those numbers are dominated by a few big winners. The top 10 startups<br/>account for 8.6 of that 11.7 billion. But there is a peloton of younger<br/>startups behind them. There are about 40 more that have a shot at being really<br/>big.  <br/>  <br/>Things got a little out of hand last summer when we had 84 companies in the<br/>batch, so we tightened up our filter to decrease the batch size. [2] Several<br/>journalists have tried to interpret that as evidence for some macro story they<br/>were telling, but the reason had nothing to do with any external trend. The<br/>reason was that we discovered we were using an n² algorithm, and we needed to<br/>buy time to fix it. Fortunately we've come up with several techniques for<br/>sharding YC, and the problem now seems to be fixed. With a new more scaleable<br/>model and only 53 companies, the current batch feels like a walk in the park.<br/>I'd guess we can grow another 2 or 3x before hitting the next bottleneck. [3]  <br/>  <br/>One consequence of funding such a large number of startups is that we see<br/>trends early. And since fundraising is one of the main things we help startups<br/>with, we're in a good position to notice trends in investing.  <br/>  <br/>I'm going to take a shot at describing where these trends are leading. Let's<br/>start with the most basic question: will the future be better or worse than<br/>the past? Will investors, in the aggregate, make more money or less?  <br/>  <br/>I think more. There are multiple forces at work, some of which will decrease<br/>returns, and some of which will increase them. I can't predict for sure which<br/>forces will prevail, but I'll describe them and you can decide for yourself.  <br/>  <br/>There are two big forces driving change in startup funding: it's becoming<br/>cheaper to start a startup, and startups are becoming a more normal thing to<br/>do.  <br/>  <br/>When I graduated from college in 1986, there were essentially two options: get<br/>a job or go to grad school. Now there's a third: start your own company.<br/>That's a big change. In principle it was possible to start your own company in<br/>1986 too, but it didn't seem like a real possibility. It seemed possible to<br/>start a consulting company, or a niche product company, but it didn't seem<br/>possible to start a company that would become big. [4]  <br/>  <br/>That kind of change, from 2 paths to 3, is the sort of big social shift that<br/>only happens once every few generations. I think we're still at the beginning<br/>of this one. It's hard to predict how big a deal it will be. As big a deal as<br/>the Industrial Revolution? Maybe. Probably not. But it will be a big enough<br/>deal that it takes almost everyone by surprise, because those big social<br/>shifts always do.  <br/>  <br/>One thing we can say for sure is that there will be a lot more startups. The<br/>monolithic, hierarchical companies of the mid 20th century are being replaced<br/>by networks of smaller companies. This process is not just something happening<br/>now in Silicon Valley. It started decades ago, and it's happening as far<br/>afield as the car industry. It has a long way to run. [5]  <br/>  <br/>The other big driver of change is that startups are becoming cheaper to start.<br/>And in fact the two forces are related: the decreasing cost of starting a<br/>startup is one of the reasons startups are becoming a more normal thing to do.  <br/>  <br/>The fact that startups need less money means founders will increasingly have<br/>the upper hand over investors. You still need just as much of their energy and<br/>imagination, but they don't need as much of your money. Because founders have<br/>the upper hand, they'll retain an increasingly large share of the stock in,<br/>and control of, their companies. Which means investors will get less stock and<br/>less control.  <br/>  <br/>Does that mean investors will make less money? Not necessarily, because there<br/>will be more good startups. The total amount of desirable startup stock<br/>available to investors will probably increase, because the number of desirable<br/>startups will probably grow faster than the percentage they sell to investors<br/>shrinks.  <br/>  <br/>There's a rule of thumb in the VC business that there are about 15 companies a<br/>year that will be really successful. Although a lot of investors unconsciously<br/>treat this number as if it were some sort of cosmological constant, I'm<br/>certain it isn't. There are probably limits on the rate at which technology<br/>can develop, but that's not the limiting factor now. If it were, each<br/>successful startup would be founded the month it became possible, and that is<br/>not the case. Right now the limiting factor on the number of big hits is the<br/>number of sufficiently good founders starting companies, and that number can<br/>and will increase. There are still a lot of people who'd make great founders<br/>who never end up starting a company. You can see that from how randomly some<br/>of the most successful startups got started. So many of the biggest startups<br/>almost didn't happen that there must be a lot of equally good startups that<br/>actually didn't happen.  <br/>  <br/>There might be 10x or even 50x more good founders out there. As more of them<br/>go ahead and start startups, those 15 big hits a year could easily become 50<br/>or even 100. [6]  <br/>  <br/>What about returns, though? Are we heading for a world in which returns will<br/>be pinched by increasingly high valuations? I think the top firms will<br/>actually make more money than they have in the past. High returns don't come<br/>from investing at low valuations. They come from investing in the companies<br/>that do really well. So if there are more of those to be had each year, the<br/>best pickers should have more hits.  <br/>  <br/>This means there should be more variability in the VC business. The firms that<br/>can recognize and attract the best startups will do even better, because there<br/>will be more of them to recognize and attract. Whereas the bad firms will get<br/>the leftovers, as they do now, and yet pay a higher price for them.  <br/>  <br/>Nor do I think it will be a problem that founders keep control of their<br/>companies for longer. The empirical evidence on that is already clear:<br/>investors make more money as founders' bitches than their bosses. Though<br/>somewhat humiliating, this is actually good news for investors, because it<br/>takes less time to serve founders than to micromanage them.  <br/>  <br/>What about angels? I think there is a lot of opportunity there. It used to<br/>suck to be an angel investor. You couldn't get access to the best deals,<br/>unless you got lucky like Andy Bechtolsheim, and when you did invest in a<br/>startup, VCs might try to strip you of your stock when they arrived later. Now<br/>an angel can go to something like Demo Day or AngelList and have access to the<br/>same deals VCs do. And the days when VCs could wash angels out of the cap<br/>table are long gone.  <br/>  <br/>I think one of the biggest unexploited opportunities in startup investing<br/>right now is angel-sized investments made quickly. Few investors understand<br/>the cost that raising money from them imposes on startups. When the company<br/>consists only of the founders, everything grinds to a halt during fundraising,<br/>which can easily take 6 weeks. The current high cost of fundraising means<br/>there is room for low-cost investors to undercut the rest. And in this<br/>context, low-cost means deciding quickly. If there were a reputable investor<br/>who invested $100k on good terms and promised to decide yes or no within 24<br/>hours, they'd get access to almost all the best deals, because every good<br/>startup would approach them first. It would be up to them to pick, because<br/>every bad startup would approach them first too, but at least they'd see<br/>everything. Whereas if an investor is notorious for taking a long time to make<br/>up their mind or negotiating a lot about valuation, founders will save them<br/>for last. And in the case of the most promising startups, which tend to have<br/>an easy time raising money, last can easily become never.  <br/>  <br/>Will the number of big hits grow linearly with the total number of new<br/>startups? Probably not, for two reasons. One is that the scariness of starting<br/>a startup in the old days was a pretty effective filter. Now that the cost of<br/>failing is becoming lower, we should expect founders to do it more. That's not<br/>a bad thing. It's common in technology for an innovation that decreases the<br/>cost of failure to increase the number of failures and yet leave you net<br/>ahead.  <br/>  <br/>The other reason the number of big hits won't grow proportionately to the<br/>number of startups is that there will start to be an increasing number of idea<br/>clashes. Although the finiteness of the number of good ideas is not the reason<br/>there are only 15 big hits a year, the number has to be finite, and the more<br/>startups there are, the more we'll see multiple companies doing the same thing<br/>at the same time. It will be interesting, in a bad way, if idea clashes become<br/>a lot more common. [7]  <br/>  <br/>Mostly because of the increasing number of early failures, the startup<br/>business of the future won't simply be the same shape, scaled up. What used to<br/>be an obelisk will become a pyramid. It will be a little wider at the top, but<br/>a lot wider at the bottom.  <br/>  <br/>What does that mean for investors? One thing it means is that there will be<br/>more opportunities for investors at the earliest stage, because that's where<br/>the volume of our imaginary solid is growing fastest. Imagine the obelisk of<br/>investors that corresponds to the obelisk of startups. As it widens out into a<br/>pyramid to match the startup pyramid, all the contents are adhering to the<br/>top, leaving a vacuum at the bottom.  <br/>  <br/>That opportunity for investors mostly means an opportunity for new investors,<br/>because the degree of risk an existing investor or firm is comfortable taking<br/>is one of the hardest things for them to change. Different types of investors<br/>are adapted to different degrees of risk, but each has its specific degree of<br/>risk deeply imprinted on it, not just in the procedures they follow but in the<br/>personalities of the people who work there.  <br/>  <br/>I think the biggest danger for VCs, and also the biggest opportunity, is at<br/>the series A stage. Or rather, what used to be the series A stage before<br/>series As turned into de facto series B rounds.  <br/>  <br/>Right now, VCs often knowingly invest too much money at the series A stage.<br/>They do it because they feel they need to get a big chunk of each series A<br/>company to compensate for the opportunity cost of the board seat it consumes.<br/>Which means when there is a lot of competition for a deal, the number that<br/>moves is the valuation (and thus amount invested) rather than the percentage<br/>of the company being sold. Which means, especially in the case of more<br/>promising startups, that series A investors often make companies take more<br/>money than they want.  <br/>  <br/>Some VCs lie and claim the company really needs that much. Others are more<br/>candid, and admit their financial models require them to own a certain<br/>percentage of each company. But we all know the amounts being raised in series<br/>A rounds are not determined by asking what would be best for the companies.<br/>They're determined by VCs starting from the amount of the company they want to<br/>own, and the market setting the valuation and thus the amount invested.  <br/>  <br/>Like a lot of bad things, this didn't happen intentionally. The VC business<br/>backed into it as their initial assumptions gradually became obsolete. The<br/>traditions and financial models of the VC business were established when<br/>founders needed investors more. In those days it was natural for founders to<br/>sell VCs a big chunk of their company in the series A round. Now founders<br/>would prefer to sell less, and VCs are digging in their heels because they're<br/>not sure if they can make money buying less than 20% of each series A company.  <br/>  <br/>The reason I describe this as a danger is that series A investors are<br/>increasingly at odds with the startups they supposedly serve, and that tends<br/>to come back to bite you eventually. The reason I describe it as an<br/>opportunity is that there is now a lot of potential energy built up, as the<br/>market has moved away from VCs' traditional business model. Which means the<br/>first VC to break ranks and start to do series A rounds for as much equity as<br/>founders want to sell (and with no "option pool" that comes only from the<br/>founders' shares) stands to reap huge benefits.  <br/>  <br/>What will happen to the VC business when that happens? Hell if I know. But I<br/>bet that particular firm will end up ahead. If one top-tier VC firm started to<br/>do series A rounds that started from the amount the company needed to raise<br/>and let the percentage acquired vary with the market, instead of the other way<br/>around, they'd instantly get almost all the best startups. And that's where<br/>the money is.  <br/>  <br/>You can't fight market forces forever. Over the last decade we've seen the<br/>percentage of the company sold in series A rounds creep inexorably downward.<br/>40% used to be common. Now VCs are fighting to hold the line at 20%. But I am<br/>daily waiting for the line to collapse. It's going to happen. You may as well<br/>anticipate it, and look bold.  <br/>  <br/>Who knows, maybe VCs will make more money by doing the right thing. It<br/>wouldn't be the first time that happened. Venture capital is a business where<br/>occasional big successes generate hundredfold returns. How much confidence can<br/>you really have in financial models for something like that anyway? The big<br/>successes only have to get a tiny bit less occasional to compensate for a 2x<br/>decrease in the stock sold in series A rounds.  <br/>  <br/>If you want to find new opportunities for investing, look for things founders<br/>complain about. Founders are your customers, and the things they complain<br/>about are unsatisfied demand. I've given two examples of things founders<br/>complain about most—investors who take too long to make up their minds, and<br/>excessive dilution in series A rounds—so those are good places to look now.<br/>But the more general recipe is: do something founders want.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] I realize revenue and not fundraising is the proper test of success for a<br/>startup. The reason we quote statistics about fundraising is because those are<br/>the numbers we have. We couldn't talk meaningfully about revenues without<br/>including the numbers from the most successful startups, and we don't have<br/>those. We often discuss revenue growth with the earlier stage startups,<br/>because that's how we gauge their progress, but when companies reach a certain<br/>size it gets presumptuous for a seed investor to do that.  <br/>  <br/>In any case, companies' market caps do eventually become a function of<br/>revenues, and post-money valuations of funding rounds are at least guesses by<br/>pros about where those market caps will end up.  <br/>  <br/>The reason only 287 have valuations is that the rest have mostly raised money<br/>on convertible notes, and although convertible notes often have valuation<br/>caps, a valuation cap is merely an upper bound on a valuation.  <br/>  <br/>[2] We didn't try to accept a particular number. We have no way of doing that<br/>even if we wanted to. We just tried to be significantly pickier.  <br/>  <br/>[3] Though you never know with bottlenecks, I'm guessing the next one will be<br/>coordinating efforts among partners.  <br/>  <br/>[4] I realize starting a company doesn't have to mean starting a startup.<br/>There will be lots of people starting normal companies too. But that's not<br/>relevant to an audience of investors.  <br/>  <br/>Geoff Ralston reports that in Silicon Valley it seemed thinkable to start a<br/>startup in the mid 1980s. It would have started there. But I know it didn't to<br/>undergraduates on the East Coast.  <br/>  <br/>[5] This trend is one of the main causes of the increase in economic<br/>inequality in the US since the mid twentieth century. The person who would in<br/>1950 have been the general manager of the x division of Megacorp is now the<br/>founder of the x company, and owns significant equity in it.  <br/>  <br/>[6] If Congress passes the founder visa in a non-broken form, that alone could<br/>in principle get us up to 20x, since 95% of the world's population lives<br/>outside the US.  <br/>  <br/>[7] If idea clashes got bad enough, it could change what it means to be a<br/>startup. We currently advise startups mostly to ignore competitors. We tell<br/>them startups are competitive like running, not like soccer; you don't have to<br/>go and steal the ball away from the other team. But if idea clashes became<br/>common enough, maybe you'd start to have to. That would be unfortunate.  <br/>  <br/> **Thanks** to Sam Altman, Paul Buchheit, Dalton Caldwell, Patrick Collison,<br/>Jessica Livingston, Andrew Mason, Geoff Ralston, and Garry Tan for reading<br/>drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>August 2007  <br/>  <br/>A good programmer working intensively on his own code can hold it in his mind<br/>the way a mathematician holds a problem he's working on. Mathematicians don't<br/>answer questions by working them out on paper the way schoolchildren are<br/>taught to. They do more in their heads: they try to understand a problem space<br/>well enough that they can walk around it the way you can walk around the<br/>memory of the house you grew up in. At its best programming is the same. You<br/>hold the whole program in your head, and you can manipulate it at will.  <br/>  <br/>That's particularly valuable at the start of a project, because initially the<br/>most important thing is to be able to change what you're doing. Not just to<br/>solve the problem in a different way, but to change the problem you're<br/>solving.  <br/>  <br/>Your code is your understanding of the problem you're exploring. So it's only<br/>when you have your code in your head that you really understand the problem.  <br/>  <br/>It's not easy to get a program into your head. If you leave a project for a<br/>few months, it can take days to really understand it again when you return to<br/>it. Even when you're actively working on a program it can take half an hour to<br/>load into your head when you start work each day. And that's in the best case.<br/>Ordinary programmers working in typical office conditions never enter this<br/>mode. Or to put it more dramatically, ordinary programmers working in typical<br/>office conditions never really understand the problems they're solving.  <br/>  <br/>Even the best programmers don't always have the whole program they're working<br/>on loaded into their heads. But there are things you can do to help:  <br/>  <br/><br/>  1. **Avoid distractions.** Distractions are bad for many types of work, but especially bad for programming, because programmers tend to operate at the limit of the detail they can handle.  <br/>  <br/>The danger of a distraction depends not on how long it is, but on how much it<br/>scrambles your brain. A programmer can leave the office and go and get a<br/>sandwich without losing the code in his head. But the wrong kind of<br/>interruption can wipe your brain in 30 seconds.  <br/>  <br/>Oddly enough, scheduled distractions may be worse than unscheduled ones. If<br/>you know you have a meeting in an hour, you don't even start working on<br/>something hard.  <br/>  <br/><br/>  2. **Work in long stretches.** Since there's a fixed cost each time you start working on a program, it's more efficient to work in a few long sessions than many short ones. There will of course come a point where you get stupid because you're tired. This varies from person to person. I've heard of people hacking for 36 hours straight, but the most I've ever been able to manage is about 18, and I work best in chunks of no more than 12.  <br/>  <br/>The optimum is not the limit you can physically endure. There's an advantage<br/>as well as a cost of breaking up a project. Sometimes when you return to a<br/>problem after a rest, you find your unconscious mind has left an answer<br/>waiting for you.  <br/>  <br/><br/>  3. **Use succinct languages.** More powerful programming languages make programs shorter. And programmers seem to think of programs at least partially in the language they're using to write them. The more succinct the language, the shorter the program, and the easier it is to load and keep in your head.  <br/>  <br/>You can magnify the effect of a powerful language by using a style called<br/>bottom-up programming, where you write programs in multiple layers, the lower<br/>ones acting as programming languages for those above. If you do this right,<br/>you only have to keep the topmost layer in your head.  <br/>  <br/><br/>  4. **Keep rewriting your program.** Rewriting a program often yields a cleaner design. But it would have advantages even if it didn't: you have to understand a program completely to rewrite it, so there is no better way to get one loaded into your head.  <br/>  <br/><br/>  5. **Write rereadable code.** All programmers know it's good to write readable code. But you yourself are the most important reader. Especially in the beginning; a prototype is a conversation with yourself. And when writing for yourself you have different priorities. If you're writing for other people, you may not want to make code too dense. Some parts of a program may be easiest to read if you spread things out, like an introductory textbook. Whereas if you're writing code to make it easy to reload into your head, it may be best to go for brevity.  <br/>  <br/><br/>  6. **Work in small groups.** When you manipulate a program in your head, your vision tends to stop at the edge of the code you own. Other parts you don't understand as well, and more importantly, can't take liberties with. So the smaller the number of programmers, the more completely a project can mutate. If there's just one programmer, as there often is at first, you can do all-encompassing redesigns.  <br/>  <br/><br/>  7. **Don't have multiple people editing the same piece of code.** You never understand other people's code as well as your own. No matter how thoroughly you've read it, you've only read it, not written it. So if a piece of code is written by multiple authors, none of them understand it as well as a single author would.  <br/>  <br/>And of course you can't safely redesign something other people are working on.<br/>It's not just that you'd have to ask permission. You don't even let yourself<br/>think of such things. Redesigning code with several authors is like changing<br/>laws; redesigning code you alone control is like seeing the other<br/>interpretation of an ambiguous image.  <br/>  <br/>If you want to put several people to work on a project, divide it into<br/>components and give each to one person.  <br/>  <br/><br/>  8. **Start small.** A program gets easier to hold in your head as you become familiar with it. You can start to treat parts as black boxes once you feel confident you've fully explored them. But when you first start working on a project, you're forced to see everything. If you start with too big a problem, you may never quite be able to encompass it. So if you need to write a big, complex program, the best way to begin may not be to write a spec for it, but to write a prototype that solves a subset of the problem. Whatever the advantages of planning, they're often outweighed by the advantages of being able to keep a program in your head. <br/><br/>It's striking how often programmers manage to hit all eight points by<br/>accident. Someone has an idea for a new project, but because it's not<br/>officially sanctioned, he has to do it in off hours—which turn out to be more<br/>productive because there are no distractions. Driven by his enthusiasm for the<br/>new project he works on it for many hours at a stretch. Because it's initially<br/>just an experiment, instead of a "production" language he uses a mere<br/>"scripting" language—which is in fact far more powerful. He completely<br/>rewrites the program several times; that wouldn't be justifiable for an<br/>official project, but this is a labor of love and he wants it to be perfect.<br/>And since no one is going to see it except him, he omits any comments except<br/>the note-to-self variety. He works in a small group perforce, because he<br/>either hasn't told anyone else about the idea yet, or it seems so unpromising<br/>that no one else is allowed to work on it. Even if there is a group, they<br/>couldn't have multiple people editing the same code, because it changes too<br/>fast for that to be possible. And the project starts small because the idea<br/>_is_ small at first; he just has some cool hack he wants to try out.  <br/>  <br/>Even more striking are the number of officially sanctioned projects that<br/>manage to do _all eight things wrong_. In fact, if you look at the way<br/>software gets written in most organizations, it's almost as if they were<br/>deliberately trying to do things wrong. In a sense, they are. One of the<br/>defining qualities of organizations since there have been such a thing is to<br/>treat individuals as interchangeable parts. This works well for more<br/>parallelizable tasks, like fighting wars. For most of history a well-drilled<br/>army of professional soldiers could be counted on to beat an army of<br/>individual warriors, no matter how valorous. But having ideas is not very<br/>parallelizable. And that's what programs are: ideas.  <br/>  <br/>It's not merely true that organizations dislike the idea of depending on<br/>individual genius, it's a tautology. It's part of the definition of an<br/>organization not to. Of our current concept of an organization, at least.  <br/>  <br/>Maybe we could define a new kind of organization that combined the efforts of<br/>individuals without requiring them to be interchangeable. Arguably a market is<br/>such a form of organization, though it may be more accurate to describe a<br/>market as a degenerate case—as what you get by default when organization isn't<br/>possible.  <br/>  <br/>Probably the best we'll do is some kind of hack, like making the programming<br/>parts of an organization work differently from the rest. Perhaps the optimal<br/>solution is for big companies not even to try to develop ideas in house, but<br/>simply to buy them. But regardless of what the solution turns out to be, the<br/>first step is to realize there's a problem. There is a contradiction in the<br/>very phrase "software company." The two words are pulling in opposite<br/>directions. Any good programmer in a large organization is going to be at odds<br/>with it, because organizations are designed to prevent what programmers strive<br/>for.  <br/>  <br/>Good programmers<br/><br/>Japanese Translation  <br/>  <br/><br/>Simplified Chinese Translation  <br/>  <br/><br/>Portuguese Translation  <br/>  <br/><br/>Bulgarian Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>April 2003  <br/>  <br/> _(This essay is derived from a keynote talk at PyCon 2003.)_  <br/>  <br/>It's hard to predict what life will be like in a hundred years. There are only<br/>a few things we can say with certainty. We know that everyone will drive<br/>flying cars, that zoning laws will be relaxed to allow buildings hundreds of<br/>stories tall, that it will be dark most of the time, and that women will all<br/>be trained in the martial arts. Here I want to zoom in on one detail of this<br/>picture. What kind of programming language will they use to write the software<br/>controlling those flying cars?  <br/>  <br/>This is worth thinking about not so much because we'll actually get to use<br/>these languages as because, if we're lucky, we'll use languages on the path<br/>from this point to that.  <br/>  <br/>  <br/>  <br/>I think that, like species, languages will form evolutionary trees, with dead-<br/>ends branching off all over. We can see this happening already. Cobol, for all<br/>its sometime popularity, does not seem to have any intellectual descendants.<br/>It is an evolutionary dead-end-- a Neanderthal language.  <br/>  <br/>I predict a similar fate for Java. People sometimes send me mail saying, "How<br/>can you say that Java won't turn out to be a successful language? It's already<br/>a successful language." And I admit that it is, if you measure success by<br/>shelf space taken up by books on it (particularly individual books on it), or<br/>by the number of undergrads who believe they have to learn it to get a job.<br/>When I say Java won't turn out to be a successful language, I mean something<br/>more specific: that Java will turn out to be an evolutionary dead-end, like<br/>Cobol.  <br/>  <br/>This is just a guess. I may be wrong. My point here is not to dis Java, but to<br/>raise the issue of evolutionary trees and get people asking, where on the tree<br/>is language X? The reason to ask this question isn't just so that our ghosts<br/>can say, in a hundred years, I told you so. It's because staying close to the<br/>main branches is a useful heuristic for finding languages that will be good to<br/>program in now.  <br/>  <br/>At any given time, you're probably happiest on the main branches of an<br/>evolutionary tree. Even when there were still plenty of Neanderthals, it must<br/>have sucked to be one. The Cro-Magnons would have been constantly coming over<br/>and beating you up and stealing your food.  <br/>  <br/>The reason I want to know what languages will be like in a hundred years is so<br/>that I know what branch of the tree to bet on now.  <br/>  <br/>  <br/>  <br/>The evolution of languages differs from the evolution of species because<br/>branches can converge. The Fortran branch, for example, seems to be merging<br/>with the descendants of Algol. In theory this is possible for species too, but<br/>it's not likely to have happened to any bigger than a cell.  <br/>  <br/>Convergence is more likely for languages partly because the space of<br/>possibilities is smaller, and partly because mutations are not random.<br/>Language designers deliberately incorporate ideas from other languages.  <br/>  <br/>It's especially useful for language designers to think about where the<br/>evolution of programming languages is likely to lead, because they can steer<br/>accordingly. In that case, "stay on a main branch" becomes more than a way to<br/>choose a good language. It becomes a heuristic for making the right decisions<br/>about language design.  <br/>  <br/>  <br/>  <br/>Any programming language can be divided into two parts: some set of<br/>fundamental operators that play the role of axioms, and the rest of the<br/>language, which could in principle be written in terms of these fundamental<br/>operators.  <br/>  <br/>I think the fundamental operators are the most important factor in a<br/>language's long term survival. The rest you can change. It's like the rule<br/>that in buying a house you should consider location first of all. Everything<br/>else you can fix later, but you can't fix the location.  <br/>  <br/>I think it's important not just that the axioms be well chosen, but that there<br/>be few of them. Mathematicians have always felt this way about axioms-- the<br/>fewer, the better-- and I think they're onto something.  <br/>  <br/>At the very least, it has to be a useful exercise to look closely at the core<br/>of a language to see if there are any axioms that could be weeded out. I've<br/>found in my long career as a slob that cruft breeds cruft, and I've seen this<br/>happen in software as well as under beds and in the corners of rooms.  <br/>  <br/>I have a hunch that the main branches of the evolutionary tree pass through<br/>the languages that have the smallest, cleanest cores. The more of a language<br/>you can write in itself, the better.  <br/>  <br/>  <br/>  <br/>Of course, I'm making a big assumption in even asking what programming<br/>languages will be like in a hundred years. Will we even be writing programs in<br/>a hundred years? Won't we just tell computers what we want them to do?  <br/>  <br/>There hasn't been a lot of progress in that department so far. My guess is<br/>that a hundred years from now people will still tell computers what to do<br/>using programs we would recognize as such. There may be tasks that we solve<br/>now by writing programs and which in a hundred years you won't have to write<br/>programs to solve, but I think there will still be a good deal of programming<br/>of the type that we do today.  <br/>  <br/>It may seem presumptuous to think anyone can predict what any technology will<br/>look like in a hundred years. But remember that we already have almost fifty<br/>years of history behind us. Looking forward a hundred years is a graspable<br/>idea when we consider how slowly languages have evolved in the past fifty.  <br/>  <br/>Languages evolve slowly because they're not really technologies. Languages are<br/>notation. A program is a formal description of the problem you want a computer<br/>to solve for you. So the rate of evolution in programming languages is more<br/>like the rate of evolution in mathematical notation than, say, transportation<br/>or communications. Mathematical notation does evolve, but not with the giant<br/>leaps you see in technology.  <br/>  <br/>  <br/>  <br/>Whatever computers are made of in a hundred years, it seems safe to predict<br/>they will be much faster than they are now. If Moore's Law continues to put<br/>out, they will be 74 quintillion (73,786,976,294,838,206,464) times faster.<br/>That's kind of hard to imagine. And indeed, the most likely prediction in the<br/>speed department may be that Moore's Law will stop working. Anything that is<br/>supposed to double every eighteen months seems likely to run up against some<br/>kind of fundamental limit eventually. But I have no trouble believing that<br/>computers will be very much faster. Even if they only end up being a paltry<br/>million times faster, that should change the ground rules for programming<br/>languages substantially. Among other things, there will be more room for what<br/>would now be considered slow languages, meaning languages that don't yield<br/>very efficient code.  <br/>  <br/>And yet some applications will still demand speed. Some of the problems we<br/>want to solve with computers are created by computers; for example, the rate<br/>at which you have to process video images depends on the rate at which another<br/>computer can generate them. And there is another class of problems which<br/>inherently have an unlimited capacity to soak up cycles: image rendering,<br/>cryptography, simulations.  <br/>  <br/>If some applications can be increasingly inefficient while others continue to<br/>demand all the speed the hardware can deliver, faster computers will mean that<br/>languages have to cover an ever wider range of efficiencies. We've seen this<br/>happening already. Current implementations of some popular new languages are<br/>shockingly wasteful by the standards of previous decades.  <br/>  <br/>This isn't just something that happens with programming languages. It's a<br/>general historical trend. As technologies improve, each generation can do<br/>things that the previous generation would have considered wasteful. People<br/>thirty years ago would be astonished at how casually we make long distance<br/>phone calls. People a hundred years ago would be even more astonished that a<br/>package would one day travel from Boston to New York via Memphis.  <br/>  <br/>  <br/>  <br/>I can already tell you what's going to happen to all those extra cycles that<br/>faster hardware is going to give us in the next hundred years. They're nearly<br/>all going to be wasted.  <br/>  <br/>I learned to program when computer power was scarce. I can remember taking all<br/>the spaces out of my Basic programs so they would fit into the memory of a 4K<br/>TRS-80. The thought of all this stupendously inefficient software burning up<br/>cycles doing the same thing over and over seems kind of gross to me. But I<br/>think my intuitions here are wrong. I'm like someone who grew up poor, and<br/>can't bear to spend money even for something important, like going to the<br/>doctor.  <br/>  <br/>Some kinds of waste really are disgusting. SUVs, for example, would arguably<br/>be gross even if they ran on a fuel which would never run out and generated no<br/>pollution. SUVs are gross because they're the solution to a gross problem.<br/>(How to make minivans look more masculine.) But not all waste is bad. Now that<br/>we have the infrastructure to support it, counting the minutes of your long-<br/>distance calls starts to seem niggling. If you have the resources, it's more<br/>elegant to think of all phone calls as one kind of thing, no matter where the<br/>other person is.  <br/>  <br/>There's good waste, and bad waste. I'm interested in good waste-- the kind<br/>where, by spending more, we can get simpler designs. How will we take<br/>advantage of the opportunities to waste cycles that we'll get from new, faster<br/>hardware?  <br/>  <br/>The desire for speed is so deeply engrained in us, with our puny computers,<br/>that it will take a conscious effort to overcome it. In language design, we<br/>should be consciously seeking out situations where we can trade efficiency for<br/>even the smallest increase in convenience.  <br/>  <br/>  <br/>  <br/>Most data structures exist because of speed. For example, many languages today<br/>have both strings and lists. Semantically, strings are more or less a subset<br/>of lists in which the elements are characters. So why do you need a separate<br/>data type? You don't, really. Strings only exist for efficiency. But it's lame<br/>to clutter up the semantics of the language with hacks to make programs run<br/>faster. Having strings in a language seems to be a case of premature<br/>optimization.  <br/>  <br/>If we think of the core of a language as a set of axioms, surely it's gross to<br/>have additional axioms that add no expressive power, simply for the sake of<br/>efficiency. Efficiency is important, but I don't think that's the right way to<br/>get it.  <br/>  <br/>The right way to solve that problem, I think, is to separate the meaning of a<br/>program from the implementation details. Instead of having both lists and<br/>strings, have just lists, with some way to give the compiler optimization<br/>advice that will allow it to lay out strings as contiguous bytes if necessary.  <br/>  <br/>Since speed doesn't matter in most of a program, you won't ordinarily need to<br/>bother with this sort of micromanagement. This will be more and more true as<br/>computers get faster.  <br/>  <br/>  <br/>  <br/>Saying less about implementation should also make programs more flexible.<br/>Specifications change while a program is being written, and this is not only<br/>inevitable, but desirable.  <br/>  <br/>The word "essay" comes from the French verb "essayer", which means "to try".<br/>An essay, in the original sense, is something you write to try to figure<br/>something out. This happens in software too. I think some of the best programs<br/>were essays, in the sense that the authors didn't know when they started<br/>exactly what they were trying to write.  <br/>  <br/>Lisp hackers already know about the value of being flexible with data<br/>structures. We tend to write the first version of a program so that it does<br/>everything with lists. These initial versions can be so shockingly inefficient<br/>that it takes a conscious effort not to think about what they're doing, just<br/>as, for me at least, eating a steak requires a conscious effort not to think<br/>where it came from.  <br/>  <br/>What programmers in a hundred years will be looking for, most of all, is a<br/>language where you can throw together an unbelievably inefficient version 1 of<br/>a program with the least possible effort. At least, that's how we'd describe<br/>it in present-day terms. What they'll say is that they want a language that's<br/>easy to program in.  <br/>  <br/>Inefficient software isn't gross. What's gross is a language that makes<br/>programmers do needless work. Wasting programmer time is the true<br/>inefficiency, not wasting machine time. This will become ever more clear as<br/>computers get faster.  <br/>  <br/>  <br/>  <br/>I think getting rid of strings is already something we could bear to think<br/>about. We did it in Arc, and it seems to be a win; some operations that would<br/>be awkward to describe as regular expressions can be described easily as<br/>recursive functions.  <br/>  <br/>How far will this flattening of data structures go? I can think of<br/>possibilities that shock even me, with my conscientiously broadened mind. Will<br/>we get rid of arrays, for example? After all, they're just a subset of hash<br/>tables where the keys are vectors of integers. Will we replace hash tables<br/>themselves with lists?  <br/>  <br/>There are more shocking prospects even than that. The Lisp that McCarthy<br/>described in 1960, for example, didn't have numbers. Logically, you don't need<br/>to have a separate notion of numbers, because you can represent them as lists:<br/>the integer n could be represented as a list of n elements. You can do math<br/>this way. It's just unbearably inefficient.  <br/>  <br/>No one actually proposed implementing numbers as lists in practice. In fact,<br/>McCarthy's 1960 paper was not, at the time, intended to be implemented at all.<br/>It was a theoretical exercise, an attempt to create a more elegant alternative<br/>to the Turing Machine. When someone did, unexpectedly, take this paper and<br/>translate it into a working Lisp interpreter, numbers certainly weren't<br/>represented as lists; they were represented in binary, as in every other<br/>language.  <br/>  <br/>Could a programming language go so far as to get rid of numbers as a<br/>fundamental data type? I ask this not so much as a serious question as as a<br/>way to play chicken with the future. It's like the hypothetical case of an<br/>irresistible force meeting an immovable object-- here, an unimaginably<br/>inefficient implementation meeting unimaginably great resources. I don't see<br/>why not. The future is pretty long. If there's something we can do to decrease<br/>the number of axioms in the core language, that would seem to be the side to<br/>bet on as t approaches infinity. If the idea still seems unbearable in a<br/>hundred years, maybe it won't in a thousand.  <br/>  <br/>Just to be clear about this, I'm not proposing that all numerical calculations<br/>would actually be carried out using lists. I'm proposing that the core<br/>language, prior to any additional notations about implementation, be defined<br/>this way. In practice any program that wanted to do any amount of math would<br/>probably represent numbers in binary, but this would be an optimization, not<br/>part of the core language semantics.  <br/>  <br/>  <br/>  <br/>Another way to burn up cycles is to have many layers of software between the<br/>application and the hardware. This too is a trend we see happening already:<br/>many recent languages are compiled into byte code. Bill Woods once told me<br/>that, as a rule of thumb, each layer of interpretation costs a factor of 10 in<br/>speed. This extra cost buys you flexibility.  <br/>  <br/>The very first version of Arc was an extreme case of this sort of multi-level<br/>slowness, with corresponding benefits. It was a classic "metacircular"<br/>interpreter written on top of Common Lisp, with a definite family resemblance<br/>to the eval function defined in McCarthy's original Lisp paper. The whole<br/>thing was only a couple hundred lines of code, so it was very easy to<br/>understand and change. The Common Lisp we used, CLisp, itself runs on top of a<br/>byte code interpreter. So here we had two levels of interpretation, one of<br/>them (the top one) shockingly inefficient, and the language was usable. Barely<br/>usable, I admit, but usable.  <br/>  <br/>Writing software as multiple layers is a powerful technique even within<br/>applications. Bottom-up programming means writing a program as a series of<br/>layers, each of which serves as a language for the one above. This approach<br/>tends to yield smaller, more flexible programs. It's also the best route to<br/>that holy grail, reusability. A language is by definition reusable. The more<br/>of your application you can push down into a language for writing that type of<br/>application, the more of your software will be reusable.  <br/>  <br/>Somehow the idea of reusability got attached to object-oriented programming in<br/>the 1980s, and no amount of evidence to the contrary seems to be able to shake<br/>it free. But although some object-oriented software is reusable, what makes it<br/>reusable is its bottom-upness, not its object-orientedness. Consider<br/>libraries: they're reusable because they're language, whether they're written<br/>in an object-oriented style or not.  <br/>  <br/>I don't predict the demise of object-oriented programming, by the way. Though<br/>I don't think it has much to offer good programmers, except in certain<br/>specialized domains, it is irresistible to large organizations. Object-<br/>oriented programming offers a sustainable way to write spaghetti code. It lets<br/>you accrete programs as a series of patches.  Large organizations always tend<br/>to develop software this way, and I expect this to be as true in a hundred<br/>years as it is today.  <br/>  <br/>  <br/>  <br/>As long as we're talking about the future, we had better talk about parallel<br/>computation, because that's where this idea seems to live. That is, no matter<br/>when you're talking, parallel computation seems to be something that is going<br/>to happen in the future.  <br/>  <br/>Will the future ever catch up with it? People have been talking about parallel<br/>computation as something imminent for at least 20 years, and it hasn't<br/>affected programming practice much so far. Or hasn't it? Already chip<br/>designers have to think about it, and so must people trying to write systems<br/>software on multi-cpu computers.  <br/>  <br/>The real question is, how far up the ladder of abstraction will parallelism<br/>go? In a hundred years will it affect even application programmers? Or will it<br/>be something that compiler writers think about, but which is usually invisible<br/>in the source code of applications?  <br/>  <br/>One thing that does seem likely is that most opportunities for parallelism<br/>will be wasted. This is a special case of my more general prediction that most<br/>of the extra computer power we're given will go to waste. I expect that, as<br/>with the stupendous speed of the underlying hardware, parallelism will be<br/>something that is available if you ask for it explicitly, but ordinarily not<br/>used. This implies that the kind of parallelism we have in a hundred years<br/>will not, except in special applications, be massive parallelism. I expect for<br/>ordinary programmers it will be more like being able to fork off processes<br/>that all end up running in parallel.  <br/>  <br/>And this will, like asking for specific implementations of data structures, be<br/>something that you do fairly late in the life of a program, when you try to<br/>optimize it. Version 1s will ordinarily ignore any advantages to be got from<br/>parallel computation, just as they will ignore advantages to be got from<br/>specific representations of data.  <br/>  <br/>Except in special kinds of applications, parallelism won't pervade the<br/>programs that are written in a hundred years. It would be premature<br/>optimization if it did.  <br/>  <br/>  <br/>  <br/>How many programming languages will there be in a hundred years? There seem to<br/>be a huge number of new programming languages lately. Part of the reason is<br/>that faster hardware has allowed programmers to make different tradeoffs<br/>between speed and convenience, depending on the application. If this is a real<br/>trend, the hardware we'll have in a hundred years should only increase it.  <br/>  <br/>And yet there may be only a few widely-used languages in a hundred years. Part<br/>of the reason I say this is optimism: it seems that, if you did a really good<br/>job, you could make a language that was ideal for writing a slow version 1,<br/>and yet with the right optimization advice to the compiler, would also yield<br/>very fast code when necessary. So, since I'm optimistic, I'm going to predict<br/>that despite the huge gap they'll have between acceptable and maximal<br/>efficiency, programmers in a hundred years will have languages that can span<br/>most of it.  <br/>  <br/>As this gap widens, profilers will become increasingly important. Little<br/>attention is paid to profiling now. Many people still seem to believe that the<br/>way to get fast applications is to write compilers that generate fast code. As<br/>the gap between acceptable and maximal performance widens, it will become<br/>increasingly clear that the way to get fast applications is to have a good<br/>guide from one to the other.  <br/>  <br/>When I say there may only be a few languages, I'm not including domain-<br/>specific "little languages". I think such embedded languages are a great idea,<br/>and I expect them to proliferate. But I expect them to be written as thin<br/>enough skins that users can see the general-purpose language underneath.  <br/>  <br/>  <br/>  <br/>Who will design the languages of the future? One of the most exciting trends<br/>in the last ten years has been the rise of open-source languages like Perl,<br/>Python, and Ruby. Language design is being taken over by hackers. The results<br/>so far are messy, but encouraging. There are some stunningly novel ideas in<br/>Perl, for example. Many are stunningly bad, but that's always true of<br/>ambitious efforts. At its current rate of mutation, God knows what Perl might<br/>evolve into in a hundred years.  <br/>  <br/>It's not true that those who can't do, teach (some of the best hackers I know<br/>are professors), but it is true that there are a lot of things that those who<br/>teach can't do. Research imposes constraining caste restrictions. In any<br/>academic field there are topics that are ok to work on and others that aren't.<br/>Unfortunately the distinction between acceptable and forbidden topics is<br/>usually based on how intellectual the work sounds when described in research<br/>papers, rather than how important it is for getting good results. The extreme<br/>case is probably literature; people studying literature rarely say anything<br/>that would be of the slightest use to those producing it.  <br/>  <br/>Though the situation is better in the sciences, the overlap between the kind<br/>of work you're allowed to do and the kind of work that yields good languages<br/>is distressingly small. (Olin Shivers has grumbled eloquently about this.) For<br/>example, types seem to be an inexhaustible source of research papers, despite<br/>the fact that static typing seems to preclude true macros-- without which, in<br/>my opinion, no language is worth using.  <br/>  <br/>The trend is not merely toward languages being developed as open-source<br/>projects rather than "research", but toward languages being designed by the<br/>application programmers who need to use them, rather than by compiler writers.<br/>This seems a good trend and I expect it to continue.  <br/>  <br/>  <br/>  <br/>Unlike physics in a hundred years, which is almost necessarily impossible to<br/>predict, I think it may be possible in principle to design a language now that<br/>would appeal to users in a hundred years.  <br/>  <br/>One way to design a language is to just write down the program you'd like to<br/>be able to write, regardless of whether there is a compiler that can translate<br/>it or hardware that can run it. When you do this you can assume unlimited<br/>resources. It seems like we ought to be able to imagine unlimited resources as<br/>well today as in a hundred years.  <br/>  <br/>What program would one like to write? Whatever is least work. Except not<br/>quite: whatever _would be_ least work if your ideas about programming weren't<br/>already influenced by the languages you're currently used to. Such influence<br/>can be so pervasive that it takes a great effort to overcome it. You'd think<br/>it would be obvious to creatures as lazy as us how to express a program with<br/>the least effort. In fact, our ideas about what's possible tend to be so<br/>limited by whatever language we think in that easier formulations of programs<br/>seem very surprising. They're something you have to discover, not something<br/>you naturally sink into.  <br/>  <br/>One helpful trick here is to use the length of the program as an approximation<br/>for how much work it is to write. Not the length in characters, of course, but<br/>the length in distinct syntactic elements-- basically, the size of the parse<br/>tree. It may not be quite true that the shortest program is the least work to<br/>write, but it's close enough that you're better off aiming for the solid<br/>target of brevity than the fuzzy, nearby one of least work. Then the algorithm<br/>for language design becomes: look at a program and ask, is there any way to<br/>write this that's shorter?  <br/>  <br/>In practice, writing programs in an imaginary hundred-year language will work<br/>to varying degrees depending on how close you are to the core. Sort routines<br/>you can write now. But it would be hard to predict now what kinds of libraries<br/>might be needed in a hundred years. Presumably many libraries will be for<br/>domains that don't even exist yet. If SETI@home works, for example, we'll need<br/>libraries for communicating with aliens. Unless of course they are<br/>sufficiently advanced that they already communicate in XML.  <br/>  <br/>At the other extreme, I think you might be able to design the core language<br/>today. In fact, some might argue that it was already mostly designed in 1958.  <br/>  <br/>  <br/>  <br/>If the hundred year language were available today, would we want to program in<br/>it? One way to answer this question is to look back. If present-day<br/>programming languages had been available in 1960, would anyone have wanted to<br/>use them?  <br/>  <br/>In some ways, the answer is no. Languages today assume infrastructure that<br/>didn't exist in 1960. For example, a language in which indentation is<br/>significant, like Python, would not work very well on printer terminals. But<br/>putting such problems aside-- assuming, for example, that programs were all<br/>just written on paper-- would programmers of the 1960s have liked writing<br/>programs in the languages we use now?  <br/>  <br/>I think so. Some of the less imaginative ones, who had artifacts of early<br/>languages built into their ideas of what a program was, might have had<br/>trouble. (How can you manipulate data without doing pointer arithmetic? How<br/>can you implement flow charts without gotos?) But I think the smartest<br/>programmers would have had no trouble making the most of present-day<br/>languages, if they'd had them.  <br/>  <br/>If we had the hundred-year language now, it would at least make a great<br/>pseudocode. What about using it to write software? Since the hundred-year<br/>language will need to generate fast code for some applications, presumably it<br/>could generate code efficient enough to run acceptably well on our hardware.<br/>We might have to give more optimization advice than users in a hundred years,<br/>but it still might be a net win.  <br/>  <br/>  <br/>  <br/>Now we have two ideas that, if you combine them, suggest interesting<br/>possibilities: (1) the hundred-year language could, in principle, be designed<br/>today, and (2) such a language, if it existed, might be good to program in<br/>today. When you see these ideas laid out like that, it's hard not to think,<br/>why not try writing the hundred-year language now?  <br/>  <br/>When you're working on language design, I think it is good to have such a<br/>target and to keep it consciously in mind. When you learn to drive, one of the<br/>principles they teach you is to align the car not by lining up the hood with<br/>the stripes painted on the road, but by aiming at some point in the distance.<br/>Even if all you care about is what happens in the next ten feet, this is the<br/>right answer. I think we can and should do the same thing with programming<br/>languages.  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>I believe Lisp Machine Lisp was the first language to embody the principle<br/>that declarations (except those of dynamic variables) were merely optimization<br/>advice, and would not change the meaning of a correct program. Common Lisp<br/>seems to have been the first to state this explicitly.  <br/>  <br/> **Thanks** to Trevor Blackwell, Robert Morris, and Dan Giffin for reading<br/>drafts of this, and to Guido van Rossum, Jeremy Hylton, and the rest of the<br/>Python crew for inviting me to speak at PyCon.  <br/>  <br/>  <br/><br/>Japanese Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>August 2013  <br/>  <br/>The biggest component in most investors' opinion of you is the opinion of<br/>other investors. Which is of course a recipe for exponential growth. When one<br/>investor wants to invest in you, that makes other investors want to, which<br/>makes others want to, and so on.  <br/>  <br/>Sometimes inexperienced founders mistakenly conclude that manipulating these<br/>forces is the essence of fundraising. They hear stories about stampedes to<br/>invest in successful startups, and think it's therefore the mark of a<br/>successful startup to have this happen. But actually the two are not that<br/>highly correlated. Lots of startups that cause stampedes end up flaming out<br/>(in extreme cases, partly as a result of the stampede), and lots of very<br/>successful startups were only moderately popular with investors the first time<br/>they raised money.  <br/>  <br/>So the point of this essay is not to explain how to create a stampede, but<br/>merely to explain the forces that generate them. These forces are always at<br/>work to some degree in fundraising, and they can cause surprising situations.<br/>If you understand them, you can at least avoid being surprised.  <br/>  <br/>One reason investors like you more when other investors like you is that you<br/>actually become a better investment. Raising money decreases the risk of<br/>failure. Indeed, although investors hate it, you are for this reason justified<br/>in raising your valuation for later investors. The investors who invested when<br/>you had no money were taking more risk, and are entitled to higher returns.<br/>Plus a company that has raised money is literally more valuable. After you<br/>raise the first million dollars, the company is at least a million dollars<br/>more valuable, because it's the same company as before, plus it has a million<br/>dollars in the bank. [1]  <br/>  <br/>Beware, though, because later investors so hate to have the price raised on<br/>them that they resist even this self-evident reasoning. Only raise the price<br/>on an investor you're comfortable with losing, because some will angrily<br/>refuse. [2]  <br/>  <br/>The second reason investors like you more when you've had some success at<br/>fundraising is that it makes you more confident, and an investors' opinion of<br/>you is the foundation of their opinion of your company. Founders are often<br/>surprised how quickly investors seem to know when they start to succeed at<br/>raising money. And while there are in fact lots of ways for such information<br/>to spread among investors, the main vector is probably the founders<br/>themselves. Though they're often clueless about technology, most investors are<br/>pretty good at reading people. When fundraising is going well, investors are<br/>quick to sense it in your increased confidence. (This is one case where the<br/>average founder's inability to remain poker-faced works to your advantage.)  <br/>  <br/>But frankly the most important reason investors like you more when you've<br/>started to raise money is that they're bad at judging startups. Judging<br/>startups is hard even for the best investors. The mediocre ones might as well<br/>be flipping coins. So when mediocre investors see that lots of other people<br/>want to invest in you, they assume there must be a reason. This leads to the<br/>phenomenon known in the Valley as the "hot deal," where you have more interest<br/>from investors than you can handle.  <br/>  <br/>The best investors aren't influenced much by the opinion of other investors.<br/>It would only dilute their own judgment to average it together with other<br/>people's. But they are indirectly influenced in the practical sense that<br/>interest from other investors imposes a deadline. This is the fourth way in<br/>which offers beget offers. If you start to get far along the track toward an<br/>offer with one firm, it will sometimes provoke other firms, even good ones, to<br/>make up their minds, lest they lose the deal.  <br/>  <br/>Unless you're a wizard at negotiation (and if you're not sure, you're not) be<br/>very careful about exaggerating this to push a good investor to decide.<br/>Founders try this sort of thing all the time, and investors are very sensitive<br/>to it. If anything oversensitive. But you're safe so long as you're telling<br/>the truth. If you're getting far along with investor B, but you'd rather raise<br/>money from investor A, you can tell investor A that this is happening. There's<br/>no manipulation in that. You're genuinely in a bind, because you really would<br/>rather raise money from A, but you can't safely reject an offer from B when<br/>it's still uncertain what A will decide.  <br/>  <br/>Do not, however, tell A who B is. VCs will sometimes ask which other VCs<br/>you're talking to, but you should never tell them. Angels you can sometimes<br/>tell about other angels, because angels cooperate more with one another. But<br/>if VCs ask, just point out that they wouldn't want you telling other firms<br/>about your conversations, and you feel obliged to do the same for any firm you<br/>talk to. If they push you, point out that you're inexperienced at<br/>fundraising—which is always a safe card to play—and you feel you have to be<br/>extra cautious. [3]  <br/>  <br/>While few startups will experience a stampede of interest, almost all will at<br/>least initially experience the other side of this phenomenon, where the herd<br/>remains clumped together at a distance. The fact that investors are so much<br/>influenced by other investors' opinions means you always start out in<br/>something of a hole. So don't be demoralized by how hard it is to get the<br/>first commitment, because much of the difficulty comes from this external<br/>force. The second will be easier.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] An accountant might say that a company that has raised a million dollars<br/>is no richer if it's convertible debt, but in practice money raised as<br/>convertible debt is little different from money raised in an equity round.  <br/>  <br/>[2] Founders are often surprised by this, but investors can get very<br/>emotional. Or rather indignant; that's the main emotion I've observed; but it<br/>is very common, to the point where it sometimes causes investors to act<br/>against their own interests. I know of one investor who invested in a startup<br/>at a $15 million valuation cap. Earlier he'd had an opportunity to invest at a<br/>$5 million cap, but he refused because a friend who invested earlier had been<br/>able to invest at a $3 million cap.  <br/>  <br/>[3] If an investor pushes you hard to tell them about your conversations with<br/>other investors, is this someone you want as an investor?  <br/>  <br/>**Thanks** to Paul Buchheit, Jessica Livingston, Geoff Ralston, and Garry Tan<br/>for reading drafts of this.  <br/>  <br/><br/>Russian Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>March 2006, rev August 2009  <br/>  <br/>A couple days ago I found to my surprise that I'd been granted a patent. It<br/>issued in 2003, but no one told me. I wouldn't know about it now except that a<br/>few months ago, while visiting Yahoo, I happened to run into a Big Cheese I<br/>knew from working there in the late nineties. He brought up something called<br/>Revenue Loop, which Viaweb had been working on when they bought us.  <br/>  <br/>The idea is basically that you sort search results not in order of textual<br/>"relevance" (as search engines did then) nor in order of how much advertisers<br/>bid (as Overture did) but in order of the bid times the number of<br/>transactions. Ordinarily you'd do this for shopping searches, though in fact<br/>one of the features of our scheme is that it automatically detects which<br/>searches are shopping searches.  <br/>  <br/>If you just order the results in order of bids, you can make the search<br/>results useless, because the first results could be dominated by lame sites<br/>that had bid the most. But if you order results by bid multiplied by<br/>transactions, far from selling out, you're getting a _better_ measure of<br/>relevance. What could be a better sign that someone was satisfied with a<br/>search result than going to the site and buying something?  <br/>  <br/>And, of course, this algorithm automatically maximizes the revenue of the<br/>search engine.  <br/>  <br/>Everyone is focused on this type of approach now, but few were in 1998\. In<br/>1998 it was all about selling banner ads. We didn't know that, so we were<br/>pretty excited when we figured out what seemed to us the optimal way of doing<br/>shopping searches.  <br/>  <br/>When Yahoo was thinking of buying us, we had a meeting with Jerry Yang in New<br/>York. For him, I now realize, this was supposed to be one of those meetings<br/>when you check out a company you've pretty much decided to buy, just to make<br/>sure they're ok guys. We weren't expected to do more than chat and seem smart<br/>and reasonable. He must have been dismayed when I jumped up to the whiteboard<br/>and launched into a presentation of our exciting new technology.  <br/>  <br/>I was just as dismayed when he didn't seem to care at all about it. At the<br/>time I thought, "boy, is this guy poker-faced. We present to him what has to<br/>be the optimal way of sorting product search results, and he's not even<br/>curious." I didn't realize till much later why he didn't care. In 1998,<br/>advertisers were overpaying enormously for ads on web sites. In 1998, if<br/>advertisers paid the maximum that traffic was worth to them, Yahoo's revenues<br/>would have _decreased._  <br/>  <br/>Things are different now, of course. Now this sort of thing is all the rage.<br/>So when I ran into the Yahoo exec I knew from the old days in the Yahoo<br/>cafeteria a few months ago, the first thing he remembered was not<br/>(fortunately) all the fights I had with him, but Revenue Loop.  <br/>  <br/>"Well," I said, "I think we actually applied for a patent on it. I'm not sure<br/>what happened to the application after I left."  <br/>  <br/>"Really? That would be an important patent."  <br/>  <br/>So someone investigated, and sure enough, that patent application had<br/>continued in the pipeline for several years after, and finally issued in 2003.  <br/>  <br/>The main thing that struck me on reading it, actually, is that lawyers at some<br/>point messed up my nice clear writing. Some clever person with a spell checker<br/>reduced one section to Zen-like incomprehensibility:<br/><br/>> Also, common spelling errors will tend to get fixed. For example, if users<br/>> searching for "compact disc player" end up spending considerable money at<br/>> sites offering compact disc players, then those pages will have a higher<br/>> relevance for that search phrase, even though the phrase "compact disc<br/>> player" is not present on those pages.<br/><br/>(That "compat disc player" wasn't a typo, guys.)  <br/>  <br/>For the fine prose of the original, see the provisional application of<br/>February 1998, back when we were still Viaweb and couldn't afford to pay<br/>lawyers to turn every "a lot of" into "considerable."  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>October 2005  <br/>  <br/>The first Summer Founders Program has just finished. We were surprised how<br/>well it went. Overall only about 10% of startups succeed, but if I had to<br/>guess now, I'd predict three or four of the eight startups we funded will make<br/>it.  <br/>  <br/>Of the startups that needed further funding, I believe all have either closed<br/>a round or are likely to soon. Two have already turned down (lowball)<br/>acquisition offers.  <br/>  <br/>We would have been happy if just one of the eight seemed promising by the end<br/>of the summer. What's going on? Did some kind of anomaly make this summer's<br/>applicants especially good? We worry about that, but we can't think of one.<br/>We'll find out this winter<br/><br/>Romanian Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>October 2015  <br/>  <br/>When I talk to a startup that's been operating for more than 8 or 9 months,<br/>the first thing I want to know is almost always the same. Assuming their<br/>expenses remain constant and their revenue growth is what it has been over the<br/>last several months, do they make it to profitability on the money they have<br/>left? Or to put it more dramatically, by default do they live or die?  <br/>  <br/>The startling thing is how often the founders themselves don't know. Half the<br/>founders I talk to don't know whether they're default alive or default dead.  <br/>  <br/>If you're among that number, Trevor Blackwell has made a handy _calculator_<br/>you can use to find out.  <br/>  <br/>The reason I want to know first whether a startup is default alive or default<br/>dead is that the rest of the conversation depends on the answer. If the<br/>company is default alive, we can talk about ambitious new things they could<br/>do. If it's default dead, we probably need to talk about how to save it. We<br/>know the current trajectory ends badly. How can they get off that trajectory?  <br/>  <br/>Why do so few founders know whether they're default alive or default dead?<br/>Mainly, I think, because they're not used to asking that. It's not a question<br/>that makes sense to ask early on, any more than it makes sense to ask a 3 year<br/>old how he plans to support himself. But as the company grows older, the<br/>question switches from meaningless to critical. That kind of switch often<br/>takes people by surprise.  <br/>  <br/>I propose the following solution: instead of starting to ask too late whether<br/>you're default alive or default dead, start asking too early. It's hard to say<br/>precisely when the question switches polarity. But it's probably not that<br/>dangerous to start worrying too early that you're default dead, whereas it's<br/>very dangerous to start worrying too late.  <br/>  <br/>The reason is a phenomenon I wrote about earlier: the fatal pinch. The fatal<br/>pinch is default dead + slow growth + not enough time to fix it. And the way<br/>founders end up in it is by not realizing that's where they're headed.  <br/>  <br/>There is another reason founders don't ask themselves whether they're default<br/>alive or default dead: they assume it will be easy to raise more money. But<br/>that assumption is often false, and worse still, the more you depend on it,<br/>the falser it becomes.  <br/>  <br/>Maybe it will help to separate facts from hopes. Instead of thinking of the<br/>future with vague optimism, explicitly separate the components. Say "We're<br/>default dead, but we're counting on investors to save us." Maybe as you say<br/>that, it will set off the same alarms in your head that it does in mine. And<br/>if you set off the alarms sufficiently early, you may be able to avoid the<br/>fatal pinch.  <br/>  <br/>It would be safe to be default dead if you could count on investors saving<br/>you. As a rule their interest is a function of growth. If you have steep<br/>revenue growth, say over 5x a year, you can start to count on investors being<br/>interested even if you're not profitable. [1] But investors are so fickle that<br/>you can never do more than start to count on them. Sometimes something about<br/>your business will spook investors even if your growth is great. So no matter<br/>how good your growth is, you can never safely treat fundraising as more than a<br/>plan A. You should always have a plan B as well: you should know (as in write<br/>down) precisely what you'll need to do to survive if you can't raise more<br/>money, and precisely when you'll have to switch to plan B if plan A isn't<br/>working.  <br/>  <br/>In any case, growing fast versus operating cheaply is far from the sharp<br/>dichotomy many founders assume it to be. In practice there is surprisingly<br/>little connection between how much a startup spends and how fast it grows.<br/>When a startup grows fast, it's usually because the product hits a nerve, in<br/>the sense of hitting some big need straight on. When a startup spends a lot,<br/>it's usually because the product is expensive to develop or sell, or simply<br/>because they're wasteful.  <br/>  <br/>If you're paying attention, you'll be asking at this point not just how to<br/>avoid the fatal pinch, but how to avoid being default dead. That one is easy:<br/>don't hire too fast. Hiring too fast is by far the biggest killer of startups<br/>that raise money. [2]  <br/>  <br/>Founders tell themselves they need to hire in order to grow. But most err on<br/>the side of overestimating this need rather than underestimating it. Why?<br/>Partly because there's so much work to do. Naive founders think that if they<br/>can just hire enough people, it will all get done. Partly because successful<br/>startups have lots of employees, so it seems like that's what one does in<br/>order to be successful. In fact the large staffs of successful startups are<br/>probably more the effect of growth than the cause. And partly because when<br/>founders have slow growth they don't want to face what is usually the real<br/>reason: the product is not appealing enough.  <br/>  <br/>Plus founders who've just raised money are often encouraged to overhire by the<br/>VCs who funded them. Kill-or-cure strategies are optimal for VCs because<br/>they're protected by the portfolio effect. VCs want to blow you up, in one<br/>sense of the phrase or the other. But as a founder your incentives are<br/>different. You want above all to survive. [3]  <br/>  <br/>Here's a common way startups die. They make something moderately appealing and<br/>have decent initial growth. They raise their first round fairly easily,<br/>because the founders seem smart and the idea sounds plausible. But because the<br/>product is only moderately appealing, growth is ok but not great. The founders<br/>convince themselves that hiring a bunch of people is the way to boost growth.<br/>Their investors agree. But (because the product is only moderately appealing)<br/>the growth never comes. Now they're rapidly running out of runway. They hope<br/>further investment will save them. But because they have high expenses and<br/>slow growth, they're now unappealing to investors. They're unable to raise<br/>more, and the company dies.  <br/>  <br/>What the company should have done is address the fundamental problem: that the<br/>product is only moderately appealing. Hiring people is rarely the way to fix<br/>that. More often than not it makes it harder. At this early stage, the product<br/>needs to evolve more than to be "built out," and that's usually easier with<br/>fewer people. [4]  <br/>  <br/>Asking whether you're default alive or default dead may save you from this.<br/>Maybe the alarm bells it sets off will counteract the forces that push you to<br/>overhire. Instead you'll be compelled to seek growth in other ways. For<br/>example, by _doing things that don't scale_, or by redesigning the product in<br/>the way only founders can. And for many if not most startups, these paths to<br/>growth will be the ones that actually work.  <br/>  <br/>Airbnb waited 4 months after raising money at the end of Y Combinator before<br/>they hired their first employee. In the meantime the founders were terribly<br/>overworked. But they were overworked evolving Airbnb into the astonishingly<br/>successful organism it is now.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Steep usage growth will also interest investors. Revenue will ultimately<br/>be a constant multiple of usage, so x% usage growth predicts x% revenue<br/>growth. But in practice investors discount merely predicted revenue, so if<br/>you're measuring usage you need a higher growth rate to impress investors.  <br/>  <br/>[2] Startups that don't raise money are saved from hiring too fast because<br/>they can't afford to. But that doesn't mean you should avoid raising money in<br/>order to avoid this problem, any more than that total abstinence is the only<br/>way to avoid becoming an alcoholic.  <br/>  <br/>[3] I would not be surprised if VCs' tendency to push founders to overhire is<br/>not even in their own interest. They don't know how many of the companies that<br/>get killed by overspending might have done well if they'd survived. My guess<br/>is a significant number.  <br/>  <br/>[4] After reading a draft, Sam Altman wrote:  <br/>  <br/>"I think you should make the hiring point more strongly. I think it's roughly<br/>correct to say that YC's most successful companies have never been the fastest<br/>to hire, and one of the marks of a great founder is being able to resist this<br/>urge."  <br/>  <br/>Paul Buchheit adds:  <br/>  <br/>"A related problem that I see a lot is premature scaling—founders take a small<br/>business that isn't really working (bad unit economics, typically) and then<br/>scale it up because they want impressive growth numbers. This is similar to<br/>over-hiring in that it makes the business much harder to fix once it's big,<br/>plus they are bleeding cash really fast."  <br/>  <br/>**Thanks** to Sam Altman, Paul Buchheit, Joe Gebbia, Jessica Livingston, and<br/>Geoff Ralston for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>May 2006  <br/>  <br/> _(This essay is derived from a keynote at Xtech.)_  <br/>  <br/>Startups happen in clusters. There are a lot of them in Silicon Valley and<br/>Boston, and few in Chicago or Miami. A country that wants startups will<br/>probably also have to reproduce whatever makes these clusters form.  <br/>  <br/>I've claimed that the recipe is a great university near a town smart people<br/>like. If you set up those conditions within the US, startups will form as<br/>inevitably as water droplets condense on a cold piece of metal. But when I<br/>consider what it would take to reproduce Silicon Valley in another country,<br/>it's clear the US is a particularly humid environment. Startups condense more<br/>easily here.  <br/>  <br/>It is by no means a lost cause to try to create a silicon valley in another<br/>country. There's room not merely to equal Silicon Valley, but to surpass it.<br/>But if you want to do that, you have to understand the advantages startups get<br/>from being in America.  <br/>  <br/> **1\. The US Allows Immigration.**  <br/>  <br/>For example, I doubt it would be possible to reproduce Silicon Valley in<br/>Japan, because one of Silicon Valley's most distinctive features is<br/>immigration. Half the people there speak with accents. And the Japanese don't<br/>like immigration. When they think about how to make a Japanese silicon valley,<br/>I suspect they unconsciously frame it as how to make one consisting only of<br/>Japanese people. This way of framing the question probably guarantees failure.  <br/>  <br/>A silicon valley has to be a mecca for the smart and the ambitious, and you<br/>can't have a mecca if you don't let people into it.  <br/>  <br/>Of course, it's not saying much that America is more open to immigration than<br/>Japan. Immigration policy is one area where a competitor could do better.  <br/>  <br/> **2\. The US Is a Rich Country.**  <br/>  <br/>I could see India one day producing a rival to Silicon Valley. Obviously they<br/>have the right people: you can tell that by the number of Indians in the<br/>current Silicon Valley. The problem with India itself is that it's still so<br/>poor.  <br/>  <br/>In poor countries, things we take for granted are missing. A friend of mine<br/>visiting India sprained her ankle falling down the steps in a railway station.<br/>When she turned to see what had happened, she found the steps were all<br/>different heights. In industrialized countries we walk down steps our whole<br/>lives and never think about this, because there's an infrastructure that<br/>prevents such a staircase from being built.  <br/>  <br/>The US has never been so poor as some countries are now. There have never been<br/>swarms of beggars in the streets of American cities. So we have no data about<br/>what it takes to get from the swarms-of-beggars stage to the silicon-valley<br/>stage. Could you have both at once, or does there have to be some baseline<br/>prosperity before you get a silicon valley?  <br/>  <br/>I suspect there is some speed limit to the evolution of an economy. Economies<br/>are made out of people, and attitudes can only change a certain amount per<br/>generation. [1]  <br/>  <br/> **3\. The US Is Not (Yet) a Police State.**  <br/>  <br/>Another country I could see wanting to have a silicon valley is China. But I<br/>doubt they could do it yet either. China still seems to be a police state, and<br/>although present rulers seem enlightened compared to the last, even<br/>enlightened despotism can probably only get you part way toward being a great<br/>economic power.  <br/>  <br/>It can get you factories for building things designed elsewhere. Can it get<br/>you the designers, though? Can imagination flourish where people can't<br/>criticize the government? Imagination means having odd ideas, and it's hard to<br/>have odd ideas about technology without also having odd ideas about politics.<br/>And in any case, many technical ideas do have political implications. So if<br/>you squash dissent, the back pressure will propagate into technical fields.<br/>[2]  <br/>  <br/>Singapore would face a similar problem. Singapore seems very aware of the<br/>importance of encouraging startups. But while energetic government<br/>intervention may be able to make a port run efficiently, it can't coax<br/>startups into existence. A state that bans chewing gum has a long way to go<br/>before it could create a San Francisco.  <br/>  <br/>Do you need a San Francisco? Might there not be an alternate route to<br/>innovation that goes through obedience and cooperation instead of<br/>individualism? Possibly, but I'd bet not. Most imaginative people seem to<br/>share a certain prickly independence, whenever and wherever they lived. You<br/>see it in Diogenes telling Alexander to get out of his light and two thousand<br/>years later in Feynman breaking into safes at Los Alamos. [3] Imaginative<br/>people don't want to follow or lead. They're most productive when everyone<br/>gets to do what they want.  <br/>  <br/>Ironically, of all rich countries the US has lost the most civil liberties<br/>recently. But I'm not too worried yet. I'm hoping once the present<br/>administration is out, the natural openness of American culture will reassert<br/>itself.  <br/>  <br/> **4\. American Universities Are Better.**  <br/>  <br/>You need a great university to seed a silicon valley, and so far there are few<br/>outside the US. I asked a handful of American computer science professors<br/>which universities in Europe were most admired, and they all basically said<br/>"Cambridge" followed by a long pause while they tried to think of others.<br/>There don't seem to be many universities elsewhere that compare with the best<br/>in America, at least in technology.  <br/>  <br/>In some countries this is the result of a deliberate policy. The German and<br/>Dutch governments, perhaps from fear of elitism, try to ensure that all<br/>universities are roughly equal in quality. The downside is that none are<br/>especially good. The best professors are spread out, instead of being<br/>concentrated as they are in the US. This probably makes them less productive,<br/>because they don't have good colleagues to inspire them. It also means no one<br/>university will be good enough to act as a mecca, attracting talent from<br/>abroad and causing startups to form around it.  <br/>  <br/>The case of Germany is a strange one. The Germans invented the modern<br/>university, and up till the 1930s theirs were the best in the world. Now they<br/>have none that stand out. As I was mulling this over, I found myself thinking:<br/>"I can understand why German universities declined in the 1930s, after they<br/>excluded Jews. But surely they should have bounced back by now." Then I<br/>realized: maybe not. There are few Jews left in Germany and most Jews I know<br/>would not want to move there. And if you took any great American university<br/>and removed the Jews, you'd have some pretty big gaps. So maybe it would be a<br/>lost cause trying to create a silicon valley in Germany, because you couldn't<br/>establish the level of university you'd need as a seed. [4]  <br/>  <br/>It's natural for US universities to compete with one another because so many<br/>are private. To reproduce the quality of American universities you probably<br/>also have to reproduce this. If universities are controlled by the central<br/>government, log-rolling will pull them all toward the mean: the new Institute<br/>of X will end up at the university in the district of a powerful politician,<br/>instead of where it should be.  <br/>  <br/> **5\. You Can Fire People in America.**  <br/>  <br/>I think one of the biggest obstacles to creating startups in Europe is the<br/>attitude toward employment. The famously rigid labor laws hurt every company,<br/>but startups especially, because startups have the least time to spare for<br/>bureaucratic hassles.  <br/>  <br/>The difficulty of firing people is a particular problem for startups because<br/>they have no redundancy. Every person has to do their job well.  <br/>  <br/>But the problem is more than just that some startup might have a problem<br/>firing someone they needed to. Across industries and countries, there's a<br/>strong inverse correlation between performance and job security. Actors and<br/>directors are fired at the end of each film, so they have to deliver every<br/>time. Junior professors are fired by default after a few years unless the<br/>university chooses to grant them tenure. Professional athletes know they'll be<br/>pulled if they play badly for just a couple games. At the other end of the<br/>scale (at least in the US) are auto workers, New York City schoolteachers, and<br/>civil servants, who are all nearly impossible to fire. The trend is so clear<br/>that you'd have to be willfully blind not to see it.  <br/>  <br/>Performance isn't everything, you say? Well, are auto workers, schoolteachers,<br/>and civil servants _happier_ than actors, professors, and professional<br/>athletes?  <br/>  <br/>European public opinion will apparently tolerate people being fired in<br/>industries where they really care about performance. Unfortunately the only<br/>industry they care enough about so far is soccer. But that is at least a<br/>precedent.  <br/>  <br/> **6\. In America Work Is Less Identified with Employment.**  <br/>  <br/>The problem in more traditional places like Europe and Japan goes deeper than<br/>the employment laws. More dangerous is the attitude they reflect: that an<br/>employee is a kind of servant, whom the employer has a duty to protect. It<br/>used to be that way in America too. In 1970 you were still supposed to get a<br/>job with a big company, for whom ideally you'd work your whole career. In<br/>return the company would take care of you: they'd try not to fire you, cover<br/>your medical expenses, and support you in old age.  <br/>  <br/>Gradually employment has been shedding such paternalistic overtones and<br/>becoming simply an economic exchange. But the importance of the new model is<br/>not just that it makes it easier for startups to grow. More important, I<br/>think, is that it it makes it easier for people to _start_ startups.  <br/>  <br/>Even in the US most kids graduating from college still think they're supposed<br/>to get jobs, as if you couldn't be productive without being someone's<br/>employee. But the less you identify work with employment, the easier it<br/>becomes to start a startup. When you see your career as a series of different<br/>types of work, instead of a lifetime's service to a single employer, there's<br/>less risk in starting your own company, because you're only replacing one<br/>segment instead of discarding the whole thing.  <br/>  <br/>The old ideas are so powerful that even the most successful startup founders<br/>have had to struggle against them. A year after the founding of Apple, Steve<br/>Wozniak still hadn't quit HP. He still planned to work there for life. And<br/>when Jobs found someone to give Apple serious venture funding, on the<br/>condition that Woz quit, he initially refused, arguing that he'd designed both<br/>the Apple I and the Apple II while working at HP, and there was no reason he<br/>couldn't continue.  <br/>  <br/> **7\. America Is Not Too Fussy.**  <br/>  <br/>If there are any laws regulating businesses, you can assume larval startups<br/>will break most of them, because they don't know what the laws are and don't<br/>have time to find out.  <br/>  <br/>For example, many startups in America begin in places where it's not really<br/>legal to run a business. Hewlett-Packard, Apple, and Google were all run out<br/>of garages. Many more startups, including ours, were initially run out of<br/>apartments. If the laws against such things were actually enforced, most<br/>startups wouldn't happen.  <br/>  <br/>That could be a problem in fussier countries. If Hewlett and Packard tried<br/>running an electronics company out of their garage in Switzerland, the old<br/>lady next door would report them to the municipal authorities.  <br/>  <br/>But the worst problem in other countries is probably the effort required just<br/>to start a company. A friend of mine started a company in Germany in the early<br/>90s, and was shocked to discover, among many other regulations, that you<br/>needed $20,000 in capital to incorporate. That's one reason I'm not typing<br/>this on an Apfel laptop. Jobs and Wozniak couldn't have come up with that kind<br/>of money in a company financed by selling a VW bus and an HP calculator. We<br/>couldn't have started Viaweb either. [5]  <br/>  <br/>Here's a tip for governments that want to encourage startups: read the stories<br/>of existing startups, and then try to simulate what would have happened in<br/>your country. When you hit something that would have killed Apple, prune it<br/>off.  <br/>  <br/> _Startups aremarginal._ They're started by the poor and the timid; they begin<br/>in marginal space and spare time; they're started by people who are supposed<br/>to be doing something else; and though businesses, their founders often know<br/>nothing about business. Young startups are fragile. A society that trims its<br/>margins sharply will kill them all.  <br/>  <br/> **8\. America Has a Large Domestic Market.**  <br/>  <br/>What sustains a startup in the beginning is the prospect of getting their<br/>initial product out. The successful ones therefore make the first version as<br/>simple as possible. In the US they usually begin by making something just for<br/>the local market.  <br/>  <br/>This works in America, because the local market is 300 million people. It<br/>wouldn't work so well in Sweden. In a small country, a startup has a harder<br/>task: they have to sell internationally from the start.  <br/>  <br/>The EU was designed partly to simulate a single, large domestic market. The<br/>problem is that the inhabitants still speak many different languages. So a<br/>software startup in Sweden is still at a disadvantage relative to one in the<br/>US, because they have to deal with internationalization from the beginning.<br/>It's significant that the most famous recent startup in Europe, Skype, worked<br/>on a problem that was intrinsically international.  <br/>  <br/>However, for better or worse it looks as if Europe will in a few decades speak<br/>a single language. When I was a student in Italy in 1990, few Italians spoke<br/>English. Now all educated people seem to be expected to-- and Europeans do not<br/>like to seem uneducated. This is presumably a taboo subject, but if present<br/>trends continue, French and German will eventually go the way of Irish and<br/>Luxembourgish: they'll be spoken in homes and by eccentric nationalists.  <br/>  <br/> **9\. America Has Venture Funding.**  <br/>  <br/>Startups are easier to start in America because funding is easier to get.<br/>There are now a few VC firms outside the US, but startup funding doesn't only<br/>come from VC firms. A more important source, because it's more personal and<br/>comes earlier in the process, is money from individual angel investors. Google<br/>might never have got to the point where they could raise millions from VC<br/>funds if they hadn't first raised a hundred thousand from Andy Bechtolsheim.<br/>And he could help them because he was one of the founders of Sun. This pattern<br/>is repeated constantly in startup hubs. It's this pattern that _makes_ them<br/>startup hubs.  <br/>  <br/>The good news is, all you have to do to get the process rolling is get those<br/>first few startups successfully launched. If they stick around after they get<br/>rich, startup founders will almost automatically fund and encourage new<br/>startups.  <br/>  <br/>The bad news is that the cycle is slow. It probably takes five years, on<br/>average, before a startup founder can make angel investments. And while<br/>governments _might_ be able to set up local VC funds by supplying the money<br/>themselves and recruiting people from existing firms to run them, only organic<br/>growth can produce angel investors.  <br/>  <br/>Incidentally, America's private universities are one reason there's so much<br/>venture capital. A lot of the money in VC funds comes from their endowments.<br/>So another advantage of private universities is that a good chunk of the<br/>country's wealth is managed by enlightened investors.  <br/>  <br/> **10\. America Has Dynamic Typing for Careers.**  <br/>  <br/>Compared to other industrialized countries the US is disorganized about<br/>routing people into careers. For example, in America people often don't decide<br/>to go to medical school till they've finished college. In Europe they<br/>generally decide in high school.  <br/>  <br/>The European approach reflects the old idea that each person has a single,<br/>definite occupation-- which is not far from the idea that each person has a<br/>natural "station" in life. If this were true, the most efficient plan would be<br/>to discover each person's station as early as possible, so they could receive<br/>the training appropriate to it.  <br/>  <br/>In the US things are more haphazard. But that turns out to be an advantage as<br/>an economy gets more liquid, just as dynamic typing turns out to work better<br/>than static for ill-defined problems. This is particularly true with startups.<br/>"Startup founder" is not the sort of career a high school student would<br/>choose. If you ask at that age, people will choose conservatively. They'll<br/>choose well-understood occupations like engineer, or doctor, or lawyer.  <br/>  <br/>Startups are the kind of thing people don't plan, so you're more likely to get<br/>them in a society where it's ok to make career decisions on the fly.  <br/>  <br/>For example, in theory the purpose of a PhD program is to train you to do<br/>research. But fortunately in the US this is another rule that isn't very<br/>strictly enforced. In the US most people in CS PhD programs are there simply<br/>because they wanted to learn more. They haven't decided what they'll do<br/>afterward. So American grad schools spawn a lot of startups, because students<br/>don't feel they're failing if they don't go into research.  <br/>  <br/>Those worried about America's "competitiveness" often suggest spending more on<br/>public schools. But perhaps America's lousy public schools have a hidden<br/>advantage. Because they're so bad, the kids adopt an attitude of waiting for<br/>college. I did; I knew I was learning so little that I wasn't even learning<br/>what the choices were, let alone which to choose. This is demoralizing, but it<br/>does at least make you keep an open mind.  <br/>  <br/>Certainly if I had to choose between bad high schools and good universities,<br/>like the US, and good high schools and bad universities, like most other<br/>industrialized countries, I'd take the US system. Better to make everyone feel<br/>like a late bloomer than a failed child prodigy.  <br/>  <br/> **Attitudes**  <br/>  <br/>There's one item conspicuously missing from this list: American attitudes.<br/>Americans are said to be more entrepreneurial, and less afraid of risk. But<br/>America has no monopoly on this. Indians and Chinese seem plenty<br/>entrepreneurial, perhaps more than Americans.  <br/>  <br/>Some say Europeans are less energetic, but I don't believe it. I think the<br/>problem with Europe is not that they lack balls, but that they lack examples.  <br/>  <br/>Even in the US, the most successful startup founders are often technical<br/>people who are quite timid, initially, about the idea of starting their own<br/>company. Few are the sort of backslapping extroverts one thinks of as<br/>typically American. They can usually only summon up the activation energy to<br/>start a startup when they meet people who've done it and realize they could<br/>too.  <br/>  <br/>I think what holds back European hackers is simply that they don't meet so<br/>many people who've done it. You see that variation even within the US.<br/>Stanford students are more entrepreneurial than Yale students, but not because<br/>of some difference in their characters; the Yale students just have fewer<br/>examples.  <br/>  <br/>I admit there seem to be different attitudes toward ambition in Europe and the<br/>US. In the US it's ok to be overtly ambitious, and in most of Europe it's not.<br/>But this can't be an intrinsically European quality; previous generations of<br/>Europeans were as ambitious as Americans. What happened? My hypothesis is that<br/>ambition was discredited by the terrible things ambitious people did in the<br/>first half of the twentieth century. Now swagger is out. (Even now the image<br/>of a very ambitious German presses a button or two, doesn't it?)  <br/>  <br/>It would be surprising if European attitudes weren't affected by the disasters<br/>of the twentieth century. It takes a while to be optimistic after events like<br/>that. But ambition is human nature. Gradually it will re-emerge. [6]  <br/>  <br/> **How To Do Better**  <br/>  <br/>I don't mean to suggest by this list that America is the perfect place for<br/>startups. It's the best place so far, but the sample size is small, and "so<br/>far" is not very long. On historical time scales, what we have now is just a<br/>prototype.  <br/>  <br/>So let's look at Silicon Valley the way you'd look at a product made by a<br/>competitor. What weaknesses could you exploit? How could you make something<br/>users would like better? The users in this case are those critical few<br/>thousand people you'd like to move to your silicon valley.  <br/>  <br/>To start with, Silicon Valley is too far from San Francisco. Palo Alto, the<br/>original ground zero, is about thirty miles away, and the present center more<br/>like forty. So people who come to work in Silicon Valley face an unpleasant<br/>choice: either live in the boring sprawl of the valley proper, or live in San<br/>Francisco and endure an hour commute each way.  <br/>  <br/>The best thing would be if the silicon valley were not merely closer to the<br/>interesting city, but interesting itself. And there is a lot of room for<br/>improvement here. Palo Alto is not so bad, but everything built since is the<br/>worst sort of strip development. You can measure how demoralizing it is by the<br/>number of people who will sacrifice two hours a day commuting rather than live<br/>there.  <br/>  <br/>Another area in which you could easily surpass Silicon Valley is public<br/>transportation. There is a train running the length of it, and by American<br/>standards it's not bad. Which is to say that to Japanese or Europeans it would<br/>seem like something out of the third world.  <br/>  <br/>The kind of people you want to attract to your silicon valley like to get<br/>around by train, bicycle, and on foot. So if you want to beat America, design<br/>a town that puts cars last. It will be a while before any American city can<br/>bring itself to do that.  <br/>  <br/> **Capital Gains**  <br/>  <br/>There are also a couple things you could do to beat America at the national<br/>level. One would be to have lower capital gains taxes. It doesn't seem<br/>critical to have the lowest _income_ taxes, because to take advantage of<br/>those, people have to move. [7] But if capital gains rates vary, you move<br/>assets, not yourself, so changes are reflected at market speeds. The lower the<br/>rate, the cheaper it is to buy stock in growing companies as opposed to real<br/>estate, or bonds, or stocks bought for the dividends they pay.  <br/>  <br/>So if you want to encourage startups you should have a low rate on capital<br/>gains. Politicians are caught between a rock and a hard place here, however:<br/>make the capital gains rate low and be accused of creating "tax breaks for the<br/>rich," or make it high and starve growing companies of investment capital. As<br/>Galbraith said, politics is a matter of choosing between the unpalatable and<br/>the disastrous. A lot of governments experimented with the disastrous in the<br/>twentieth century; now the trend seems to be toward the merely unpalatable.  <br/>  <br/>Oddly enough, the leaders now are European countries like Belgium, which has a<br/>capital gains tax rate of zero.  <br/>  <br/> **Immigration**  <br/>  <br/>The other place you could beat the US would be with smarter immigration<br/>policy. There are huge gains to be made here. Silicon valleys are made of<br/>people, remember.  <br/>  <br/>Like a company whose software runs on Windows, those in the current Silicon<br/>Valley are all too aware of the shortcomings of the INS, but there's little<br/>they can do about it. They're hostages of the platform.  <br/>  <br/>America's immigration system has never been well run, and since 2001 there has<br/>been an additional admixture of paranoia. What fraction of the smart people<br/>who want to come to America can even get in? I doubt even half. Which means if<br/>you made a competing technology hub that let in all smart people, you'd<br/>immediately get more than half the world's top talent, for free.  <br/>  <br/>US immigration policy is particularly ill-suited to startups, because it<br/>reflects a model of work from the 1970s. It assumes good technical people have<br/>college degrees, and that work means working for a big company.  <br/>  <br/>If you don't have a college degree you can't get an H1B visa, the type usually<br/>issued to programmers. But a test that excludes Steve Jobs, Bill Gates, and<br/>Michael Dell can't be a good one. Plus you can't get a visa for working on<br/>your own company, only for working as an employee of someone else's. And if<br/>you want to apply for citizenship you daren't work for a startup at all,<br/>because if your sponsor goes out of business, you have to start over.  <br/>  <br/>American immigration policy keeps out most smart people, and channels the rest<br/>into unproductive jobs. It would be easy to do better. Imagine if, instead,<br/>you treated immigration like recruiting-- if you made a conscious effort to<br/>seek out the smartest people and get them to come to your country.  <br/>  <br/>A country that got immigration right would have a huge advantage. At this<br/>point you could become a mecca for smart people simply by having an<br/>immigration system that let them in.  <br/>  <br/> **A Good Vector**  <br/>  <br/>If you look at the kinds of things you have to do to create an environment<br/>where startups condense, none are great sacrifices. Great universities?<br/>Livable towns? Civil liberties? Flexible employment laws? Immigration policies<br/>that let in smart people? Tax laws that encourage growth? It's not as if you<br/>have to risk destroying your country to get a silicon valley; these are all<br/>good things in their own right.  <br/>  <br/>And then of course there's the question, can you afford not to? I can imagine<br/>a future in which the default choice of ambitious young people is to start<br/>their own company rather than work for someone else's. I'm not sure that will<br/>happen, but it's where the trend points now. And if that is the future, places<br/>that don't have startups will be a whole step behind, like those that missed<br/>the Industrial Revolution.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] On the verge of the Industrial Revolution, England was already the richest<br/>country in the world. As far as such things can be compared, per capita income<br/>in England in 1750 was higher than India's in 1960.  <br/>  <br/>Deane, Phyllis, _The First Industrial Revolution_ , Cambridge University<br/>Press, 1965.  <br/>  <br/>[2] This has already happened once in China, during the Ming Dynasty, when the<br/>country turned its back on industrialization at the command of the court. One<br/>of Europe's advantages was that it had no government powerful enough to do<br/>that.  <br/>  <br/>[3] Of course, Feynman and Diogenes were from adjacent traditions, but<br/>Confucius, though more polite, was no more willing to be told what to think.  <br/>  <br/>[4] For similar reasons it might be a lost cause to try to establish a silicon<br/>valley in Israel. Instead of no Jews moving there, only Jews would move there,<br/>and I don't think you could build a silicon valley out of just Jews any more<br/>than you could out of just Japanese.  <br/>  <br/>(This is not a remark about the qualities of these groups, just their sizes.<br/>Japanese are only about 2% of the world population, and Jews about .2%.)  <br/>  <br/>[5] According to the World Bank, the initial capital requirement for German<br/>companies is 47.6% of the per capita income. Doh.  <br/>  <br/>World Bank, _Doing Business in 2006_ , http://doingbusiness.org  <br/>  <br/>[6] For most of the twentieth century, Europeans looked back on the summer of<br/>1914 as if they'd been living in a dream world. It seems more accurate (or at<br/>least, as accurate) to call the years after 1914 a nightmare than to call<br/>those before a dream. A lot of the optimism Europeans consider distinctly<br/>American is simply what they too were feeling in 1914.  <br/>  <br/>[7] The point where things start to go wrong seems to be about 50%. Above that<br/>people get serious about tax avoidance. The reason is that the payoff for<br/>avoiding tax grows hyperexponentially (x/1-x for 0 < x < 1). If your income<br/>tax rate is 10%, moving to Monaco would only give you 11% more income, which<br/>wouldn't even cover the extra cost. If it's 90%, you'd get ten times as much<br/>income. And at 98%, as it was briefly in Britain in the 70s, moving to Monaco<br/>would give you fifty times as much income. It seems quite likely that European<br/>governments of the 70s never drew this curve.  <br/>  <br/> **Thanks** to Trevor Blackwell, Matthias Felleisen, Jessica Livingston,<br/>Robert Morris, Neil Rimer, Hugues Steinier, Brad Templeton, Fred Wilson, and<br/>Stephen Wolfram for reading drafts of this, and to Ed Dumbill for inviting me<br/>to speak.  <br/>  <br/><br/>French Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>April 2008  <br/>  <br/>Umair Haque wrote recently that the reason there aren't more Googles is that<br/>most startups get bought before they can change the world.<br/><br/>> Google, despite serious interest from Microsoft and Yahoo—what must have<br/>> seemed like lucrative interest at the time—didn't sell out. Google might<br/>> simply have been nothing but Yahoo's or MSN's search box.  <br/>>  <br/>> Why isn't it? Because Google had a deeply felt sense of purpose: a<br/>> conviction to change the world for the better.<br/><br/>This has a nice sound to it, but it isn't true. Google's founders were willing<br/>to sell early on. They just wanted more than acquirers were willing to pay.  <br/>  <br/>It was the same with Facebook. They would have sold, but Yahoo blew it by<br/>offering too little.  <br/>  <br/>Tip for acquirers: when a startup turns you down, consider raising your offer,<br/>because there's a good chance the outrageous price they want will later seem a<br/>bargain. [1]  <br/>  <br/>From the evidence I've seen so far, startups that turn down acquisition offers<br/>usually end up doing better. Not always, but usually there's a bigger offer<br/>coming, or perhaps even an IPO.  <br/>  <br/>Of course, the reason startups do better when they turn down acquisition<br/>offers is not necessarily that all such offers undervalue startups. More<br/>likely the reason is that the kind of founders who have the balls to turn down<br/>a big offer also tend to be very successful. That spirit is exactly what you<br/>want in a startup.  <br/>  <br/>While I'm sure Larry and Sergey do want to change the world, at least now, the<br/>reason Google survived to become a big, independent company is the same reason<br/>Facebook has so far remained independent: acquirers underestimated them.  <br/>  <br/>Corporate M&A is a strange business in that respect. They consistently lose<br/>the best deals, because turning down reasonable offers is the most reliable<br/>test you could invent for whether a startup will make it big.  <br/>  <br/> **VCs**  <br/>  <br/>So what's the real reason there aren't more Googles? Curiously enough, it's<br/>the same reason Google and Facebook have remained independent: money guys<br/>undervalue the most innovative startups.  <br/>  <br/>The reason there aren't more Googles is not that investors encourage<br/>innovative startups to sell out, but that they won't even fund them. I've<br/>learned a lot about VCs during the 3 years we've been doing Y Combinator,<br/>because we often have to work quite closely with them. The most surprising<br/>thing I've learned is how conservative they are. VC firms present an image of<br/>boldly encouraging innovation. Only a handful actually do, and even they are<br/>more conservative in reality than you'd guess from reading their sites.  <br/>  <br/>I used to think of VCs as piratical: bold but unscrupulous. On closer<br/>acquaintance they turn out to be more like bureaucrats. They're more<br/>upstanding than I used to think (the good ones, at least), but less bold.<br/>Maybe the VC industry has changed. Maybe they used to be bolder. But I suspect<br/>it's the startup world that has changed, not them. The low cost of starting a<br/>startup means the average good bet is a riskier one, but most existing VC<br/>firms still operate as if they were investing in hardware startups in 1985.  <br/>  <br/>Howard Aiken said "Don't worry about people stealing your ideas. If your ideas<br/>are any good, you'll have to ram them down people's throats." I have a similar<br/>feeling when I'm trying to convince VCs to invest in startups Y Combinator has<br/>funded. They're terrified of really novel ideas, unless the founders are good<br/>enough salesmen to compensate.  <br/>  <br/>But it's the bold ideas that generate the biggest returns. Any really good new<br/>idea will seem bad to most people; otherwise someone would already be doing<br/>it. And yet most VCs are driven by consensus, not just within their firms, but<br/>within the VC community. The biggest factor determining how a VC will feel<br/>about your startup is how other VCs feel about it. I doubt they realize it,<br/>but this algorithm guarantees they'll miss all the very best ideas. The more<br/>people who have to like a new idea, the more outliers you lose.  <br/>  <br/>Whoever the next Google is, they're probably being told right now by VCs to<br/>come back when they have more "traction."  <br/>  <br/>Why are VCs so conservative? It's probably a combination of factors. The large<br/>size of their investments makes them conservative. Plus they're investing<br/>other people's money, which makes them worry they'll get in trouble if they do<br/>something risky and it fails. Plus most of them are money guys rather than<br/>technical guys, so they don't understand what the startups they're investing<br/>in do.  <br/>  <br/> **What's Next**  <br/>  <br/>The exciting thing about market economies is that stupidity equals<br/>opportunity. And so it is in this case. There is a huge, unexploited<br/>opportunity in startup investing. Y Combinator funds startups at the very<br/>beginning. VCs will fund them once they're already starting to succeed. But<br/>between the two there is a substantial gap.  <br/>  <br/>There are companies that will give $20k to a startup that has nothing more<br/>than the founders, and there are companies that will give $2 million to a<br/>startup that's already taking off, but there aren't enough investors who will<br/>give $200k to a startup that seems very promising but still has some things to<br/>figure out. This territory is occupied mostly by individual angel<br/>investors—people like Andy Bechtolsheim, who gave Google $100k when they<br/>seemed promising but still had some things to figure out. I like angels, but<br/>there just aren't enough of them, and investing is for most of them a part<br/>time job.  <br/>  <br/>And yet as it gets cheaper to start startups, this sparsely occupied territory<br/>is becoming more and more valuable. Nowadays a lot of startups don't want to<br/>raise multi-million dollar series A rounds. They don't need that much money,<br/>and they don't want the hassles that come with it. The median startup coming<br/>out of Y Combinator wants to raise $250-500k. When they go to VC firms they<br/>have to ask for more because they know VCs aren't interested in such small<br/>deals.  <br/>  <br/>VCs are money managers. They're looking for ways to put large sums to work.<br/>But the startup world is evolving away from their current model.  <br/>  <br/>Startups have gotten cheaper. That means they want less money, but also that<br/>there are more of them. So you can still get large returns on large amounts of<br/>money; you just have to spread it more broadly.  <br/>  <br/>I've tried to explain this to VC firms. Instead of making one $2 million<br/>investment, make five $400k investments. Would that mean sitting on too many<br/>boards? Don't sit on their boards. Would that mean too much due diligence? Do<br/>less. If you're investing at a tenth the valuation, you only have to be a<br/>tenth as sure.  <br/>  <br/>It seems obvious. But I've proposed to several VC firms that they set aside<br/>some money and designate one partner to make more, smaller bets, and they<br/>react as if I'd proposed the partners all get nose rings. It's remarkable how<br/>wedded they are to their standard m.o.  <br/>  <br/>But there is a big opportunity here, and one way or the other it's going to<br/>get filled. Either VCs will evolve down into this gap or, more likely, new<br/>investors will appear to fill it. That will be a good thing when it happens,<br/>because these new investors will be compelled by the structure of the<br/>investments they make to be ten times bolder than present day VCs. And that<br/>will get us a lot more Googles. At least, as long as acquirers remain stupid.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] Another tip: If you want to get all that value, don't destroy the startup<br/>after you buy it. Give the founders enough autonomy that they can grow the<br/>acquisition into what it would have become.  <br/>  <br/> **Thanks** to Sam Altman, Paul Buchheit, David Hornik, Jessica Livingston,<br/>Robert Morris, and Fred Wilson for reading drafts of this.  <br/>  <br/><br/>Russian Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/><br/>April 2012  <br/>  <br/>A palliative care nurse called Bronnie Ware made a list of the biggest regrets<br/>of the dying. Her list seems plausible. I could see myself — _can_ see myself<br/>— making at least 4 of these 5 mistakes.  <br/>  <br/>If you had to compress them into a single piece of advice, it might be: don't<br/>be a cog. The 5 regrets paint a portrait of post-industrial man, who shrinks<br/>himself into a shape that fits his circumstances, then turns dutifully till he<br/>stops.  <br/>  <br/>The alarming thing is, the mistakes that produce these regrets are all errors<br/>of omission. You forget your dreams, ignore your family, suppress your<br/>feelings, neglect your friends, and forget to be happy. Errors of omission are<br/>a particularly dangerous type of mistake, because you make them by default.  <br/>  <br/>I would like to avoid making these mistakes. But how do you avoid mistakes you<br/>make by default? Ideally you transform your life so it has other defaults. But<br/>it may not be possible to do that completely. As long as these mistakes happen<br/>by default, you probably have to be reminded not to make them. So I inverted<br/>the 5 regrets, yielding a list of 5 commands<br/><br/>> Don't ignore your dreams; don't work too much; say what you think; cultivate<br/>> friendships; be happy.<br/><br/>which I then put at the top of the file I use as a todo list.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>May 2002  <br/>  <br/>  <br/>  <br/>In the software business there is an ongoing struggle between the pointy-<br/>headed academics, and another equally formidable force, the pointy-haired<br/>bosses. Everyone knows who the pointy-haired boss is, right? I think most<br/>people in the technology world not only recognize this cartoon character, but<br/>know the actual person in their company that he is modelled upon.  <br/>  <br/>The pointy-haired boss miraculously combines two qualities that are common by<br/>themselves, but rarely seen together: (a) he knows nothing whatsoever about<br/>technology, and (b) he has very strong opinions about it.  <br/>  <br/>Suppose, for example, you need to write a piece of software. The pointy-haired<br/>boss has no idea how this software has to work, and can't tell one programming<br/>language from another, and yet he knows what language you should write it in.<br/>Exactly. He thinks you should write it in Java.  <br/>  <br/>Why does he think this? Let's take a look inside the brain of the pointy-<br/>haired boss. What he's thinking is something like this. Java is a standard. I<br/>know it must be, because I read about it in the press all the time. Since it<br/>is a standard, I won't get in trouble for using it. And that also means there<br/>will always be lots of Java programmers, so if the programmers working for me<br/>now quit, as programmers working for me mysteriously always do, I can easily<br/>replace them.  <br/>  <br/>Well, this doesn't sound that unreasonable. But it's all based on one unspoken<br/>assumption, and that assumption turns out to be false. The pointy-haired boss<br/>believes that all programming languages are pretty much equivalent. If that<br/>were true, he would be right on target. If languages are all equivalent, sure,<br/>use whatever language everyone else is using.  <br/>  <br/>But all languages are not equivalent, and I think I can prove this to you<br/>without even getting into the differences between them. If you asked the<br/>pointy-haired boss in 1992 what language software should be written in, he<br/>would have answered with as little hesitation as he does today. Software<br/>should be written in C++. But if languages are all equivalent, why should the<br/>pointy-haired boss's opinion ever change? In fact, why should the developers<br/>of Java have even bothered to create a new language?  <br/>  <br/>Presumably, if you create a new language, it's because you think it's better<br/>in some way than what people already had. And in fact, Gosling makes it clear<br/>in the first Java white paper that Java was designed to fix some problems with<br/>C++. So there you have it: languages are not all equivalent. If you follow the<br/>trail through the pointy-haired boss's brain to Java and then back through<br/>Java's history to its origins, you end up holding an idea that contradicts the<br/>assumption you started with.  <br/>  <br/>So, who's right? James Gosling, or the pointy-haired boss? Not surprisingly,<br/>Gosling is right. Some languages _are_ better, for certain problems, than<br/>others. And you know, that raises some interesting questions. Java was<br/>designed to be better, for certain problems, than C++. What problems? When is<br/>Java better and when is C++? Are there situations where other languages are<br/>better than either of them?  <br/>  <br/>Once you start considering this question, you have opened a real can of worms.<br/>If the pointy-haired boss had to think about the problem in its full<br/>complexity, it would make his brain explode. As long as he considers all<br/>languages equivalent, all he has to do is choose the one that seems to have<br/>the most momentum, and since that is more a question of fashion than<br/>technology, even he can probably get the right answer. But if languages vary,<br/>he suddenly has to solve two simultaneous equations, trying to find an optimal<br/>balance between two things he knows nothing about: the relative suitability of<br/>the twenty or so leading languages for the problem he needs to solve, and the<br/>odds of finding programmers, libraries, etc. for each. If that's what's on the<br/>other side of the door, it is no surprise that the pointy-haired boss doesn't<br/>want to open it.  <br/>  <br/>The disadvantage of believing that all programming languages are equivalent is<br/>that it's not true. But the advantage is that it makes your life a lot<br/>simpler. And I think that's the main reason the idea is so widespread. It is a<br/>_comfortable_ idea.  <br/>  <br/>We know that Java must be pretty good, because it is the cool, new programming<br/>language. Or is it? If you look at the world of programming languages from a<br/>distance, it looks like Java is the latest thing. (From far enough away, all<br/>you can see is the large, flashing billboard paid for by Sun.) But if you look<br/>at this world up close, you find that there are degrees of coolness. Within<br/>the hacker subculture, there is another language called Perl that is<br/>considered a lot cooler than Java. Slashdot, for example, is generated by<br/>Perl. I don't think you would find those guys using Java Server Pages. But<br/>there is another, newer language, called Python, whose users tend to look down<br/>on Perl, and more waiting in the wings.  <br/>  <br/>If you look at these languages in order, Java, Perl, Python, you notice an<br/>interesting pattern. At least, you notice this pattern if you are a Lisp<br/>hacker. Each one is progressively more like Lisp. Python copies even features<br/>that many Lisp hackers consider to be mistakes. You could translate simple<br/>Lisp programs into Python line for line. It's 2002, and programming languages<br/>have almost caught up with 1958.  <br/>  <br/> **Catching Up with Math**  <br/>  <br/>What I mean is that Lisp was first discovered by John McCarthy in 1958, and<br/>popular programming languages are only now catching up with the ideas he<br/>developed then.  <br/>  <br/>Now, how could that be true? Isn't computer technology something that changes<br/>very rapidly? I mean, in 1958, computers were refrigerator-sized behemoths<br/>with the processing power of a wristwatch. How could any technology that old<br/>even be relevant, let alone superior to the latest developments?  <br/>  <br/>I'll tell you how. It's because Lisp was not really designed to be a<br/>programming language, at least not in the sense we mean today. What we mean by<br/>a programming language is something we use to tell a computer what to do.<br/>McCarthy did eventually intend to develop a programming language in this<br/>sense, but the Lisp that we actually ended up with was based on something<br/>separate that he did as a theoretical exercise\-- an effort to define a more<br/>convenient alternative to the Turing Machine. As McCarthy said later,<br/><br/>> Another way to show that Lisp was neater than Turing machines was to write a<br/>> universal Lisp function and show that it is briefer and more comprehensible<br/>> than the description of a universal Turing machine. This was the Lisp<br/>> function _eval_..., which computes the value of a Lisp expression....<br/>> Writing _eval_ required inventing a notation representing Lisp functions as<br/>> Lisp data, and such a notation was devised for the purposes of the paper<br/>> with no thought that it would be used to express Lisp programs in practice.<br/><br/>What happened next was that, some time in late 1958, Steve Russell, one of<br/>McCarthy's grad students, looked at this definition of _eval_ and realized<br/>that if he translated it into machine language, the result would be a Lisp<br/>interpreter.  <br/>  <br/>This was a big surprise at the time. Here is what McCarthy said about it later<br/>in an interview:<br/><br/>> Steve Russell said, look, why don't I program this _eval_..., and I said to<br/>> him, ho, ho, you're confusing theory with practice, this _eval_ is intended<br/>> for reading, not for computing. But he went ahead and did it. That is, he<br/>> compiled the _eval_ in my paper into [IBM] 704 machine code, fixing bugs,<br/>> and then advertised this as a Lisp interpreter, which it certainly was. So<br/>> at that point Lisp had essentially the form that it has today....<br/><br/>Suddenly, in a matter of weeks I think, McCarthy found his theoretical<br/>exercise transformed into an actual programming language-- and a more powerful<br/>one than he had intended.  <br/>  <br/>So the short explanation of why this 1950s language is not obsolete is that it<br/>was not technology but math, and math doesn't get stale. The right thing to<br/>compare Lisp to is not 1950s hardware, but, say, the Quicksort algorithm,<br/>which was discovered in 1960 and is still the fastest general-purpose sort.  <br/>  <br/>There is one other language still surviving from the 1950s, Fortran, and it<br/>represents the opposite approach to language design. Lisp was a piece of<br/>theory that unexpectedly got turned into a programming language. Fortran was<br/>developed intentionally as a programming language, but what we would now<br/>consider a very low-level one.  <br/>  <br/>Fortran I, the language that was developed in 1956, was a very different<br/>animal from present-day Fortran. Fortran I was pretty much assembly language<br/>with math. In some ways it was less powerful than more recent assembly<br/>languages; there were no subroutines, for example, only branches. Present-day<br/>Fortran is now arguably closer to Lisp than to Fortran I.  <br/>  <br/>Lisp and Fortran were the trunks of two separate evolutionary trees, one<br/>rooted in math and one rooted in machine architecture. These two trees have<br/>been converging ever since. Lisp started out powerful, and over the next<br/>twenty years got fast. So-called mainstream languages started out fast, and<br/>over the next forty years gradually got more powerful, until now the most<br/>advanced of them are fairly close to Lisp. Close, but they are still missing a<br/>few things....  <br/>  <br/> **What Made Lisp Different**  <br/>  <br/>When it was first developed, Lisp embodied nine new ideas. Some of these we<br/>now take for granted, others are only seen in more advanced languages, and two<br/>are still unique to Lisp. The nine ideas are, in order of their adoption by<br/>the mainstream,<br/><br/>  1. Conditionals. A conditional is an if-then-else construct. We take these for granted now, but Fortran I didn't have them. It had only a conditional goto closely based on the underlying machine instruction.  <br/>  <br/><br/>  2. A function type. In Lisp, functions are a data type just like integers or strings. They have a literal representation, can be stored in variables, can be passed as arguments, and so on.  <br/>  <br/><br/>  3. Recursion. Lisp was the first programming language to support it.  <br/>  <br/><br/>  4. Dynamic typing. In Lisp, all variables are effectively pointers. Values are what have types, not variables, and assigning or binding variables means copying pointers, not what they point to.  <br/>  <br/><br/>  5. Garbage-collection.  <br/>  <br/><br/>  6. Programs composed of expressions. Lisp programs are trees of expressions, each of which returns a value. This is in contrast to Fortran and most succeeding languages, which distinguish between expressions and statements.  <br/>  <br/>It was natural to have this distinction in Fortran I because you could not<br/>nest statements. And so while you needed expressions for math to work, there<br/>was no point in making anything else return a value, because there could not<br/>be anything waiting for it.  <br/>  <br/>This limitation went away with the arrival of block-structured languages, but<br/>by then it was too late. The distinction between expressions and statements<br/>was entrenched. It spread from Fortran into Algol and then to both their<br/>descendants.  <br/>  <br/><br/>  7. A symbol type. Symbols are effectively pointers to strings stored in a hash table. So you can test equality by comparing a pointer, instead of comparing each character.  <br/>  <br/><br/>  8. A notation for code using trees of symbols and constants.  <br/>  <br/><br/>  9. The whole language there all the time. There is no real distinction between read-time, compile-time, and runtime. You can compile or run code while reading, read or run code while compiling, and read or compile code at runtime.  <br/>  <br/>Running code at read-time lets users reprogram Lisp's syntax; running code at<br/>compile-time is the basis of macros; compiling at runtime is the basis of<br/>Lisp's use as an extension language in programs like Emacs; and reading at<br/>runtime enables programs to communicate using s-expressions, an idea recently<br/>reinvented as XML.<br/><br/>When Lisp first appeared, these ideas were far removed from ordinary<br/>programming practice, which was dictated largely by the hardware available in<br/>the late 1950s. Over time, the default language, embodied in a succession of<br/>popular languages, has gradually evolved toward Lisp. Ideas 1-5 are now<br/>widespread. Number 6 is starting to appear in the mainstream. Python has a<br/>form of 7, though there doesn't seem to be any syntax for it.  <br/>  <br/>As for number 8, this may be the most interesting of the lot. Ideas 8 and 9<br/>only became part of Lisp by accident, because Steve Russell implemented<br/>something McCarthy had never intended to be implemented. And yet these ideas<br/>turn out to be responsible for both Lisp's strange appearance and its most<br/>distinctive features. Lisp looks strange not so much because it has a strange<br/>syntax as because it has no syntax; you express programs directly in the parse<br/>trees that get built behind the scenes when other languages are parsed, and<br/>these trees are made of lists, which are Lisp data structures.  <br/>  <br/>Expressing the language in its own data structures turns out to be a very<br/>powerful feature. Ideas 8 and 9 together mean that you can write programs that<br/>write programs. That may sound like a bizarre idea, but it's an everyday thing<br/>in Lisp. The most common way to do it is with something called a _macro._  <br/>  <br/>The term "macro" does not mean in Lisp what it means in other languages. A<br/>Lisp macro can be anything from an abbreviation to a compiler for a new<br/>language. If you want to really understand Lisp, or just expand your<br/>programming horizons, I would learn more about macros.  <br/>  <br/>Macros (in the Lisp sense) are still, as far as I know, unique to Lisp. This<br/>is partly because in order to have macros you probably have to make your<br/>language look as strange as Lisp. It may also be because if you do add that<br/>final increment of power, you can no longer claim to have invented a new<br/>language, but only a new dialect of Lisp.  <br/>  <br/>I mention this mostly as a joke, but it is quite true. If you define a<br/>language that has car, cdr, cons, quote, cond, atom, eq, and a notation for<br/>functions expressed as lists, then you can build all the rest of Lisp out of<br/>it. That is in fact the defining quality of Lisp: it was in order to make this<br/>so that McCarthy gave Lisp the shape it has.  <br/>  <br/> **Where Languages Matter**  <br/>  <br/>So suppose Lisp does represent a kind of limit that mainstream languages are<br/>approaching asymptotically-- does that mean you should actually use it to<br/>write software? How much do you lose by using a less powerful language? Isn't<br/>it wiser, sometimes, not to be at the very edge of innovation? And isn't<br/>popularity to some extent its own justification? Isn't the pointy-haired boss<br/>right, for example, to want to use a language for which he can easily hire<br/>programmers?  <br/>  <br/>There are, of course, projects where the choice of programming language<br/>doesn't matter much. As a rule, the more demanding the application, the more<br/>leverage you get from using a powerful language. But plenty of projects are<br/>not demanding at all. Most programming probably consists of writing little<br/>glue programs, and for little glue programs you can use any language that<br/>you're already familiar with and that has good libraries for whatever you need<br/>to do. If you just need to feed data from one Windows app to another, sure,<br/>use Visual Basic.  <br/>  <br/>You can write little glue programs in Lisp too (I use it as a desktop<br/>calculator), but the biggest win for languages like Lisp is at the other end<br/>of the spectrum, where you need to write sophisticated programs to solve hard<br/>problems in the face of fierce competition. A good example is the airline fare<br/>search program that ITA Software licenses to Orbitz. These guys entered a<br/>market already dominated by two big, entrenched competitors, Travelocity and<br/>Expedia, and seem to have just humiliated them technologically.  <br/>  <br/>The core of ITA's application is a 200,000 line Common Lisp program that<br/>searches many orders of magnitude more possibilities than their competitors,<br/>who apparently are still using mainframe-era programming techniques. (Though<br/>ITA is also in a sense using a mainframe-era programming language.) I have<br/>never seen any of ITA's code, but according to one of their top hackers they<br/>use a lot of macros, and I am not surprised to hear it.  <br/>  <br/> **Centripetal Forces**  <br/>  <br/>I'm not saying there is no cost to using uncommon technologies. The pointy-<br/>haired boss is not completely mistaken to worry about this. But because he<br/>doesn't understand the risks, he tends to magnify them.  <br/>  <br/>I can think of three problems that could arise from using less common<br/>languages. Your programs might not work well with programs written in other<br/>languages. You might have fewer libraries at your disposal. And you might have<br/>trouble hiring programmers.  <br/>  <br/>How much of a problem is each of these? The importance of the first varies<br/>depending on whether you have control over the whole system. If you're writing<br/>software that has to run on a remote user's machine on top of a buggy, closed<br/>operating system (I mention no names), there may be advantages to writing your<br/>application in the same language as the OS. But if you control the whole<br/>system and have the source code of all the parts, as ITA presumably does, you<br/>can use whatever languages you want. If any incompatibility arises, you can<br/>fix it yourself.  <br/>  <br/>In server-based applications you can get away with using the most advanced<br/>technologies, and I think this is the main cause of what Jonathan Erickson<br/>calls the "programming language renaissance." This is why we even hear about<br/>new languages like Perl and Python. We're not hearing about these languages<br/>because people are using them to write Windows apps, but because people are<br/>using them on servers. And as software shifts off the desktop and onto servers<br/>(a future even Microsoft seems resigned to), there will be less and less<br/>pressure to use middle-of-the-road technologies.  <br/>  <br/>As for libraries, their importance also depends on the application. For less<br/>demanding problems, the availability of libraries can outweigh the intrinsic<br/>power of the language. Where is the breakeven point? Hard to say exactly, but<br/>wherever it is, it is short of anything you'd be likely to call an<br/>application. If a company considers itself to be in the software business, and<br/>they're writing an application that will be one of their products, then it<br/>will probably involve several hackers and take at least six months to write.<br/>In a project of that size, powerful languages probably start to outweigh the<br/>convenience of pre-existing libraries.  <br/>  <br/>The third worry of the pointy-haired boss, the difficulty of hiring<br/>programmers, I think is a red herring. How many hackers do you need to hire,<br/>after all? Surely by now we all know that software is best developed by teams<br/>of less than ten people. And you shouldn't have trouble hiring hackers on that<br/>scale for any language anyone has ever heard of. If you can't find ten Lisp<br/>hackers, then your company is probably based in the wrong city for developing<br/>software.  <br/>  <br/>In fact, choosing a more powerful language probably decreases the size of the<br/>team you need, because (a) if you use a more powerful language you probably<br/>won't need as many hackers, and (b) hackers who work in more advanced<br/>languages are likely to be smarter.  <br/>  <br/>I'm not saying that you won't get a lot of pressure to use what are perceived<br/>as "standard" technologies. At Viaweb (now Yahoo Store), we raised some<br/>eyebrows among VCs and potential acquirers by using Lisp. But we also raised<br/>eyebrows by using generic Intel boxes as servers instead of "industrial<br/>strength" servers like Suns, for using a then-obscure open-source Unix variant<br/>called FreeBSD instead of a real commercial OS like Windows NT, for ignoring a<br/>supposed e-commerce standard called SET that no one now even remembers, and so<br/>on.  <br/>  <br/>You can't let the suits make technical decisions for you. Did it alarm some<br/>potential acquirers that we used Lisp? Some, slightly, but if we hadn't used<br/>Lisp, we wouldn't have been able to write the software that made them want to<br/>buy us. What seemed like an anomaly to them was in fact cause and effect.  <br/>  <br/>If you start a startup, don't design your product to please VCs or potential<br/>acquirers. _Design your product to please the users._ If you win the users,<br/>everything else will follow. And if you don't, no one will care how<br/>comfortingly orthodox your technology choices were.  <br/>  <br/> **The Cost of Being Average**  <br/>  <br/>How much do you lose by using a less powerful language? There is actually some<br/>data out there about that.  <br/>  <br/>The most convenient measure of power is probably code size. The point of high-<br/>level languages is to give you bigger abstractions-- bigger bricks, as it<br/>were, so you don't need as many to build a wall of a given size. So the more<br/>powerful the language, the shorter the program (not simply in characters, of<br/>course, but in distinct elements).  <br/>  <br/>How does a more powerful language enable you to write shorter programs? One<br/>technique you can use, if the language will let you, is something called<br/>bottom-up programming. Instead of simply writing your application in the base<br/>language, you build on top of the base language a language for writing<br/>programs like yours, then write your program in it. The combined code can be<br/>much shorter than if you had written your whole program in the base language--<br/>indeed, this is how most compression algorithms work. A bottom-up program<br/>should be easier to modify as well, because in many cases the language layer<br/>won't have to change at all.  <br/>  <br/>Code size is important, because the time it takes to write a program depends<br/>mostly on its length. If your program would be three times as long in another<br/>language, it will take three times as long to write-- and you can't get around<br/>this by hiring more people, because beyond a certain size new hires are<br/>actually a net lose. Fred Brooks described this phenomenon in his famous book<br/>_The Mythical Man-Month,_ and everything I've seen has tended to confirm what<br/>he said.  <br/>  <br/>So how much shorter are your programs if you write them in Lisp? Most of the<br/>numbers I've heard for Lisp versus C, for example, have been around 7-10x. But<br/>a recent article about ITA in _New Architect_ magazine said that "one line of<br/>Lisp can replace 20 lines of C," and since this article was full of quotes<br/>from ITA's president, I assume they got this number from ITA. If so then we<br/>can put some faith in it; ITA's software includes a lot of C and C++ as well<br/>as Lisp, so they are speaking from experience.  <br/>  <br/>My guess is that these multiples aren't even constant. I think they increase<br/>when you face harder problems and also when you have smarter programmers. A<br/>really good hacker can squeeze more out of better tools.  <br/>  <br/>As one data point on the curve, at any rate, if you were to compete with ITA<br/>and chose to write your software in C, they would be able to develop software<br/>twenty times faster than you. If you spent a year on a new feature, they'd be<br/>able to duplicate it in less than three weeks. Whereas if they spent just<br/>three months developing something new, it would be _five years_ before you had<br/>it too.  <br/>  <br/>And you know what? That's the best-case scenario. When you talk about code-<br/>size ratios, you're implicitly assuming that you can actually write the<br/>program in the weaker language. But in fact there are limits on what<br/>programmers can do. If you're trying to solve a hard problem with a language<br/>that's too low-level, you reach a point where there is just too much to keep<br/>in your head at once.  <br/>  <br/>So when I say it would take ITA's imaginary competitor five years to duplicate<br/>something ITA could write in Lisp in three months, I mean five years if<br/>nothing goes wrong. In fact, the way things work in most companies, any<br/>development project that would take five years is likely never to get finished<br/>at all.  <br/>  <br/>I admit this is an extreme case. ITA's hackers seem to be unusually smart, and<br/>C is a pretty low-level language. But in a competitive market, even a<br/>differential of two or three to one would be enough to guarantee that you'd<br/>always be behind.  <br/>  <br/> **A Recipe**  <br/>  <br/>This is the kind of possibility that the pointy-haired boss doesn't even want<br/>to think about. And so most of them don't. Because, you know, when it comes<br/>down to it, the pointy-haired boss doesn't mind if his company gets their ass<br/>kicked, so long as no one can prove it's his fault. The safest plan for him<br/>personally is to stick close to the center of the herd.  <br/>  <br/>Within large organizations, the phrase used to describe this approach is<br/>"industry best practice." Its purpose is to shield the pointy-haired boss from<br/>responsibility: if he chooses something that is "industry best practice," and<br/>the company loses, he can't be blamed. He didn't choose, the industry did.  <br/>  <br/>I believe this term was originally used to describe accounting methods and so<br/>on. What it means, roughly, is _don't do anything weird._ And in accounting<br/>that's probably a good idea. The terms "cutting-edge" and "accounting" do not<br/>sound good together. But when you import this criterion into decisions about<br/>technology, you start to get the wrong answers.  <br/>  <br/>Technology often _should_ be cutting-edge. In programming languages, as Erann<br/>Gat has pointed out, what "industry best practice" actually gets you is not<br/>the best, but merely the average. When a decision causes you to develop<br/>software at a fraction of the rate of more aggressive competitors, "best<br/>practice" is a misnomer.  <br/>  <br/>So here we have two pieces of information that I think are very valuable. In<br/>fact, I know it from my own experience. Number 1, languages vary in power.<br/>Number 2, most managers deliberately ignore this. Between them, these two<br/>facts are literally a recipe for making money. ITA is an example of this<br/>recipe in action. If you want to win in a software business, just take on the<br/>hardest problem you can find, use the most powerful language you can get, and<br/>wait for your competitors' pointy-haired bosses to revert to the mean.  <br/>  <br/><br/>* * *<br/><br/>  <br/>  <br/>  <br/>  <br/>**Appendix: Power**  <br/>  <br/>As an illustration of what I mean about the relative power of programming<br/>languages, consider the following problem. We want to write a function that<br/>generates accumulators-- a function that takes a number n, and returns a<br/>function that takes another number i and returns n incremented by i.  <br/>  <br/>(That's _incremented by_ , not plus. An accumulator has to accumulate.)  <br/>  <br/>In Common Lisp this would be  (defun foo (n) (lambda (i) (incf n i)))  and in<br/>Perl 5,  sub foo { my ($n) = @_; sub {$n += shift} }  which has more elements<br/>than the Lisp version because you have to extract parameters manually in Perl.  <br/>  <br/>In Smalltalk the code is slightly longer than in Lisp  foo: n |s| s := n.<br/>^[:i| s := s+i. ]  because although in general lexical variables work, you<br/>can't do an assignment to a parameter, so you have to create a new variable s.  <br/>  <br/>In Javascript the example is, again, slightly longer, because Javascript<br/>retains the distinction between statements and expressions, so you need<br/>explicit `return` statements to return values:  function foo(n) { return<br/>function (i) { return n += i } }  (To be fair, Perl also retains this<br/>distinction, but deals with it in typical Perl fashion by letting you omit<br/>`return`s.)  <br/>  <br/>If you try to translate the Lisp/Perl/Smalltalk/Javascript code into Python<br/>you run into some limitations. Because Python doesn't fully support lexical<br/>variables, you have to create a data structure to hold the value of n. And<br/>although Python does have a function data type, there is no literal<br/>representation for one (unless the body is only a single expression) so you<br/>need to create a named function to return. This is what you end up with:  def<br/>foo(n): s = [n] def bar(i): s[0] += i return s[0] return bar  Python users<br/>might legitimately ask why they can't just write  def foo(n): return lambda i:<br/>return n += i  or even  def foo(n): lambda i: n += i  and my guess is that<br/>they probably will, one day. (But if they don't want to wait for Python to<br/>evolve the rest of the way into Lisp, they could always just...)  <br/>  <br/>In OO languages, you can, to a limited extent, simulate a closure (a function<br/>that refers to variables defined in enclosing scopes) by defining a class with<br/>one method and a field to replace each variable from an enclosing scope. This<br/>makes the programmer do the kind of code analysis that would be done by the<br/>compiler in a language with full support for lexical scope, and it won't work<br/>if more than one function refers to the same variable, but it is enough in<br/>simple cases like this.  <br/>  <br/>Python experts seem to agree that this is the preferred way to solve the<br/>problem in Python, writing either  def foo(n): class acc: def __init__(self,<br/>s): self.s = s def inc(self, i): self.s += i return self.s return acc(n).inc<br/>or  class foo: def __init__(self, n): self.n = n def __call__(self, i): self.n<br/>+= i return self.n  I include these because I wouldn't want Python advocates<br/>to say I was misrepresenting the language, but both seem to me more complex<br/>than the first version. You're doing the same thing, setting up a separate<br/>place to hold the accumulator; it's just a field in an object instead of the<br/>head of a list. And the use of these special, reserved field names, especially<br/>`__call__`, seems a bit of a hack.  <br/>  <br/>In the rivalry between Perl and Python, the claim of the Python hackers seems<br/>to be that that Python is a more elegant alternative to Perl, but what this<br/>case shows is that power is the ultimate elegance: the Perl program is simpler<br/>(has fewer elements), even if the syntax is a bit uglier.  <br/>  <br/>How about other languages? In the other languages mentioned in this talk--<br/>Fortran, C, C++, Java, and Visual Basic-- it is not clear whether you can<br/>actually solve this problem. Ken Anderson says that the following code is<br/>about as close as you can get in Java:  public interface Inttoint { public int<br/>call(int i); }  public static Inttoint foo(final int n) { return new<br/>Inttoint() { int s = n; public int call(int i) { s = s + i; return s; }}; }<br/>This falls short of the spec because it only works for integers. After many<br/>email exchanges with Java hackers, I would say that writing a properly<br/>polymorphic version that behaves like the preceding examples is somewhere<br/>between damned awkward and impossible. If anyone wants to write one I'd be<br/>very curious to see it, but I personally have timed out.  <br/>  <br/>It's not literally true that you can't solve this problem in other languages,<br/>of course. The fact that all these languages are Turing-equivalent means that,<br/>strictly speaking, you can write any program in any of them. So how would you<br/>do it? In the limit case, by writing a Lisp interpreter in the less powerful<br/>language.  <br/>  <br/>That sounds like a joke, but it happens so often to varying degrees in large<br/>programming projects that there is a name for the phenomenon, Greenspun's<br/>Tenth Rule:<br/><br/>> Any sufficiently complicated C or Fortran program contains an ad hoc<br/>> informally-specified bug-ridden slow implementation of half of Common Lisp.<br/><br/>If you try to solve a hard problem, the question is not whether you will use a<br/>powerful enough language, but whether you will (a) use a powerful language,<br/>(b) write a de facto interpreter for one, or (c) yourself become a human<br/>compiler for one. We see this already begining to happen in the Python<br/>example, where we are in effect simulating the code that a compiler would<br/>generate to implement a lexical variable.  <br/>  <br/>This practice is not only common, but institutionalized. For example, in the<br/>OO world you hear a good deal about "patterns". I wonder if these patterns are<br/>not sometimes evidence of case (c), the human compiler, at work. When I see<br/>patterns in my programs, I consider it a sign of trouble. The shape of a<br/>program should reflect only the problem it needs to solve. Any other<br/>regularity in the code is a sign, to me at least, that I'm using abstractions<br/>that aren't powerful enough-- often that I'm generating by hand the expansions<br/>of some macro that I need to write.  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/><br/>  * The IBM 704 CPU was about the size of a refrigerator, but a lot heavier. The CPU weighed 3150 pounds, and the 4K of RAM was in a separate box weighing another 4000 pounds. The Sub-Zero 690, one of the largest household refrigerators, weighs 656 pounds.  <br/>  <br/><br/>  * Steve Russell also wrote the first (digital) computer game, Spacewar, in 1962.  <br/>  <br/><br/>  * If you want to trick a pointy-haired boss into letting you write software in Lisp, you could try telling him it's XML.  <br/>  <br/><br/>  * Here is the accumulator generator in other Lisp dialects:  Scheme: (define (foo n) (lambda (i) (set! n (+ n i)) n)) Goo: (df foo (n) (op incf n _))) Arc: (def foo (n) [++ n _]) <br/>  * Erann Gat's sad tale about "industry best practice" at JPL inspired me to address this generally misapplied phrase.  <br/>  <br/><br/>  * Peter Norvig found that 16 of the 23 patterns in _Design Patterns_ were "invisible or simpler" in Lisp.  <br/>  <br/><br/>  * Thanks to the many people who answered my questions about various languages and/or read drafts of this, including Ken Anderson, Trevor Blackwell, Erann Gat, Dan Giffin, Sarah Harlin, Jeremy Hylton, Robert Morris, Peter Norvig, Guy Steele, and Anton van Straaten. They bear no blame for any opinions expressed.  <br/>  <br/><br/>  <br/>  <br/>**Related:**  <br/>  <br/>Many people have responded to this talk, so I have set up an additional page<br/>to deal with the issues they have raised: Re: Revenge of the Nerds.  <br/>  <br/>It also set off an extensive and often useful discussion on the LL1 mailing<br/>list. See particularly the mail by Anton van Straaten on semantic compression.  <br/>  <br/>Some of the mail on LL1 led me to try to go deeper into the subject of<br/>language power in Succinctness is Power.  <br/>  <br/>A larger set of canonical implementations of the accumulator generator<br/>benchmark are collected together on their own page.  <br/>  <br/>Japanese Translation, Spanish Translation, Chinese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>February 2009  <br/>  <br/>One of the things I always tell startups is a principle I learned from Paul<br/>Buchheit: it's better to make a few people really happy than to make a lot of<br/>people semi-happy. I was saying recently to a reporter that if I could only<br/>tell startups 10 things, this would be one of them. Then I thought: what would<br/>the other 9 be?  <br/>  <br/>When I made the list there turned out to be 13:<br/><br/>**1\. Pick good cofounders.**  <br/>  <br/>Cofounders are for a startup what location is for real estate. You can change<br/>anything about a house except where it is. In a startup you can change your<br/>idea easily, but changing your cofounders is hard. [1] And the success of a<br/>startup is almost always a function of its founders.  <br/>  <br/> **2\. Launch fast.**  <br/>  <br/>The reason to launch fast is not so much that it's critical to get your<br/>product to market early, but that you haven't really started working on it<br/>till you've launched. Launching teaches you what you should have been<br/>building. Till you know that you're wasting your time. So the main value of<br/>whatever you launch with is as a pretext for engaging users.  <br/>  <br/> **3\. Let your idea evolve.**  <br/>  <br/>This is the second half of launching fast. Launch fast and iterate. It's a big<br/>mistake to treat a startup as if it were merely a matter of implementing some<br/>brilliant initial idea. As in an essay, most of the ideas appear in the<br/>implementing.  <br/>  <br/> **4\. Understand your users.**  <br/>  <br/>You can envision the wealth created by a startup as a rectangle, where one<br/>side is the number of users and the other is how much you improve their lives.<br/>[2] The second dimension is the one you have most control over. And indeed,<br/>the growth in the first will be driven by how well you do in the second. As in<br/>science, the hard part is not answering questions but asking them: the hard<br/>part is seeing something new that users lack. The better you understand them<br/>the better the odds of doing that. That's why so many successful startups make<br/>something the founders needed.  <br/>  <br/> **5\. Better to make a few users love you than a lot ambivalent.**  <br/>  <br/>Ideally you want to make large numbers of users love you, but you can't expect<br/>to hit that right away. Initially you have to choose between satisfying all<br/>the needs of a subset of potential users, or satisfying a subset of the needs<br/>of all potential users. Take the first. It's easier to expand userwise than<br/>satisfactionwise. And perhaps more importantly, it's harder to lie to<br/>yourself. If you think you're 85% of the way to a great product, how do you<br/>know it's not 70%? Or 10%? Whereas it's easy to know how many users you have.  <br/>  <br/> **6\. Offer surprisingly good customer service.**  <br/>  <br/>Customers are used to being maltreated. Most of the companies they deal with<br/>are quasi-monopolies that get away with atrocious customer service. Your own<br/>ideas about what's possible have been unconsciously lowered by such<br/>experiences. Try making your customer service not merely good, but<br/>surprisingly good. Go out of your way to make people happy. They'll be<br/>overwhelmed; you'll see. In the earliest stages of a startup, it pays to offer<br/>customer service on a level that wouldn't scale, because it's a way of<br/>learning about your users.  <br/>  <br/> **7\. You make what you measure.**  <br/>  <br/>I learned this one from Joe Kraus. [3] Merely measuring something has an<br/>uncanny tendency to improve it. If you want to make your user numbers go up,<br/>put a big piece of paper on your wall and every day plot the number of users.<br/>You'll be delighted when it goes up and disappointed when it goes down. Pretty<br/>soon you'll start noticing what makes the number go up, and you'll start to do<br/>more of that. Corollary: be careful what you measure.  <br/>  <br/> **8\. Spend little.**  <br/>  <br/>I can't emphasize enough how important it is for a startup to be cheap. Most<br/>startups fail before they make something people want, and the most common form<br/>of failure is running out of money. So being cheap is (almost) interchangeable<br/>with iterating rapidly. [4] But it's more than that. A culture of cheapness<br/>keeps companies young in something like the way exercise keeps people young.  <br/>  <br/> **9\. Get ramen profitable.**  <br/>  <br/>"Ramen profitable" means a startup makes just enough to pay the founders'<br/>living expenses. It's not rapid prototyping for business models (though it can<br/>be), but more a way of hacking the investment process. Once you cross over<br/>into ramen profitable, it completely changes your relationship with investors.<br/>It's also great for morale.  <br/>  <br/> **10\. Avoid distractions.**  <br/>  <br/>Nothing kills startups like distractions. The worst type are those that pay<br/>money: day jobs, consulting, profitable side-projects. The startup may have<br/>more long-term potential, but you'll always interrupt working on it to answer<br/>calls from people paying you now. Paradoxically, fundraising is this type of<br/>distraction, so try to minimize that too.  <br/>  <br/> **11\. Don't get demoralized.**  <br/>  <br/>Though the immediate cause of death in a startup tends to be running out of<br/>money, the underlying cause is usually lack of focus. Either the company is<br/>run by stupid people (which can't be fixed with advice) or the people are<br/>smart but got demoralized. Starting a startup is a huge moral weight.<br/>Understand this and make a conscious effort not to be ground down by it, just<br/>as you'd be careful to bend at the knees when picking up a heavy box.  <br/>  <br/> **12\. Don't give up.**  <br/>  <br/>Even if you get demoralized, don't give up. You can get surprisingly far by<br/>just not giving up. This isn't true in all fields. There are a lot of people<br/>who couldn't become good mathematicians no matter how long they persisted. But<br/>startups aren't like that. Sheer effort is usually enough, so long as you keep<br/>morphing your idea.  <br/>  <br/> **13\. Deals fall through.**  <br/>  <br/>One of the most useful skills we learned from Viaweb was not getting our hopes<br/>up. We probably had 20 deals of various types fall through. After the first 10<br/>or so we learned to treat deals as background processes that we should ignore<br/>till they terminated. It's very dangerous to morale to start to depend on<br/>deals closing, not just because they so often don't, but because it makes them<br/>less likely to.<br/><br/>Having gotten it down to 13 sentences, I asked myself which I'd choose if I<br/>could only keep one.  <br/>  <br/>Understand your users. That's the key. The essential task in a startup is to<br/>create wealth; the dimension of wealth you have most control over is how much<br/>you improve users' lives; and the hardest part of that is knowing what to make<br/>for them. Once you know what to make, it's mere effort to make it, and most<br/>decent hackers are capable of that.  <br/>  <br/>Understanding your users is part of half the principles in this list. That's<br/>the reason to launch early, to understand your users. Evolving your idea is<br/>the embodiment of understanding your users. Understanding your users well will<br/>tend to push you toward making something that makes a few people deeply happy.<br/>The most important reason for having surprisingly good customer service is<br/>that it helps you understand your users. And understanding your users will<br/>even ensure your morale, because when everything else is collapsing around<br/>you, having just ten users who love you will keep you going.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Strictly speaking it's impossible without a time machine.  <br/>  <br/>[2] In practice it's more like a ragged comb.  <br/>  <br/>[3] Joe thinks one of the founders of Hewlett Packard said it first, but he<br/>doesn't remember which.  <br/>  <br/>[4] They'd be interchangeable if markets stood still. Since they don't,<br/>working twice as fast is better than having twice as much time.  <br/>  <br/><br/>Turkish Translation  <br/><br/>Spanish Translation  <br/><br/>Bulgarian Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>May 2002  <br/>  <br/>  <br/>  <br/>In the discussion about issues raised by Revenge of the Nerds on the LL1<br/>mailing list, Paul Prescod wrote something that stuck in my mind.<br/><br/>> Python's goal is regularity and readability, not succinctness.<br/><br/>On the face of it, this seems a rather damning thing to claim about a<br/>programming language. As far as I can tell, succinctness = power. If so, then<br/>substituting, we get<br/><br/>> Python's goal is regularity and readability, not power.<br/><br/>and this doesn't seem a tradeoff (if it _is_ a tradeoff) that you'd want to<br/>make. It's not far from saying that Python's goal is not to be effective as a<br/>programming language.  <br/>  <br/>Does succinctness = power? This seems to me an important question, maybe the<br/>most important question for anyone interested in language design, and one that<br/>it would be useful to confront directly. I don't feel sure yet that the answer<br/>is a simple yes, but it seems a good hypothesis to begin with.  <br/>  <br/> **Hypothesis**  <br/>  <br/>My hypothesis is that succinctness is power, or is close enough that except in<br/>pathological examples you can treat them as identical.  <br/>  <br/>It seems to me that succinctness is what programming languages are _for._<br/>Computers would be just as happy to be told what to do directly in machine<br/>language. I think that the main reason we take the trouble to develop high-<br/>level languages is to get leverage, so that we can say (and more importantly,<br/>think) in 10 lines of a high-level language what would require 1000 lines of<br/>machine language. In other words, the main point of high-level languages is to<br/>make source code smaller.  <br/>  <br/>If smaller source code is the purpose of high-level languages, and the power<br/>of something is how well it achieves its purpose, then the measure of the<br/>power of a programming language is how small it makes your programs.  <br/>  <br/>Conversely, a language that doesn't make your programs small is doing a bad<br/>job of what programming languages are supposed to do, like a knife that<br/>doesn't cut well, or printing that's illegible.  <br/>  <br/>**Metrics**  <br/>  <br/>Small in what sense though? The most common measure of code size is lines of<br/>code. But I think that this metric is the most common because it is the<br/>easiest to measure. I don't think anyone really believes it is the true test<br/>of the length of a program. Different languages have different conventions for<br/>how much you should put on a line; in C a lot of lines have nothing on them<br/>but a delimiter or two.  <br/>  <br/>Another easy test is the number of characters in a program, but this is not<br/>very good either; some languages (Perl, for example) just use shorter<br/>identifiers than others.  <br/>  <br/>I think a better measure of the size of a program would be the number of<br/>elements, where an element is anything that would be a distinct node if you<br/>drew a tree representing the source code. The name of a variable or function<br/>is an element; an integer or a floating-point number is an element; a segment<br/>of literal text is an element; an element of a pattern, or a format directive,<br/>is an element; a new block is an element. There are borderline cases (is -5<br/>two elements or one?) but I think most of them are the same for every<br/>language, so they don't affect comparisons much.  <br/>  <br/>This metric needs fleshing out, and it could require interpretation in the<br/>case of specific languages, but I think it tries to measure the right thing,<br/>which is the number of parts a program has. I think the tree you'd draw in<br/>this exercise is what you have to make in your head in order to conceive of<br/>the program, and so its size is proportionate to the amount of work you have<br/>to do to write or read it.  <br/>  <br/> **Design**  <br/>  <br/>This kind of metric would allow us to compare different languages, but that is<br/>not, at least for me, its main value. The main value of the succinctness test<br/>is as a guide in _designing_ languages. The most useful comparison between<br/>languages is between two potential variants of the same language. What can I<br/>do in the language to make programs shorter?  <br/>  <br/>If the conceptual load of a program is proportionate to its complexity, and a<br/>given programmer can tolerate a fixed conceptual load, then this is the same<br/>as asking, what can I do to enable programmers to get the most done? And that<br/>seems to me identical to asking, how can I design a good language?  <br/>  <br/>(Incidentally, nothing makes it more patently obvious that the old chestnut<br/>"all languages are equivalent" is false than designing languages. When you are<br/>designing a new language, you're _constantly_ comparing two languages-- the<br/>language if I did x, and if I didn't-- to decide which is better. If this were<br/>really a meaningless question, you might as well flip a coin.)  <br/>  <br/>Aiming for succinctness seems a good way to find new ideas. If you can do<br/>something that makes many different programs shorter, it is probably not a<br/>coincidence: you have probably discovered a useful new abstraction. You might<br/>even be able to write a program to help by searching source code for repeated<br/>patterns. Among other languages, those with a reputation for succinctness<br/>would be the ones to look to for new ideas: Forth, Joy, Icon.  <br/>  <br/> **Comparison**  <br/>  <br/>The first person to write about these issues, as far as I know, was Fred<br/>Brooks in the _Mythical Man Month_. He wrote that programmers seemed to<br/>generate about the same amount of code per day regardless of the language.<br/>When I first read this in my early twenties, it was a big surprise to me and<br/>seemed to have huge implications. It meant that (a) the only way to get<br/>software written faster was to use a more succinct language, and (b) someone<br/>who took the trouble to do this could leave competitors who didn't in the<br/>dust.  <br/>  <br/>Brooks' hypothesis, if it's true, seems to be at the very heart of hacking. In<br/>the years since, I've paid close attention to any evidence I could get on the<br/>question, from formal studies to anecdotes about individual projects. I have<br/>seen nothing to contradict him.  <br/>  <br/>I have not yet seen evidence that seemed to me conclusive, and I don't expect<br/>to. Studies like Lutz Prechelt's comparison of programming languages, while<br/>generating the kind of results I expected, tend to use problems that are too<br/>short to be meaningful tests. A better test of a language is what happens in<br/>programs that take a month to write. And the only real test, if you believe as<br/>I do that the main purpose of a language is to be good to think in (rather<br/>than just to tell a computer what to do once you've thought of it) is what new<br/>things you can write in it. So any language comparison where you have to meet<br/>a predefined spec is testing slightly the wrong thing.  <br/>  <br/>The true test of a language is how well you can discover and solve new<br/>problems, not how well you can use it to solve a problem someone else has<br/>already formulated. These two are quite different criteria. In art, mediums<br/>like embroidery and mosaic work well if you know beforehand what you want to<br/>make, but are absolutely lousy if you don't. When you want to discover the<br/>image as you make it-- as you have to do with anything as complex as an image<br/>of a person, for example-- you need to use a more fluid medium like pencil or<br/>ink wash or oil paint. And indeed, the way tapestries and mosaics are made in<br/>practice is to make a painting first, then copy it. (The word "cartoon" was<br/>originally used to describe a painting intended for this purpose).  <br/>  <br/>What this means is that we are never likely to have accurate comparisons of<br/>the relative power of programming languages. We'll have precise comparisons,<br/>but not accurate ones. In particular, explicit studies for the purpose of<br/>comparing languages, because they will probably use small problems, and will<br/>necessarily use predefined problems, will tend to underestimate the power of<br/>the more powerful languages.  <br/>  <br/>Reports from the field, though they will necessarily be less precise than<br/>"scientific" studies, are likely to be more meaningful. For example, Ulf Wiger<br/>of Ericsson did a study that concluded that Erlang was 4-10x more succinct<br/>than C++, and proportionately faster to develop software in:<br/><br/>> Comparisons between Ericsson-internal development projects indicate similar<br/>> line/hour productivity, including all phases of software development, rather<br/>> independently of which language (Erlang, PLEX, C, C++, or Java) was used.<br/>> What differentiates the different languages then becomes source code volume.<br/><br/>The study also deals explictly with a point that was only implicit in Brooks'<br/>book (since he measured lines of debugged code): programs written in more<br/>powerful languages tend to have fewer bugs. That becomes an end in itself,<br/>possibly more important than programmer productivity, in applications like<br/>network switches.  <br/>  <br/> **The Taste Test**  <br/>  <br/>Ultimately, I think you have to go with your gut. What does it feel like to<br/>program in the language? I think the way to find (or design) the best language<br/>is to become hypersensitive to how well a language lets you think, then<br/>choose/design the language that feels best. If some language feature is<br/>awkward or restricting, don't worry, you'll know about it.  <br/>  <br/>Such hypersensitivity will come at a cost. You'll find that you can't _stand_<br/>programming in clumsy languages. I find it unbearably restrictive to program<br/>in languages without macros, just as someone used to dynamic typing finds it<br/>unbearably restrictive to have to go back to programming in a language where<br/>you have to declare the type of every variable, and can't make a list of<br/>objects of different types.  <br/>  <br/>I'm not the only one. I know many Lisp hackers that this has happened to. In<br/>fact, the most accurate measure of the relative power of programming languages<br/>might be the percentage of people who know the language who will take any job<br/>where they get to use that language, regardless of the application domain.  <br/>  <br/> **Restrictiveness**  <br/>  <br/>I think most hackers know what it means for a language to feel restrictive.<br/>What's happening when you feel that? I think it's the same feeling you get<br/>when the street you want to take is blocked off, and you have to take a long<br/>detour to get where you wanted to go. There is something you want to say, and<br/>the language won't let you.  <br/>  <br/>What's really going on here, I think, is that a restrictive language is one<br/>that isn't succinct enough. The problem is not simply that you can't say what<br/>you planned to. It's that the detour the language makes you take is _longer._<br/>Try this thought experiment. Suppose there were some program you wanted to<br/>write, and the language wouldn't let you express it the way you planned to,<br/>but instead forced you to write the program in some other way that was<br/>_shorter._ For me at least, that wouldn't feel very restrictive. It would be<br/>like the street you wanted to take being blocked off, and the policeman at the<br/>intersection directing you to a shortcut instead of a detour. Great!  <br/>  <br/>I think most (ninety percent?) of the feeling of restrictiveness comes from<br/>being forced to make the program you write in the language longer than one you<br/>have in your head. Restrictiveness is mostly lack of succinctness. So when a<br/>language feels restrictive, what that (mostly) means is that it isn't succinct<br/>enough, and when a language isn't succinct, it will feel restrictive.  <br/>  <br/> **Readability**  <br/>  <br/>The quote I began with mentions two other qualities, regularity and<br/>readability. I'm not sure what regularity is, or what advantage, if any, code<br/>that is regular and readable has over code that is merely readable. But I<br/>think I know what is meant by readability, and I think it is also related to<br/>succinctness.  <br/>  <br/>We have to be careful here to distinguish between the readability of an<br/>individual line of code and the readability of the whole program. It's the<br/>second that matters. I agree that a line of Basic is likely to be more<br/>readable than a line of Lisp. But a program written in Basic is is going to<br/>have more lines than the same program written in Lisp (especially once you<br/>cross over into Greenspunland). The total effort of reading the Basic program<br/>will surely be greater.<br/><br/>> total effort = effort per line x number of lines<br/><br/>I'm not as sure that readability is directly proportionate to succinctness as<br/>I am that power is, but certainly succinctness is a factor (in the<br/>mathematical sense; see equation above) in readability. So it may not even be<br/>meaningful to say that the goal of a language is readability, not<br/>succinctness; it could be like saying the goal was readability, not<br/>readability.  <br/>  <br/>What readability-per-line does mean, to the user encountering the language for<br/>the first time, is that source code will _look unthreatening_. So readability-<br/>per-line could be a good marketing decision, even if it is a bad design<br/>decision. It's isomorphic to the very successful technique of letting people<br/>pay in installments: instead of frightening them with a high upfront price,<br/>you tell them the low monthly payment. Installment plans are a net lose for<br/>the buyer, though, as mere readability-per-line probably is for the<br/>programmer. The buyer is going to make a _lot_ of those low, low payments; and<br/>the programmer is going to read a _lot_ of those individually readable lines.  <br/>  <br/>This tradeoff predates programming languages. If you're used to reading novels<br/>and newspaper articles, your first experience of reading a math paper can be<br/>dismaying. It could take half an hour to read a single page. And yet, I am<br/>pretty sure that the notation is not the problem, even though it may feel like<br/>it is. The math paper is hard to read because the ideas are hard. If you<br/>expressed the same ideas in prose (as mathematicians had to do before they<br/>evolved succinct notations), they wouldn't be any easier to read, because the<br/>paper would grow to the size of a book.  <br/>  <br/> **To What Extent?**  <br/>  <br/>A number of people have rejected the idea that succinctness = power. I think<br/>it would be more useful, instead of simply arguing that they are the same or<br/>aren't, to ask: to what _extent_ does succinctness = power? Because clearly<br/>succinctness is a large part of what higher-level languages are for. If it is<br/>not all they're for, then what else are they for, and how important,<br/>relatively, are these other functions?  <br/>  <br/>I'm not proposing this just to make the debate more civilized. I really want<br/>to know the answer. When, if ever, is a language too succinct for its own<br/>good?  <br/>  <br/>The hypothesis I began with was that, except in pathological examples, I<br/>thought succinctness could be considered identical with power. What I meant<br/>was that in any language anyone would design, they would be identical, but<br/>that if someone wanted to design a language explicitly to disprove this<br/>hyphothesis, they could probably do it. I'm not even sure of that, actually.  <br/>  <br/> **Languages, not Programs**  <br/>  <br/>We should be clear that we are talking about the succinctness of languages,<br/>not of individual programs. It certainly is possible for individual programs<br/>to be written too densely.  <br/>  <br/>I wrote about this in On Lisp. A complex macro may have to save many times its<br/>own length to be justified. If writing some hairy macro could save you ten<br/>lines of code every time you use it, and the macro is itself ten lines of<br/>code, then you get a net saving in lines if you use it more than once. But<br/>that could still be a bad move, because macro definitions are harder to read<br/>than ordinary code. You might have to use the macro ten or twenty times before<br/>it yielded a net improvement in readability.  <br/>  <br/>I'm sure every language has such tradeoffs (though I suspect the stakes get<br/>higher as the language gets more powerful). Every programmer must have seen<br/>code that some clever person has made marginally shorter by using dubious<br/>programming tricks.  <br/>  <br/>So there is no argument about that-- at least, not from me. Individual<br/>programs can certainly be too succinct for their own good. The question is,<br/>can a language be? Can a language compel programmers to write code that's<br/>short (in elements) at the expense of overall readability?  <br/>  <br/>One reason it's hard to imagine a language being too succinct is that if there<br/>were some excessively compact way to phrase something, there would probably<br/>also be a longer way. For example, if you felt Lisp programs using a lot of<br/>macros or higher-order functions were too dense, you could, if you preferred,<br/>write code that was isomorphic to Pascal. If you don't want to express<br/>factorial in Arc as a call to a higher-order function  (rec zero 1 * 1-)  you<br/>can also write out a recursive definition:  (rfn fact (x) (if (zero x) 1 (* x<br/>(fact (1- x)))))  Though I can't off the top of my head think of any examples,<br/>I am interested in the question of whether a language could be too succinct.<br/>Are there languages that force you to write code in a way that is crabbed and<br/>incomprehensible? If anyone has examples, I would be very interested to see<br/>them.  <br/>  <br/>(Reminder: What I'm looking for are programs that are very dense according to<br/>the metric of "elements" sketched above, not merely programs that are short<br/>because delimiters can be omitted and everything has a one-character name.)  <br/>  <br/>  <br/>  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Lutz Prechelt: Comparison of Seven Languages  <br/>  <br/><br/>Erann Gat: Lisp vs. Java  <br/>  <br/><br/>Peter Norvig Tries Prechelt's Test  <br/>  <br/><br/>Matthias Felleisen: Expressive Power of Languages  <br/>  <br/><br/>Kragen Sitaker: Redundancy and Power  <br/>  <br/><br/>Forth  <br/>  <br/><br/>Joy  <br/>  <br/><br/>Icon  <br/>  <br/><br/>J  <br/>  <br/><br/>K  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>February 2002  <br/>  <br/>  <br/>  <br/>I was talking recently to a friend who teaches at MIT. His field is hot now<br/>and every year he is inundated by applications from would-be graduate<br/>students. "A lot of them seem smart," he said. "What I can't tell is whether<br/>they have any kind of taste."  <br/>  <br/>Taste. You don't hear that word much now. And yet we still need the underlying<br/>concept, whatever we call it. What my friend meant was that he wanted students<br/>who were not just good technicians, but who could use their technical<br/>knowledge to design beautiful things.  <br/>  <br/>Mathematicians call good work "beautiful," and so, either now or in the past,<br/>have scientists, engineers, musicians, architects, designers, writers, and<br/>painters. Is it just a coincidence that they used the same word, or is there<br/>some overlap in what they meant? If there is an overlap, can we use one<br/>field's discoveries about beauty to help us in another?  <br/>  <br/>For those of us who design things, these are not just theoretical questions.<br/>If there is such a thing as beauty, we need to be able to recognize it. We<br/>need good taste to make good things. Instead of treating beauty as an airy<br/>abstraction, to be either blathered about or avoided depending on how one<br/>feels about airy abstractions, let's try considering it as a practical<br/>question: _how do you make good stuff?_  <br/>  <br/>  <br/>  <br/>If you mention taste nowadays, a lot of people will tell you that "taste is<br/>subjective." They believe this because it really feels that way to them. When<br/>they like something, they have no idea why. It could be because it's<br/>beautiful, or because their mother had one, or because they saw a movie star<br/>with one in a magazine, or because they know it's expensive. Their thoughts<br/>are a tangle of unexamined impulses.  <br/>  <br/>Most of us are encouraged, as children, to leave this tangle unexamined. If<br/>you make fun of your little brother for coloring people green in his coloring<br/>book, your mother is likely to tell you something like "you like to do it your<br/>way and he likes to do it his way."  <br/>  <br/>Your mother at this point is not trying to teach you important truths about<br/>aesthetics. She's trying to get the two of you to stop bickering.  <br/>  <br/>Like many of the half-truths adults tell us, this one contradicts other things<br/>they tell us. After dinning into you that taste is merely a matter of personal<br/>preference, they take you to the museum and tell you that you should pay<br/>attention because Leonardo is a great artist.  <br/>  <br/>What goes through the kid's head at this point? What does he think "great<br/>artist" means? After having been told for years that everyone just likes to do<br/>things their own way, he is unlikely to head straight for the conclusion that<br/>a great artist is someone whose work is _better_ than the others'. A far more<br/>likely theory, in his Ptolemaic model of the universe, is that a great artist<br/>is something that's good for you, like broccoli, because someone said so in a<br/>book.  <br/>  <br/>  <br/>  <br/>Saying that taste is just personal preference is a good way to prevent<br/>disputes. The trouble is, it's not true. You feel this when you start to<br/>design things.  <br/>  <br/>Whatever job people do, they naturally want to do better. Football players<br/>like to win games. CEOs like to increase earnings. It's a matter of pride, and<br/>a real pleasure, to get better at your job. But if your job is to design<br/>things, and there is no such thing as beauty, then there is _no way to get<br/>better at your job._ If taste is just personal preference, then everyone's is<br/>already perfect: you like whatever you like, and that's it.  <br/>  <br/>As in any job, as you continue to design things, you'll get better at it. Your<br/>tastes will change. And, like anyone who gets better at their job, you'll know<br/>you're getting better. If so, your old tastes were not merely different, but<br/>worse. Poof goes the axiom that taste can't be wrong.  <br/>  <br/>Relativism is fashionable at the moment, and that may hamper you from thinking<br/>about taste, even as yours grows. But if you come out of the closet and admit,<br/>at least to yourself, that there is such a thing as good and bad design, then<br/>you can start to study good design in detail. How has your taste changed? When<br/>you made mistakes, what caused you to make them? What have other people<br/>learned about design?  <br/>  <br/>Once you start to examine the question, it's surprising how much different<br/>fields' ideas of beauty have in common. The same principles of good design<br/>crop up again and again.  <br/>  <br/>  <br/>  <br/> **Good design is simple.** You hear this from math to painting. In math it<br/>means that a shorter proof tends to be a better one. Where axioms are<br/>concerned, especially, less is more. It means much the same thing in<br/>programming. For architects and designers it means that beauty should depend<br/>on a few carefully chosen structural elements rather than a profusion of<br/>superficial ornament. (Ornament is not in itself bad, only when it's<br/>camouflage on insipid form.) Similarly, in painting, a still life of a few<br/>carefully observed and solidly modelled objects will tend to be more<br/>interesting than a stretch of flashy but mindlessly repetitive painting of,<br/>say, a lace collar. In writing it means: say what you mean and say it briefly.  <br/>  <br/>It seems strange to have to emphasize simplicity. You'd think simple would be<br/>the default. Ornate is more work. But something seems to come over people when<br/>they try to be creative. Beginning writers adopt a pompous tone that doesn't<br/>sound anything like the way they speak. Designers trying to be artistic resort<br/>to swooshes and curlicues. Painters discover that they're expressionists. It's<br/>all evasion. Underneath the long words or the "expressive" brush strokes,<br/>there is not much going on, and that's frightening.  <br/>  <br/>When you're forced to be simple, you're forced to face the real problem. When<br/>you can't deliver ornament, you have to deliver substance.  <br/>  <br/>  <br/>  <br/> **Good design is timeless.** In math, every proof is timeless unless it<br/>contains a mistake. So what does Hardy mean when he says there is no permanent<br/>place for ugly mathematics? He means the same thing Kelly Johnson did: if<br/>something is ugly, it can't be the best solution. There must be a better one,<br/>and eventually someone will discover it.  <br/>  <br/>Aiming at timelessness is a way to make yourself find the best answer: if you<br/>can imagine someone surpassing you, you should do it yourself. Some of the<br/>greatest masters did this so well that they left little room for those who<br/>came after. Every engraver since Durer has had to live in his shadow.  <br/>  <br/>Aiming at timelessness is also a way to evade the grip of fashion. Fashions<br/>almost by definition change with time, so if you can make something that will<br/>still look good far into the future, then its appeal must derive more from<br/>merit and less from fashion.  <br/>  <br/>Strangely enough, if you want to make something that will appeal to future<br/>generations, one way to do it is to try to appeal to past generations. It's<br/>hard to guess what the future will be like, but we can be sure it will be like<br/>the past in caring nothing for present fashions. So if you can make something<br/>that appeals to people today and would also have appealed to people in 1500,<br/>there is a good chance it will appeal to people in 2500.  <br/>  <br/>  <br/>  <br/> **Good design solves the right problem.** The typical stove has four burners<br/>arranged in a square, and a dial to control each. How do you arrange the<br/>dials? The simplest answer is to put them in a row. But this is a simple<br/>answer to the wrong question. The dials are for humans to use, and if you put<br/>them in a row, the unlucky human will have to stop and think each time about<br/>which dial matches which burner. Better to arrange the dials in a square like<br/>the burners.  <br/>  <br/>A lot of bad design is industrious, but misguided. In the mid twentieth<br/>century there was a vogue for setting text in sans-serif fonts. These fonts<br/>_are_ closer to the pure, underlying letterforms. But in text that's not the<br/>problem you're trying to solve. For legibility it's more important that<br/>letters be easy to tell apart. It may look Victorian, but a Times Roman<br/>lowercase g is easy to tell from a lowercase y.  <br/>  <br/>Problems can be improved as well as solutions. In software, an intractable<br/>problem can usually be replaced by an equivalent one that's easy to solve.<br/>Physics progressed faster as the problem became predicting observable<br/>behavior, instead of reconciling it with scripture.  <br/>  <br/>  <br/>  <br/> **Good design is suggestive.** Jane Austen's novels contain almost no<br/>description; instead of telling you how everything looks, she tells her story<br/>so well that you envision the scene for yourself. Likewise, a painting that<br/>suggests is usually more engaging than one that tells. Everyone makes up their<br/>own story about the Mona Lisa.  <br/>  <br/>In architecture and design, this principle means that a building or object<br/>should let you use it how you want: a good building, for example, will serve<br/>as a backdrop for whatever life people want to lead in it, instead of making<br/>them live as if they were executing a program written by the architect.  <br/>  <br/>In software, it means you should give users a few basic elements that they can<br/>combine as they wish, like Lego. In math it means a proof that becomes the<br/>basis for a lot of new work is preferable to a proof that was difficult, but<br/>doesn't lead to future discoveries; in the sciences generally, citation is<br/>considered a rough indicator of merit.  <br/>  <br/>  <br/>  <br/> **Good design is often slightly funny.** This one may not always be true. But<br/>Durer's engravings and Saarinen's womb chair and the Pantheon and the original<br/>Porsche 911 all seem to me slightly funny. Godel's incompleteness theorem<br/>seems like a practical joke.  <br/>  <br/>I think it's because humor is related to strength. To have a sense of humor is<br/>to be strong: to keep one's sense of humor is to shrug off misfortunes, and to<br/>lose one's sense of humor is to be wounded by them. And so the mark-- or at<br/>least the prerogative-- of strength is not to take oneself too seriously. The<br/>confident will often, like swallows, seem to be making fun of the whole<br/>process slightly, as Hitchcock does in his films or Bruegel in his paintings--<br/>or Shakespeare, for that matter.  <br/>  <br/>Good design may not have to be funny, but it's hard to imagine something that<br/>could be called humorless also being good design.  <br/>  <br/>  <br/>  <br/> **Good design is hard.** If you look at the people who've done great work,<br/>one thing they all seem to have in common is that they worked very hard. If<br/>you're not working hard, you're probably wasting your time.  <br/>  <br/>Hard problems call for great efforts. In math, difficult proofs require<br/>ingenious solutions, and those tend to be interesting. Ditto in engineering.  <br/>  <br/>When you have to climb a mountain you toss everything unnecessary out of your<br/>pack. And so an architect who has to build on a difficult site, or a small<br/>budget, will find that he is forced to produce an elegant design. Fashions and<br/>flourishes get knocked aside by the difficult business of solving the problem<br/>at all.  <br/>  <br/>Not every kind of hard is good. There is good pain and bad pain. You want the<br/>kind of pain you get from going running, not the kind you get from stepping on<br/>a nail. A difficult problem could be good for a designer, but a fickle client<br/>or unreliable materials would not be.  <br/>  <br/>In art, the highest place has traditionally been given to paintings of people.<br/>There is something to this tradition, and not just because pictures of faces<br/>get to press buttons in our brains that other pictures don't. We are so good<br/>at looking at faces that we force anyone who draws them to work hard to<br/>satisfy us. If you draw a tree and you change the angle of a branch five<br/>degrees, no one will know. When you change the angle of someone's eye five<br/>degrees, people notice.  <br/>  <br/>When Bauhaus designers adopted Sullivan's "form follows function," what they<br/>meant was, form _should_ follow function. And if function is hard enough, form<br/>is forced to follow it, because there is no effort to spare for error. Wild<br/>animals are beautiful because they have hard lives.  <br/>  <br/>  <br/>  <br/> **Good design looks easy.** Like great athletes, great designers make it look<br/>easy. Mostly this is an illusion. The easy, conversational tone of good<br/>writing comes only on the eighth rewrite.  <br/>  <br/>In science and engineering, some of the greatest discoveries seem so simple<br/>that you say to yourself, I could have thought of that. The discoverer is<br/>entitled to reply, why didn't you?  <br/>  <br/>Some Leonardo heads are just a few lines. You look at them and you think, all<br/>you have to do is get eight or ten lines in the right place and you've made<br/>this beautiful portrait. Well, yes, but you have to get them in _exactly_ the<br/>right place. The slightest error will make the whole thing collapse.  <br/>  <br/>Line drawings are in fact the most difficult visual medium, because they<br/>demand near perfection. In math terms, they are a closed-form solution; lesser<br/>artists literally solve the same problems by successive approximation. One of<br/>the reasons kids give up drawing at ten or so is that they decide to start<br/>drawing like grownups, and one of the first things they try is a line drawing<br/>of a face. Smack!  <br/>  <br/>In most fields the appearance of ease seems to come with practice. Perhaps<br/>what practice does is train your unconscious mind to handle tasks that used to<br/>require conscious thought. In some cases you literally train your body. An<br/>expert pianist can play notes faster than the brain can send signals to his<br/>hand. Likewise an artist, after a while, can make visual perception flow in<br/>through his eye and out through his hand as automatically as someone tapping<br/>his foot to a beat.  <br/>  <br/>When people talk about being in "the zone," I think what they mean is that the<br/>spinal cord has the situation under control. Your spinal cord is less<br/>hesitant, and it frees conscious thought for the hard problems.  <br/>  <br/>  <br/>  <br/>**Good design uses symmetry.** I think symmetry may just be one way to achieve<br/>simplicity, but it's important enough to be mentioned on its own. Nature uses<br/>it a lot, which is a good sign.  <br/>  <br/>There are two kinds of symmetry, repetition and recursion. Recursion means<br/>repetition in subelements, like the pattern of veins in a leaf.  <br/>  <br/>Symmetry is unfashionable in some fields now, in reaction to excesses in the<br/>past. Architects started consciously making buildings asymmetric in Victorian<br/>times and by the 1920s asymmetry was an explicit premise of modernist<br/>architecture. Even these buildings only tended to be asymmetric about major<br/>axes, though; there were hundreds of minor symmetries.  <br/>  <br/>In writing you find symmetry at every level, from the phrases in a sentence to<br/>the plot of a novel. You find the same in music and art. Mosaics (and some<br/>Cezannes) get extra visual punch by making the whole picture out of the same<br/>atoms. Compositional symmetry yields some of the most memorable paintings,<br/>especially when two halves react to one another, as in the _Creation of Adam_<br/>or _American Gothic._  <br/>  <br/>In math and engineering, recursion, especially, is a big win. Inductive proofs<br/>are wonderfully short. In software, a problem that can be solved by recursion<br/>is nearly always best solved that way. The Eiffel Tower looks striking partly<br/>because it is a recursive solution, a tower on a tower.  <br/>  <br/>The danger of symmetry, and repetition especially, is that it can be used as a<br/>substitute for thought.  <br/>  <br/>  <br/>  <br/> **Good design resembles nature.** It's not so much that resembling nature is<br/>intrinsically good as that nature has had a long time to work on the problem.<br/>It's a good sign when your answer resembles nature's.  <br/>  <br/>It's not cheating to copy. Few would deny that a story should be like life.<br/>Working from life is a valuable tool in painting too, though its role has<br/>often been misunderstood. The aim is not simply to make a record. The point of<br/>painting from life is that it gives your mind something to chew on: when your<br/>eyes are looking at something, your hand will do more interesting work.  <br/>  <br/>Imitating nature also works in engineering. Boats have long had spines and<br/>ribs like an animal's ribcage. In some cases we may have to wait for better<br/>technology: early aircraft designers were mistaken to design aircraft that<br/>looked like birds, because they didn't have materials or power sources light<br/>enough (the Wrights' engine weighed 152 lbs. and generated only 12 hp.) or<br/>control systems sophisticated enough for machines that flew like birds, but I<br/>could imagine little unmanned reconnaissance planes flying like birds in fifty<br/>years.  <br/>  <br/>Now that we have enough computer power, we can imitate nature's method as well<br/>as its results. Genetic algorithms may let us create things too complex to<br/>design in the ordinary sense.  <br/>  <br/>  <br/>  <br/> **Good design is redesign.** It's rare to get things right the first time.<br/>Experts expect to throw away some early work. They plan for plans to change.  <br/>  <br/>It takes confidence to throw work away. You have to be able to think, _there's<br/>more where that came from._ When people first start drawing, for example,<br/>they're often reluctant to redo parts that aren't right; they feel they've<br/>been lucky to get that far, and if they try to redo something, it will turn<br/>out worse. Instead they convince themselves that the drawing is not that bad,<br/>really-- in fact, maybe they meant it to look that way.  <br/>  <br/>Dangerous territory, that; if anything you should cultivate dissatisfaction.<br/>In Leonardo's drawings there are often five or six attempts to get a line<br/>right. The distinctive back of the Porsche 911 only appeared in the redesign<br/>of an awkward prototype. In Wright's early plans for the Guggenheim, the right<br/>half was a ziggurat; he inverted it to get the present shape.  <br/>  <br/>Mistakes are natural. Instead of treating them as disasters, make them easy to<br/>acknowledge and easy to fix. Leonardo more or less invented the sketch, as a<br/>way to make drawing bear a greater weight of exploration. Open-source software<br/>has fewer bugs because it admits the possibility of bugs.  <br/>  <br/>It helps to have a medium that makes change easy. When oil paint replaced<br/>tempera in the fifteenth century, it helped painters to deal with difficult<br/>subjects like the human figure because, unlike tempera, oil can be blended and<br/>overpainted.  <br/>  <br/>  <br/>  <br/>**Good design can copy.** Attitudes to copying often make a round trip. A<br/>novice imitates without knowing it; next he tries consciously to be original;<br/>finally, he decides it's more important to be right than original.  <br/>  <br/>Unknowing imitation is almost a recipe for bad design. If you don't know where<br/>your ideas are coming from, you're probably imitating an imitator. Raphael so<br/>pervaded mid-nineteenth century taste that almost anyone who tried to draw was<br/>imitating him, often at several removes. It was this, more than Raphael's own<br/>work, that bothered the Pre-Raphaelites.  <br/>  <br/>The ambitious are not content to imitate. The second phase in the growth of<br/>taste is a conscious attempt at originality.  <br/>  <br/>I think the greatest masters go on to achieve a kind of selflessness. They<br/>just want to get the right answer, and if part of the right answer has already<br/>been discovered by someone else, that's no reason not to use it. They're<br/>confident enough to take from anyone without feeling that their own vision<br/>will be lost in the process.  <br/>  <br/>  <br/>  <br/>**Good design is often strange.** Some of the very best work has an uncanny<br/>quality: Euler's Formula, Bruegel's _Hunters in the Snow,_ the SR-71, Lisp.<br/>They're not just beautiful, but strangely beautiful.  <br/>  <br/>I'm not sure why. It may just be my own stupidity. A can-opener must seem<br/>miraculous to a dog. Maybe if I were smart enough it would seem the most<br/>natural thing in the world that ei*pi = -1. It is after all necessarily true.  <br/>  <br/>Most of the qualities I've mentioned are things that can be cultivated, but I<br/>don't think it works to cultivate strangeness. The best you can do is not<br/>squash it if it starts to appear. Einstein didn't try to make relativity<br/>strange. He tried to make it true, and the truth turned out to be strange.  <br/>  <br/>At an art school where I once studied, the students wanted most of all to<br/>develop a personal style. But if you just try to make good things, you'll<br/>inevitably do it in a distinctive way, just as each person walks in a<br/>distinctive way. Michelangelo was not trying to paint like Michelangelo. He<br/>was just trying to paint well; he couldn't help painting like Michelangelo.  <br/>  <br/>The only style worth having is the one you can't help. And this is especially<br/>true for strangeness. There is no shortcut to it. The Northwest Passage that<br/>the Mannerists, the Romantics, and two generations of American high school<br/>students have searched for does not seem to exist. The only way to get there<br/>is to go through good and come out the other side.  <br/>  <br/>  <br/>  <br/>**Good design happens in chunks.** The inhabitants of fifteenth century<br/>Florence included Brunelleschi, Ghiberti, Donatello, Masaccio, Filippo Lippi,<br/>Fra Angelico, Verrocchio, Botticelli, Leonardo, and Michelangelo. Milan at the<br/>time was as big as Florence. How many fifteenth century Milanese artists can<br/>you name?  <br/>  <br/>Something was happening in Florence in the fifteenth century. And it can't<br/>have been heredity, because it isn't happening now. You have to assume that<br/>whatever inborn ability Leonardo and Michelangelo had, there were people born<br/>in Milan with just as much. What happened to the Milanese Leonardo?  <br/>  <br/>There are roughly a thousand times as many people alive in the US right now as<br/>lived in Florence during the fifteenth century. A thousand Leonardos and a<br/>thousand Michelangelos walk among us. If DNA ruled, we should be greeted daily<br/>by artistic marvels. We aren't, and the reason is that to make Leonardo you<br/>need more than his innate ability. You also need Florence in 1450.  <br/>  <br/>Nothing is more powerful than a community of talented people working on<br/>related problems. Genes count for little by comparison: being a genetic<br/>Leonardo was not enough to compensate for having been born near Milan instead<br/>of Florence. Today we move around more, but great work still comes<br/>disproportionately from a few hotspots: the Bauhaus, the Manhattan Project,<br/>the _New Yorker,_ Lockheed's Skunk Works, Xerox Parc.  <br/>  <br/>At any given time there are a few hot topics and a few groups doing great work<br/>on them, and it's nearly impossible to do good work yourself if you're too far<br/>removed from one of these centers. You can push or pull these trends to some<br/>extent, but you can't break away from them. (Maybe _you_ can, but the Milanese<br/>Leonardo couldn't.)  <br/>  <br/>  <br/>  <br/>**Good design is often daring.** At every period of history, people have<br/>believed things that were just ridiculous, and believed them so strongly that<br/>you risked ostracism or even violence by saying otherwise.  <br/>  <br/>If our own time were any different, that would be remarkable. As far as I can<br/>tell it isn't.  <br/>  <br/>This problem afflicts not just every era, but in some degree every field. Much<br/>Renaissance art was in its time considered shockingly secular: according to<br/>Vasari, Botticelli repented and gave up painting, and Fra Bartolommeo and<br/>Lorenzo di Credi actually burned some of their work. Einstein's theory of<br/>relativity offended many contemporary physicists, and was not fully accepted<br/>for decades-- in France, not until the 1950s.  <br/>  <br/>Today's experimental error is tomorrow's new theory. If you want to discover<br/>great new things, then instead of turning a blind eye to the places where<br/>conventional wisdom and truth don't quite meet, you should pay particular<br/>attention to them.  <br/>  <br/>  <br/>  <br/>As a practical matter, I think it's easier to see ugliness than to imagine<br/>beauty. Most of the people who've made beautiful things seem to have done it<br/>by fixing something that they thought ugly. Great work usually seems to happen<br/>because someone sees something and thinks, _I could do better than that._<br/>Giotto saw traditional Byzantine madonnas painted according to a formula that<br/>had satisfied everyone for centuries, and to him they looked wooden and<br/>unnatural. Copernicus was so troubled by a hack that all his contemporaries<br/>could tolerate that he felt there must be a better solution.  <br/>  <br/>Intolerance for ugliness is not in itself enough. You have to understand a<br/>field well before you develop a good nose for what needs fixing. You have to<br/>do your homework. But as you become expert in a field, you'll start to hear<br/>little voices saying, _What a hack! There must be a better way._ Don't ignore<br/>those voices. Cultivate them. The recipe for great work is: very exacting<br/>taste, plus the ability to gratify it.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>Sullivan actually said "form ever follows function," but I think the usual<br/>misquotation is closer to what modernist architects meant.  <br/>  <br/>Stephen G. Brush, "Why was Relativity Accepted?" _Phys. Perspect. 1 (1999)<br/>184-214.  <br/>  <br/>  <br/>_<br/><br/>Japanese Translation  <br/>  <br/><br/>Chinese Translation  <br/>  <br/><br/>Slovenian Translation  <br/>  <br/><br/>German Translation  <br/>  <br/><br/>Interview: Milton Glaser  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>December 2001 (rev. May 2002)<br/><br/>_(This article came about in response to some questions on theLL1 mailing<br/>list. It is now incorporated in Revenge of the Nerds.)_  <br/>  <br/>When McCarthy designed Lisp in the late 1950s, it was a radical departure from<br/>existing languages, the most important of which was Fortran.  <br/>  <br/>Lisp embodied nine new ideas:  <br/>  <br/><br/>* * *<br/><br/>**1\. Conditionals.** A conditional is an if-then-else construct. We take<br/>these for granted now. They were invented by McCarthy in the course of<br/>developing Lisp. (Fortran at that time only had a conditional goto, closely<br/>based on the branch instruction in the underlying hardware.) McCarthy, who was<br/>on the Algol committee, got conditionals into Algol, whence they spread to<br/>most other languages.  <br/>  <br/> **2\. A function type.** In Lisp, functions are first class objects-- they're<br/>a data type just like integers, strings, etc, and have a literal<br/>representation, can be stored in variables, can be passed as arguments, and so<br/>on.  <br/>  <br/> **3\. Recursion.** Recursion existed as a mathematical concept before Lisp of<br/>course, but Lisp was the first programming language to support it. (It's<br/>arguably implicit in making functions first class objects.)  <br/>  <br/> **4\. A new concept of variables.** In Lisp, all variables are effectively<br/>pointers. Values are what have types, not variables, and assigning or binding<br/>variables means copying pointers, not what they point to.  <br/>  <br/> **5\. Garbage-collection.**  <br/>  <br/> **6\. Programs composed of expressions.** Lisp programs are trees of<br/>expressions, each of which returns a value. (In some Lisps expressions can<br/>return multiple values.) This is in contrast to Fortran and most succeeding<br/>languages, which distinguish between expressions and statements.  <br/>  <br/>It was natural to have this distinction in Fortran because (not surprisingly<br/>in a language where the input format was punched cards) the language was line-<br/>oriented. You could not nest statements. And so while you needed expressions<br/>for math to work, there was no point in making anything else return a value,<br/>because there could not be anything waiting for it.  <br/>  <br/>This limitation went away with the arrival of block-structured languages, but<br/>by then it was too late. The distinction between expressions and statements<br/>was entrenched. It spread from Fortran into Algol and thence to both their<br/>descendants.  <br/>  <br/>When a language is made entirely of expressions, you can compose expressions<br/>however you want. You can say either (using Arc syntax)  <br/>  <br/>(if foo (= x 1) (= x 2))  <br/>  <br/>or  <br/>  <br/>(= x (if foo 1 2))  <br/>  <br/> **7\. A symbol type.** Symbols differ from strings in that you can test<br/>equality by comparing a pointer.  <br/>  <br/> **8\. A notation for code** using trees of symbols.  <br/>  <br/> **9\. The whole language always available.** There is no real distinction<br/>between read-time, compile-time, and runtime. You can compile or run code<br/>while reading, read or run code while compiling, and read or compile code at<br/>runtime.  <br/>  <br/>Running code at read-time lets users reprogram Lisp's syntax; running code at<br/>compile-time is the basis of macros; compiling at runtime is the basis of<br/>Lisp's use as an extension language in programs like Emacs; and reading at<br/>runtime enables programs to communicate using s-expressions, an idea recently<br/>reinvented as XML.<br/><br/>* * *<br/><br/>  <br/>  <br/>When Lisp was first invented, all these ideas were far removed from ordinary<br/>programming practice, which was dictated largely by the hardware available in<br/>the late 1950s.  <br/>  <br/>Over time, the default language, embodied in a succession of popular<br/>languages, has gradually evolved toward Lisp. 1-5 are now widespread. 6 is<br/>starting to appear in the mainstream. Python has a form of 7, though there<br/>doesn't seem to be any syntax for it. 8, which (with 9) is what makes Lisp<br/>macros possible, is so far still unique to Lisp, perhaps because (a) it<br/>requires those parens, or something just as bad, and (b) if you add that final<br/>increment of power, you can no longer claim to have invented a new language,<br/>but only to have designed a new dialect of Lisp ; -)  <br/>  <br/>Though useful to present-day programmers, it's strange to describe Lisp in<br/>terms of its variation from the random expedients other languages adopted.<br/>That was not, probably, how McCarthy thought of it. Lisp wasn't designed to<br/>fix the mistakes in Fortran; it came about more as the byproduct of an attempt<br/>to axiomatize computation.  <br/>  <br/>  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>May 2003  <br/>  <br/> _(This essay is derived from a guest lecture at Harvard, which incorporated<br/>an earlier talk at Northeastern.)_  <br/>  <br/>When I finished grad school in computer science I went to art school to study<br/>painting. A lot of people seemed surprised that someone interested in<br/>computers would also be interested in painting. They seemed to think that<br/>hacking and painting were very different kinds of work-- that hacking was<br/>cold, precise, and methodical, and that painting was the frenzied expression<br/>of some primal urge.  <br/>  <br/>Both of these images are wrong. Hacking and painting have a lot in common. In<br/>fact, of all the different types of people I've known, hackers and painters<br/>are among the most alike.  <br/>  <br/>What hackers and painters have in common is that they're both makers. Along<br/>with composers, architects, and writers, what hackers and painters are trying<br/>to do is make good things. They're not doing research per se, though if in the<br/>course of trying to make good things they discover some new technique, so much<br/>the better.  <br/>  <br/>  <br/>  <br/>I've never liked the term "computer science." The main reason I don't like it<br/>is that there's no such thing. Computer science is a grab bag of tenuously<br/>related areas thrown together by an accident of history, like Yugoslavia. At<br/>one end you have people who are really mathematicians, but call what they're<br/>doing computer science so they can get DARPA grants. In the middle you have<br/>people working on something like the natural history of computers-- studying<br/>the behavior of algorithms for routing data through networks, for example. And<br/>then at the other extreme you have the hackers, who are trying to write<br/>interesting software, and for whom computers are just a medium of expression,<br/>as concrete is for architects or paint for painters. It's as if<br/>mathematicians, physicists, and architects all had to be in the same<br/>department.  <br/>  <br/>Sometimes what the hackers do is called "software engineering," but this term<br/>is just as misleading. Good software designers are no more engineers than<br/>architects are. The border between architecture and engineering is not sharply<br/>defined, but it's there. It falls between what and how: architects decide what<br/>to do, and engineers figure out how to do it.  <br/>  <br/>What and how should not be kept too separate. You're asking for trouble if you<br/>try to decide what to do without understanding how to do it. But hacking can<br/>certainly be more than just deciding how to implement some spec. At its best,<br/>it's creating the spec-- though it turns out the best way to do that is to<br/>implement it.  <br/>  <br/>  <br/>  <br/>Perhaps one day "computer science" will, like Yugoslavia, get broken up into<br/>its component parts. That might be a good thing. Especially if it meant<br/>independence for my native land, hacking.  <br/>  <br/>Bundling all these different types of work together in one department may be<br/>convenient administratively, but it's confusing intellectually. That's the<br/>other reason I don't like the name "computer science." Arguably the people in<br/>the middle are doing something like an experimental science. But the people at<br/>either end, the hackers and the mathematicians, are not actually doing<br/>science.  <br/>  <br/>The mathematicians don't seem bothered by this. They happily set to work<br/>proving theorems like the other mathematicians over in the math department,<br/>and probably soon stop noticing that the building they work in says ``computer<br/>science'' on the outside. But for the hackers this label is a problem. If what<br/>they're doing is called science, it makes them feel they ought to be acting<br/>scientific. So instead of doing what they really want to do, which is to<br/>design beautiful software, hackers in universities and research labs feel they<br/>ought to be writing research papers.  <br/>  <br/>In the best case, the papers are just a formality. Hackers write cool<br/>software, and then write a paper about it, and the paper becomes a proxy for<br/>the achievement represented by the software. But often this mismatch causes<br/>problems. It's easy to drift away from building beautiful things toward<br/>building ugly things that make more suitable subjects for research papers.  <br/>  <br/>Unfortunately, beautiful things don't always make the best subjects for<br/>papers. Number one, research must be original-- and as anyone who has written<br/>a PhD dissertation knows, the way to be sure that you're exploring virgin<br/>territory is to to stake out a piece of ground that no one wants. Number two,<br/>research must be substantial-- and awkward systems yield meatier papers,<br/>because you can write about the obstacles you have to overcome in order to get<br/>things done. Nothing yields meaty problems like starting with the wrong<br/>assumptions. Most of AI is an example of this rule; if you assume that<br/>knowledge can be represented as a list of predicate logic expressions whose<br/>arguments represent abstract concepts, you'll have a lot of papers to write<br/>about how to make this work. As Ricky Ricardo used to say, "Lucy, you got a<br/>lot of explaining to do."  <br/>  <br/>The way to create something beautiful is often to make subtle tweaks to<br/>something that already exists, or to combine existing ideas in a slightly new<br/>way. This kind of work is hard to convey in a research paper.  <br/>  <br/>  <br/>  <br/>So why do universities and research labs continue to judge hackers by<br/>publications? For the same reason that "scholastic aptitude" gets measured by<br/>simple-minded standardized tests, or the productivity of programmers gets<br/>measured in lines of code. These tests are easy to apply, and there is nothing<br/>so tempting as an easy test that kind of works.  <br/>  <br/>Measuring what hackers are actually trying to do, designing beautiful<br/>software, would be much more difficult. You need a good sense of design to<br/>judge good design<br/><br/>Japanese Translation  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>German Translation  <br/>  <br/><br/>Portuguese Translation  <br/>  <br/><br/>Czech Translation  <br/>  <br/><br/>Why Good Design Comes from Bad Design  <br/>  <br/><br/>Knuth: Computer Programming as an Art  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>November 2004  <br/>  <br/>A lot of people are writing now about why Kerry lost. Here I want to examine a<br/>more specific question: why were the exit polls so wrong?  <br/>  <br/>In Ohio, which Kerry ultimately lost 49-51, exit polls gave him a 52-48<br/>victory. And this wasn't just random error. In every swing state they<br/>overestimated the Kerry vote. In Florida, which Bush ultimately won 52-47,<br/>exit polls predicted a dead heat.  <br/>  <br/>(These are not early numbers. They're from about midnight eastern time, long<br/>after polls closed in Ohio and Florida. And yet by the next afternoon the exit<br/>poll numbers online corresponded to the returns. The only way I can imagine<br/>this happening is if those in charge of the exit polls cooked the books after<br/>seeing the actual returns. But that's another issue.)  <br/>  <br/>What happened? The source of the problem may be a variant of the Bradley<br/>Effect. This term was invented after Tom Bradley, the black mayor of Los<br/>Angeles, lost an election for governor of California despite a comfortable<br/>lead in the polls. Apparently voters were afraid to say they planned to vote<br/>against him, lest their motives be (perhaps correctly) suspected.  <br/>  <br/>It seems likely that something similar happened in exit polls this year. In<br/>theory, exit polls ought to be very accurate. You're not asking people what<br/>they would do. You're asking what they just did.  <br/>  <br/>How can you get errors asking that? Because some people don't respond. To get<br/>a truly random sample, pollsters ask, say, every 20th person leaving the<br/>polling place who they voted for. But not everyone wants to answer. And the<br/>pollsters can't simply ignore those who won't, or their sample isn't random<br/>anymore. So what they do, apparently, is note down the age and race and sex of<br/>the person, and guess from that who they voted for.  <br/>  <br/>This works so long as there is no _correlation_ between who people vote for<br/>and whether they're willing to talk about it. But this year there may have<br/>been. It may be that a significant number of those who voted for Bush didn't<br/>want to say so.  <br/>  <br/>Why not? Because people in the US are more conservative than they're willing<br/>to admit. The values of the elite in this country, at least at the moment, are<br/>NPR values. The average person, as I think both Republicans and Democrats<br/>would agree, is more socially conservative. But while some openly flaunt the<br/>fact that they don't share the opinions of the elite, others feel a little<br/>nervous about it, as if they had bad table manners.  <br/>  <br/>For example, according to current NPR values, you can't say anything that<br/>might be perceived as disparaging towards homosexuals. To do so is<br/>"homophobic." And yet a large number of Americans are deeply religious, and<br/>the Bible is quite explicit on the subject of homosexuality. What are they to<br/>do? I think what many do is keep their opinions, but keep them to themselves.  <br/>  <br/>They know what they believe, but they also know what they're supposed to<br/>believe. And so when a stranger (for example, a pollster) asks them their<br/>opinion about something like gay marriage, they will not always say what they<br/>really think.  <br/>  <br/>When the values of the elite are liberal, polls will tend to underestimate the<br/>conservativeness of ordinary voters. This seems to me the leading theory to<br/>explain why the exit polls were so far off this year. NPR values said one<br/>ought to vote for Kerry. So all the people who voted for Kerry felt virtuous<br/>for doing so, and were eager to tell pollsters they had. No one who voted for<br/>Kerry did it as an act of quiet defiance.  <br/>  <br/>  <br/>  <br/>  <br/><br/>Support for a Woman President  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>February 2015  <br/>  <br/>One of the most valuable exercises you can try if you want to understand<br/>startups is to look at the most successful companies and explain why they were<br/>not as lame as they seemed when they first launched. Because they practically<br/>all seemed lame at first. Not just small, lame. Not just the first step up a<br/>big mountain. More like the first step into a swamp.  <br/>  <br/>A Basic interpreter for the Altair? How could that ever grow into a giant<br/>company? People sleeping on airbeds in strangers' apartments? A web site for<br/>college students to stalk one another? A wimpy little single-board computer<br/>for hobbyists that used a TV as a monitor? A new search engine, when there<br/>were already about 10, and they were all trying to de-emphasize search? These<br/>ideas didn't just seem small. They seemed wrong. They were the kind of ideas<br/>you could not merely ignore, but ridicule.  <br/>  <br/>Often the founders themselves didn't know why their ideas were promising. They<br/>were attracted to these ideas by instinct, because they were living in the<br/>future and they sensed that something was missing. But they could not have put<br/>into words exactly how their ugly ducklings were going to grow into big,<br/>beautiful swans.  <br/>  <br/>Most people's first impulse when they hear about a lame-sounding new startup<br/>idea is to make fun of it. Even a lot of people who should know better.  <br/>  <br/>When I encounter a startup with a lame-sounding idea, I ask "What Microsoft is<br/>this the Altair Basic of?" Now it's a puzzle, and the burden is on me to solve<br/>it. Sometimes I can't think of an answer, especially when the idea is a made-<br/>up one. But it's remarkable how often there does turn out to be an answer.<br/>Often it's one the founders themselves hadn't seen yet.  <br/>  <br/>Intriguingly, there are sometimes multiple answers. I talked to a startup a<br/>few days ago that could grow into 3 distinct Microsofts. They'd probably vary<br/>in size by orders of magnitude. But you can never predict how big a Microsoft<br/>is going to be, so in cases like that I encourage founders to follow whichever<br/>path is most immediately exciting to them. Their instincts got them this far.<br/>Why stop now?  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>November 2004  <br/>  <br/> _(This is a new essay for the Japanese edition ofHackers & Painters. It tries<br/>to explain why Americans make some things well and others badly.)_  <br/>  <br/>A few years ago an Italian friend of mine travelled by train from Boston to<br/>Providence. She had only been in America for a couple weeks and hadn't seen<br/>much of the country yet. She arrived looking astonished. "It's so _ugly!"_  <br/>  <br/>People from other rich countries can scarcely imagine the squalor of the man-<br/>made bits of America. In travel books they show you mostly natural<br/>environments: the Grand Canyon, whitewater rafting, horses in a field. If you<br/>see pictures with man-made things in them, it will be either a view of the New<br/>York skyline shot from a discreet distance, or a carefully cropped image of a<br/>seacoast town in Maine.  <br/>  <br/>How can it be, visitors must wonder. How can the richest country in the world<br/>look like this?  <br/>  <br/>Oddly enough, it may not be a coincidence. Americans are good at some things<br/>and bad at others. We're good at making movies and software, and bad at making<br/>cars and cities. And I think we may be good at what we're good at for the same<br/>reason we're bad at what we're bad at. We're impatient. In America, if you<br/>want to do something, you don't worry that it might come out badly, or upset<br/>delicate social balances, or that people might think you're getting above<br/>yourself. If you want to do something, as Nike says, _just do it._  <br/>  <br/>  <br/>  <br/>This works well in some fields and badly in others. I suspect it works in<br/>movies and software because they're both messy processes. "Systematic" is the<br/>last word I'd use to describe the way good programmers write software. Code is<br/>not something they assemble painstakingly after careful planning, like the<br/>pyramids. It's something they plunge into, working fast and constantly<br/>changing their minds, like a charcoal sketch.  <br/>  <br/>In software, paradoxical as it sounds, good craftsmanship means working fast.<br/>If you work slowly and meticulously, you merely end up with a very fine<br/>implementation of your initial, mistaken idea. Working slowly and meticulously<br/>is premature optimization. Better to get a prototype done fast, and see what<br/>new ideas it gives you.  <br/>  <br/>It sounds like making movies works a lot like making software. Every movie is<br/>a Frankenstein, full of imperfections and usually quite different from what<br/>was originally envisioned. But interesting, and finished fairly quickly.  <br/>  <br/>I think we get away with this in movies and software because they're both<br/>malleable mediums. Boldness pays.  And if at the last minute two parts don't<br/>quite fit, you can figure out some hack that will at least conceal the<br/>problem.  <br/>  <br/>Not so with cars, or cities. They are all too physical. If the car business<br/>worked like software or movies, you'd surpass your competitors by making a car<br/>that weighed only fifty pounds, or folded up to the size of a motorcycle when<br/>you wanted to park it. But with physical products there are more constraints.<br/>You don't win by dramatic innovations so much as by good taste and attention<br/>to detail.  <br/>  <br/>The trouble is, the very word "taste" sounds slightly ridiculous to American<br/>ears. It seems pretentious, or frivolous, or even effeminate. Blue staters<br/>think it's "subjective," and red staters think it's for sissies. So anyone in<br/>America who really cares about design will be sailing upwind.  <br/>  <br/>  <br/>  <br/>Twenty years ago we used to hear that the problem with the US car industry was<br/>the workers. We don't hear that any more now that Japanese companies are<br/>building cars in the US. The problem with American cars is bad design. You can<br/>see that just by looking at them.  <br/>  <br/>All that extra sheet metal on the AMC Matador wasn't added by the workers. The<br/>problem with this car, as with American cars today, is that it was designed by<br/>marketing people instead of designers.  <br/>  <br/>Why do the Japanese make better cars than us? Some say it's because their<br/>culture encourages cooperation. That may come into it. But in this case it<br/>seems more to the point that their culture prizes design and craftsmanship.  <br/>  <br/>For centuries the Japanese have made finer things than we have in the West.<br/>When you look at swords they made in 1200, you just can't believe the date on<br/>the label is right. Presumably their cars fit together more precisely than<br/>ours for the same reason their joinery always has. They're obsessed with<br/>making things well.  <br/>  <br/>Not us. When we make something in America, our aim is just to get the job<br/>done. Once we reach that point, we take one of two routes. We can stop there,<br/>and have something crude but serviceable, like a Vise-grip. Or we can improve<br/>it, which usually means encrusting it with gratuitous ornament. When we want<br/>to make a car "better," we stick tail fins on it, or make it longer, or make<br/>the windows smaller, depending on the current fashion.  <br/>  <br/>Ditto for houses. In America you can have either a flimsy box banged together<br/>out of two by fours and drywall, or a McMansion-- a flimsy box banged together<br/>out of two by fours and drywall, but larger, more dramatic-looking, and full<br/>of expensive fittings. Rich people don't get better design or craftsmanship;<br/>they just get a larger, more conspicuous version of the standard house.  <br/>  <br/>We don't especially prize design or craftsmanship here. What we like is speed,<br/>and we're willing to do something in an ugly way to get it done fast. In some<br/>fields, like software or movies, this is a net win.  <br/>  <br/>But it's not just that software and movies are malleable mediums. In those<br/>businesses, the designers (though they're not generally called that) have more<br/>power. Software companies, at least successful ones, tend to be run by<br/>programmers. And in the film industry, though producers may second-guess<br/>directors, the director controls most of what appears on the screen. And so<br/>American software and movies, and Japanese cars, all have this in common: the<br/>people in charge care about design-- the former because the designers are in<br/>charge, and the latter because the whole culture cares about design.  <br/>  <br/>I think most Japanese executives would be horrified at the idea of making a<br/>bad car. Whereas American executives, in their hearts, still believe the most<br/>important thing about a car is the image it projects. Make a good car? What's<br/>"good?" It's so _subjective._ If you want to know how to design a car, ask a<br/>focus group.  <br/>  <br/>Instead of relying on their own internal design compass (like Henry Ford did),<br/>American car companies try to make what marketing people think consumers want.<br/>But it isn't working. American cars continue to lose market share. And the<br/>reason is that the customer doesn't want what he thinks he wants.  <br/>  <br/>Letting focus groups design your cars for you only wins in the short term. In<br/>the long term, it pays to bet on good design. The focus group may say they<br/>want the meretricious feature du jour, but what they want even more is to<br/>imitate sophisticated buyers, and they, though a small minority, really do<br/>care about good design. Eventually the pimps and drug dealers notice that the<br/>doctors and lawyers have switched from Cadillac to Lexus, and do the same.  <br/>  <br/>Apple is an interesting counterexample to the general American trend. If you<br/>want to buy a nice CD player, you'll probably buy a Japanese one. But if you<br/>want to buy an MP3 player, you'll probably buy an iPod. What happened? Why<br/>doesn't Sony dominate MP3 players? Because Apple is in the consumer<br/>electronics business now, and unlike other American companies, they're<br/>obsessed with good design. Or more precisely, their CEO is.  <br/>  <br/>I just got an iPod, and it's not just nice. It's _surprisingly_ nice. For it<br/>to surprise me, it must be satisfying expectations I didn't know I had. No<br/>focus group is going to discover those. Only a great designer can.  <br/>  <br/>  <br/>  <br/>Cars aren't the worst thing we make in America. Where the just-do-it model<br/>fails most dramatically is in our cities-- or rather, exurbs. If real estate<br/>developers operated on a large enough scale, if they built whole towns, market<br/>forces would compel them to build towns that didn't suck. But they only build<br/>a couple office buildings or suburban streets at a time, and the result is so<br/>depressing that the inhabitants consider it a great treat to fly to Europe and<br/>spend a couple weeks living what is, for people there, just everyday life. [1]  <br/>  <br/>But the just-do-it model does have advantages. It seems the clear winner for<br/>generating wealth and technical innovations (which are practically the same<br/>thing). I think speed is the reason. It's hard to create wealth by making a<br/>commodity. The real value is in things that are new, and if you want to be the<br/>first to make something, it helps to work fast. For better or worse, the just-<br/>do-it model is fast, whether you're Dan Bricklin writing the prototype of<br/>VisiCalc in a weekend, or a real estate developer building a block of shoddy<br/>condos in a month.  <br/>  <br/>If I had to choose between the just-do-it model and the careful model, I'd<br/>probably choose just-do-it. But do we have to choose? Could we have it both<br/>ways? Could Americans have nice places to live without undermining the<br/>impatient, individualistic spirit that makes us good at software? Could other<br/>countries introduce more individualism into their technology companies and<br/>research labs without having it metastasize as strip malls? I'm optimistic.<br/>It's harder to say about other countries, but in the US, at least, I think we<br/>can have both.  <br/>  <br/>Apple is an encouraging example. They've managed to preserve enough of the<br/>impatient, hackerly spirit you need to write software. And yet when you pick<br/>up a new Apple laptop, well, it doesn't seem American. It's too perfect. It<br/>seems as if it must have been made by a Swedish or a Japanese company.  <br/>  <br/>In many technologies, version 2 has higher resolution. Why not in design<br/>generally? I think we'll gradually see national characters superseded by<br/>occupational characters: hackers in Japan will be allowed to behave with a<br/>willfulness that would now seem unJapanese, and products in America will be<br/>designed with an insistence on taste that would now seem unAmerican. Perhaps<br/>the most successful countries, in the future, will be those most willing to<br/>ignore what are now considered national characters, and do each kind of work<br/>in the way that works best. Race you.  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Japanese cities are ugly too, but for different reasons. Japan is prone to<br/>earthquakes, so buildings are traditionally seen as temporary; there is no<br/>grand tradition of city planning like the one Europeans inherited from Rome.<br/>The other cause is the notoriously corrupt relationship between the government<br/>and construction companies.  <br/>  <br/> **Thanks** to Trevor Blackwell, Barry Eisler, Sarah Harlin, Shiro Kawai,<br/>Jessica Livingston, Jackie McDonough, Robert Morris, and Eric Raymond for<br/>reading drafts of this.  <br/>  <br/>  <br/><br/>American Gothic  <br/>  <br/><br/>The John Rain Books  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>October 2008  <br/>  <br/>The economic situation is apparently so grim that some experts fear we may be<br/>in for a stretch as bad as the mid seventies.  <br/>  <br/>When Microsoft and Apple were founded.  <br/>  <br/>As those examples suggest, a recession may not be such a bad time to start a<br/>startup. I'm not claiming it's a particularly good time either. The truth is<br/>more boring: the state of the economy doesn't matter much either way.  <br/>  <br/>If we've learned one thing from funding so many startups, it's that they<br/>succeed or fail based on the qualities of the founders. The economy has some<br/>effect, certainly, but as a predictor of success it's rounding error compared<br/>to the founders.  <br/>  <br/>Which means that what matters is who you are, not when you do it. If you're<br/>the right sort of person, you'll win even in a bad economy. And if you're not,<br/>a good economy won't save you. Someone who thinks "I better not start a<br/>startup now, because the economy is so bad" is making the same mistake as the<br/>people who thought during the Bubble "all I have to do is start a startup, and<br/>I'll be rich."  <br/>  <br/>So if you want to improve your chances, you should think far more about who<br/>you can recruit as a cofounder than the state of the economy. And if you're<br/>worried about threats to the survival of your company, don't look for them in<br/>the news. Look in the mirror.  <br/>  <br/>But for any given team of founders, would it not pay to wait till the economy<br/>is better before taking the leap? If you're starting a restaurant, maybe, but<br/>not if you're working on technology. Technology progresses more or less<br/>independently of the stock market. So for any given idea, the payoff for<br/>acting fast in a bad economy will be higher than for waiting. Microsoft's<br/>first product was a Basic interpreter for the Altair. That was exactly what<br/>the world needed in 1975, but if Gates and Allen had decided to wait a few<br/>years, it would have been too late.  <br/>  <br/>Of course, the idea you have now won't be the last you have. There are always<br/>new ideas. But if you have a specific idea you want to act on, act now.  <br/>  <br/>That doesn't mean you can ignore the economy. Both customers and investors<br/>will be feeling pinched. It's not necessarily a problem if customers feel<br/>pinched: you may even be able to benefit from it, by making things that save<br/>money. Startups often make things cheaper, so in that respect they're better<br/>positioned to prosper in a recession than big companies.  <br/>  <br/>Investors are more of a problem. Startups generally need to raise some amount<br/>of external funding, and investors tend to be less willing to invest in bad<br/>times. They shouldn't be. Everyone knows you're supposed to buy when times are<br/>bad and sell when times are good. But of course what makes investing so<br/>counterintuitive is that in equity markets, good times are defined as everyone<br/>thinking it's time to buy. You have to be a contrarian to be correct, and by<br/>definition only a minority of investors can be.  <br/>  <br/>So just as investors in 1999 were tripping over one another trying to buy into<br/>lousy startups, investors in 2009 will presumably be reluctant to invest even<br/>in good ones.  <br/>  <br/>You'll have to adapt to this. But that's nothing new: startups always have to<br/>adapt to the whims of investors. Ask any founder in any economy if they'd<br/>describe investors as fickle, and watch the face they make. Last year you had<br/>to be prepared to explain how your startup was viral. Next year you'll have to<br/>explain how it's recession-proof.  <br/>  <br/>(Those are both good things to be. The mistake investors make is not the<br/>criteria they use but that they always tend to focus on one to the exclusion<br/>of the rest.)  <br/>  <br/>Fortunately the way to make a startup recession-proof is to do exactly what<br/>you should do anyway: run it as cheaply as possible. For years I've been<br/>telling founders that the surest route to success is to be the cockroaches of<br/>the corporate world. The immediate cause of death in a startup is always<br/>running out of money. So the cheaper your company is to operate, the harder it<br/>is to kill. And fortunately it has gotten very cheap to run a startup. A<br/>recession will if anything make it cheaper still.  <br/>  <br/>If nuclear winter really is here, it may be safer to be a cockroach even than<br/>to keep your job. Customers may drop off individually if they can no longer<br/>afford you, but you're not going to lose them all at once; markets don't<br/>"reduce headcount."  <br/>  <br/>What if you quit your job to start a startup that fails, and you can't find<br/>another? That could be a problem if you work in sales or marketing. In those<br/>fields it can take months to find a new job in a bad economy. But hackers seem<br/>to be more liquid. Good hackers can always get some kind of job. It might not<br/>be your dream job, but you're not going to starve.  <br/>  <br/>Another advantage of bad times is that there's less competition. Technology<br/>trains leave the station at regular intervals. If everyone else is cowering in<br/>a corner, you may have a whole car to yourself.  <br/>  <br/>You're an investor too. As a founder, you're buying stock with work: the<br/>reason Larry and Sergey are so rich is not so much that they've done work<br/>worth tens of billions of dollars, but that they were the first investors in<br/>Google. And like any investor you should buy when times are bad.  <br/>  <br/>Were you nodding in agreement, thinking "stupid investors" a few paragraphs<br/>ago when I was talking about how investors are reluctant to put money into<br/>startups in bad markets, even though that's the time they should rationally be<br/>most willing to buy? Well, founders aren't much better. When times get bad,<br/>hackers go to grad school. And no doubt that will happen this time too. In<br/>fact, what makes the preceding paragraph true is that most readers won't<br/>believe it—at least to the extent of acting on it.  <br/>  <br/>So maybe a recession is a good time to start a startup. It's hard to say<br/>whether advantages like lack of competition outweigh disadvantages like<br/>reluctant investors. But it doesn't matter much either way. It's the people<br/>that matter. And for a given set of people working on a given technology, the<br/>time to act is always now.  <br/>  <br/><br/>Russian Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>September 2009  <br/>  <br/>Publishers of all types, from news to music, are unhappy that consumers won't<br/>pay for content anymore. At least, that's how they see it.  <br/>  <br/>In fact consumers never really were paying for content, and publishers weren't<br/>really selling it either. If the content was what they were selling, why has<br/>the price of books or music or movies always depended mostly on the format?<br/>Why didn't better content cost more? [1]  <br/>  <br/>A copy of _Time_ costs $5 for 58 pages, or 8.6 cents a page. _The Economist_<br/>costs $7 for 86 pages, or 8.1 cents a page. Better journalism is actually<br/>slightly cheaper.  <br/>  <br/>Almost every form of publishing has been organized as if the medium was what<br/>they were selling, and the content was irrelevant. Book publishers, for<br/>example, set prices based on the cost of producing and distributing books.<br/>They treat the words printed in the book the same way a textile manufacturer<br/>treats the patterns printed on its fabrics.  <br/>  <br/>Economically, the print media are in the business of marking up paper. We can<br/>all imagine an old-style editor getting a scoop and saying "this will sell a<br/>lot of papers!" Cross out that final S and you're describing their business<br/>model. The reason they make less money now is that people don't need as much<br/>paper.  <br/>  <br/>A few months ago I ran into a friend in a cafe. I had a copy of the _New York<br/>Times_ , which I still occasionally buy on weekends. As I was leaving I<br/>offered it to him, as I've done countless times before in the same situation.<br/>But this time something new happened. I felt that sheepish feeling you get<br/>when you offer someone something worthless. "Do you, er, want a printout of<br/>yesterday's news?" I asked. (He didn't.)  <br/>  <br/>Now that the medium is evaporating, publishers have nothing left to sell. Some<br/>seem to think they're going to sell content—that they were always in the<br/>content business, really. But they weren't, and it's unclear whether anyone<br/>could be.  <br/>  <br/> **Selling**  <br/>  <br/>There have always been people in the business of selling information, but that<br/>has historically been a distinct business from publishing. And the business of<br/>selling information to consumers has always been a marginal one. When I was a<br/>kid there were people who used to sell newsletters containing stock tips,<br/>printed on colored paper that made them hard for the copiers of the day to<br/>reproduce. That is a different world, both culturally and economically, from<br/>the one publishers currently inhabit.  <br/>  <br/>People will pay for information they think they can make money from. That's<br/>why they paid for those stock tip newsletters, and why companies pay now for<br/>Bloomberg terminals and Economist Intelligence Unit reports. But will people<br/>pay for information otherwise? History offers little encouragement.  <br/>  <br/>If audiences were willing to pay more for better content, why wasn't anyone<br/>already selling it to them? There was no reason you couldn't have done that in<br/>the era of physical media. So were the print media and the music labels simply<br/>overlooking this opportunity? Or is it, rather, nonexistent?  <br/>  <br/>What about iTunes? Doesn't that show people will pay for content? Well, not<br/>really. iTunes is more of a tollbooth than a store. Apple controls the default<br/>path onto the iPod. They offer a convenient list of songs, and whenever you<br/>choose one they ding your credit card for a small amount, just below the<br/>threshold of attention. Basically, iTunes makes money by taxing people, not<br/>selling them stuff. You can only do that if you own the channel, and even then<br/>you don't make much from it, because a toll has to be ignorable to work. Once<br/>a toll becomes painful, people start to find ways around it, and that's pretty<br/>easy with digital content.  <br/>  <br/>The situation is much the same with digital books. Whoever controls the device<br/>sets the terms. It's in their interest for content to be as cheap as possible,<br/>and since they own the channel, there's a lot they can do to drive prices<br/>down. Prices will fall even further once writers realize they don't need<br/>publishers. Getting a book printed and distributed is a daunting prospect for<br/>a writer, but most can upload a file.  <br/>  <br/>Is software a counterexample? People pay a lot for desktop software, and<br/>that's just information. True, but I don't think publishers can learn much<br/>from software. Software companies can charge a lot because (a) many of the<br/>customers are businesses, who get in trouble if they use pirated versions, and<br/>(b) though in form merely information, software is treated by both maker and<br/>purchaser as a different type of thing from a song or an article. A Photoshop<br/>user needs Photoshop in a way that no one needs a particular song or article.  <br/>  <br/>That's why there's a separate word, "content," for information that's not<br/>software. Software is a different business. Software and content blur together<br/>in some of the most lightweight software, like casual games. But those are<br/>usually free. To make money the way software companies do, publishers would<br/>have to become software companies, and being publishers gives them no<br/>particular head start in that domain. [2]  <br/>  <br/>The most promising countertrend is the premium cable channel. People still pay<br/>for those. But broadcasting isn't publishing: you're not selling a copy of<br/>something. That's one reason the movie business hasn't seen their revenues<br/>decline the way the news and music businesses have. They only have one foot in<br/>publishing.  <br/>  <br/>To the extent the movie business can avoid becoming publishers, they may avoid<br/>publishing's problems. But there are limits to how well they'll be able to do<br/>that. Once publishing—giving people copies—becomes the most natural way of<br/>distributing your content, it probably doesn't work to stick to old forms of<br/>distribution just because you make more that way. If free copies of your<br/>content are available online, then you're competing with publishing's form of<br/>distribution, and that's just as bad as being a publisher.  <br/>  <br/>Apparently some people in the music business hope to retroactively convert it<br/>away from publishing, by getting listeners to pay for subscriptions. It seems<br/>unlikely that will work if they're just streaming the same files you can get<br/>as mp3s.  <br/>  <br/> **Next**  <br/>  <br/>What happens to publishing if you can't sell content? You have two choices:<br/>give it away and make money from it indirectly, or find ways to embody it in<br/>things people will pay for.  <br/>  <br/>The first is probably the future of most current media. Give music away and<br/>make money from concerts and t-shirts. Publish articles for free and make<br/>money from one of a dozen permutations of advertising. Both publishers and<br/>investors are down on advertising at the moment, but it has more potential<br/>than they realize.  <br/>  <br/>I'm not claiming that potential will be realized by the existing players. The<br/>optimal ways to make money from the written word probably require different<br/>words written by different people.  <br/>  <br/>It's harder to say what will happen to movies. They could evolve into ads. Or<br/>they could return to their roots and make going to the theater a treat. If<br/>they made the experience good enough, audiences might start to prefer it to<br/>watching pirated movies at home. [3] Or maybe the movie business will dry up,<br/>and the people working in it will go to work for game developers.  <br/>  <br/>I don't know how big embodying information in physical form will be. It may be<br/>surprisingly large; people overvalue physical stuff. There should remain some<br/>market for printed books, at least.  <br/>  <br/>I can see the evolution of book publishing in the books on my shelves. Clearly<br/>at some point in the 1960s the big publishing houses started to ask: how<br/>cheaply can we make books before people refuse to buy them? The answer turned<br/>out to be one step short of phonebooks. As long as it isn't floppy, consumers<br/>still perceive it as a book.  <br/>  <br/>That worked as long as buying printed books was the only way to read them. If<br/>printed books are optional, publishers will have to work harder to entice<br/>people to buy them. There should be some market, but it's hard to foresee how<br/>big, because its size will depend not on macro trends like the amount people<br/>read, but on the ingenuity of individual publishers. [4]  <br/>  <br/>Some magazines may thrive by focusing on the magazine as a physical object.<br/>Fashion magazines could be made lush in a way that would be hard to match<br/>digitally, at least for a while. But this is probably not an option for most<br/>magazines.  <br/>  <br/>I don't know exactly what the future will look like, but I'm not too worried<br/>about it. This sort of change tends to create as many good things as it kills.<br/>Indeed, the really interesting question is not what will happen to existing<br/>forms, but what new forms will appear.  <br/>  <br/>The reason I've been writing about existing forms is that I don't _know_ what<br/>new forms will appear. But though I can't predict specific winners, I can<br/>offer a recipe for recognizing them. When you see something that's taking<br/>advantage of new technology to give people something they want that they<br/>couldn't have before, you're probably looking at a winner. And when you see<br/>something that's merely reacting to new technology in an attempt to preserve<br/>some existing source of revenue, you're probably looking at a loser.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] I don't like the word "content" and tried for a while to avoid using it,<br/>but I have to admit there's no other word that means the right thing.<br/>"Information" is too general.  <br/>  <br/>Ironically, the main reason I don't like "content" is the thesis of this<br/>essay. The word suggests an undifferentiated slurry, but economically that's<br/>how both publishers and audiences treat it. Content is information you don't<br/>need.  <br/>  <br/>[2] Some types of publishers would be at a disadvantage trying to enter the<br/>software business. Record labels, for example, would probably find it more<br/>natural to expand into casinos than software, because the kind of people who<br/>run them would be more at home at the mafia end of the business spectrum than<br/>the don't-be-evil end.  <br/>  <br/>[3] I never watch movies in theaters anymore. The tipping point for me was the<br/>ads they show first.  <br/>  <br/>[4] Unfortunately, making physically nice books will only be a niche within a<br/>niche. Publishers are more likely to resort to expedients like selling<br/>autographed copies, or editions with the buyer's picture on the cover.  <br/>  <br/> **Thanks** to Michael Arrington, Trevor Blackwell, Steven Levy, Robert<br/>Morris, and Geoff Ralston for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>September 2001  <br/>  <br/> _(This article explains why much of the next generation of software may be<br/>server-based, what that will mean for programmers, and why this new kind of<br/>software is a great opportunity for startups. It's derived from a talk at BBN<br/>Labs.)_  <br/>  <br/>In the summer of 1995, my friend Robert Morris and I decided to start a<br/>startup. The PR campaign leading up to Netscape's IPO was running full blast<br/>then, and there was a lot of talk in the press about online commerce. At the<br/>time there might have been thirty actual stores on the Web, all made by hand.<br/>If there were going to be a lot of online stores, there would need to be<br/>software for making them, so we decided to write some.  <br/>  <br/>For the first week or so we intended to make this an ordinary desktop<br/>application. Then one day we had the idea of making the software run on our<br/>Web server, using the browser as an interface. We tried rewriting the software<br/>to work over the Web, and it was clear that this was the way to go. If we<br/>wrote our software to run on the server, it would be a lot easier for the<br/>users and for us as well.  <br/>  <br/>This turned out to be a good plan. Now, as Yahoo Store, this software is the<br/>most popular online store builder, with about 14,000 users.  <br/>  <br/>When we started Viaweb, hardly anyone understood what we meant when we said<br/>that the software ran on the server. It was not until Hotmail was launched a<br/>year later that people started to get it. Now everyone knows that this is a<br/>valid approach. There is a name now for what we were: an Application Service<br/>Provider, or ASP.  <br/>  <br/>I think that a lot of the next generation of software will be written on this<br/>model. Even Microsoft, who have the most to lose, seem to see the inevitablity<br/>of moving some things off the desktop. If software moves off the desktop and<br/>onto servers, it will mean a very different world for developers. This article<br/>describes the surprising things we saw, as some of the first visitors to this<br/>new world. To the extent software does move onto servers, what I'm describing<br/>here is the future.  <br/>  <br/> **The Next Thing?**  <br/>  <br/>When we look back on the desktop software era, I think we'll marvel at the<br/>inconveniences people put up with, just as we marvel now at what early car<br/>owners put up with. For the first twenty or thirty years, you had to be a car<br/>expert to own a car. But cars were such a big win that lots of people who<br/>weren't car experts wanted to have them as well.  <br/>  <br/>Computers are in this phase now. When you own a desktop computer, you end up<br/>learning a lot more than you wanted to know about what's happening inside it.<br/>But more than half the households in the US own one. My mother has a computer<br/>that she uses for email and for keeping accounts. About a year ago she was<br/>alarmed to receive a letter from Apple, offering her a discount on a new<br/>version of the operating system. There's something wrong when a sixty-five<br/>year old woman who wants to use a computer for email and accounts has to think<br/>about installing new operating systems. Ordinary users shouldn't even know the<br/>words "operating system," much less "device driver" or "patch."  <br/>  <br/>There is now another way to deliver software that will save users from<br/>becoming system administrators. Web-based applications are programs that run<br/>on Web servers and use Web pages as the user interface. For the average user<br/>this new kind of software will be easier, cheaper, more mobile, more reliable,<br/>and often more powerful than desktop software.  <br/>  <br/>With Web-based software, most users won't have to think about anything except<br/>the applications they use. All the messy, changing stuff will be sitting on a<br/>server somewhere, maintained by the kind of people who are good at that kind<br/>of thing. And so you won't ordinarily need a computer, per se, to use<br/>software. All you'll need will be something with a keyboard, a screen, and a<br/>Web browser. Maybe it will have wireless Internet access. Maybe it will also<br/>be your cell phone. Whatever it is, it will be consumer electronics: something<br/>that costs about $200, and that people choose mostly based on how the case<br/>looks. You'll pay more for Internet services than you do for the hardware,<br/>just as you do now with telephones. [1]  <br/>  <br/>It will take about a tenth of a second for a click to get to the server and<br/>back, so users of heavily interactive software, like Photoshop, will still<br/>want to have the computations happening on the desktop. But if you look at the<br/>kind of things most people use computers for, a tenth of a second latency<br/>would not be a problem. My mother doesn't really need a desktop computer, and<br/>there are a lot of people like her.  <br/>  <br/> **The Win for Users**  <br/>  <br/>Near my house there is a car with a bumper sticker that reads "death before<br/>inconvenience." Most people, most of the time, will take whatever choice<br/>requires least work. If Web-based software wins, it will be because it's more<br/>convenient. And it looks as if it will be, for users and developers both.  <br/>  <br/>To use a purely Web-based application, all you need is a browser connected to<br/>the Internet. So you can use a Web-based application anywhere. When you<br/>install software on your desktop computer, you can only use it on that<br/>computer. Worse still, your files are trapped on that computer. The<br/>inconvenience of this model becomes more and more evident as people get used<br/>to networks.  <br/>  <br/>The thin end of the wedge here was Web-based email. Millions of people now<br/>realize that you should have access to email messages no matter where you are.<br/>And if you can see your email, why not your calendar? If you can discuss a<br/>document with your colleagues, why can't you edit it? Why should any of your<br/>data be trapped on some computer sitting on a faraway desk?  <br/>  <br/>The whole idea of "your computer" is going away, and being replaced with "your<br/>data." You should be able to get at your data from any computer. Or rather,<br/>any client, and a client doesn't have to be a computer.  <br/>  <br/>Clients shouldn't store data; they should be like telephones. In fact they may<br/>become telephones, or vice versa. And as clients get smaller, you have another<br/>reason not to keep your data on them: something you carry around with you can<br/>be lost or stolen. Leaving your PDA in a taxi is like a disk crash, except<br/>that your data is handed to someone else instead of being vaporized.  <br/>  <br/>With purely Web-based software, neither your data nor the applications are<br/>kept on the client. So you don't have to install anything to use it. And when<br/>there's no installation, you don't have to worry about installation going<br/>wrong. There can't be incompatibilities between the application and your<br/>operating system, because the software doesn't run on your operating system.  <br/>  <br/>Because it needs no installation, it will be easy, and common, to try Web-<br/>based software before you "buy" it. You should expect to be able to test-drive<br/>any Web-based application for free, just by going to the site where it's<br/>offered. At Viaweb our whole site was like a big arrow pointing users to the<br/>test drive.  <br/>  <br/>After trying the demo, signing up for the service should require nothing more<br/>than filling out a brief form (the briefer the better). And that should be the<br/>last work the user has to do. With Web-based software, you should get new<br/>releases without paying extra, or doing any work, or possibly even knowing<br/>about it.  <br/>  <br/>Upgrades won't be the big shocks they are now. Over time applications will<br/>quietly grow more powerful. This will take some effort on the part of the<br/>developers. They will have to design software so that it can be updated<br/>without confusing the users. That's a new problem, but there are ways to solve<br/>it.  <br/>  <br/>With Web-based applications, everyone uses the same version, and bugs can be<br/>fixed as soon as they're discovered. So Web-based software should have far<br/>fewer bugs than desktop software. At Viaweb, I doubt we ever had ten known<br/>bugs at any one time. That's orders of magnitude better than desktop software.  <br/>  <br/>Web-based applications can be used by several people at the same time. This is<br/>an obvious win for collaborative applications, but I bet users will start to<br/>want this in most applications once they realize it's possible. It will often<br/>be useful to let two people edit the same document, for example. Viaweb let<br/>multiple users edit a site simultaneously, more because that was the right way<br/>to write the software than because we expected users to want to, but it turned<br/>out that many did.  <br/>  <br/>When you use a Web-based application, your data will be safer. Disk crashes<br/>won't be a thing of the past, but users won't hear about them anymore. They'll<br/>happen within server farms. And companies offering Web-based applications will<br/>actually do backups-- not only because they'll have real system administrators<br/>worrying about such things, but because an ASP that does lose people's data<br/>will be in big, big trouble. When people lose their own data in a disk crash,<br/>they can't get that mad, because they only have themselves to be mad at. When<br/>a company loses their data for them, they'll get a lot madder.  <br/>  <br/>Finally, Web-based software should be less vulnerable to viruses. If the<br/>client doesn't run anything except a browser, there's less chance of running<br/>viruses, and no data locally to damage. And a program that attacked the<br/>servers themselves should find them very well defended. [2]  <br/>  <br/>For users, Web-based software will be _less stressful._ I think if you looked<br/>inside the average Windows user you'd find a huge and pretty much untapped<br/>desire for software meeting that description. Unleashed, it could be a<br/>powerful force.  <br/>  <br/> **City of Code**  <br/>  <br/>To developers, the most conspicuous difference between Web-based and desktop<br/>software is that a Web-based application is not a single piece of code. It<br/>will be a collection of programs of different types rather than a single big<br/>binary. And so designing Web-based software is like desiging a city rather<br/>than a building: as well as buildings you need roads, street signs, utilities,<br/>police and fire departments, and plans for both growth and various kinds of<br/>disasters.  <br/>  <br/>At Viaweb, software included fairly big applications that users talked to<br/>directly, programs that those programs used, programs that ran constantly in<br/>the background looking for problems, programs that tried to restart things if<br/>they broke, programs that ran occasionally to compile statistics or build<br/>indexes for searches, programs we ran explicitly to garbage-collect resources<br/>or to move or restore data, programs that pretended to be users (to measure<br/>performance or expose bugs), programs for diagnosing network troubles,<br/>programs for doing backups, interfaces to outside services, software that<br/>drove an impressive collection of dials displaying real-time server statistics<br/>(a hit with visitors, but indispensable for us too), modifications (including<br/>bug fixes) to open-source software, and a great many configuration files and<br/>settings. Trevor Blackwell wrote a spectacular program for moving stores to<br/>new servers across the country, without shutting them down, after we were<br/>bought by Yahoo. Programs paged us, sent faxes and email to users, conducted<br/>transactions with credit card processors, and talked to one another through<br/>sockets, pipes, http requests, ssh, udp packets, shared memory, and files.<br/>Some of Viaweb even consisted of the absence of programs, since one of the<br/>keys to Unix security is not to run unnecessary utilities that people might<br/>use to break into your servers.  <br/>  <br/>It did not end with software. We spent a lot of time thinking about server<br/>configurations. We built the servers ourselves, from components-- partly to<br/>save money, and partly to get exactly what we wanted. We had to think about<br/>whether our upstream ISP had fast enough connections to all the backbones. We<br/>serially dated RAID suppliers.  <br/>  <br/>But hardware is not just something to worry about. When you control it you can<br/>do more for users. With a desktop application, you can specify certain minimum<br/>hardware, but you can't add more. If you administer the servers, you can in<br/>one step enable all your users to page people, or send faxes, or send commands<br/>by phone, or process credit cards, etc, just by installing the relevant<br/>hardware. We always looked for new ways to add features with hardware, not<br/>just because it pleased users, but also as a way to distinguish ourselves from<br/>competitors who (either because they sold desktop software, or resold Web-<br/>based applications through ISPs) didn't have direct control over the hardware.  <br/>  <br/>Because the software in a Web-based application will be a collection of<br/>programs rather than a single binary, it can be written in any number of<br/>different languages. When you're writing desktop software, you're practically<br/>forced to write the application in the same language as the underlying<br/>operating system-- meaning C and C++. And so these languages (especially among<br/>nontechnical people like managers and VCs) got to be considered as the<br/>languages for "serious" software development. But that was just an artifact of<br/>the way desktop software had to be delivered. For server-based software you<br/>can use any language you want. [3] Today a lot of the top hackers are using<br/>languages far removed from C and C++: Perl, Python, and even Lisp.  <br/>  <br/>With server-based software, no one can tell you what language to use, because<br/>you control the whole system, right down to the hardware. Different languages<br/>are good for different tasks. You can use whichever is best for each. And when<br/>you have competitors, "you can" means "you must" (we'll return to this later),<br/>because if you don't take advantage of this possibility, your competitors<br/>will.  <br/>  <br/>Most of our competitors used C and C++, and this made their software visibly<br/>inferior because (among other things), they had no way around the<br/>statelessness of CGI scripts. If you were going to change something, all the<br/>changes had to happen on one page, with an Update button at the bottom. As<br/>I've written elsewhere, by using Lisp, which many people still consider a<br/>research language, we could make the Viaweb editor behave more like desktop<br/>software.  <br/>  <br/> **Releases**  <br/>  <br/>One of the most important changes in this new world is the way you do<br/>releases. In the desktop software business, doing a release is a huge trauma,<br/>in which the whole company sweats and strains to push out a single, giant<br/>piece of code. Obvious comparisons suggest themselves, both to the process and<br/>the resulting product.  <br/>  <br/>With server-based software, you can make changes almost as you would in a<br/>program you were writing for yourself. You release software as a series of<br/>incremental changes instead of an occasional big explosion. A typical desktop<br/>software company might do one or two releases a year. At Viaweb we often did<br/>three to five releases a day.  <br/>  <br/>When you switch to this new model, you realize how much software development<br/>is affected by the way it is released. Many of the nastiest problems you see<br/>in the desktop software business are due to catastrophic nature of releases.  <br/>  <br/>When you release only one new version a year, you tend to deal with bugs<br/>wholesale. Some time before the release date you assemble a new version in<br/>which half the code has been torn out and replaced, introducing countless<br/>bugs. Then a squad of QA people step in and start counting them, and the<br/>programmers work down the list, fixing them. They do not generally get to the<br/>end of the list, and indeed, no one is sure where the end is. It's like<br/>fishing rubble out of a pond. You never really know what's happening inside<br/>the software. At best you end up with a statistical sort of correctness.  <br/>  <br/>With server-based software, most of the change is small and incremental. That<br/>in itself is less likely to introduce bugs. It also means you know what to<br/>test most carefully when you're about to release software: the last thing you<br/>changed. You end up with a much firmer grip on the code. As a general rule,<br/>you do know what's happening inside it. You don't have the source code<br/>memorized, of course, but when you read the source you do it like a pilot<br/>scanning the instrument panel, not like a detective trying to unravel some<br/>mystery.  <br/>  <br/>Desktop software breeds a certain fatalism about bugs. You know that you're<br/>shipping something loaded with bugs, and you've even set up mechanisms to<br/>compensate for it (e.g. patch releases). So why worry about a few more? Soon<br/>you're releasing whole features you know are broken. Apple did this earlier<br/>this year. They felt under pressure to release their new OS, whose release<br/>date had already slipped four times, but some of the software (support for CDs<br/>and DVDs) wasn't ready. The solution? They released the OS without the<br/>unfinished parts, and users will have to install them later.  <br/>  <br/>With Web-based software, you never have to release software before it works,<br/>and you can release it as soon as it does work.  <br/>  <br/>The industry veteran may be thinking, it's a fine-sounding idea to say that<br/>you never have to release software before it works, but what happens when<br/>you've promised to deliver a new version of your software by a certain date?<br/>With Web-based software, you wouldn't make such a promise, because there are<br/>no versions. Your software changes gradually and continuously. Some changes<br/>might be bigger than others, but the idea of versions just doesn't naturally<br/>fit onto Web-based software.  <br/>  <br/>If anyone remembers Viaweb this might sound odd, because we were always<br/>announcing new versions. This was done entirely for PR purposes. The trade<br/>press, we learned, thinks in version numbers. They will give you major<br/>coverage for a major release, meaning a new first digit on the version number,<br/>and generally a paragraph at most for a point release, meaning a new digit<br/>after the decimal point.  <br/>  <br/>Some of our competitors were offering desktop software and actually had<br/>version numbers. And for these releases, the mere fact of which seemed to us<br/>evidence of their backwardness, they would get all kinds of publicity. We<br/>didn't want to miss out, so we started giving version numbers to our software<br/>too. When we wanted some publicity, we'd make a list of all the features we'd<br/>added since the last "release," stick a new version number on the software,<br/>and issue a press release saying that the new version was available<br/>immediately. Amazingly, no one ever called us on it.  <br/>  <br/>By the time we were bought, we had done this three times, so we were on<br/>Version 4. Version 4.1 if I remember correctly. After Viaweb became Yahoo<br/>Store, there was no longer such a desperate need for publicity, so although<br/>the software continued to evolve, the whole idea of version numbers was<br/>quietly dropped.  <br/>  <br/> **Bugs**  <br/>  <br/>The other major technical advantage of Web-based software is that you can<br/>reproduce most bugs. You have the users' data right there on your disk. If<br/>someone breaks your software, you don't have to try to guess what's going on,<br/>as you would with desktop software: you should be able to reproduce the error<br/>while they're on the phone with you. You might even know about it already, if<br/>you have code for noticing errors built into your application.  <br/>  <br/>Web-based software gets used round the clock, so everything you do is<br/>immediately put through the wringer. Bugs turn up quickly.  <br/>  <br/>Software companies are sometimes accused of letting the users debug their<br/>software. And that is just what I'm advocating. For Web-based software it's<br/>actually a good plan, because the bugs are fewer and transient. When you<br/>release software gradually you get far fewer bugs to start with. And when you<br/>can reproduce errors and release changes instantly, you can find and fix most<br/>bugs as soon as they appear. We never had enough bugs at any one time to<br/>bother with a formal bug-tracking system.  <br/>  <br/>You should test changes before you release them, of course, so no major bugs<br/>should get released. Those few that inevitably slip through will involve<br/>borderline cases and will only affect the few users that encounter them before<br/>someone calls in to complain. As long as you fix bugs right away, the net<br/>effect, for the average user, is far fewer bugs. I doubt the average Viaweb<br/>user ever saw a bug.  <br/>  <br/>Fixing fresh bugs is easier than fixing old ones. It's usually fairly quick to<br/>find a bug in code you just wrote. When it turns up you often know what's<br/>wrong before you even look at the source, because you were already worrying<br/>about it subconsciously. Fixing a bug in something you wrote six months ago<br/>(the average case if you release once a year) is a lot more work. And since<br/>you don't understand the code as well, you're more likely to fix it in an ugly<br/>way, or even introduce more bugs. [4]  <br/>  <br/>When you catch bugs early, you also get fewer compound bugs. Compound bugs are<br/>two separate bugs that interact: you trip going downstairs, and when you reach<br/>for the handrail it comes off in your hand. In software this kind of bug is<br/>the hardest to find, and also tends to have the worst consequences. [5] The<br/>traditional "break everything and then filter out the bugs" approach<br/>inherently yields a lot of compound bugs. And software that's released in a<br/>series of small changes inherently tends not to. The floors are constantly<br/>being swept clean of any loose objects that might later get stuck in<br/>something.  <br/>  <br/>It helps if you use a technique called functional programming. Functional<br/>programming means avoiding side-effects. It's something you're more likely to<br/>see in research papers than commercial software, but for Web-based<br/>applications it turns out to be really useful. It's hard to write entire<br/>programs as purely functional code, but you can write substantial chunks this<br/>way. It makes those parts of your software easier to test, because they have<br/>no state, and that is very convenient in a situation where you are constantly<br/>making and testing small modifications. I wrote much of Viaweb's editor in<br/>this style, and we made our scripting language, RTML, a purely functional<br/>language.  <br/>  <br/>People from the desktop software business will find this hard to credit, but<br/>at Viaweb bugs became almost a game. Since most released bugs involved<br/>borderline cases, the users who encountered them were likely to be advanced<br/>users, pushing the envelope. Advanced users are more forgiving about bugs,<br/>especially since you probably introduced them in the course of adding some<br/>feature they were asking for. In fact, because bugs were rare and you had to<br/>be doing sophisticated things to see them, advanced users were often proud to<br/>catch one. They would call support in a spirit more of triumph than anger, as<br/>if they had scored points off us.  <br/>  <br/> **Support**  <br/>  <br/>When you can reproduce errors, it changes your approach to customer support.<br/>At most software companies, support is offered as a way to make customers feel<br/>better. They're either calling you about a known bug, or they're just doing<br/>something wrong and you have to figure out what. In either case there's not<br/>much you can learn from them. And so you tend to view support calls as a pain<br/>in the ass that you want to isolate from your developers as much as possible.  <br/>  <br/>This was not how things worked at Viaweb. At Viaweb, support was free, because<br/>we wanted to hear from customers. If someone had a problem, we wanted to know<br/>about it right away so that we could reproduce the error and release a fix.  <br/>  <br/>So at Viaweb the developers were always in close contact with support. The<br/>customer support people were about thirty feet away from the programmers, and<br/>knew that they could always interrupt anything with a report of a genuine bug.<br/>We would leave a board meeting to fix a serious bug.  <br/>  <br/>Our approach to support made everyone happier. The customers were delighted.<br/>Just imagine how it would feel to call a support line and be treated as<br/>someone bringing important news. The customer support people liked it because<br/>it meant they could help the users, instead of reading scripts to them. And<br/>the programmers liked it because they could reproduce bugs instead of just<br/>hearing vague second-hand reports about them.  <br/>  <br/>Our policy of fixing bugs on the fly changed the relationship between customer<br/>support people and hackers. At most software companies, support people are<br/>underpaid human shields, and hackers are little copies of God the Father,<br/>creators of the world. Whatever the procedure for reporting bugs, it is likely<br/>to be one-directional: support people who hear about bugs fill out some form<br/>that eventually gets passed on (possibly via QA) to programmers, who put it on<br/>their list of things to do. It was very different at Viaweb. Within a minute<br/>of hearing about a bug from a customer, the support people could be standing<br/>next to a programmer hearing him say "Shit, you're right, it's a bug." It<br/>delighted the support people to hear that "you're right" from the hackers.<br/>They used to bring us bugs with the same expectant air as a cat bringing you a<br/>mouse it has just killed. It also made them more careful in judging the<br/>seriousness of a bug, because now their honor was on the line.  <br/>  <br/>After we were bought by Yahoo, the customer support people were moved far away<br/>from the programmers. It was only then that we realized that they were<br/>effectively QA and to some extent marketing as well. In addition to catching<br/>bugs, they were the keepers of the knowledge of vaguer, buglike things, like<br/>features that confused users. [6] They were also a kind of proxy focus group;<br/>we could ask them which of two new features users wanted more, and they were<br/>always right.  <br/>  <br/> **Morale**  <br/>  <br/>Being able to release software immediately is a big motivator. Often as I was<br/>walking to work I would think of some change I wanted to make to the software,<br/>and do it that day. This worked for bigger features as well. Even if something<br/>was going to take two weeks to write (few projects took longer), I knew I<br/>could see the effect in the software as soon as it was done.  <br/>  <br/>If I'd had to wait a year for the next release, I would have shelved most of<br/>these ideas, for a while at least. The thing about ideas, though, is that they<br/>lead to more ideas. Have you ever noticed that when you sit down to write<br/>something, half the ideas that end up in it are ones you thought of while<br/>writing it? The same thing happens with software. Working to implement one<br/>idea gives you more ideas. So shelving an idea costs you not only that delay<br/>in implementing it, but also all the ideas that implementing it would have led<br/>to. In fact, shelving an idea probably even inhibits new ideas: as you start<br/>to think of some new feature, you catch sight of the shelf and think "but I<br/>already have a lot of new things I want to do for the next release."  <br/>  <br/>What big companies do instead of implementing features is plan them. At Viaweb<br/>we sometimes ran into trouble on this account. Investors and analysts would<br/>ask us what we had planned for the future. The truthful answer would have<br/>been, we didn't have any plans. We had general ideas about things we wanted to<br/>improve, but if we knew how we would have done it already. What were we going<br/>to do in the next six months? Whatever looked like the biggest win. I don't<br/>know if I ever dared give this answer, but that was the truth. Plans are just<br/>another word for ideas on the shelf. When we thought of good ideas, we<br/>implemented them.  <br/>  <br/>At Viaweb, as at many software companies, most code had one definite owner.<br/>But when you owned something you really owned it: no one except the owner of a<br/>piece of software had to approve (or even know about) a release. There was no<br/>protection against breakage except the fear of looking like an idiot to one's<br/>peers, and that was more than enough. I may have given the impression that we<br/>just blithely plowed forward writing code. We did go fast, but we thought very<br/>carefully before we released software onto those servers. And paying attention<br/>is more important to reliability than moving slowly. Because he pays close<br/>attention, a Navy pilot can land a 40,000 lb. aircraft at 140 miles per hour<br/>on a pitching carrier deck, at night, more safely than the average teenager<br/>can cut a bagel.  <br/>  <br/>This way of writing software is a double-edged sword of course. It works a lot<br/>better for a small team of good, trusted programmers than it would for a big<br/>company of mediocre ones, where bad ideas are caught by committees instead of<br/>the people that had them.  <br/>  <br/> **Brooks in Reverse**  <br/>  <br/>Fortunately, Web-based software does require fewer programmers. I once worked<br/>for a medium-sized desktop software company that had over 100 people working<br/>in engineering as a whole. Only 13 of these were in product development. All<br/>the rest were working on releases, ports, and so on. With Web-based software,<br/>all you need (at most) are the 13 people, because there are no releases,<br/>ports, and so on.  <br/>  <br/>Viaweb was written by just three people. [7] I was always under pressure to<br/>hire more, because we wanted to get bought, and we knew that buyers would have<br/>a hard time paying a high price for a company with only three programmers.<br/>(Solution: we hired more, but created new projects for them.)  <br/>  <br/>When you can write software with fewer programmers, it saves you more than<br/>money. As Fred Brooks pointed out in _The Mythical Man-Month,_ adding people<br/>to a project tends to slow it down. The number of possible connections between<br/>developers grows exponentially with the size of the group. The larger the<br/>group, the more time they'll spend in meetings negotiating how their software<br/>will work together, and the more bugs they'll get from unforeseen<br/>interactions. Fortunately, this process also works in reverse: as groups get<br/>smaller, software development gets exponentially more efficient. I can't<br/>remember the programmers at Viaweb ever having an actual meeting. We never had<br/>more to say at any one time than we could say as we were walking to lunch.  <br/>  <br/>If there is a downside here, it is that all the programmers have to be to some<br/>degree system administrators as well. When you're hosting software, someone<br/>has to be watching the servers, and in practice the only people who can do<br/>this properly are the ones who wrote the software. At Viaweb our system had so<br/>many components and changed so frequently that there was no definite border<br/>between software and infrastructure. Arbitrarily declaring such a border would<br/>have constrained our design choices. And so although we were constantly hoping<br/>that one day ("in a couple months") everything would be stable enough that we<br/>could hire someone whose job was just to worry about the servers, it never<br/>happened.  <br/>  <br/>I don't think it could be any other way, as long as you're still actively<br/>developing the product. Web-based software is never going to be something you<br/>write, check in, and go home. It's a live thing, running on your servers right<br/>now. A bad bug might not just crash one user's process; it could crash them<br/>all. If a bug in your code corrupts some data on disk, you have to fix it. And<br/>so on. We found that you don't have to watch the servers every minute (after<br/>the first year or so), but you definitely want to keep an eye on things you've<br/>changed recently. You don't release code late at night and then go home.  <br/>  <br/> **Watching Users**  <br/>  <br/>With server-based software, you're in closer touch with your code. You can<br/>also be in closer touch with your users. Intuit is famous for introducing<br/>themselves to customers at retail stores and asking to follow them home. If<br/>you've ever watched someone use your software for the first time, you know<br/>what surprises must have awaited them.  <br/>  <br/>Software should do what users think it will. But you can't have any idea what<br/>users will be thinking, believe me, until you watch them. And server-based<br/>software gives you unprecedented information about their behavior. You're not<br/>limited to small, artificial focus groups. You can see every click made by<br/>every user. You have to consider carefully what you're going to look at,<br/>because you don't want to violate users' privacy, but even the most general<br/>statistical sampling can be very useful.  <br/>  <br/>When you have the users on your server, you don't have to rely on benchmarks,<br/>for example. Benchmarks are simulated users. With server-based software, you<br/>can watch actual users. To decide what to optimize, just log into a server and<br/>see what's consuming all the CPU. And you know when to stop optimizing too: we<br/>eventually got the Viaweb editor to the point where it was memory-bound rather<br/>than CPU-bound, and since there was nothing we could do to decrease the size<br/>of users' data (well, nothing easy), we knew we might as well stop there.  <br/>  <br/>Efficiency matters for server-based software, because you're paying for the<br/>hardware. The number of users you can support per server is the divisor of<br/>your capital cost, so if you can make your software very efficient you can<br/>undersell competitors and still make a profit. At Viaweb we got the capital<br/>cost per user down to about $5. It would be less now, probably less than the<br/>cost of sending them the first month's bill. Hardware is free now, if your<br/>software is reasonably efficient.  <br/>  <br/>Watching users can guide you in design as well as optimization. Viaweb had a<br/>scripting language called RTML that let advanced users define their own page<br/>styles. We found that RTML became a kind of suggestion box, because users only<br/>used it when the predefined page styles couldn't do what they wanted.<br/>Originally the editor put button bars across the page, for example, but after<br/>a number of users used RTML to put buttons down the left side, we made that an<br/>option (in fact the default) in the predefined page styles.  <br/>  <br/>Finally, by watching users you can often tell when they're in trouble. And<br/>since the customer is always right, that's a sign of something you need to<br/>fix. At Viaweb the key to getting users was the online test drive. It was not<br/>just a series of slides built by marketing people. In our test drive, users<br/>actually used the software. It took about five minutes, and at the end of it<br/>they had built a real, working store.  <br/>  <br/>The test drive was the way we got nearly all our new users. I think it will be<br/>the same for most Web-based applications. If users can get through a test<br/>drive successfully, they'll like the product. If they get confused or bored,<br/>they won't. So anything we could do to get more people through the test drive<br/>would increase our growth rate.  <br/>  <br/>I studied click trails of people taking the test drive and found that at a<br/>certain step they would get confused and click on the browser's Back button.<br/>(If you try writing Web-based applications, you'll find that the Back button<br/>becomes one of your most interesting philosophical problems.) So I added a<br/>message at that point, telling users that they were nearly finished, and<br/>reminding them not to click on the Back button. Another great thing about Web-<br/>based software is that you get instant feedback from changes: the number of<br/>people completing the test drive rose immediately from 60% to 90%. And since<br/>the number of new users was a function of the number of completed test drives,<br/>our revenue growth increased by 50%, just from that change.  <br/>  <br/> **Money**  <br/>  <br/>In the early 1990s I read an article in which someone said that software was a<br/>subscription business. At first this seemed a very cynical statement. But<br/>later I realized that it reflects reality: software development is an ongoing<br/>process. I think it's cleaner if you openly charge subscription fees, instead<br/>of forcing people to keep buying and installing new versions so that they'll<br/>keep paying you. And fortunately, subscriptions are the natural way to bill<br/>for Web-based applications.  <br/>  <br/>Hosting applications is an area where companies will play a role that is not<br/>likely to be filled by freeware. Hosting applications is a lot of stress, and<br/>has real expenses. No one is going to want to do it for free.  <br/>  <br/>For companies, Web-based applications are an ideal source of revenue. Instead<br/>of starting each quarter with a blank slate, you have a recurring revenue<br/>stream. Because your software evolves gradually, you don't have to worry that<br/>a new model will flop; there never need be a new model, per se, and if you do<br/>something to the software that users hate, you'll know right away. You have no<br/>trouble with uncollectable bills; if someone won't pay you can just turn off<br/>the service. And there is no possibility of piracy.  <br/>  <br/>That last "advantage" may turn out to be a problem. Some amount of piracy is<br/>to the advantage of software companies. If some user really would not have<br/>bought your software at any price, you haven't lost anything if he uses a<br/>pirated copy. In fact you gain, because he is one more user helping to make<br/>your software the standard-- or who might buy a copy later, when he graduates<br/>from high school.  <br/>  <br/>When they can, companies like to do something called price discrimination,<br/>which means charging each customer as much as they can afford. [8] Software is<br/>particularly suitable for price discrimination, because the marginal cost is<br/>close to zero. This is why some software costs more to run on Suns than on<br/>Intel boxes: a company that uses Suns is not interested in saving money and<br/>can safely be charged more. Piracy is effectively the lowest tier of price<br/>discrimination. I think that software companies understand this and<br/>deliberately turn a blind eye to some kinds of piracy. [9] With server-based<br/>software they are going to have to come up with some other solution.  <br/>  <br/>Web-based software sells well, especially in comparison to desktop software,<br/>because it's easy to buy. You might think that people decide to buy something,<br/>and then buy it, as two separate steps. That's what I thought before Viaweb,<br/>to the extent I thought about the question at all. In fact the second step can<br/>propagate back into the first: if something is hard to buy, people will change<br/>their mind about whether they wanted it. And vice versa: you'll sell more of<br/>something when it's easy to buy. I buy more books because Amazon exists. Web-<br/>based software is just about the easiest thing in the world to buy, especially<br/>if you have just done an online demo. Users should not have to do much more<br/>than enter a credit card number. (Make them do more at your peril.)  <br/>  <br/>Sometimes Web-based software is offered through ISPs acting as resellers. This<br/>is a bad idea. You have to be administering the servers, because you need to<br/>be constantly improving both hardware and software. If you give up direct<br/>control of the servers, you give up most of the advantages of developing Web-<br/>based applications.  <br/>  <br/>Several of our competitors shot themselves in the foot this way-- usually, I<br/>think, because they were overrun by suits who were excited about this huge<br/>potential channel, and didn't realize that it would ruin the product they<br/>hoped to sell through it. Selling Web-based software through ISPs is like<br/>selling sushi through vending machines.  <br/>  <br/> **Customers**  <br/>  <br/>Who will the customers be? At Viaweb they were initially individuals and<br/>smaller companies, and I think this will be the rule with Web-based<br/>applications. These are the users who are ready to try new things, partly<br/>because they're more flexible, and partly because they want the lower costs of<br/>new technology.  <br/>  <br/>Web-based applications will often be the best thing for big companies too<br/>(though they'll be slow to realize it). The best intranet is the Internet. If<br/>a company uses true Web-based applications, the software will work better, the<br/>servers will be better administered, and employees will have access to the<br/>system from anywhere.  <br/>  <br/>The argument against this approach usually hinges on security: if access is<br/>easier for employees, it will be for bad guys too. Some larger merchants were<br/>reluctant to use Viaweb because they thought customers' credit card<br/>information would be safer on their own servers. It was not easy to make this<br/>point diplomatically, but in fact the data was almost certainly safer in our<br/>hands than theirs. Who can hire better people to manage security, a technology<br/>startup whose whole business is running servers, or a clothing retailer? Not<br/>only did we have better people worrying about security, we worried more about<br/>it. If someone broke into the clothing retailer's servers, it would affect at<br/>most one merchant, could probably be hushed up, and in the worst case might<br/>get one person fired. If someone broke into ours, it could affect thousands of<br/>merchants, would probably end up as news on CNet, and could put us out of<br/>business.  <br/>  <br/>If you want to keep your money safe, do you keep it under your mattress at<br/>home, or put it in a bank? This argument applies to every aspect of server<br/>administration: not just security, but uptime, bandwidth, load management,<br/>backups, etc. Our existence depended on doing these things right. Server<br/>problems were the big no-no for us, like a dangerous toy would be for a toy<br/>maker, or a salmonella outbreak for a food processor.  <br/>  <br/>A big company that uses Web-based applications is to that extent outsourcing<br/>IT. Drastic as it sounds, I think this is generally a good idea. Companies are<br/>likely to get better service this way than they would from in-house system<br/>administrators. System administrators can become cranky and unresponsive<br/>because they're not directly exposed to competitive pressure: a salesman has<br/>to deal with customers, and a developer has to deal with competitors'<br/>software, but a system administrator, like an old bachelor, has few external<br/>forces to keep him in line. [10] At Viaweb we had external forces in plenty to<br/>keep us in line. The people calling us were customers, not just co-workers. If<br/>a server got wedged, we jumped; just thinking about it gives me a jolt of<br/>adrenaline, years later.  <br/>  <br/>So Web-based applications will ordinarily be the right answer for big<br/>companies too. They will be the last to realize it, however, just as they were<br/>with desktop computers. And partly for the same reason: it will be worth a lot<br/>of money to convince big companies that they need something more expensive.  <br/>  <br/>There is always a tendency for rich customers to buy expensive solutions, even<br/>when cheap solutions are better, because the people offering expensive<br/>solutions can spend more to sell them. At Viaweb we were always up against<br/>this. We lost several high-end merchants to Web consulting firms who convinced<br/>them they'd be better off if they paid half a million dollars for a custom-<br/>made online store on their own server. They were, as a rule, not better off,<br/>as more than one discovered when Christmas shopping season came around and<br/>loads rose on their server. Viaweb was a lot more sophisticated than what most<br/>of these merchants got, but we couldn't afford to tell them. At $300 a month,<br/>we couldn't afford to send a team of well-dressed and authoritative-sounding<br/>people to make presentations to customers.  <br/>  <br/>A large part of what big companies pay extra for is the cost of selling<br/>expensive things to them. (If the Defense Department pays a thousand dollars<br/>for toilet seats, it's partly because it costs a lot to sell toilet seats for<br/>a thousand dollars.) And this is one reason intranet software will continue to<br/>thrive, even though it is probably a bad idea. It's simply more expensive.<br/>There is nothing you can do about this conundrum, so the best plan is to go<br/>for the smaller customers first. The rest will come in time.  <br/>  <br/> **Son of Server**  <br/>  <br/>Running software on the server is nothing new. In fact it's the old model:<br/>mainframe applications are all server-based. If server-based software is such<br/>a good idea, why did it lose last time? Why did desktop computers eclipse<br/>mainframes?  <br/>  <br/>At first desktop computers didn't look like much of a threat. The first users<br/>were all hackers-- or hobbyists, as they were called then. They liked<br/>microcomputers because they were cheap. For the first time, you could have<br/>your own computer. The phrase "personal computer" is part of the language now,<br/>but when it was first used it had a deliberately audacious sound, like the<br/>phrase "personal satellite" would today.  <br/>  <br/>Why did desktop computers take over? I think it was because they had better<br/>software. And I think the reason microcomputer software was better was that it<br/>could be written by small companies.  <br/>  <br/>I don't think many people realize how fragile and tentative startups are in<br/>the earliest stage. Many startups begin almost by accident-- as a couple guys,<br/>either with day jobs or in school, writing a prototype of something that<br/>might, if it looks promising, turn into a company. At this larval stage, any<br/>significant obstacle will stop the startup dead in its tracks. Writing<br/>mainframe software required too much commitment up front. Development machines<br/>were expensive, and because the customers would be big companies, you'd need<br/>an impressive-looking sales force to sell it to them. Starting a startup to<br/>write mainframe software would be a much more serious undertaking than just<br/>hacking something together on your Apple II in the evenings. And so you didn't<br/>get a lot of startups writing mainframe applications.  <br/>  <br/>The arrival of desktop computers inspired a lot of new software, because<br/>writing applications for them seemed an attainable goal to larval startups.<br/>Development was cheap, and the customers would be individual people that you<br/>could reach through computer stores or even by mail-order.  <br/>  <br/>The application that pushed desktop computers out into the mainstream was<br/>VisiCalc, the first spreadsheet. It was written by two guys working in an<br/>attic, and yet did things no mainframe software could do. [11] VisiCalc was<br/>such an advance, in its time, that people bought Apple IIs just to run it. And<br/>this was the beginning of a trend: desktop computers won because startups<br/>wrote software for them.  <br/>  <br/>It looks as if server-based software will be good this time around, because<br/>startups will write it. Computers are so cheap now that you can get started,<br/>as we did, using a desktop computer as a server. Inexpensive processors have<br/>eaten the workstation market (you rarely even hear the word now) and are most<br/>of the way through the server market; Yahoo's servers, which deal with loads<br/>as high as any on the Internet, all have the same inexpensive Intel processors<br/>that you have in your desktop machine. And once you've written the software,<br/>all you need to sell it is a Web site. Nearly all our users came direct to our<br/>site through word of mouth and references in the press. [12]  <br/>  <br/>Viaweb was a typical larval startup. We were terrified of starting a company,<br/>and for the first few months comforted ourselves by treating the whole thing<br/>as an experiment that we might call off at any moment. Fortunately, there were<br/>few obstacles except technical ones. While we were writing the software, our<br/>Web server was the same desktop machine we used for development, connected to<br/>the outside world by a dialup line. Our only expenses in that phase were food<br/>and rent.  <br/>  <br/>There is all the more reason for startups to write Web-based software now,<br/>because writing desktop software has become a lot less fun. If you want to<br/>write desktop software now you do it on Microsoft's terms, calling their APIs<br/>and working around their buggy OS. And if you manage to write something that<br/>takes off, you may find that you were merely doing market research for<br/>Microsoft.  <br/>  <br/>If a company wants to make a platform that startups will build on, they have<br/>to make it something that hackers themselves will want to use. That means it<br/>has to be inexpensive and well-designed. The Mac was popular with hackers when<br/>it first came out, and a lot of them wrote software for it. [13] You see this<br/>less with Windows, because hackers don't use it. The kind of people who are<br/>good at writing software tend to be running Linux or FreeBSD now.  <br/>  <br/>I don't think we would have started a startup to write desktop software,<br/>because desktop software has to run on Windows, and before we could write<br/>software for Windows we'd have to use it. The Web let us do an end-run around<br/>Windows, and deliver software running on Unix direct to users through the<br/>browser. That is a liberating prospect, a lot like the arrival of PCs twenty-<br/>five years ago.  <br/>  <br/> **Microsoft**  <br/>  <br/>Back when desktop computers arrived, IBM was the giant that everyone was<br/>afraid of. It's hard to imagine now, but I remember the feeling very well. Now<br/>the frightening giant is Microsoft, and I don't think they are as blind to the<br/>threat facing them as IBM was. After all, Microsoft deliberately built their<br/>business in IBM's blind spot.  <br/>  <br/>I mentioned earlier that my mother doesn't really need a desktop computer.<br/>Most users probably don't. That's a problem for Microsoft, and they know it.<br/>If applications run on remote servers, no one needs Windows. What will<br/>Microsoft do? Will they be able to use their control of the desktop to<br/>prevent, or constrain, this new generation of software?  <br/>  <br/>My guess is that Microsoft will develop some kind of server/desktop hybrid,<br/>where the operating system works together with servers they control. At a<br/>minimum, files will be centrally available for users who want that. I don't<br/>expect Microsoft to go all the way to the extreme of doing the computations on<br/>the server, with only a browser for a client, if they can avoid it. If you<br/>only need a browser for a client, you don't need Microsoft on the client, and<br/>if Microsoft doesn't control the client, they can't push users towards their<br/>server-based applications.  <br/>  <br/>I think Microsoft will have a hard time keeping the genie in the bottle. There<br/>will be too many different types of clients for them to control them all. And<br/>if Microsoft's applications only work with some clients, competitors will be<br/>able to trump them by offering applications that work from any client. [14]  <br/>  <br/>In a world of Web-based applications, there is no automatic place for<br/>Microsoft. They may succeed in making themselves a place, but I don't think<br/>they'll dominate this new world as they did the world of desktop applications.  <br/>  <br/>It's not so much that a competitor will trip them up as that they will trip<br/>over themselves. With the rise of Web-based software, they will be facing not<br/>just technical problems but their own wishful thinking. What they need to do<br/>is cannibalize their existing business, and I can't see them facing that. The<br/>same single-mindedness that has brought them this far will now be working<br/>against them. IBM was in exactly the same situation, and they could not master<br/>it. IBM made a late and half-hearted entry into the microcomputer business<br/>because they were ambivalent about threatening their cash cow, mainframe<br/>computing. Microsoft will likewise be hampered by wanting to save the desktop.<br/>A cash cow can be a damned heavy monkey on your back.  <br/>  <br/>I'm not saying that no one will dominate server-based applications. Someone<br/>probably will eventually. But I think that there will be a good long period of<br/>cheerful chaos, just as there was in the early days of microcomputers. That<br/>was a good time for startups. Lots of small companies flourished, and did it<br/>by making cool things.  <br/>  <br/> **Startups but More So**  <br/>  <br/>The classic startup is fast and informal, with few people and little money.<br/>Those few people work very hard, and technology magnifies the effect of the<br/>decisions they make. If they win, they win big.  <br/>  <br/>In a startup writing Web-based applications, everything you associate with<br/>startups is taken to an extreme. You can write and launch a product with even<br/>fewer people and even less money. You have to be even faster, and you can get<br/>away with being more informal. You can literally launch your product as three<br/>guys sitting in the living room of an apartment, and a server collocated at an<br/>ISP. We did.  <br/>  <br/>Over time the teams have gotten smaller, faster, and more informal. In 1960,<br/>software development meant a roomful of men with horn rimmed glasses and<br/>narrow black neckties, industriously writing ten lines of code a day on IBM<br/>coding forms. In 1980, it was a team of eight to ten people wearing jeans to<br/>the office and typing into vt100s. Now it's a couple of guys sitting in a<br/>living room with laptops. (And jeans turn out not to be the last word in<br/>informality.)  <br/>  <br/>Startups are stressful, and this, unfortunately, is also taken to an extreme<br/>with Web-based applications. Many software companies, especially at the<br/>beginning, have periods where the developers slept under their desks and so<br/>on. The alarming thing about Web-based software is that there is nothing to<br/>prevent this becoming the default. The stories about sleeping under desks<br/>usually end: then at last we shipped it and we all went home and slept for a<br/>week. Web-based software never ships. You can work 16-hour days for as long as<br/>you want to. And because you can, and your competitors can, you tend to be<br/>forced to. You can, so you must. It's Parkinson's Law running in reverse.  <br/>  <br/>The worst thing is not the hours but the responsibility. Programmers and<br/>system administrators traditionally each have their own separate worries.<br/>Programmers have to worry about bugs, and system administrators have to worry<br/>about infrastructure. Programmers may spend a long day up to their elbows in<br/>source code, but at some point they get to go home and forget about it. System<br/>administrators never quite leave the job behind, but when they do get paged at<br/>4:00 AM, they don't usually have to do anything very complicated. With Web-<br/>based applications, these two kinds of stress get combined. The programmers<br/>become system administrators, but without the sharply defined limits that<br/>ordinarily make the job bearable.  <br/>  <br/>At Viaweb we spent the first six months just writing software. We worked the<br/>usual long hours of an early startup. In a desktop software company, this<br/>would have been the part where we were working hard, but it felt like a<br/>vacation compared to the next phase, when we took users onto our server. The<br/>second biggest benefit of selling Viaweb to Yahoo (after the money) was to be<br/>able to dump ultimate responsibility for the whole thing onto the shoulders of<br/>a big company.  <br/>  <br/>Desktop software forces users to become system administrators. Web-based<br/>software forces programmers to. There is less stress in total, but more for<br/>the programmers. That's not necessarily bad news. If you're a startup<br/>competing with a big company, it's good news. [15] Web-based applications<br/>offer a straightforward way to outwork your competitors. No startup asks for<br/>more.  <br/>  <br/> **Just Good Enough**  <br/>  <br/>One thing that might deter you from writing Web-based applications is the<br/>lameness of Web pages as a UI. That is a problem, I admit. There were a few<br/>things we would have _really_ liked to add to HTML and HTTP. What matters,<br/>though, is that Web pages are just good enough.  <br/>  <br/>There is a parallel here with the first microcomputers. The processors in<br/>those machines weren't actually intended to be the CPUs of computers. They<br/>were designed to be used in things like traffic lights. But guys like Ed<br/>Roberts, who designed the Altair, realized that they were just good enough.<br/>You could combine one of these chips with some memory (256 bytes in the first<br/>Altair), and front panel switches, and you'd have a working computer. Being<br/>able to have your own computer was so exciting that there were plenty of<br/>people who wanted to buy them, however limited.  <br/>  <br/>Web pages weren't designed to be a UI for applications, but they're just good<br/>enough. And for a significant number of users, software that you can use from<br/>any browser will be enough of a win in itself to outweigh any awkwardness in<br/>the UI. Maybe you can't write the best-looking spreadsheet using HTML, but you<br/>can write a spreadsheet that several people can use simultaneously from<br/>different locations without special client software, or that can incorporate<br/>live data feeds, or that can page you when certain conditions are triggered.<br/>More importantly, you can write new kinds of applications that don't even have<br/>names yet. VisiCalc was not merely a microcomputer version of a mainframe<br/>application, after all-- it was a new type of application.  <br/>  <br/>Of course, server-based applications don't have to be Web-based. You could<br/>have some other kind of client. But I'm pretty sure that's a bad idea. It<br/>would be very convenient if you could assume that everyone would install your<br/>client-- so convenient that you could easily convince yourself that they all<br/>would-- but if they don't, you're hosed. Because Web-based software assumes<br/>nothing about the client, it will work anywhere the Web works. That's a big<br/>advantage already, and the advantage will grow as new Web devices proliferate.<br/>Users will like you because your software just works, and your life will be<br/>easier because you won't have to tweak it for every new client.  [16]  <br/>  <br/>I feel like I've watched the evolution of the Web as closely as anyone, and I<br/>can't predict what's going to happen with clients. Convergence is probably<br/>coming, but where? I can't pick a winner. One thing I can predict is conflict<br/>between AOL and Microsoft. Whatever Microsoft's .NET turns out to be, it will<br/>probably involve connecting the desktop to servers. Unless AOL fights back,<br/>they will either be pushed aside or turned into a pipe between Microsoft<br/>client and server software. If Microsoft and AOL get into a client war, the<br/>only thing sure to work on both will be browsing the Web, meaning Web-based<br/>applications will be the only kind that work everywhere.  <br/>  <br/>How will it all play out? I don't know. And you don't have to know if you bet<br/>on Web-based applications. No one can break that without breaking browsing.<br/>The Web may not be the only way to deliver software, but it's one that works<br/>now and will continue to work for a long time. Web-based applications are<br/>cheap to develop, and easy for even the smallest startup to deliver. They're a<br/>lot of work, and of a particularly stressful kind, but that only makes the<br/>odds better for startups.  <br/>  <br/> **Why Not?**  <br/>  <br/>E. B. White was amused to learn from a farmer friend that many electrified<br/>fences don't have any current running through them. The cows apparently learn<br/>to stay away from them, and after that you don't need the current. "Rise up,<br/>cows!" he wrote, "Take your liberty while despots snore!"  <br/>  <br/>If you're a hacker who has thought of one day starting a startup, there are<br/>probably two things keeping you from doing it. One is that you don't know<br/>anything about business. The other is that you're afraid of competition.<br/>Neither of these fences have any current in them.  <br/>  <br/>There are only two things you have to know about business: build something<br/>users love, and make more than you spend. If you get these two right, you'll<br/>be ahead of most startups. You can figure out the rest as you go.  <br/>  <br/>You may not at first make more than you spend, but as long as the gap is<br/>closing fast enough you'll be ok. If you start out underfunded, it will at<br/>least encourage a habit of frugality. The less you spend, the easier it is to<br/>make more than you spend. Fortunately, it can be very cheap to launch a Web-<br/>based application. We launched on under $10,000, and it would be even cheaper<br/>today. We had to spend thousands on a server, and thousands more to get SSL.<br/>(The only company selling SSL software at the time was Netscape.) Now you can<br/>rent a much more powerful server, with SSL included, for less than we paid for<br/>bandwidth alone. You could launch a Web-based application now for less than<br/>the cost of a fancy office chair.  <br/>  <br/>As for building something users love, here are some general tips. Start by<br/>making something clean and simple that you would want to use yourself. Get a<br/>version 1.0 out fast, then continue to improve the software, listening closely<br/>to the users as you do. The customer is always right, but different customers<br/>are right about different things; the least sophisticated users show you what<br/>you need to simplify and clarify, and the most sophisticated tell you what<br/>features you need to add. The best thing software can be is easy, but the way<br/>to do this is to get the defaults right, not to limit users' choices. Don't<br/>get complacent if your competitors' software is lame; the standard to compare<br/>your software to is what it could be, not what your current competitors happen<br/>to have. Use your software yourself, all the time. Viaweb was supposed to be<br/>an online store builder, but we used it to make our own site too. Don't listen<br/>to marketing people or designers or product managers just because of their job<br/>titles. If they have good ideas, use them, but it's up to you to decide;<br/>software has to be designed by hackers who understand design, not designers<br/>who know a little about software. If you can't design software as well as<br/>implement it, don't start a startup.  <br/>  <br/>Now let's talk about competition. What you're afraid of is not presumably<br/>groups of hackers like you, but actual companies, with offices and business<br/>plans and salesmen and so on, right? Well, they are more afraid of you than<br/>you are of them, and they're right. It's a lot easier for a couple of hackers<br/>to figure out how to rent office space or hire sales people than it is for a<br/>company of any size to get software written. I've been on both sides, and I<br/>know. When Viaweb was bought by Yahoo, I suddenly found myself working for a<br/>big company, and it was like trying to run through waist-deep water.  <br/>  <br/>I don't mean to disparage Yahoo. They had some good hackers, and the top<br/>management were real butt-kickers. For a big company, they were exceptional.<br/>But they were still only about a tenth as productive as a small startup. No<br/>big company can do much better than that. What's scary about Microsoft is that<br/>a company so big can develop software at all. They're like a mountain that can<br/>walk.  <br/>  <br/>Don't be intimidated. You can do as much that Microsoft can't as they can do<br/>that you can't. And no one can stop you. You don't have to ask anyone's<br/>permission to develop Web-based applications. You don't have to do licensing<br/>deals, or get shelf space in retail stores, or grovel to have your application<br/>bundled with the OS. You can deliver software right to the browser, and no one<br/>can get between you and potential users without preventing them from browsing<br/>the Web.  <br/>  <br/>You may not believe it, but I promise you, Microsoft is scared of you. The<br/>complacent middle managers may not be, but Bill is, because he was you once,<br/>back in 1975, the last time a new way of delivering software appeared.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Realizing that much of the money is in the services, companies building<br/>lightweight clients have usually tried to combine the hardware with an online<br/>service. This approach has not worked well, partly because you need two<br/>different kinds of companies to build consumer electronics and to run an<br/>online service, and partly because users hate the idea. Giving away the razor<br/>and making money on the blades may work for Gillette, but a razor is much<br/>smaller commitment than a Web terminal. Cell phone handset makers are<br/>satisfied to sell hardware without trying to capture the service revenue as<br/>well. That should probably be the model for Internet clients too. If someone<br/>just sold a nice-looking little box with a Web browser that you could use to<br/>connect through any ISP, every technophobe in the country would buy one.  <br/>  <br/>[2] Security always depends more on not screwing up than any design decision,<br/>but the nature of server-based software will make developers pay more<br/>attention to not screwing up. Compromising a server could cause such damage<br/>that ASPs (that want to stay in business) are likely to be careful about<br/>security.  <br/>  <br/>[3] In 1995, when we started Viaweb, Java applets were supposed to be the<br/>technology everyone was going to use to develop server-based applications.<br/>Applets seemed to us an old-fashioned idea. Download programs to run on the<br/>client? Simpler just to go all the way and run the programs on the server. We<br/>wasted little time on applets, but countless other startups must have been<br/>lured into this tar pit. Few can have escaped alive, or Microsoft could not<br/>have gotten away with dropping Java in the most recent version of Explorer.  <br/>  <br/>[4] This point is due to Trevor Blackwell, who adds "the cost of writing<br/>software goes up more than linearly with its size. Perhaps this is mainly due<br/>to fixing old bugs, and the cost can be more linear if all bugs are found<br/>quickly."  <br/>  <br/>[5] The hardest kind of bug to find may be a variant of compound bug where one<br/>bug happens to compensate for another. When you fix one bug, the other becomes<br/>visible. But it will seem as if the fix is at fault, since that was the last<br/>thing you changed.  <br/>  <br/>[6] Within Viaweb we once had a contest to describe the worst thing about our<br/>software. Two customer support people tied for first prize with entries I<br/>still shiver to recall. We fixed both problems immediately.  <br/>  <br/>[7] Robert Morris wrote the ordering system, which shoppers used to place<br/>orders. Trevor Blackwell wrote the image generator and the manager, which<br/>merchants used to retrieve orders, view statistics, and configure domain names<br/>etc. I wrote the editor, which merchants used to build their sites. The<br/>ordering system and image generator were written in C and C++, the manager<br/>mostly in Perl, and the editor in Lisp.  <br/>  <br/>[8] Price discrimination is so pervasive (how often have you heard a retailer<br/>claim that their buying power meant lower prices for you?) that I was<br/>surprised to find it was outlawed in the U.S. by the Robinson-Patman Act of<br/>1936. This law does not appear to be vigorously enforced.  <br/>  <br/>[9] In _No Logo,_ Naomi Klein says that clothing brands favored by "urban<br/>youth" do not try too hard to prevent shoplifting because in their target<br/>market the shoplifters are also the fashion leaders.  <br/>  <br/>[10] Companies often wonder what to outsource and what not to. One possible<br/>answer: outsource any job that's not directly exposed to competitive pressure,<br/>because outsourcing it will thereby expose it to competitive pressure.  <br/>  <br/>[11] The two guys were Dan Bricklin and Bob Frankston. Dan wrote a prototype<br/>in Basic in a couple days, then over the course of the next year they worked<br/>together (mostly at night) to make a more powerful version written in 6502<br/>machine language. Dan was at Harvard Business School at the time and Bob<br/>nominally had a day job writing software. "There was no great risk in doing a<br/>business," Bob wrote, "If it failed it failed. No big deal."  <br/>  <br/>[12] It's not quite as easy as I make it sound. It took a painfully long time<br/>for word of mouth to get going, and we did not start to get a lot of press<br/>coverage until we hired a PR firm (admittedly the best in the business) for<br/>$16,000 per month. However, it was true that the only significant channel was<br/>our own Web site.  <br/>  <br/>[13] If the Mac was so great, why did it lose? Cost, again. Microsoft<br/>concentrated on the software business, and unleashed a swarm of cheap<br/>component suppliers on Apple hardware. It did not help, either, that suits<br/>took over during a critical period.  <br/>  <br/>[14] One thing that would help Web-based applications, and help keep the next<br/>generation of software from being overshadowed by Microsoft, would be a good<br/>open-source browser. Mozilla is open-source but seems to have suffered from<br/>having been corporate software for so long. A small, fast browser that was<br/>actively maintained would be a great thing in itself, and would probably also<br/>encourage companies to build little Web appliances.  <br/>  <br/>Among other things, a proper open-source browser would cause HTTP and HTML to<br/>continue to evolve (as e.g. Perl has). It would help Web-based applications<br/>greatly to be able to distinguish between selecting a link and following it;<br/>all you'd need to do this would be a trivial enhancement of HTTP, to allow<br/>multiple urls in a request. Cascading menus would also be good.  <br/>  <br/>If you want to change the world, write a new Mosaic. Think it's too late? In<br/>1998 a lot of people thought it was too late to launch a new search engine,<br/>but Google proved them wrong. There is always room for something new if the<br/>current options suck enough. Make sure it works on all the free OSes first--<br/>new things start with their users.  <br/>  <br/>[15] Trevor Blackwell, who probably knows more about this from personal<br/>experience than anyone, writes:  <br/>  <br/>"I would go farther in saying that because server-based software is so hard on<br/>the programmers, it causes a fundamental economic shift away from large<br/>companies. It requires the kind of intensity and dedication from programmers<br/>that they will only be willing to provide when it's their own company.<br/>Software companies can hire skilled people to work in a not-too-demanding<br/>environment, and can hire unskilled people to endure hardships, but they can't<br/>hire highly skilled people to bust their asses. Since capital is no longer<br/>needed, big companies have little to bring to the table."  <br/>  <br/>[16] In the original version of this essay, I advised avoiding Javascript.<br/>That was a good plan in 2001, but Javascript now works.  <br/>  <br/>**Thanks** to Sarah Harlin, Trevor Blackwell, Robert Morris, Eric Raymond, Ken<br/>Anderson, and Dan Giffin for reading drafts of this paper; to Dan Bricklin and<br/>Bob Frankston for information about VisiCalc; and again to Ken Anderson for<br/>inviting me to speak at BBN.  <br/>  <br/><br/>Some Technical Details  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Microsoft finally agrees  <br/>  <br/><br/>Gates Email  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>March 2005  <br/>  <br/> _(This essay is derived from a talk at the Harvard Computer Society.)_  <br/>  <br/>You need three things to create a successful startup: to start with good<br/>people, to make something customers actually want, and to spend as little<br/>money as possible. Most startups that fail do it because they fail at one of<br/>these. A startup that does all three will probably succeed.  <br/>  <br/>And that's kind of exciting, when you think about it, because all three are<br/>doable. Hard, but doable. And since a startup that succeeds ordinarily makes<br/>its founders rich, that implies getting rich is doable too. Hard, but doable.  <br/>  <br/>If there is one message I'd like to get across about startups, that's it.<br/>There is no magically difficult step that requires brilliance to solve.  <br/>  <br/> **The Idea**  <br/>  <br/>In particular, you don't need a brilliant idea to start a startup around. The<br/>way a startup makes money is to offer people better technology than they have<br/>now. But what people have now is often so bad that it doesn't take brilliance<br/>to do better.  <br/>  <br/>Google's plan, for example, was simply to create a search site that didn't<br/>suck. They had three new ideas: index more of the Web, use links to rank<br/>search results, and have clean, simple web pages with unintrusive keyword-<br/>based ads. Above all, they were determined to make a site that was good to<br/>use. No doubt there are great technical tricks within Google, but the overall<br/>plan was straightforward. And while they probably have bigger ambitions now,<br/>this alone brings them a billion dollars a year. [1]  <br/>  <br/>There are plenty of other areas that are just as backward as search was before<br/>Google. I can think of several heuristics for generating ideas for startups,<br/>but most reduce to this: look at something people are trying to do, and figure<br/>out how to do it in a way that doesn't suck.  <br/>  <br/>For example, dating sites currently suck far worse than search did before<br/>Google. They all use the same simple-minded model. They seem to have<br/>approached the problem by thinking about how to do database matches instead of<br/>how dating works in the real world. An undergrad could build something better<br/>as a class project. And yet there's a lot of money at stake. Online dating is<br/>a valuable business now, and it might be worth a hundred times as much if it<br/>worked.  <br/>  <br/>An idea for a startup, however, is only a beginning. A lot of would-be startup<br/>founders think the key to the whole process is the initial idea, and from that<br/>point all you have to do is execute. Venture capitalists know better. If you<br/>go to VC firms with a brilliant idea that you'll tell them about if they sign<br/>a nondisclosure agreement, most will tell you to get lost. That shows how much<br/>a mere idea is worth. The market price is less than the inconvenience of<br/>signing an NDA.  <br/>  <br/>Another sign of how little the initial idea is worth is the number of startups<br/>that change their plan en route. Microsoft's original plan was to make money<br/>selling programming languages, of all things. Their current business model<br/>didn't occur to them until IBM dropped it in their lap five years later.  <br/>  <br/>Ideas for startups are worth something, certainly, but the trouble is, they're<br/>not transferrable. They're not something you could hand to someone else to<br/>execute. Their value is mainly as starting points: as questions for the people<br/>who had them to continue thinking about.  <br/>  <br/>What matters is not ideas, but the people who have them. Good people can fix<br/>bad ideas, but good ideas can't save bad people.  <br/>  <br/>**People**  <br/>  <br/>What do I mean by good people? One of the best tricks I learned during our<br/>startup was a rule for deciding who to hire. Could you describe the person as<br/>an animal? It might be hard to translate that into another language, but I<br/>think everyone in the US knows what it means. It means someone who takes their<br/>work a little too seriously; someone who does what they do so well that they<br/>pass right through professional and cross over into obsessive.  <br/>  <br/>What it means specifically depends on the job: a salesperson who just won't<br/>take no for an answer; a hacker who will stay up till 4:00 AM rather than go<br/>to bed leaving code with a bug in it; a PR person who will cold-call _New York<br/>Times_ reporters on their cell phones; a graphic designer who feels physical<br/>pain when something is two millimeters out of place.  <br/>  <br/>Almost everyone who worked for us was an animal at what they did. The woman in<br/>charge of sales was so tenacious that I used to feel sorry for potential<br/>customers on the phone with her. You could sense them squirming on the hook,<br/>but you knew there would be no rest for them till they'd signed up.  <br/>  <br/>If you think about people you know, you'll find the animal test is easy to<br/>apply. Call the person's image to mind and imagine the sentence "so-and-so is<br/>an animal." If you laugh, they're not. You don't need or perhaps even want<br/>this quality in big companies, but you need it in a startup.  <br/>  <br/>For programmers we had three additional tests. Was the person genuinely smart?<br/>If so, could they actually get things done? And finally, since a few good<br/>hackers have unbearable personalities, could we stand to have them around?  <br/>  <br/>That last test filters out surprisingly few people. We could bear any amount<br/>of nerdiness if someone was truly smart. What we couldn't stand were people<br/>with a lot of attitude. But most of those weren't truly smart, so our third<br/>test was largely a restatement of the first.  <br/>  <br/>When nerds are unbearable it's usually because they're trying too hard to seem<br/>smart. But the smarter they are, the less pressure they feel to act smart. So<br/>as a rule you can recognize genuinely smart people by their ability to say<br/>things like "I don't know," "Maybe you're right," and "I don't understand x<br/>well enough."  <br/>  <br/>This technique doesn't always work, because people can be influenced by their<br/>environment. In the MIT CS department, there seems to be a tradition of acting<br/>like a brusque know-it-all. I'm told it derives ultimately from Marvin Minsky,<br/>in the same way the classic airline pilot manner is said to derive from Chuck<br/>Yeager. Even genuinely smart people start to act this way there, so you have<br/>to make allowances.  <br/>  <br/>It helped us to have Robert Morris, who is one of the readiest to say "I don't<br/>know" of anyone I've met. (At least, he was before he became a professor at<br/>MIT.) No one dared put on attitude around Robert, because he was obviously<br/>smarter than they were and yet had zero attitude himself.  <br/>  <br/>Like most startups, ours began with a group of friends, and it was through<br/>personal contacts that we got most of the people we hired. This is a crucial<br/>difference between startups and big companies. Being friends with someone for<br/>even a couple days will tell you more than companies could ever learn in<br/>interviews. [2]  <br/>  <br/>It's no coincidence that startups start around universities, because that's<br/>where smart people meet. It's not what people learn in classes at MIT and<br/>Stanford that has made technology companies spring up around them. They could<br/>sing campfire songs in the classes so long as admissions worked the same.  <br/>  <br/>If you start a startup, there's a good chance it will be with people you know<br/>from college or grad school. So in theory you ought to try to make friends<br/>with as many smart people as you can in school, right? Well, no. Don't make a<br/>conscious effort to schmooze; that doesn't work well with hackers.  <br/>  <br/>What you should do in college is work on your own projects. Hackers should do<br/>this even if they don't plan to start startups, because it's the only real way<br/>to learn how to program. In some cases you may collaborate with other<br/>students, and this is the best way to get to know good hackers. The project<br/>may even grow into a startup. But once again, I wouldn't aim too directly at<br/>either target. Don't force things; just work on stuff you like with people you<br/>like.  <br/>  <br/>Ideally you want between two and four founders. It would be hard to start with<br/>just one. One person would find the moral weight of starting a company hard to<br/>bear. Even Bill Gates, who seems to be able to bear a good deal of moral<br/>weight, had to have a co-founder. But you don't want so many founders that the<br/>company starts to look like a group photo. Partly because you don't need a lot<br/>of people at first, but mainly because the more founders you have, the worse<br/>disagreements you'll have. When there are just two or three founders, you know<br/>you have to resolve disputes immediately or perish. If there are seven or<br/>eight, disagreements can linger and harden into factions. You don't want mere<br/>voting; you need unanimity.  <br/>  <br/>In a technology startup, which most startups are, the founders should include<br/>technical people. During the Internet Bubble there were a number of startups<br/>founded by business people who then went looking for hackers to create their<br/>product for them. This doesn't work well. Business people are bad at deciding<br/>what to do with technology, because they don't know what the options are, or<br/>which kinds of problems are hard and which are easy. And when business people<br/>try to hire hackers, they can't tell which ones are good. Even other hackers<br/>have a hard time doing that. For business people it's roulette.  <br/>  <br/>Do the founders of a startup have to include business people? That depends. We<br/>thought so when we started ours, and we asked several people who were said to<br/>know about this mysterious thing called "business" if they would be the<br/>president. But they all said no, so I had to do it myself. And what I<br/>discovered was that business was no great mystery. It's not something like<br/>physics or medicine that requires extensive study. You just try to get people<br/>to pay you for stuff.  <br/>  <br/>I think the reason I made such a mystery of business was that I was disgusted<br/>by the idea of doing it. I wanted to work in the pure, intellectual world of<br/>software, not deal with customers' mundane problems. People who don't want to<br/>get dragged into some kind of work often develop a protective incompetence at<br/>it. Paul Erdos was particularly good at this. By seeming unable even to cut a<br/>grapefruit in half (let alone go to the store and buy one), he forced other<br/>people to do such things for him, leaving all his time free for math. Erdos<br/>was an extreme case, but most husbands use the same trick to some degree.  <br/>  <br/>Once I was forced to discard my protective incompetence, I found that business<br/>was neither so hard nor so boring as I feared. There are esoteric areas of<br/>business that are quite hard, like tax law or the pricing of derivatives, but<br/>you don't need to know about those in a startup. All you need to know about<br/>business to run a startup are commonsense things people knew before there were<br/>business schools, or even universities.  <br/>  <br/>If you work your way down the Forbes 400 making an x next to the name of each<br/>person with an MBA, you'll learn something important about business school.<br/>After Warren Buffett, you don't hit another MBA till number 22, Phil Knight,<br/>the CEO of Nike. There are only 5 MBAs in the top 50\. What you notice in the<br/>Forbes 400 are a lot of people with technical backgrounds. Bill Gates, Steve<br/>Jobs, Larry Ellison, Michael Dell, Jeff Bezos, Gordon Moore. The rulers of the<br/>technology business tend to come from technology, not business. So if you want<br/>to invest two years in something that will help you succeed in business, the<br/>evidence suggests you'd do better to learn how to hack than get an MBA. [3]  <br/>  <br/>There is one reason you might want to include business people in a startup,<br/>though: because you have to have at least one person willing and able to focus<br/>on what customers want. Some believe only business people can do this-- that<br/>hackers can implement software, but not design it. That's nonsense. There's<br/>nothing about knowing how to program that prevents hackers from understanding<br/>users, or about not knowing how to program that magically enables business<br/>people to understand them.  <br/>  <br/>If you can't understand users, however, you should either learn how or find a<br/>co-founder who can. That is the single most important issue for technology<br/>startups, and the rock that sinks more of them than anything else.  <br/>  <br/> **What Customers Want**  <br/>  <br/>It's not just startups that have to worry about this. I think most businesses<br/>that fail do it because they don't give customers what they want. Look at<br/>restaurants. A large percentage fail, about a quarter in the first year. But<br/>can you think of one restaurant that had really good food and went out of<br/>business?  <br/>  <br/>Restaurants with great food seem to prosper no matter what. A restaurant with<br/>great food can be expensive, crowded, noisy, dingy, out of the way, and even<br/>have bad service, and people will keep coming. It's true that a restaurant<br/>with mediocre food can sometimes attract customers through gimmicks. But that<br/>approach is very risky. It's more straightforward just to make the food good.  <br/>  <br/>It's the same with technology. You hear all kinds of reasons why startups<br/>fail. But can you think of one that had a massively popular product and still<br/>failed?  <br/>  <br/>In nearly every failed startup, the real problem was that customers didn't<br/>want the product. For most, the cause of death is listed as "ran out of<br/>funding," but that's only the immediate cause. Why couldn't they get more<br/>funding? Probably because the product was a dog, or never seemed likely to be<br/>done, or both.  <br/>  <br/>When I was trying to think of the things every startup needed to do, I almost<br/>included a fourth: get a version 1 out as soon as you can. But I decided not<br/>to, because that's implicit in making something customers want. The only way<br/>to make something customers want is to get a prototype in front of them and<br/>refine it based on their reactions.  <br/>  <br/>The other approach is what I call the "Hail Mary" strategy. You make elaborate<br/>plans for a product, hire a team of engineers to develop it (people who do<br/>this tend to use the term "engineer" for hackers), and then find after a year<br/>that you've spent two million dollars to develop something no one wants. This<br/>was not uncommon during the Bubble, especially in companies run by business<br/>types, who thought of software development as something terrifying that<br/>therefore had to be carefully planned.  <br/>  <br/>We never even considered that approach. As a Lisp hacker, I come from the<br/>tradition of rapid prototyping. I would not claim (at least, not here) that<br/>this is the right way to write every program, but it's certainly the right way<br/>to write software for a startup. In a startup, your initial plans are almost<br/>certain to be wrong in some way, and your first priority should be to figure<br/>out where. The only way to do that is to try implementing them.  <br/>  <br/>Like most startups, we changed our plan on the fly. At first we expected our<br/>customers to be Web consultants. But it turned out they didn't like us,<br/>because our software was easy to use and we hosted the site. It would be too<br/>easy for clients to fire them. We also thought we'd be able to sign up a lot<br/>of catalog companies, because selling online was a natural extension of their<br/>existing business. But in 1996 that was a hard sell. The middle managers we<br/>talked to at catalog companies saw the Web not as an opportunity, but as<br/>something that meant more work for them.  <br/>  <br/>We did get a few of the more adventurous catalog companies. Among them was<br/>Frederick's of Hollywood, which gave us valuable experience dealing with heavy<br/>loads on our servers. But most of our users were small, individual merchants<br/>who saw the Web as an opportunity to build a business. Some had retail stores,<br/>but many only existed online. And so we changed direction to focus on these<br/>users. Instead of concentrating on the features Web consultants and catalog<br/>companies would want, we worked to make the software easy to use.  <br/>  <br/>I learned something valuable from that. It's worth trying very, very hard to<br/>make technology easy to use. Hackers are so used to computers that they have<br/>no idea how horrifying software seems to normal people. Stephen Hawking's<br/>editor told him that every equation he included in his book would cut sales in<br/>half. When you work on making technology easier to use, you're riding that<br/>curve up instead of down. A 10% improvement in ease of use doesn't just<br/>increase your sales 10%. It's more likely to double your sales.  <br/>  <br/>How do you figure out what customers want? Watch them. One of the best places<br/>to do this was at trade shows. Trade shows didn't pay as a way of getting new<br/>customers, but they were worth it as market research. We didn't just give<br/>canned presentations at trade shows. We used to show people how to build real,<br/>working stores. Which meant we got to watch as they used our software, and<br/>talk to them about what they needed.  <br/>  <br/>No matter what kind of startup you start, it will probably be a stretch for<br/>you, the founders, to understand what users want. The only kind of software<br/>you can build without studying users is the sort for which you are the typical<br/>user. But this is just the kind that tends to be open source: operating<br/>systems, programming languages, editors, and so on. So if you're developing<br/>technology for money, you're probably not going to be developing it for people<br/>like you. Indeed, you can use this as a way to generate ideas for startups:<br/>what do people who are not like you want from technology?  <br/>  <br/>When most people think of startups, they think of companies like Apple or<br/>Google. Everyone knows these, because they're big consumer brands. But for<br/>every startup like that, there are twenty more that operate in niche markets<br/>or live quietly down in the infrastructure. So if you start a successful<br/>startup, odds are you'll start one of those.  <br/>  <br/>Another way to say that is, if you try to start the kind of startup that has<br/>to be a big consumer brand, the odds against succeeding are steeper. The best<br/>odds are in niche markets. Since startups make money by offering people<br/>something better than they had before, the best opportunities are where things<br/>suck most. And it would be hard to find a place where things suck more than in<br/>corporate IT departments. You would not believe the amount of money companies<br/>spend on software, and the crap they get in return. This imbalance equals<br/>opportunity.  <br/>  <br/>If you want ideas for startups, one of the most valuable things you could do<br/>is find a middle-sized non-technology company and spend a couple weeks just<br/>watching what they do with computers. Most good hackers have no more idea of<br/>the horrors perpetrated in these places than rich Americans do of what goes on<br/>in Brazilian slums.  <br/>  <br/>Start by writing software for smaller companies, because it's easier to sell<br/>to them. It's worth so much to sell stuff to big companies that the people<br/>selling them the crap they currently use spend a lot of time and money to do<br/>it. And while you can outhack Oracle with one frontal lobe tied behind your<br/>back, you can't outsell an Oracle salesman. So if you want to win through<br/>better technology, aim at smaller customers. [4]  <br/>  <br/>They're the more strategically valuable part of the market anyway. In<br/>technology, the low end always eats the high end. It's easier to make an<br/>inexpensive product more powerful than to make a powerful product cheaper. So<br/>the products that start as cheap, simple options tend to gradually grow more<br/>powerful till, like water rising in a room, they squash the "high-end"<br/>products against the ceiling. Sun did this to mainframes, and Intel is doing<br/>it to Sun. Microsoft Word did it to desktop publishing software like Interleaf<br/>and Framemaker. Mass-market digital cameras are doing it to the expensive<br/>models made for professionals. Avid did it to the manufacturers of specialized<br/>video editing systems, and now Apple is doing it to Avid. _Henry Ford_ did it<br/>to the car makers that preceded him. If you build the simple, inexpensive<br/>option, you'll not only find it easier to sell at first, but you'll also be in<br/>the best position to conquer the rest of the market.  <br/>  <br/>It's very dangerous to let anyone fly under you. If you have the cheapest,<br/>easiest product, you'll own the low end. And if you don't, you're in the<br/>crosshairs of whoever does.  <br/>  <br/> **Raising Money**  <br/>  <br/>To make all this happen, you're going to need money. Some startups have been<br/>self-funding-- Microsoft for example-- but most aren't. I think it's wise to<br/>take money from investors. To be self-funding, you have to start as a<br/>consulting company, and it's hard to switch from that to a product company.  <br/>  <br/>Financially, a startup is like a pass/fail course. The way to get rich from a<br/>startup is to maximize the company's chances of succeeding, not to maximize<br/>the amount of stock you retain. So if you can trade stock for something that<br/>improves your odds, it's probably a smart move.  <br/>  <br/>To most hackers, getting investors seems like a terrifying and mysterious<br/>process. Actually it's merely tedious. I'll try to give an outline of how it<br/>works.  <br/>  <br/>The first thing you'll need is a few tens of thousands of dollars to pay your<br/>expenses while you develop a prototype. This is called seed capital. Because<br/>so little money is involved, raising seed capital is comparatively easy-- at<br/>least in the sense of getting a quick yes or no.  <br/>  <br/>Usually you get seed money from individual rich people called "angels." Often<br/>they're people who themselves got rich from technology. At the seed stage,<br/>investors don't expect you to have an elaborate business plan. Most know that<br/>they're supposed to decide quickly. It's not unusual to get a check within a<br/>week based on a half-page agreement.  <br/>  <br/>We started Viaweb with $10,000 of seed money from our friend Julian. But he<br/>gave us a lot more than money. He's a former CEO and also a corporate lawyer,<br/>so he gave us a lot of valuable advice about business, and also did all the<br/>legal work of getting us set up as a company. Plus he introduced us to one of<br/>the two angel investors who supplied our next round of funding.  <br/>  <br/>Some angels, especially those with technology backgrounds, may be satisfied<br/>with a demo and a verbal description of what you plan to do. But many will<br/>want a copy of your business plan, if only to remind themselves what they<br/>invested in.  <br/>  <br/>Our angels asked for one, and looking back, I'm amazed how much worry it<br/>caused me. "Business plan" has that word "business" in it, so I figured it had<br/>to be something I'd have to read a book about business plans to write. Well,<br/>it doesn't. At this stage, all most investors expect is a brief description of<br/>what you plan to do and how you're going to make money from it, and the<br/>resumes of the founders. If you just sit down and write out what you've been<br/>saying to one another, that should be fine. It shouldn't take more than a<br/>couple hours, and you'll probably find that writing it all down gives you more<br/>ideas about what to do.  <br/>  <br/>For the angel to have someone to make the check out to, you're going to have<br/>to have some kind of company. Merely incorporating yourselves isn't hard. The<br/>problem is, for the company to exist, you have to decide who the founders are,<br/>and how much stock they each have. If there are two founders with the same<br/>qualifications who are both equally committed to the business, that's easy.<br/>But if you have a number of people who are expected to contribute in varying<br/>degrees, arranging the proportions of stock can be hard. And once you've done<br/>it, it tends to be set in stone.  <br/>  <br/>I have no tricks for dealing with this problem. All I can say is, try hard to<br/>do it right. I do have a rule of thumb for recognizing when you have, though.<br/>When everyone feels they're getting a slightly bad deal, that they're doing<br/>more than they should for the amount of stock they have, the stock is<br/>optimally apportioned.  <br/>  <br/>There is more to setting up a company than incorporating it, of course:<br/>insurance, business license, unemployment compensation, various things with<br/>the IRS. I'm not even sure what the list is, because we, ah, skipped all that.<br/>When we got real funding near the end of 1996, we hired a great CFO, who fixed<br/>everything retroactively. It turns out that no one comes and arrests you if<br/>you don't do everything you're supposed to when starting a company. And a good<br/>thing too, or a lot of startups would never get started. [5]  <br/>  <br/>It can be dangerous to delay turning yourself into a company, because one or<br/>more of the founders might decide to split off and start another company doing<br/>the same thing. This does happen. So when you set up the company, as well as<br/>as apportioning the stock, you should get all the founders to sign something<br/>agreeing that everyone's ideas belong to this company, and that this company<br/>is going to be everyone's only job.  <br/>  <br/>[If this were a movie, ominous music would begin here.]  <br/>  <br/>While you're at it, you should ask what else they've signed. One of the worst<br/>things that can happen to a startup is to run into intellectual property<br/>problems. We did, and it came closer to killing us than any competitor ever<br/>did.  <br/>  <br/>As we were in the middle of getting bought, we discovered that one of our<br/>people had, early on, been bound by an agreement that said all his ideas<br/>belonged to the giant company that was paying for him to go to grad school. In<br/>theory, that could have meant someone else owned big chunks of our software.<br/>So the acquisition came to a screeching halt while we tried to sort this out.<br/>The problem was, since we'd been about to be acquired, we'd allowed ourselves<br/>to run low on cash. Now we needed to raise more to keep going. But it's hard<br/>to raise money with an IP cloud over your head, because investors can't judge<br/>how serious it is.  <br/>  <br/>Our existing investors, knowing that we needed money and had nowhere else to<br/>get it, at this point attempted certain gambits which I will not describe in<br/>detail, except to remind readers that the word "angel" is a metaphor. The<br/>founders thereupon proposed to walk away from the company, after giving the<br/>investors a brief tutorial on how to administer the servers themselves. And<br/>while this was happening, the acquirers used the delay as an excuse to welch<br/>on the deal.  <br/>  <br/>Miraculously it all turned out ok. The investors backed down; we did another<br/>round of funding at a reasonable valuation; the giant company finally gave us<br/>a piece of paper saying they didn't own our software; and six months later we<br/>were bought by Yahoo for much more than the earlier acquirer had agreed to<br/>pay. So we were happy in the end, though the experience probably took several<br/>years off my life.  <br/>  <br/>Don't do what we did. Before you consummate a startup, ask everyone about<br/>their previous IP history.  <br/>  <br/>Once you've got a company set up, it may seem presumptuous to go knocking on<br/>the doors of rich people and asking them to invest tens of thousands of<br/>dollars in something that is really just a bunch of guys with some ideas. But<br/>when you look at it from the rich people's point of view, the picture is more<br/>encouraging. Most rich people are looking for good investments. If you really<br/>think you have a chance of succeeding, you're doing them a favor by letting<br/>them invest. Mixed with any annoyance they might feel about being approached<br/>will be the thought: are these guys the next Google?  <br/>  <br/>Usually angels are financially equivalent to founders. They get the same kind<br/>of stock and get diluted the same amount in future rounds. How much stock<br/>should they get? That depends on how ambitious you feel. When you offer x<br/>percent of your company for y dollars, you're implicitly claiming a certain<br/>value for the whole company. Venture investments are usually described in<br/>terms of that number. If you give an investor new shares equal to 5% of those<br/>already outstanding in return for $100,000, then you've done the deal at a<br/>pre-money valuation of $2 million.  <br/>  <br/>How do you decide what the value of the company should be? There is no<br/>rational way. At this stage the company is just a bet. I didn't realize that<br/>when we were raising money. Julian thought we ought to value the company at<br/>several million dollars. I thought it was preposterous to claim that a couple<br/>thousand lines of code, which was all we had at the time, were worth several<br/>million dollars. Eventually we settled on one millon, because Julian said no<br/>one would invest in a company with a valuation any lower. [6]  <br/>  <br/>What I didn't grasp at the time was that the valuation wasn't just the value<br/>of the code we'd written so far. It was also the value of our ideas, which<br/>turned out to be right, and of all the future work we'd do, which turned out<br/>to be a lot.  <br/>  <br/>The next round of funding is the one in which you might deal with actual<br/>venture capital firms. But don't wait till you've burned through your last<br/>round of funding to start approaching them. VCs are slow to make up their<br/>minds. They can take months. You don't want to be running out of money while<br/>you're trying to negotiate with them.  <br/>  <br/>Getting money from an actual VC firm is a bigger deal than getting money from<br/>angels. The amounts of money involved are larger, millions usually. So the<br/>deals take longer, dilute you more, and impose more onerous conditions.  <br/>  <br/>Sometimes the VCs want to install a new CEO of their own choosing. Usually the<br/>claim is that you need someone mature and experienced, with a business<br/>background. Maybe in some cases this is true. And yet Bill Gates was young and<br/>inexperienced and had no business background, and he seems to have done ok.<br/>Steve Jobs got booted out of his own company by someone mature and<br/>experienced, with a business background, who then proceeded to ruin the<br/>company. So I think people who are mature and experienced, with a business<br/>background, may be overrated. We used to call these guys "newscasters,"<br/>because they had neat hair and spoke in deep, confident voices, and generally<br/>didn't know much more than they read on the teleprompter.  <br/>  <br/>We talked to a number of VCs, but eventually we ended up financing our startup<br/>entirely with angel money. The main reason was that we feared a brand-name VC<br/>firm would stick us with a newscaster as part of the deal. That might have<br/>been ok if he was content to limit himself to talking to the press, but what<br/>if he wanted to have a say in running the company? That would have led to<br/>disaster, because our software was so complex. We were a company whose whole<br/>m.o. was to win through better technology. The strategic decisions were mostly<br/>decisions about technology, and we didn't need any help with those.  <br/>  <br/>This was also one reason we didn't go public. Back in 1998 our CFO tried to<br/>talk me into it. In those days you could go public as a dogfood portal, so as<br/>a company with a real product and real revenues, we might have done well. But<br/>I feared it would have meant taking on a newscaster-- someone who, as they<br/>say, "can talk Wall Street's language."  <br/>  <br/>I'm happy to see Google is bucking that trend. They didn't talk Wall Street's<br/>language when they did their IPO, and Wall Street didn't buy. And now Wall<br/>Street is collectively kicking itself. They'll pay attention next time. Wall<br/>Street learns new languages fast when money is involved.  <br/>  <br/>You have more leverage negotiating with VCs than you realize. The reason is<br/>other VCs. I know a number of VCs now, and when you talk to them you realize<br/>that it's a seller's market. Even now there is too much money chasing too few<br/>good deals.  <br/>  <br/>VCs form a pyramid. At the top are famous ones like Sequoia and Kleiner<br/>Perkins, but beneath those are a huge number you've never heard of. What they<br/>all have in common is that a dollar from them is worth one dollar. Most VCs<br/>will tell you that they don't just provide money, but connections and advice.<br/>If you're talking to Vinod Khosla or John Doerr or Mike Moritz, this is true.<br/>But such advice and connections can come very expensive. And as you go down<br/>the food chain the VCs get rapidly  dumber. A few steps down from the top<br/>you're basically talking to bankers who've picked up a few new vocabulary<br/>words from reading _Wired_. (Does your product use _XML?_ ) So I'd advise you<br/>to be skeptical about claims of experience and connections. Basically, a VC is<br/>a source of money. I'd be inclined to go with whoever offered the most money<br/>the soonest with the least strings attached.  <br/>  <br/>You may wonder how much to tell VCs. And you should, because some of them may<br/>one day be funding your competitors. I think the best plan is not to be<br/>overtly secretive, but not to tell them everything either. After all, as most<br/>VCs say, they're more interested in the people than the ideas. The main reason<br/>they want to talk about your idea is to judge you, not the idea. So as long as<br/>you seem like you know what you're doing, you can probably keep a few things<br/>back from them. [7]  <br/>  <br/>Talk to as many VCs as you can, even if you don't want their money, because a)<br/>they may be on the board of someone who will buy you, and b) if you seem<br/>impressive, they'll be discouraged from investing in your competitors. The<br/>most efficient way to reach VCs, especially if you only want them to know<br/>about you and don't want their money, is at the conferences that are<br/>occasionally organized for startups to present to them.  <br/>  <br/> **Not Spending It**  <br/>  <br/>When and if you get an infusion of real money from investors, what should you<br/>do with it? Not spend it, that's what. In nearly every startup that fails, the<br/>proximate cause is running out of money. Usually there is something deeper<br/>wrong. But even a proximate cause of death is worth trying hard to avoid.  <br/>  <br/>During the Bubble many startups tried to "get big fast." Ideally this meant<br/>getting a lot of customers fast. But it was easy for the meaning to slide over<br/>into hiring a lot of people fast.  <br/>  <br/>Of the two versions, the one where you get a lot of customers fast is of<br/>course preferable. But even that may be overrated. The idea is to get there<br/>first and get all the users, leaving none for competitors. But I think in most<br/>businesses the advantages of being first to market are not so overwhelmingly<br/>great. Google is again a case in point. When they appeared it seemed as if<br/>search was a mature market, dominated by big players who'd spent millions to<br/>build their brands: Yahoo, Lycos, Excite, Infoseek, Altavista, Inktomi. Surely<br/>1998 was a little late to arrive at the party.  <br/>  <br/>But as the founders of Google knew, brand is worth next to nothing in the<br/>search business. You can come along at any point and make something better,<br/>and users will gradually seep over to you. As if to emphasize the point,<br/>Google never did any advertising. They're like dealers; they sell the stuff,<br/>but they know better than to use it themselves.  <br/>  <br/>The competitors Google buried would have done better to spend those millions<br/>improving their software. Future startups should learn from that mistake.<br/>Unless you're in a market where products are as undifferentiated as cigarettes<br/>or vodka or laundry detergent, spending a lot on brand advertising is a sign<br/>of breakage. And few if any Web businesses are so undifferentiated. The dating<br/>sites are running big ad campaigns right now, which is all the more evidence<br/>they're ripe for the picking. (Fee, fie, fo, fum, I smell a company run by<br/>marketing guys.)  <br/>  <br/>We were compelled by circumstances to grow slowly, and in retrospect it was a<br/>good thing. The founders all learned to do every job in the company. As well<br/>as writing software, I had to do sales and customer support. At sales I was<br/>not very good. I was persistent, but I didn't have the smoothness of a good<br/>salesman. My message to potential customers was: you'd be stupid not to sell<br/>online, and if you sell online you'd be stupid to use anyone else's software.<br/>Both statements were true, but that's not the way to convince people.  <br/>  <br/>I was great at customer support though. Imagine talking to a customer support<br/>person who not only knew everything about the product, but would apologize<br/>abjectly if there was a bug, and then fix it immediately, while you were on<br/>the phone with them. Customers loved us. And we loved them, because when<br/>you're growing slow by word of mouth, your first batch of users are the ones<br/>who were smart enough to find you by themselves. There is nothing more<br/>valuable, in the early stages of a startup, than smart users. If you listen to<br/>them, they'll tell you exactly how to make a winning product. And not only<br/>will they give you this advice for free, they'll pay you.  <br/>  <br/>We officially launched in early 1996. By the end of that year we had about 70<br/>users. Since this was the era of "get big fast," I worried about how small and<br/>obscure we were. But in fact we were doing exactly the right thing. Once you<br/>get big (in users or employees) it gets hard to change your product. That year<br/>was effectively a laboratory for improving our software. By the end of it, we<br/>were so far ahead of our competitors that they never had a hope of catching<br/>up. And since all the hackers had spent many hours talking to users, we<br/>understood online commerce way better than anyone else.  <br/>  <br/>That's the key to success as a startup. There is nothing more important than<br/>understanding your business. You might think that anyone in a business must,<br/>ex officio, understand it. Far from it. Google's secret weapon was simply that<br/>they understood search. I was working for Yahoo when Google appeared, and<br/>Yahoo didn't understand search. I know because I once tried to convince the<br/>powers that be that we had to make search better, and I got in reply what was<br/>then the party line about it: that Yahoo was no longer a mere "search engine."<br/>Search was now only a small percentage of our page views, less than one<br/>month's growth, and now that we were established as a "media company," or<br/>"portal," or whatever we were, search could safely be allowed to wither and<br/>drop off, like an umbilical cord.  <br/>  <br/>Well, a small fraction of page views they may be, but they are an important<br/>fraction, because they are the page views that Web sessions start with. I<br/>think Yahoo gets that now.  <br/>  <br/>Google understands a few other things most Web companies still don't. The most<br/>important is that you should put users before advertisers, even though the<br/>advertisers are paying and users aren't. One of my favorite bumper stickers<br/>reads "if the people lead, the leaders will follow." Paraphrased for the Web,<br/>this becomes "get all the users, and the advertisers will follow." More<br/>generally, design your product to please users first, and then think about how<br/>to make money from it. If you don't put users first, you leave a gap for<br/>competitors who do.  <br/>  <br/>To make something users love, you have to understand them. And the bigger you<br/>are, the harder that is. So I say "get big slow." The slower you burn through<br/>your funding, the more time you have to learn.  <br/>  <br/>The other reason to spend money slowly is to encourage a culture of cheapness.<br/>That's something Yahoo did understand. David Filo's title was "Chief Yahoo,"<br/>but he was proud that his unofficial title was "Cheap Yahoo." Soon after we<br/>arrived at Yahoo, we got an email from Filo, who had been crawling around our<br/>directory hierarchy, asking if it was really necessary to store so much of our<br/>data on expensive RAID drives. I was impressed by that. Yahoo's market cap<br/>then was already in the billions, and they were still worrying about wasting a<br/>few gigs of disk space.  <br/>  <br/>When you get a couple million dollars from a VC firm, you tend to feel rich.<br/>It's important to realize you're not. A rich company is one with large<br/>revenues. This money isn't revenue. It's money investors have given you in the<br/>hope you'll be able to generate revenues. So despite those millions in the<br/>bank, you're still poor.  <br/>  <br/>For most startups the model should be grad student, not law firm. Aim for cool<br/>and cheap, not expensive and impressive. For us the test of whether a startup<br/>understood this was whether they had Aeron chairs. The Aeron came out during<br/>the Bubble and was very popular with startups. Especially the type, all too<br/>common then, that was like a bunch of kids playing house with money supplied<br/>by VCs. We had office chairs so cheap that the arms all fell off. This was<br/>slightly embarrassing at the time, but in retrospect the grad-studenty<br/>atmosphere of our office was another of those things we did right without<br/>knowing it.  <br/>  <br/>Our offices were in a wooden triple-decker in Harvard Square. It had been an<br/>apartment until about the 1970s, and there was still a claw-footed bathtub in<br/>the bathroom. It must once have been inhabited by someone fairly eccentric,<br/>because a lot of the chinks in the walls were stuffed with aluminum foil, as<br/>if to protect against cosmic rays. When eminent visitors came to see us, we<br/>were a bit sheepish about the low production values. But in fact that place<br/>was the perfect space for a startup. We felt like our role was to be impudent<br/>underdogs instead of corporate stuffed shirts, and that is exactly the spirit<br/>you want.  <br/>  <br/>An apartment is also the right kind of place for developing software. Cube<br/>farms suck for that, as you've probably discovered if you've tried it. Ever<br/>notice how much easier it is to hack at home than at work? So why not make<br/>work more like home?  <br/>  <br/>When you're looking for space for a startup, don't feel that it has to look<br/>professional. Professional means doing good work, not elevators and glass<br/>walls. I'd advise most startups to avoid corporate space at first and just<br/>rent an apartment. You want to live at the office in a startup, so why not<br/>have a place designed to be lived in as your office?  <br/>  <br/>Besides being cheaper and better to work in, apartments tend to be in better<br/>locations than office buildings. And for a startup location is very important.<br/>The key to productivity is for people to come back to work after dinner. Those<br/>hours after the phone stops ringing are by far the best for getting work done.<br/>Great things happen when a group of employees go out to dinner together, talk<br/>over ideas, and then come back to their offices to implement them. So you want<br/>to be in a place where there are a lot of restaurants around, not some dreary<br/>office park that's a wasteland after 6:00 PM. Once a company shifts over into<br/>the model where everyone drives home to the suburbs for dinner, however late,<br/>you've lost something extraordinarily valuable. God help you if you actually<br/>start in that mode.  <br/>  <br/>If I were going to start a startup today, there are only three places I'd<br/>consider doing it: on the Red Line near Central, Harvard, or Davis Squares<br/>(Kendall is too sterile); in Palo Alto on University or California Aves; and<br/>in Berkeley immediately north or south of campus. These are the only places I<br/>know that have the right kind of vibe.  <br/>  <br/>The most important way to not spend money is by not hiring people. I may be an<br/>extremist, but I think hiring people is the worst thing a company can do. To<br/>start with, people are a recurring expense, which is the worst kind. They also<br/>tend to cause you to grow out of your space, and perhaps even move to the sort<br/>of uncool office building that will make your software worse. But worst of<br/>all, they slow you down: instead of sticking your head in someone's office and<br/>checking out an idea with them, eight people have to have a meeting about it.<br/>So the fewer people you can hire, the better.  <br/>  <br/>During the Bubble a lot of startups had the opposite policy. They wanted to<br/>get "staffed up" as soon as possible, as if you couldn't get anything done<br/>unless there was someone with the corresponding job title. That's big company<br/>thinking. Don't hire people to fill the gaps in some a priori org chart. The<br/>only reason to hire someone is to do something you'd like to do but can't.  <br/>  <br/>If hiring unnecessary people is expensive and slows you down, why do nearly<br/>all companies do it? I think the main reason is that people like the idea of<br/>having a lot of people working for them. This weakness often extends right up<br/>to the CEO. If you ever end up running a company, you'll find the most common<br/>question people ask is how many employees you have. This is their way of<br/>weighing you. It's not just random people who ask this; even reporters do. And<br/>they're going to be a lot more impressed if the answer is a thousand than if<br/>it's ten.  <br/>  <br/>This is ridiculous, really. If two companies have the same revenues, it's the<br/>one with fewer employees that's more impressive. When people used to ask me<br/>how many people our startup had, and I answered "twenty," I could see them<br/>thinking that we didn't count for much. I used to want to add "but our main<br/>competitor, whose ass we regularly kick, has a hundred and forty, so can we<br/>have credit for the larger of the two numbers?"  <br/>  <br/>As with office space, the number of your employees is a choice between seeming<br/>impressive, and being impressive. Any of you who were nerds in high school<br/>know about this choice. Keep doing it when you start a company.  <br/>  <br/> **Should You?**  <br/>  <br/>But should you start a company? Are you the right sort of person to do it? If<br/>you are, is it worth it?  <br/>  <br/>More people are the right sort of person to start a startup than realize it.<br/>That's the main reason I wrote this. There could be ten times more startups<br/>than there are, and that would probably be a good thing.  <br/>  <br/>I was, I now realize, exactly the right sort of person to start a startup. But<br/>the idea terrified me at first. I was forced into it because I was a Lisp<br/>hacker. The company I'd been consulting for seemed to be running into trouble,<br/>and there were not a lot of other companies using Lisp. Since I couldn't bear<br/>the thought of programming in another language (this was 1995, remember, when<br/>"another language" meant C++) the only option seemed to be to start a new<br/>company using Lisp.  <br/>  <br/>I realize this sounds far-fetched, but if you're a Lisp hacker you'll know<br/>what I mean. And if the idea of starting a startup frightened me so much that<br/>I only did it out of necessity, there must be a lot of people who would be<br/>good at it but who are too intimidated to try.  <br/>  <br/>So who should start a startup? Someone who is a good hacker, between about 23<br/>and 38, and who wants to solve the money problem in one shot instead of<br/>getting paid gradually over a conventional working life.  <br/>  <br/>I can't say precisely what a good hacker is. At a first rate university this<br/>might include the top half of computer science majors. Though of course you<br/>don't have to be a CS major to be a hacker; I was a philosophy major in<br/>college.  <br/>  <br/>It's hard to tell whether you're a good hacker, especially when you're young.<br/>Fortunately the process of starting startups tends to select them<br/>automatically. What drives people to start startups is (or should be) looking<br/>at existing technology and thinking, don't these guys realize they should be<br/>doing x, y, and z? And that's also a sign that one is a good hacker.  <br/>  <br/>I put the lower bound at 23 not because there's something that doesn't happen<br/>to your brain till then, but because you need to see what it's like in an<br/>existing business before you try running your own. The business doesn't have<br/>to be a startup. I spent a year working for a software company to pay off my<br/>college loans. It was the worst year of my adult life, but I learned, without<br/>realizing it at the time, a lot of valuable lessons about the software<br/>business. In this case they were mostly negative lessons: don't have a lot of<br/>meetings; don't have chunks of code that multiple people own; don't have a<br/>sales guy running the company; don't make a high-end product; don't let your<br/>code get too big; don't leave finding bugs to QA people; don't go too long<br/>between releases; don't isolate developers from users; don't move from<br/>Cambridge to Route 128; and so on. [8] But negative lessons are just as<br/>valuable as positive ones. Perhaps even more valuable: it's hard to repeat a<br/>brilliant performance, but it's straightforward to avoid errors. [9]  <br/>  <br/>The other reason it's hard to start a company before 23 is that people won't<br/>take you seriously. VCs won't trust you, and will try to reduce you to a<br/>mascot as a condition of funding. Customers will worry you're going to flake<br/>out and leave them stranded. Even you yourself, unless you're very unusual,<br/>will feel your age to some degree; you'll find it awkward to be the boss of<br/>someone much older than you, and if you're 21, hiring only people younger<br/>rather limits your options.  <br/>  <br/>Some people could probably start a company at 18 if they wanted to. Bill Gates<br/>was 19 when he and Paul Allen started Microsoft. (Paul Allen was 22, though,<br/>and that probably made a difference.) So if you're thinking, I don't care what<br/>he says, I'm going to start a company now, you may be the sort of person who<br/>could get away with it.  <br/>  <br/>The other cutoff, 38, has a lot more play in it. One reason I put it there is<br/>that I don't think many people have the physical stamina much past that age. I<br/>used to work till 2:00 or 3:00 AM every night, seven days a week. I don't know<br/>if I could do that now.  <br/>  <br/>Also, startups are a big risk financially. If you try something that blows up<br/>and leaves you broke at 26, big deal; a lot of 26 year olds are broke. By 38<br/>you can't take so many risks-- especially if you have kids.  <br/>  <br/>My final test may be the most restrictive. Do you actually want to start a<br/>startup? What it amounts to, economically, is compressing your working life<br/>into the smallest possible space. Instead of working at an ordinary rate for<br/>40 years, you work like hell for four. And maybe end up with nothing-- though<br/>in that case it probably won't take four years.  <br/>  <br/>During this time you'll do little but work, because when you're not working,<br/>your competitors will be. My only leisure activities were running, which I<br/>needed to do to keep working anyway, and about fifteen minutes of reading a<br/>night. I had a girlfriend for a total of two months during that three year<br/>period. Every couple weeks I would take a few hours off to visit a used<br/>bookshop or go to a friend's house for dinner. I went to visit my family<br/>twice. Otherwise I just worked.  <br/>  <br/>Working was often fun, because the people I worked with were some of my best<br/>friends. Sometimes it was even technically interesting. But only about 10% of<br/>the time. The best I can say for the other 90% is that some of it is funnier<br/>in hindsight than it seemed then. Like the time the power went off in<br/>Cambridge for about six hours, and we made the mistake of trying to start a<br/>gasoline powered generator inside our offices. I won't try that again.  <br/>  <br/>I don't think the amount of bullshit you have to deal with in a startup is<br/>more than you'd endure in an ordinary working life. It's probably less, in<br/>fact; it just seems like a lot because it's compressed into a short period. So<br/>mainly what a startup buys you is time. That's the way to think about it if<br/>you're trying to decide whether to start one. If you're the sort of person who<br/>would like to solve the money problem once and for all instead of working for<br/>a salary for 40 years, then a startup makes sense.  <br/>  <br/>For a lot of people the conflict is between startups and graduate school. Grad<br/>students are just the age, and just the sort of people, to start software<br/>startups. You may worry that if you do you'll blow your chances of an academic<br/>career. But it's possible to be part of a startup and stay in grad school,<br/>especially at first. Two of our three original hackers were in grad school the<br/>whole time, and both got their degrees. There are few sources of energy so<br/>powerful as a procrastinating grad student.  <br/>  <br/>If you do have to leave grad school, in the worst case it won't be for too<br/>long. If a startup fails, it will probably fail quickly enough that you can<br/>return to academic life. And if it succeeds, you may find you no longer have<br/>such a burning desire to be an assistant professor.  <br/>  <br/>If you want to do it, do it. Starting a startup is not the great mystery it<br/>seems from outside. It's not something you have to know about "business" to<br/>do. Build something users love, and spend less than you make. How hard is<br/>that?  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Google's revenues are about two billion a year, but half comes from ads on<br/>other sites.  <br/>  <br/>[2] One advantage startups have over established companies is that there are<br/>no discrimination laws about starting businesses. For example, I would be<br/>reluctant to start a startup with a woman who had small children, or was<br/>likely to have them soon. But you're not allowed to ask prospective employees<br/>if they plan to have kids soon. Believe it or not, under current US law,<br/>you're not even allowed to discriminate on the basis of intelligence. Whereas<br/>when you're starting a company, you can discriminate on any basis you want<br/>about who you start it with.  <br/>  <br/>[3] Learning to hack is a lot cheaper than business school, because you can do<br/>it mostly on your own. For the price of a Linux box, a copy of K&R, and a few<br/>hours of advice from your neighbor's fifteen year old son, you'll be well on<br/>your way.  <br/>  <br/>[4] Corollary: Avoid starting a startup to sell things to the biggest company<br/>of all, the government. Yes, there are lots of opportunities to sell them<br/>technology. But let someone else start those startups.  <br/>  <br/>[5] A friend who started a company in Germany told me they do care about the<br/>paperwork there, and that there's more of it. Which helps explain why there<br/>are not more startups in Germany.  <br/>  <br/>[6] At the seed stage our valuation was in principle $100,000, because Julian<br/>got 10% of the company. But this is a very misleading number, because the<br/>money was the least important of the things Julian gave us.  <br/>  <br/>[7] The same goes for companies that seem to want to acquire you. There will<br/>be a few that are only pretending to in order to pick your brains. But you can<br/>never tell for sure which these are, so the best approach is to seem entirely<br/>open, but to fail to mention a few critical technical secrets.  <br/>  <br/>[8] I was as bad an employee as this place was a company. I apologize to<br/>anyone who had to work with me there.  <br/>  <br/>[9] You could probably write a book about how to succeed in business by doing<br/>everything in exactly the opposite way from the DMV.  <br/>  <br/> **Thanks** to Trevor Blackwell, Sarah Harlin, Jessica Livingston, and Robert<br/>Morris for reading drafts of this essay, and to Steve Melendez and Gregory<br/>Price for inviting me to speak.  <br/>  <br/><br/>Domain Name Search  <br/>  <br/><br/>Turkish Translation  <br/>  <br/><br/>Hebrew Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Chinese Translation  <br/>  <br/><br/>French Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>August 2007  <br/>  <br/> _(This is a talk I gave at the last Y Combinator dinner of the summer.<br/>Usually we don't have a speaker at the last dinner; it's more of a party. But<br/>it seemed worth spoiling the atmosphere if I could save some of the startups<br/>from preventable deaths. So at the last minute I cooked up this rather grim<br/>talk. I didn't mean this as an essay; I wrote it down because I only had two<br/>hours before dinner and think fastest while writing.)_  <br/>  <br/>A couple days ago I told a reporter that we expected about a third of the<br/>companies we funded to succeed. Actually I was being conservative. I'm hoping<br/>it might be as much as a half. Wouldn't it be amazing if we could achieve a<br/>50% success rate?  <br/>  <br/>Another way of saying that is that half of you are going to die. Phrased that<br/>way, it doesn't sound good at all. In fact, it's kind of weird when you think<br/>about it, because our definition of success is that the founders get rich. If<br/>half the startups we fund succeed, then half of you are going to get rich and<br/>the other half are going to get nothing.  <br/>  <br/>If you can just avoid dying, you get rich. That sounds like a joke, but it's<br/>actually a pretty good description of what happens in a typical startup. It<br/>certainly describes what happened in Viaweb. We avoided dying till we got<br/>rich.  <br/>  <br/>It was really close, too. When we were visiting Yahoo to talk about being<br/>acquired, we had to interrupt everything and borrow one of their conference<br/>rooms to talk down an investor who was about to back out of a new funding<br/>round we needed to stay alive. So even in the middle of getting rich we were<br/>fighting off the grim reaper.  <br/>  <br/>You may have heard that quote about luck consisting of opportunity meeting<br/>preparation. You've now done the preparation. The work you've done so far has,<br/>in effect, put you in a position to get lucky: you can now get rich by not<br/>letting your company die. That's more than most people have. So let's talk<br/>about how not to die.  <br/>  <br/>We've done this five times now, and we've seen a bunch of startups die. About<br/>10 of them so far. We don't know exactly what happens when they die, because<br/>they generally don't die loudly and heroically. Mostly they crawl off<br/>somewhere and die.  <br/>  <br/>For us the main indication of impending doom is when we don't hear from you.<br/>When we haven't heard from, or about, a startup for a couple months, that's a<br/>bad sign. If we send them an email asking what's up, and they don't reply,<br/>that's a really bad sign. So far that is a 100% accurate predictor of death.  <br/>  <br/>Whereas if a startup regularly does new deals and releases and either sends us<br/>mail or shows up at YC events, they're probably going to live.  <br/>  <br/>I realize this will sound naive, but maybe the linkage works in both<br/>directions. Maybe if you can arrange that we keep hearing from you, you won't<br/>die.  <br/>  <br/>That may not be so naive as it sounds. You've probably noticed that having<br/>dinners every Tuesday with us and the other founders causes you to get more<br/>done than you would otherwise, because every dinner is a mini Demo Day. Every<br/>dinner is a kind of a deadline. So the mere constraint of staying in regular<br/>contact with us will push you to make things happen, because otherwise you'll<br/>be embarrassed to tell us that you haven't done anything new since the last<br/>time we talked.  <br/>  <br/>If this works, it would be an amazing hack. It would be pretty cool if merely<br/>by staying in regular contact with us you could get rich. It sounds crazy, but<br/>there's a good chance that would work.  <br/>  <br/>A variant is to stay in touch with other YC-funded startups. There is now a<br/>whole neighborhood of them in San Francisco. If you move there, the peer<br/>pressure that made you work harder all summer will continue to operate.  <br/>  <br/>When startups die, the official cause of death is always either running out of<br/>money or a critical founder bailing. Often the two occur simultaneously. But I<br/>think the underlying cause is usually that they've become demoralized. You<br/>rarely hear of a startup that's working around the clock doing deals and<br/>pumping out new features, and dies because they can't pay their bills and<br/>their ISP unplugs their server.  <br/>  <br/>Startups rarely die in mid keystroke. So keep typing!  <br/>  <br/>If so many startups get demoralized and fail when merely by hanging on they<br/>could get rich, you have to assume that running a startup can be demoralizing.<br/>That is certainly true. I've been there, and that's why I've never done<br/>another startup. The low points in a startup are just unbelievably low. I bet<br/>even Google had moments where things seemed hopeless.  <br/>  <br/>Knowing that should help. If you know it's going to feel terrible sometimes,<br/>then when it feels terrible you won't think "ouch, this feels terrible, I give<br/>up." It feels that way for everyone. And if you just hang on, things will<br/>probably get better. The metaphor people use to describe the way a startup<br/>feels is at least a roller coaster and not drowning. You don't just sink and<br/>sink; there are ups after the downs.  <br/>  <br/>Another feeling that seems alarming but is in fact normal in a startup is the<br/>feeling that what you're doing isn't working. The reason you can expect to<br/>feel this is that what you do probably won't work. Startups almost never get<br/>it right the first time. Much more commonly you launch something, and no one<br/>cares. Don't assume when this happens that you've failed. That's normal for<br/>startups. But don't sit around doing nothing. Iterate.  <br/>  <br/>I like Paul Buchheit's suggestion of trying to make something that at least<br/>someone really loves. As long as you've made something that a few users are<br/>ecstatic about, you're on the right track. It will be good for your morale to<br/>have even a handful of users who really love you, and startups run on morale.<br/>But also it will tell you what to focus on. What is it about you that they<br/>love? Can you do more of that? Where can you find more people who love that<br/>sort of thing? As long as you have some core of users who love you, all you<br/>have to do is expand it. It may take a while, but as long as you keep plugging<br/>away, you'll win in the end. Both Blogger and Delicious did that. Both took<br/>years to succeed. But both began with a core of fanatically devoted users, and<br/>all Evan and Joshua had to do was grow that core incrementally. Wufoo is on<br/>the same trajectory now.  <br/>  <br/>So when you release something and it seems like no one cares, look more<br/>closely. Are there zero users who really love you, or is there at least some<br/>little group that does? It's quite possible there will be zero. In that case,<br/>tweak your product and try again. Every one of you is working on a space that<br/>contains at least one winning permutation somewhere in it. If you just keep<br/>trying, you'll find it.  <br/>  <br/>Let me mention some things not to do. The number one thing not to do is other<br/>things. If you find yourself saying a sentence that ends with "but we're going<br/>to keep working on the startup," you are in big trouble. Bob's going to grad<br/>school, but we're going to keep working on the startup. We're moving back to<br/>Minnesota, but we're going to keep working on the startup. We're taking on<br/>some consulting projects, but we're going to keep working on the startup. You<br/>may as well just translate these to "we're giving up on the startup, but we're<br/>not willing to admit that to ourselves," because that's what it means most of<br/>the time. A startup is so hard that working on it can't be preceded by "but."  <br/>  <br/>In particular, don't go to graduate school, and don't start other projects.<br/>Distraction is fatal to startups. Going to (or back to) school is a huge<br/>predictor of death because in addition to the distraction it gives you<br/>something to say you're doing. If you're only doing a startup, then if the<br/>startup fails, you fail. If you're in grad school and your startup fails, you<br/>can say later "Oh yeah, we had this startup on the side when I was in grad<br/>school, but it didn't go anywhere."  <br/>  <br/>You can't use euphemisms like "didn't go anywhere" for something that's your<br/>only occupation. People won't let you.  <br/>  <br/>One of the most interesting things we've discovered from working on Y<br/>Combinator is that founders are more motivated by the fear of looking bad than<br/>by the hope of getting millions of dollars. So if you want to get millions of<br/>dollars, put yourself in a position where failure will be public and<br/>humiliating.  <br/>  <br/>When we first met the founders of Octopart, they seemed very smart, but not a<br/>great bet to succeed, because they didn't seem especially committed. One of<br/>the two founders was still in grad school. It was the usual story: he'd drop<br/>out if it looked like the startup was taking off. Since then he has not only<br/>dropped out of grad school, but appeared full length in Newsweek with the word<br/>"Billionaire" printed across his chest. He just cannot fail now. Everyone he<br/>knows has seen that picture. Girls who dissed him in high school have seen it.<br/>His mom probably has it on the fridge. It would be unthinkably humiliating to<br/>fail now. At this point he is committed to fight to the death.  <br/>  <br/>I wish every startup we funded could appear in a Newsweek article describing<br/>them as the next generation of billionaires, because then none of them would<br/>be able to give up. The success rate would be 90%. I'm not kidding.  <br/>  <br/>When we first knew the Octoparts they were lighthearted, cheery guys. Now when<br/>we talk to them they seem grimly determined. The electronic parts distributors<br/>are trying to squash them to keep their monopoly pricing. (If it strikes you<br/>as odd that people still order electronic parts out of thick paper catalogs in<br/>2007, there's a reason for that. The distributors want to prevent the<br/>transparency that comes from having prices online.) I feel kind of bad that<br/>we've transformed these guys from lighthearted to grimly determined. But that<br/>comes with the territory. If a startup succeeds, you get millions of dollars,<br/>and you don't get that kind of money just by asking for it. You have to assume<br/>it takes some amount of pain.  <br/>  <br/>And however tough things get for the Octoparts, I predict they'll succeed.<br/>They may have to morph themselves into something totally different, but they<br/>won't just crawl off and die. They're smart; they're working in a promising<br/>field; and they just cannot give up.  <br/>  <br/>All of you guys already have the first two. You're all smart and working on<br/>promising ideas. Whether you end up among the living or the dead comes down to<br/>the third ingredient, not giving up.  <br/>  <br/>So I'll tell you now: bad shit is coming. It always is in a startup. The odds<br/>of getting from launch to liquidity without some kind of disaster happening<br/>are one in a thousand. So don't get demoralized. When the disaster strikes,<br/>just say to yourself, ok, this was what Paul was talking about. What did he<br/>say to do? Oh, yeah. Don't give up.  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Arabic Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>July 2008  <br/>  <br/>At this year's startup school, David Heinemeier Hansson gave a talk in which<br/>he suggested that startup founders should do things the old fashioned way.<br/>Instead of hoping to get rich by building a valuable company and then selling<br/>stock in a "liquidity event," founders should start companies that make money<br/>and live off the revenues.  <br/>  <br/>Sounds like a good plan. Let's think about the optimal way to do this.  <br/>  <br/>One disadvantage of living off the revenues of your company is that you have<br/>to keep running it. And as anyone who runs their own business can tell you,<br/>that requires your complete attention. You can't just start a business and<br/>check out once things are going well, or they stop going well surprisingly<br/>fast.  <br/>  <br/>The main economic motives of startup founders seem to be freedom and security.<br/>They want enough money that (a) they don't have to worry about running out of<br/>money and (b) they can spend their time how they want. Running your own<br/>business offers neither. You certainly don't have freedom: no boss is so<br/>demanding. Nor do you have security, because if you stop paying attention to<br/>the company, its revenues go away, and with them your income.  <br/>  <br/>The best case, for most people, would be if you could hire someone to manage<br/>the company for you once you'd grown it to a certain size. Suppose you could<br/>find a really good manager. Then you would have both freedom and security. You<br/>could pay as little attention to the business as you wanted, knowing that your<br/>manager would keep things running smoothly. And that being so, revenues would<br/>continue to flow in, so you'd have security as well.  <br/>  <br/>There will of course be some founders who wouldn't like that idea: the ones<br/>who like running their company so much that there's nothing else they'd rather<br/>do. But this group must be small. The way you succeed in most businesses is to<br/>be fanatically attentive to customers' needs. What are the odds that your own<br/>desires would coincide exactly with the demands of this powerful, external<br/>force?  <br/>  <br/>Sure, running your own company can be fairly interesting. Viaweb was more<br/>interesting than any job I'd had before. And since I made much more money from<br/>it, it offered the highest ratio of income to boringness of anything I'd done,<br/>by orders of magnitude. But was it _the_ most interesting work I could imagine<br/>doing? No.  <br/>  <br/>Whether the number of founders in the same position is asymptotic or merely<br/>large, there are certainly a lot of them. For them the right approach would be<br/>to hand the company over to a professional manager eventually, if they could<br/>find one who was good enough.  <br/>  <br/>_____  <br/>  <br/>So far so good. But what if your manager was hit by a bus? What you really<br/>want is a management company to run your company for you. Then you don't<br/>depend on any one person.  <br/>  <br/>If you own rental property, there are companies you can hire to manage it for<br/>you. Some will do everything, from finding tenants to fixing leaks. Of course,<br/>running companies is a lot more complicated than managing rental property, but<br/>let's suppose there were management companies that could do it for you. They'd<br/>charge a lot, but wouldn't it be worth it? I'd sacrifice a large percentage of<br/>the income for the extra peace of mind.  <br/>  <br/>I realize what I'm describing already sounds too good to be true, but I can<br/>think of a way to make it even more attractive. If company management<br/>companies existed, there would be an additional service they could offer<br/>clients: they could let them insure their returns by pooling their risk. After<br/>all, even a perfect manager can't save a company when, as sometimes happens,<br/>its whole market dies, just as property managers can't save you from the<br/>building burning down. But a company that managed a large enough number of<br/>companies could say to all its clients: we'll combine the revenues from all<br/>your companies, and pay you your proportionate share.  <br/>  <br/>If such management companies existed, they'd offer the maximum of freedom and<br/>security. Someone would run your company for you, and you'd be protected even<br/>if it happened to die.  <br/>  <br/>Let's think about how such a management company might be organized. The<br/>simplest way would be to have a new kind of stock representing the total pool<br/>of companies they were managing. When you signed up, you'd trade your<br/>company's stock for shares of this pool, in proportion to an estimate of your<br/>company's value that you'd both agreed upon. Then you'd automatically get your<br/>share of the returns of the whole pool.  <br/>  <br/>The catch is that because this kind of trade would be hard to undo, you<br/>couldn't switch management companies. But there's a way they could fix that:<br/>suppose all the company management companies got together and agreed to allow<br/>their clients to exchange shares in all their pools. Then you could, in<br/>effect, simultaneously choose all the management companies to run yours for<br/>you, in whatever proportion you wanted, and change your mind later as often as<br/>you wanted.  <br/>  <br/>If such pooled-risk company management companies existed, signing up with one<br/>would seem the ideal plan for most people following the route David advocated.  <br/>  <br/>Good news: they do exist. What I've just described is an acquisition by a<br/>public company.  <br/>  <br/>_____  <br/>  <br/>Unfortunately, though public acquirers are structurally identical to pooled-<br/>risk company management companies, they don't think of themselves that way.<br/>With a property management company, you can just walk in whenever you want and<br/>say "manage my rental property for me" and they'll do it. Whereas acquirers<br/>are, as of this writing, extremely fickle. Sometimes they're in a buying mood<br/>and they'll overpay enormously; other times they're not interested. They're<br/>like property management companies run by madmen. Or more precisely, by<br/>Benjamin Graham's Mr. Market.  <br/>  <br/>So while on average public acquirers behave like pooled-risk company managers,<br/>you need a window of several years to get average case performance. If you<br/>wait long enough (five years, say) you're likely to hit an up cycle where some<br/>acquirer is hot to buy you. But you can't choose when it happens.  <br/>  <br/>You can't assume investors will carry you for as long as you might have to<br/>wait. Your company has to make money. Opinions are divided about how early to<br/>focus on that. Joe Kraus says you should try charging customers right away.<br/>And yet some of the most successful startups, including Google, ignored<br/>revenue at first and concentrated exclusively on development. The answer<br/>probably depends on the type of company you're starting. I can imagine some<br/>where trying to make sales would be a good heuristic for product design, and<br/>others where it would just be a distraction. The test is probably whether it<br/>helps you to understand your users.  <br/>  <br/>You can choose whichever revenue strategy you think is best for the type of<br/>company you're starting, so long as you're profitable. Being profitable<br/>ensures you'll get at least the average of the acquisition market—in which<br/>public companies do behave as pooled-risk company management companies.  <br/>  <br/>David isn't mistaken in saying you should start a company to live off its<br/>revenues. The mistake is thinking this is somehow opposed to starting a<br/>company and selling it. In fact, for most people the latter is merely the<br/>optimal case of the former.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Thanks** to Trevor Blackwell, Jessica Livingston, Michael Mandel, Robert<br/>Morris, and Fred Wilson for reading drafts of this.  <br/>  <br/>  <br/>  <br/><br/>Russian Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>October 2009  <br/>  <br/> _(This essay is derived from a talk at the 2009 Startup School.)_  <br/>  <br/>I wasn't sure what to talk about at Startup School, so I decided to ask the<br/>founders of the startups we'd funded. What hadn't I written about yet?  <br/>  <br/>I'm in the unusual position of being able to test the essays I write about<br/>startups. I hope the ones on other topics are right, but I have no way to test<br/>them. The ones on startups get tested by about 70 people every 6 months.  <br/>  <br/>So I sent all the founders an email asking what surprised them about starting<br/>a startup. This amounts to asking what I got wrong, because if I'd explained<br/>things well enough, nothing should have surprised them.  <br/>  <br/>I'm proud to report I got one response saying:<br/><br/>> What surprised me the most is that everything was actually fairly<br/>> predictable!<br/><br/>The bad news is that I got over 100 other responses listing the surprises they<br/>encountered.  <br/>  <br/>There were very clear patterns in the responses; it was remarkable how often<br/>several people had been surprised by exactly the same thing. These were the<br/>biggest:  <br/>  <br/>**1\. Be Careful with Cofounders**  <br/>  <br/>This was the surprise mentioned by the most founders. There were two types of<br/>responses: that you have to be careful who you pick as a cofounder, and that<br/>you have to work hard to maintain your relationship.  <br/>  <br/>What people wished they'd paid more attention to when choosing cofounders was<br/>character and commitment, not ability. This was particularly true with<br/>startups that failed. The lesson: don't pick cofounders who will flake.  <br/>  <br/>Here's a typical reponse:<br/><br/>> You haven't seen someone's true colors unless you've worked with them on a<br/>> startup.<br/><br/>The reason character is so important is that it's tested more severely than in<br/>most other situations. One founder said explicitly that the relationship<br/>between founders was more important than ability:<br/><br/>> I would rather cofound a startup with a friend than a stranger with higher<br/>> output. Startups are so hard and emotional that the bonds and emotional and<br/>> social support that come with friendship outweigh the extra output lost.<br/><br/>We learned this lesson a long time ago. If you look at the YC application,<br/>there are more questions about the commitment and relationship of the founders<br/>than their ability.  <br/>  <br/>Founders of successful startups talked less about choosing cofounders and more<br/>about how hard they worked to maintain their relationship.<br/><br/>> One thing that surprised me is how the relationship of startup founders goes<br/>> from a friendship to a marriage. My relationship with my cofounder went from<br/>> just being friends to seeing each other all the time, fretting over the<br/>> finances and cleaning up shit. And the startup was our baby. I summed it up<br/>> once like this: "It's like we're married, but we're not fucking."<br/><br/>Several people used that word "married." It's a far more intense relationship<br/>than you usually see between coworkers—partly because the stresses are so much<br/>greater, and partly because at first the founders are the whole company. So<br/>this relationship has to be built of top quality materials and carefully<br/>maintained. It's the basis of everything.  <br/>  <br/>**2\. Startups Take Over Your Life**  <br/>  <br/>Just as the relationship between cofounders is more intense than it usually is<br/>between coworkers, so is the relationship between the founders and the<br/>company. Running a startup is not like having a job or being a student,<br/>because it never stops. This is so foreign to most people's experience that<br/>they don't get it till it happens. [1]<br/><br/>> I didn't realize I would spend almost every waking moment either working or<br/>> thinking about our startup. You enter a whole different way of life when<br/>> it's your company vs. working for someone else's company.<br/><br/>It's exacerbated by the fast pace of startups, which makes it seem like time<br/>slows down:<br/><br/>> I think the thing that's been most surprising to me is how one's perspective<br/>> on time shifts. Working on our startup, I remember time seeming to stretch<br/>> out, so that a month was a huge interval.<br/><br/>In the best case, total immersion can be exciting:<br/><br/>> It's surprising how much you become consumed by your startup, in that you<br/>> think about it day and night, but never once does it feel like "work."<br/><br/>Though I have to say, that quote is from someone we funded this summer. In a<br/>couple years he may not sound so chipper.  <br/>  <br/>**3\. It's an Emotional Roller-coaster**  <br/>  <br/>This was another one lots of people were surprised about. The ups and downs<br/>were more extreme than they were prepared for.  <br/>  <br/>In a startup, things seem great one moment and hopeless the next. And by next,<br/>I mean a couple hours later.<br/><br/>> The emotional ups and downs were the biggest surprise for me. One day, we'd<br/>> think of ourselves as the next Google and dream of buying islands; the next,<br/>> we'd be pondering how to let our loved ones know of our utter failure; and<br/>> on and on.<br/><br/>The hard part, obviously, is the lows. For a lot of founders that was the big<br/>surprise:<br/><br/>> How hard it is to keep everyone motivated during rough days or weeks, i.e.<br/>> how low the lows can be.<br/><br/>After a while, if you don't have significant success to cheer you up, it wears<br/>you out:<br/><br/>> Your most basic advice to founders is "just don't die," but the energy to<br/>> keep a company going in lieu of unburdening success isn't free; it is<br/>> siphoned from the founders themselves.<br/><br/>There's a limit to how much you can take. If you get to the point where you<br/>can't keep working anymore, it's not the end of the world. Plenty of famous<br/>founders have had some failures along the way.  <br/>  <br/>**4\. It Can Be Fun**  <br/>  <br/>The good news is, the highs are also very high. Several founders said what<br/>surprised them most about doing a startup was how fun it was:<br/><br/>> I think you've left out just how fun it is to do a startup. I am more<br/>> fulfilled in my work than pretty much any of my friends who did not start<br/>> companies.<br/><br/>What they like most is the freedom:<br/><br/>> I'm surprised by how much better it feels to be working on something that is<br/>> challenging and creative, something I believe in, as opposed to the hired-<br/>> gun stuff I was doing before. I knew it would feel better; what's surprising<br/>> is how much better.<br/><br/>Frankly, though, if I've misled people here, I'm not eager to fix that. I'd<br/>rather have everyone think starting a startup is grim and hard than have<br/>founders go into it expecting it to be fun, and a few months later saying<br/>"This is supposed to be _fun_? Are you kidding?"  <br/>  <br/>The truth is, it wouldn't be fun for most people. A lot of what we try to do<br/>in the application process is to weed out the people who wouldn't like it,<br/>both for our sake and theirs.  <br/>  <br/>The best way to put it might be that starting a startup is fun the way a<br/>survivalist training course would be fun, if you're into that sort of thing.<br/>Which is to say, not at all, if you're not.  <br/>  <br/>**5\. Persistence Is the Key**  <br/>  <br/>A lot of founders were surprised how important persistence was in startups. It<br/>was both a negative and a positive surprise: they were surprised both by the<br/>degree of persistence required<br/><br/>> Everyone said how determined and resilient you must be, but going through it<br/>> made me realize that the determination required was still understated.<br/><br/>and also by the degree to which persistence alone was able to dissolve<br/>obstacles:<br/><br/>> If you are persistent, even problems that seem out of your control (i.e.<br/>> immigration) seem to work themselves out.<br/><br/>Several founders mentioned specifically how much more important persistence<br/>was than intelligence.<br/><br/>> I've been surprised again and again by just how much more important<br/>> persistence is than raw intelligence.<br/><br/>This applies not just to intelligence but to ability in general, and that's<br/>why so many people said character was more important in choosing cofounders.  <br/>  <br/>**6\. Think Long-Term**  <br/>  <br/>You need persistence because everything takes longer than you expect. A lot of<br/>people were surprised by that.<br/><br/>> I'm continually surprised by how long everything can take. Assuming your<br/>> product doesn't experience the explosive growth that very few products do,<br/>> everything from development to dealmaking (especially dealmaking) seems to<br/>> take 2-3x longer than I always imagine.<br/><br/>One reason founders are surprised is that because they work fast, they expect<br/>everyone else to. There's a shocking amount of shear stress at every point<br/>where a startup touches a more bureaucratic organization, like a big company<br/>or a VC fund. That's why fundraising and the enterprise market kill and maim<br/>so many startups. [2]  <br/>  <br/>But I think the reason most founders are surprised by how long it takes is<br/>that they're overconfident. They think they're going to be an instant success,<br/>like YouTube or Facebook. You tell them only 1 out of 100 successful startups<br/>has a trajectory like that, and they all think "we're going to be that 1."  <br/>  <br/>Maybe they'll listen to one of the more successful founders:<br/><br/>> The top thing I didn't understand before going into it is that persistence<br/>> is the name of the game. For the vast majority of startups that become<br/>> successful, it's going to be a _really_ long journey, at least 3 years and<br/>> probably 5+.<br/><br/>There is a positive side to thinking longer-term. It's not just that you have<br/>to resign yourself to everything taking longer than it should. If you work<br/>patiently it's less stressful, and you can do better work:<br/><br/>> Because we're relaxed, it's so much easier to have fun doing what we do.<br/>> Gone is the awkward nervous energy fueled by the desperate need to not fail<br/>> guiding our actions. We can concentrate on doing what's best for our<br/>> company, product, employees and customers.<br/><br/>That's why things get so much better when you hit ramen profitability. You can<br/>shift into a different mode of working.  <br/>  <br/> **7\. Lots of Little Things**  <br/>  <br/>We often emphasize how rarely startups win simply because they hit on some<br/>magic idea. I think founders have now gotten that into their heads. But a lot<br/>were surprised to find this also applies within startups. You have to do lots<br/>of different things:<br/><br/>> It's much more of a grind than glamorous. A timeslice selected at random<br/>> would more likely find me tracking down a weird DLL loading bug on Swedish<br/>> Windows, or tracking down a bug in the financial model Excel spreadsheet the<br/>> night before a board meeting, rather than having brilliant flashes of<br/>> strategic insight.<br/><br/>Most hacker-founders would like to spend all their time programming. You won't<br/>get to, unless you fail. Which can be transformed into: If you spend all your<br/>time programming, you will fail.  <br/>  <br/>The principle extends even into programming. There is rarely a single<br/>brilliant hack that ensures success:<br/><br/>> I learnt never to bet on any one feature or deal or anything to bring you<br/>> success. It is never a single thing. Everything is just incremental and you<br/>> just have to keep doing lots of those things until you strike something.<br/><br/>Even in the rare cases where a clever hack makes your fortune, you probably<br/>won't know till later:<br/><br/>> There is no such thing as a killer feature. Or at least you won't know what<br/>> it is.<br/><br/>So the best strategy is to try lots of different things. The reason not to put<br/>all your eggs in one basket is not the usual one, which applies even when you<br/>know which basket is best. In a startup you don't even know that.  <br/>  <br/>**8\. Start with Something Minimal**  <br/>  <br/>Lots of founders mentioned how important it was to launch with the simplest<br/>possible thing. By this point everyone knows you should release fast and<br/>iterate. It's practically a mantra at YC. But even so a lot of people seem to<br/>have been burned by not doing it:<br/><br/>> Build the absolute smallest thing that can be considered a complete<br/>> application and ship it.<br/><br/>Why do people take too long on the first version? Pride, mostly. They hate to<br/>release something that could be better. They worry what people will say about<br/>them. But you have to overcome this:<br/><br/>> Doing something "simple" at first glance does not mean you aren't doing<br/>> something meaningful, defensible, or valuable.<br/><br/>Don't worry what people will say. If your first version is so impressive that<br/>trolls don't make fun of it, you waited too long to launch. [3]  <br/>  <br/>One founder said this should be your approach to all programming, not just<br/>startups, and I tend to agree.<br/><br/>> Now, when coding, I try to think "How can I write this such that if people<br/>> saw my code, they'd be amazed at how little there is and how little it<br/>> does?"<br/><br/>Over-engineering is poison. It's not like doing extra work for extra credit.<br/>It's more like telling a lie that you then have to remember so you don't<br/>contradict it.  <br/>  <br/>**9\. Engage Users**  <br/>  <br/>Product development is a conversation with the user that doesn't really start<br/>till you launch. Before you launch, you're like a police artist before he's<br/>shown the first version of his sketch to the witness.  <br/>  <br/>It's so important to launch fast that it may be better to think of your<br/>initial version not as a product, but as a trick for getting users to start<br/>talking to you.<br/><br/>> I learned to think about the initial stages of a startup as a giant<br/>> experiment. All products should be considered experiments, and those that<br/>> have a market show promising results extremely quickly.<br/><br/>Once you start talking to users, I guarantee you'll be surprised by what they<br/>tell you.<br/><br/>> When you let customers tell you what they're after, they will often reveal<br/>> amazing details about what they find valuable as well what they're willing<br/>> to pay for.<br/><br/>The surprise is generally positive as well as negative. They won't like what<br/>you've built, but there will be other things they would like that would be<br/>trivially easy to implement. It's not till you start the conversation by<br/>launching the wrong thing that they can express (or perhaps even realize) what<br/>they're looking for.  <br/>  <br/>**10\. Change Your Idea**  <br/>  <br/>To benefit from engaging with users you have to be willing to change your<br/>idea. We've always encouraged founders to see a startup idea as a hypothesis<br/>rather than a blueprint. And yet they're still surprised how well it works to<br/>change the idea.<br/><br/>> Normally if you complain about something being hard, the general advice is<br/>> to work harder. With a startup, I think you should find a problem that's<br/>> easy for you to solve. Optimizing in solution-space is familiar and<br/>> straightforward, but you can make enormous gains playing around in problem-<br/>> space.<br/><br/>Whereas mere determination, without flexibility, is a greedy algorithm that<br/>may get you nothing more than a mediocre local maximum:<br/><br/>> When someone is determined, there's still a danger that they'll follow a<br/>> long, hard path that ultimately leads nowhere.<br/><br/>You want to push forward, but at the same time twist and turn to find the most<br/>promising path. One founder put it very succinctly:<br/><br/>> Fast iteration is the key to success.<br/><br/>One reason this advice is so hard to follow is that people don't realize how<br/>hard it is to judge startup ideas, particularly their own. Experienced<br/>founders learn to keep an open mind:<br/><br/>> Now I don't laugh at ideas anymore, because I realized how terrible I was at<br/>> knowing if they were good or not.<br/><br/>You can never tell what will work. You just have to do whatever seems best at<br/>each point. We do this with YC itself. We still don't know if it will work,<br/>but it seems like a decent hypothesis.  <br/>  <br/>**11\. Don't Worry about Competitors**  <br/>  <br/>When you think you've got a great idea, it's sort of like having a guilty<br/>conscience about something. All someone has to do is look at you funny, and<br/>you think "Oh my God, _they know._ "  <br/>  <br/>These alarms are almost always false:<br/><br/>> Companies that seemed like competitors and threats at first glance usually<br/>> never were when you really looked at it. Even if they were operating in the<br/>> same area, they had a different goal.<br/><br/>One reason people overreact to competitors is that they overvalue ideas. If<br/>ideas really were the key, a competitor with the same idea would be a real<br/>threat. But it's usually execution that matters:<br/><br/>> All the scares induced by seeing a new competitor pop up are forgotten weeks<br/>> later. It always comes down to your own product and approach to the market.<br/><br/>This is generally true even if competitors get lots of attention.<br/><br/>> Competitors riding on lots of good blogger perception aren't really the<br/>> winners and can disappear from the map quickly. You need consumers after<br/>> all.<br/><br/>Hype doesn't make satisfied users, at least not for something as complicated<br/>as technology.  <br/>  <br/> **12\. It's Hard to Get Users**  <br/>  <br/>A lot of founders complained about how hard it was to get users, though.<br/><br/>> I had no idea how much time and effort needed to go into attaining users.<br/><br/>This is a complicated topic. When you can't get users, it's hard to say<br/>whether the problem is lack of exposure, or whether the product's simply bad.<br/>Even good products can be blocked by switching or integration costs:<br/><br/>> Getting people to use a new service is incredibly difficult. This is<br/>> especially true for a service that other companies can use, because it<br/>> requires their developers to do work. If you're small, they don't think it<br/>> is urgent. [4]<br/><br/>The sharpest criticism of YC came from a founder who said we didn't focus<br/>enough on customer acquisition:<br/><br/>> YC preaches "make something people want" as an engineering task, a never<br/>> ending stream of feature after feature until enough people are happy and the<br/>> application takes off. There's very little focus on the cost of customer<br/>> acquisition.<br/><br/>This may be true; this may be something we need to fix, especially for<br/>applications like games. If you make something where the challenges are mostly<br/>technical, you can rely on word of mouth, like Google did. One founder was<br/>surprised by how well that worked for him:<br/><br/>> There is an irrational fear that no one will buy your product. But if you<br/>> work hard and incrementally make it better, there is no need to worry.<br/><br/>But with other types of startups you may win less by features and more by<br/>deals and marketing.  <br/>  <br/>**13\. Expect the Worst with Deals**  <br/>  <br/>Deals fall through. That's a constant of the startup world. Startups are<br/>powerless, and good startup ideas generally seem wrong. So everyone is nervous<br/>about closing deals with you, and you have no way to make them.  <br/>  <br/>This is particularly true with investors:<br/><br/>> In retrospect, it would have been much better if we had operated under the<br/>> assumption that we would never get any additional outside investment. That<br/>> would have focused us on finding revenue streams early.<br/><br/>My advice is generally pessimistic. Assume you won't get money, and if someone<br/>does offer you any, assume you'll never get any more.<br/><br/>> If someone offers you money, take it. You say it a lot, but I think it needs<br/>> even more emphasizing. We had the opportunity to raise a lot more money than<br/>> we did last year and I wish we had.<br/><br/>Why do founders ignore me? Mostly because they're optimistic by nature. The<br/>mistake is to be optimistic about things you can't control. By all means be<br/>optimistic about your ability to make something great. But you're asking for<br/>trouble if you're optimistic about big companies or investors.  <br/>  <br/>**14\. Investors Are Clueless**  <br/>  <br/>A lot of founders mentioned how surprised they were by the cluelessness of<br/>investors:<br/><br/>> They don't even know about the stuff they've invested in. I met some<br/>> investors that had invested in a hardware device and when I asked them to<br/>> demo the device they had difficulty switching it on.<br/><br/>Angels are a bit better than VCs, because they usually have startup experience<br/>themselves:<br/><br/>> VC investors don't know half the time what they are talking about and are<br/>> years behind in their thinking. A few were great, but 95% of the investors<br/>> we dealt with were unprofessional, didn't seem to be very good at business<br/>> or have any kind of creative vision. Angels were generally much better to<br/>> talk to.<br/><br/>Why are founders surprised that VCs are clueless? I think it's because they<br/>seem so formidable.  <br/>  <br/>The reason VCs seem formidable is that it's their profession to. You get to be<br/>a VC by convincing asset managers to trust you with hundreds of millions of<br/>dollars. How do you do that? You have to seem confident, and you have to seem<br/>like you understand technology. [5]  <br/>  <br/>**15\. You May Have to Play Games**  <br/>  <br/>Because investors are so bad at judging you, you have to work harder than you<br/>should at selling yourself. One founder said the thing that surprised him most<br/>was<br/><br/>> The degree to which feigning certitude impressed investors.<br/><br/>This is the thing that has surprised _me_ most about YC founders' experiences.<br/>This summer we invited some of the alumni to talk to the new startups about<br/>fundraising, and pretty much 100% of their advice was about investor<br/>psychology. I thought I was cynical about VCs, but the founders were much more<br/>cynical.<br/><br/>> A lot of what startup founders do is just posturing. It works.<br/><br/>VCs themselves have no idea of the extent to which the startups they like are<br/>the ones that are best at selling themselves to VCs. [6] It's exactly the same<br/>phenomenon we saw a step earlier. VCs get money by seeming confident to LPs,<br/>and founders get money by seeming confident to VCs.  <br/>  <br/>**16\. Luck Is a Big Factor**  <br/>  <br/>With two such random linkages in the path between startups and money, it<br/>shouldn't be surprising that luck is a big factor in deals. And yet a lot of<br/>founders are surprised by it.<br/><br/>> I didn't realize how much of a role luck plays and how much is outside of<br/>> our control.<br/><br/>If you think about famous startups, it's pretty clear how big a role luck<br/>plays. Where would Microsoft be if IBM insisted on an exclusive license for<br/>DOS?  <br/>  <br/>Why are founders fooled by this? Business guys probably aren't, but hackers<br/>are used to a world where skill is paramount, and you get what you deserve.<br/><br/>> When we started our startup, I had bought the hype of the startup founder<br/>> dream: that this is a game of skill. It is, in some ways. Having skill is<br/>> valuable. So is being determined as all hell. But being lucky is the<br/>> critical ingredient.<br/><br/>Actually the best model would be to say that the outcome is the _product_ of<br/>skill, determination, and luck. No matter how much skill and determination you<br/>have, if you roll a zero for luck, the outcome is zero.  <br/>  <br/>These quotes about luck are not from founders whose startups failed. Founders<br/>who fail quickly tend to blame themselves. Founders who succeed quickly don't<br/>usually realize how lucky they were. It's the ones in the middle who see how<br/>important luck is.  <br/>  <br/>**17\. The Value of Community**  <br/>  <br/>A surprising number of founders said what surprised them most about starting a<br/>startup was the value of community. Some meant the micro-community of YC<br/>founders:<br/><br/>> The immense value of the peer group of YC companies, and facing similar<br/>> obstacles at similar times.<br/><br/>which shouldn't be that surprising, because that's why it's structured that<br/>way. Others were surprised at the value of the startup community in the larger<br/>sense:<br/><br/>> How advantageous it is to live in Silicon Valley, where you can't help but<br/>> hear all the cutting-edge tech and startup news, and run into useful people<br/>> constantly.<br/><br/>The specific thing that surprised them most was the general spirit of<br/>benevolence:<br/><br/>> One of the most surprising things I saw was the willingness of people to<br/>> help us. Even people who had nothing to gain went out of their way to help<br/>> our startup succeed.<br/><br/>and particularly how it extended all the way to the top:<br/><br/>> The surprise for me was how accessible important and interesting people are.<br/>> It's amazing how easily you can reach out to people and get immediate<br/>> feedback.<br/><br/>This is one of the reasons I like being part of this world. Creating wealth is<br/>not a zero-sum game, so you don't have to stab people in the back to win.  <br/>  <br/>**18\. You Get No Respect**  <br/>  <br/>There was one surprise founders mentioned that I'd forgotten about: that<br/>outside the startup world, startup founders get no respect.<br/><br/>> In social settings, I found that I got a lot more respect when I said, "I<br/>> worked on Microsoft Office" instead of "I work at a small startup you've<br/>> never heard of called x."<br/><br/>Partly this is because the rest of the world just doesn't get startups, and<br/>partly it's yet another consequence of the fact that most good startup ideas<br/>seem bad:<br/><br/>> If you pitch your idea to a random person, 95% of the time you'll find the<br/>> person instinctively thinks the idea will be a flop and you're wasting your<br/>> time (although they probably won't say this directly).<br/><br/>Unfortunately this extends even to dating:<br/><br/>> It surprised me that being a startup founder does not get you more<br/>> admiration from women.<br/><br/>I did know about that, but I'd forgotten.  <br/>  <br/>**19\. Things Change as You Grow**  <br/>  <br/>The last big surprise founders mentioned is how much things changed as they<br/>grew. The biggest change was that you got to program even less:<br/><br/>> Your job description as technical founder/CEO is completely rewritten every<br/>> 6-12 months. Less coding, more managing/planning/company building, hiring,<br/>> cleaning up messes, and generally getting things in place for what needs to<br/>> happen a few months from now.<br/><br/>In particular, you now have to deal with employees, who often have different<br/>motivations:<br/><br/>> I knew the founder equation and had been focused on it since I knew I wanted<br/>> to start a startup as a 19 year old. The employee equation is quite<br/>> different so it took me a while to get it down.<br/><br/>Fortunately, it can become a lot less stressful once you reach cruising<br/>altitude:<br/><br/>> I'd say 75% of the stress is gone now from when we first started. Running a<br/>> business is so much more enjoyable now. We're more confident. We're more<br/>> patient. We fight less. We sleep more.<br/><br/>I wish I could say it was this way for every startup that succeeded, but 75%<br/>is probably on the high side.  <br/>  <br/>**The Super-Pattern**  <br/>  <br/>There were a few other patterns, but these were the biggest. One's first<br/>thought when looking at them all is to ask if there's a super-pattern, a<br/>pattern to the patterns.  <br/>  <br/>I saw it immediately, and so did a YC founder I read the list to. These are<br/>supposed to be the surprises, the things I didn't tell people. What do they<br/>all have in common? They're all things I tell people. If I wrote a new essay<br/>with the same outline as this that wasn't summarizing the founders' responses,<br/>everyone would say I'd run out of ideas and was just repeating myself.  <br/>  <br/>What is going on here?  <br/>  <br/>When I look at the responses, the common theme is that starting a startup was<br/>like I said, but way more so. People just don't seem to get how different it<br/>is till they do it. Why? The key to that mystery is to ask, how different<br/>_from what?_ Once you phrase it that way, the answer is obvious: from a job.<br/>Everyone's model of work is a job. It's completely pervasive. Even if you've<br/>never had a job, your parents probably did, along with practically every other<br/>adult you've met.  <br/>  <br/>Unconsciously, everyone expects a startup to be like a job, and that explains<br/>most of the surprises. It explains why people are surprised how carefully you<br/>have to choose cofounders and how hard you have to work to maintain your<br/>relationship. You don't have to do that with coworkers. It explains why the<br/>ups and downs are surprisingly extreme. In a job there is much more damping.<br/>But it also explains why the good times are surprisingly good: most people<br/>can't imagine such freedom. As you go down the list, almost all the surprises<br/>are surprising in how much a startup differs from a job.  <br/>  <br/>You probably can't overcome anything so pervasive as the model of work you<br/>grew up with. So the best solution is to be consciously aware of that. As you<br/>go into a startup, you'll be thinking "everyone says it's really extreme."<br/>Your next thought will probably be "but I can't believe it will be that bad."<br/>If you want to avoid being surprised, the next thought after that should be:<br/>"and the reason I can't believe it will be that bad is that my model of work<br/>is a job."  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] Graduate students might understand it. In grad school you always feel you<br/>should be working on your thesis. It doesn't end every semester like classes<br/>do.  <br/>  <br/>[2] The best way for a startup to engage with slow-moving organizations is to<br/>fork off separate processes to deal with them. It's when they're on the<br/>critical path that they kill you—when you depend on closing a deal to move<br/>forward. It's worth taking extreme measures to avoid that.  <br/>  <br/>[3] This is a variant of Reid Hoffman's principle that if you aren't<br/>embarrassed by what you launch with, you waited too long to launch.  <br/>  <br/>[4] The question to ask about what you've built is not whether it's good, but<br/>whether it's good enough to supply the activation energy required.  <br/>  <br/>[5] Some VCs seem to understand technology because they actually do, but<br/>that's overkill; the defining test is whether you can talk about it well<br/>enough to convince limited partners.  <br/>  <br/>[6] This is the same phenomenon you see with defense contractors or fashion<br/>brands. The dumber the customers, the more effort you expend on the process of<br/>selling things to them rather than making the things you sell.  <br/>  <br/> **Thanks:** to Jessica Livingston for reading drafts of this, and to all the<br/>founders who responded to my email.  <br/>  <br/>  <br/>  <br/> **Related:**  <br/>  <br/><br/>Startups in 13 Sentences  <br/><br/>The Hardest Lessons for Startups to Learn  <br/><br/>How Not to Die  <br/><br/>The 18 Mistakes That Kill Startups  <br/><br/>A Fundraising Survival Guide  <br/><br/>Russian Translation  <br/><br/>Korean Translation  <br/><br/>Hebrew Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>April 2001  <br/>  <br/>This essay developed out of conversations I've had with several other<br/>programmers about why Java smelled suspicious. It's not a critique of Java! It<br/>is a case study of hacker's radar.  <br/>  <br/>Over time, hackers develop a nose for good (and bad) technology. I thought it<br/>might be interesting to try and write down what made Java seem suspect to me.  <br/>  <br/>Some people who've read this think it's an interesting attempt to write about<br/>something that hasn't been written about before. Others say I will get in<br/>trouble for appearing to be writing about things I don't understand. So, just<br/>in case it does any good, let me clarify that I'm not writing here about Java<br/>(which I have never used) but about hacker's radar (which I have thought about<br/>a lot).  <br/>  <br/><br/>* * *<br/><br/>  <br/>  <br/>The aphorism "you can't tell a book by its cover" originated in the times when<br/>books were sold in plain cardboard covers, to be bound by each purchaser<br/>according to his own taste. In those days, you couldn't tell a book by its<br/>cover. But publishing has advanced since then: present-day publishers work<br/>hard to make the cover something you can tell a book by.  <br/>  <br/>I spend a lot of time in bookshops and I feel as if I have by now learned to<br/>understand everything publishers mean to tell me about a book, and perhaps a<br/>bit more. The time I haven't spent in bookshops I've spent mostly in front of<br/>computers, and I feel as if I've learned, to some degree, to judge technology<br/>by its cover as well. It may be just luck, but I've saved myself from a few<br/>technologies that turned out to be real stinkers.  <br/>  <br/>So far, Java seems like a stinker to me. I've never written a Java program,<br/>never more than glanced over reference books about it, but I have a hunch that<br/>it won't be a very successful language. I may turn out to be mistaken; making<br/>predictions about technology is a dangerous business. But for what it's worth,<br/>as a sort of time capsule, here's why I don't like the look of Java:  <br/>  <br/>1\. It has been so energetically hyped. Real standards don't have to be<br/>promoted. No one had to promote C, or Unix, or HTML. A real standard tends to<br/>be already established by the time most people hear about it. On the hacker<br/>radar screen, Perl is as big as Java, or bigger, just on the strength of its<br/>own merits.  <br/>  <br/>2\. It's aimed low. In the original Java white paper, Gosling explicitly says<br/>Java was designed not to be too difficult for programmers used to C. It was<br/>designed to be another C++: C plus a few ideas taken from more advanced<br/>languages. Like the creators of sitcoms or junk food or package tours, Java's<br/>designers were consciously designing a product for people not as smart as<br/>them. Historically, languages designed for other people to use have been bad:<br/>Cobol, PL/I, Pascal, Ada, C++. The good languages have been those that were<br/>designed for their own creators: C, Perl, Smalltalk, Lisp.  <br/>  <br/>3\. It has ulterior motives. Someone once said that the world would be a<br/>better place if people only wrote books because they had something to say,<br/>rather than because they wanted to write a book. Likewise, the reason we hear<br/>about Java all the time is not because it has something to say about<br/>programming languages. We hear about Java as part of a plan by Sun to<br/>undermine Microsoft.  <br/>  <br/>4\. No one loves it. C, Perl, Python, Smalltalk, and Lisp programmers love<br/>their languages. I've never heard anyone say that they loved Java.  <br/>  <br/>5\. People are forced to use it. A lot of the people I know using Java are<br/>using it because they feel they have to. Either it's something they felt they<br/>had to do to get funded, or something they thought customers would want, or<br/>something they were told to do by management. These are smart people; if the<br/>technology was good, they'd have used it voluntarily.  <br/>  <br/>6\. It has too many cooks. The best programming languages have been developed<br/>by small groups. Java seems to be run by a committee. If it turns out to be a<br/>good language, it will be the first time in history that a committee has<br/>designed a good language.  <br/>  <br/>7\. It's bureaucratic. From what little I know about Java, there seem to be a<br/>lot of protocols for doing things. Really good languages aren't like that.<br/>They let you do what you want and get out of the way.  <br/>  <br/>8\. It's pseudo-hip. Sun now pretends that Java is a grassroots, open-source<br/>language effort like Perl or Python. This one just happens to be controlled by<br/>a giant company. So the language is likely to have the same drab clunkiness as<br/>anything else that comes out of a big company.  <br/>  <br/>9\. It's designed for large organizations. Large organizations have different<br/>aims from hackers. They want languages that are (believed to be) suitable for<br/>use by large teams of mediocre programmers-- languages with features that,<br/>like the speed limiters in U-Haul trucks, prevent fools from doing too much<br/>damage. Hackers don't like a language that talks down to them. Hackers just<br/>want power. Historically, languages designed for large organizations (PL/I,<br/>Ada) have lost, while hacker languages (C, Perl) have won. The reason: today's<br/>teenage hacker is tomorrow's CTO.  <br/>  <br/>10\. The wrong people like it. The programmers I admire most are not, on the<br/>whole, captivated by Java. Who does like Java? Suits, who don't know one<br/>language from another, but know that they keep hearing about Java in the<br/>press; programmers at big companies, who are amazed to find that there is<br/>something even better than C++; and plug-and-chug undergrads, who are ready to<br/>like anything that might get them a job (will this be on the test?). These<br/>people's opinions change with every wind.  <br/>  <br/>11\. Its daddy is in a pinch. Sun's business model is being undermined on two<br/>fronts. Cheap Intel processors, of the same type used in desktop machines, are<br/>now more than fast enough for servers. And FreeBSD seems to be at least as<br/>good an OS for servers as Solaris. Sun's advertising implies that you need Sun<br/>servers for industrial strength applications. If this were true, Yahoo would<br/>be first in line to buy Suns; but when I worked there, the servers were all<br/>Intel boxes running FreeBSD. This bodes ill for Sun's future. If Sun runs into<br/>trouble, they could drag Java down with them.  <br/>  <br/>12\. The DoD likes it. The Defense Department is encouraging developers to use<br/>Java. This seems to me the most damning sign of all. The Defense Department<br/>does a fine (though expensive) job of defending the country, but they love<br/>plans and procedures and protocols. Their culture is the opposite of hacker<br/>culture; on questions of software they will tend to bet wrong. The last time<br/>the DoD really liked a programming language, it was Ada.  <br/>  <br/>Bear in mind, this is not a critique of Java, but a critique of its cover. I<br/>don't know Java well enough to like it or dislike it. This is just an<br/>explanation of why I don't find that I'm eager to learn it.  <br/>  <br/>It may seem cavalier to dismiss a language before you've even tried writing<br/>programs in it. But this is something all programmers have to do. There are<br/>too many technologies out there to learn them all. You have to learn to judge<br/>by outward signs which will be worth your time. I have likewise cavalierly<br/>dismissed Cobol, Ada, Visual Basic, the IBM AS400, VRML, ISO 9000, the SET<br/>protocol, VMS, Novell Netware, and CORBA, among others. They just smelled<br/>wrong.  <br/>  <br/>It could be that in Java's case I'm mistaken. It could be that a language<br/>promoted by one big company to undermine another, designed by a committee for<br/>a "mainstream" audience, hyped to the skies, and beloved of the DoD, happens<br/>nonetheless to be a clean, beautiful, powerful language that I would love<br/>programming in. It could be, but it seems very unlikely.  <br/>  <br/><br/>Trevor Re: Java's Cover  <br/>  <br/><br/>Berners-Lee Re: Java  <br/>  <br/><br/>Being Popular  <br/>  <br/><br/>Sun Internal Memo  <br/>  <br/><br/>2005: BusinessWeek Agrees  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>September 2009  <br/>  <br/>Like all investors, we spend a lot of time trying to learn how to predict<br/>which startups will succeed. We probably spend more time thinking about it<br/>than most, because we invest the earliest. Prediction is usually all we have<br/>to rely on.  <br/>  <br/>We learned quickly that the most important predictor of success is<br/>determination. At first we thought it might be intelligence. Everyone likes to<br/>believe that's what makes startups succeed. It makes a better story that a<br/>company won because its founders were so smart. The PR people and reporters<br/>who spread such stories probably believe them themselves. But while it<br/>certainly helps to be smart, it's not the deciding factor. There are plenty of<br/>people as smart as Bill Gates who achieve nothing.  <br/>  <br/>In most domains, talent is overrated compared to determination—partly because<br/>it makes a better story, partly because it gives onlookers an excuse for being<br/>lazy, and partly because after a while determination starts to look like<br/>talent.  <br/>  <br/>I can't think of any field in which determination is overrated, but the<br/>relative importance of determination and talent probably do vary somewhat.<br/>Talent probably matters more in types of work that are purer, in the sense<br/>that one is solving mostly a single type of problem instead of many different<br/>types. I suspect determination would not take you as far in math as it would<br/>in, say, organized crime.  <br/>  <br/>I don't mean to suggest by this comparison that types of work that depend more<br/>on talent are always more admirable. Most people would agree it's more<br/>admirable to be good at math than memorizing long strings of digits, even<br/>though the latter depends more on natural ability.  <br/>  <br/>Perhaps one reason people believe startup founders win by being smarter is<br/>that intelligence does matter more in technology startups than it used to in<br/>earlier types of companies. You probably do need to be a bit smarter to<br/>dominate Internet search than you had to be to dominate railroads or hotels or<br/>newspapers. And that's probably an ongoing trend. But even in the highest of<br/>high tech industries, success still depends more on determination than brains.  <br/>  <br/>If determination is so important, can we isolate its components? Are some more<br/>important than others? Are there some you can cultivate?  <br/>  <br/>The simplest form of determination is sheer willfulness. When you want<br/>something, you must have it, no matter what.  <br/>  <br/>A good deal of willfulness must be inborn, because it's common to see families<br/>where one sibling has much more of it than another. Circumstances can alter<br/>it, but at the high end of the scale, nature seems to be more important than<br/>nurture. Bad circumstances can break the spirit of a strong-willed person, but<br/>I don't think there's much you can do to make a weak-willed person stronger-<br/>willed.  <br/>  <br/>Being strong-willed is not enough, however. You also have to be hard on<br/>yourself. Someone who was strong-willed but self-indulgent would not be called<br/>determined. Determination implies your willfulness is balanced by discipline.  <br/>  <br/>That word balance is a significant one. The more willful you are, the more<br/>disciplined you have to be. The stronger your will, the less anyone will be<br/>able to argue with you except yourself. And someone has to argue with you,<br/>because everyone has base impulses, and if you have more will than discipline<br/>you'll just give into them and end up on a local maximum like drug addiction.  <br/>  <br/>We can imagine will and discipline as two fingers squeezing a slippery melon<br/>seed. The harder they squeeze, the further the seed flies, but they must both<br/>squeeze equally or the seed spins off sideways.  <br/>  <br/>If this is true it has interesting implications, because discipline can be<br/>cultivated, and in fact does tend to vary quite a lot in the course of an<br/>individual's life. If determination is effectively the product of will and<br/>discipline, then you can become more determined by being more disciplined. [1]  <br/>  <br/>Another consequence of the melon seed model is that the more willful you are,<br/>the more dangerous it is to be undisciplined. There seem to be plenty of<br/>examples to confirm that. In some very energetic people's lives you see<br/>something like wing flutter, where they alternate between doing great work and<br/>doing absolutely nothing. Externally this would look a lot like bipolar<br/>disorder.  <br/>  <br/>The melon seed model is inaccurate in at least one respect, however: it's<br/>static. In fact the dangers of indiscipline increase with temptation. Which<br/>means, interestingly, that determination tends to erode itself. If you're<br/>sufficiently determined to achieve great things, this will probably increase<br/>the number of temptations around you. Unless you become proportionally more<br/>disciplined, willfulness will then get the upper hand, and your achievement<br/>will revert to the mean.  <br/>  <br/>That's why Julius Caesar thought thin men so dangerous. They weren't tempted<br/>by the minor perquisites of power.  <br/>  <br/>The melon seed model implies it's possible to be too disciplined. Is it? I<br/>think there probably are people whose willfulness is crushed down by excessive<br/>discipline, and who would achieve more if they weren't so hard on themselves.<br/>One reason the young sometimes succeed where the old fail is that they don't<br/>realize how incompetent they are. This lets them do a kind of deficit<br/>spending. When they first start working on something, they overrate their<br/>achievements. But that gives them confidence to keep working, and their<br/>performance improves. Whereas someone clearer-eyed would see their initial<br/>incompetence for what it was, and perhaps be discouraged from continuing.  <br/>  <br/>There's one other major component of determination: ambition. If willfulness<br/>and discipline are what get you to your destination, ambition is how you<br/>choose it.  <br/>  <br/>I don't know if it's exactly right to say that ambition is a component of<br/>determination, but they're not entirely orthogonal. It would seem a misnomer<br/>if someone said they were very determined to do something trivially easy.  <br/>  <br/>And fortunately ambition seems to be quite malleable; there's a lot you can do<br/>to increase it. Most people don't know how ambitious to be, especially when<br/>they're young. They don't know what's hard, or what they're capable of. And<br/>this problem is exacerbated by having few peers. Ambitious people are rare, so<br/>if everyone is mixed together randomly, as they tend to be early in people's<br/>lives, then the ambitious ones won't have many ambitious peers. When you take<br/>people like this and put them together with other ambitious people, they bloom<br/>like dying plants given water. Probably most ambitious people are starved for<br/>the sort of encouragement they'd get from ambitious peers, whatever their age.<br/>[2]  <br/>  <br/>Achievements also tend to increase your ambition. With each step you gain<br/>confidence to stretch further next time.  <br/>  <br/>So here in sum is how determination seems to work: it consists of willfulness<br/>balanced with discipline, aimed by ambition. And fortunately at least two of<br/>these three qualities can be cultivated. You may be able to increase your<br/>strength of will somewhat; you can definitely learn self-discipline; and<br/>almost everyone is practically malnourished when it comes to ambition.  <br/>  <br/>I feel like I understand determination a bit better now. But only a bit:<br/>willfulness, discipline, and ambition are all concepts almost as complicated<br/>as determination. [3]  <br/>  <br/>Note too that determination and talent are not the whole story. There's a<br/>third factor in achievement: how much you like the work. If you really love<br/>working on something, you don't need determination to drive you; it's what<br/>you'd do anyway. But most types of work have aspects one doesn't like, because<br/>most types of work consist of doing things for other people, and it's very<br/>unlikely that the tasks imposed by their needs will happen to align exactly<br/>with what you want to do.  <br/>  <br/>Indeed, if you want to create the most wealth, the way to do it is to focus<br/>more on their needs than your interests, and make up the difference with<br/>determination.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Loosely speaking. What I'm claiming with the melon seed model is more like<br/>determination is proportionate to wd^m - k|w - d|^n, where w is will and d<br/>discipline.  <br/>  <br/>[2] Which means one of the best ways to help a society generally is to create<br/>events and institutions that bring ambitious people together. It's like<br/>pulling the control rods out of a reactor: the energy they emit encourages<br/>other ambitious people, instead of being absorbed by the normal people they're<br/>usually surrounded with.  <br/>  <br/>Conversely, it's probably a mistake to do as some European countries have done<br/>and try to ensure none of your universities is significantly better than the<br/>others.  <br/>  <br/>[3] For example, willfulness clearly has two subcomponents, stubbornness and<br/>energy. The first alone yields someone who's stubbornly inert. The second<br/>alone yields someone flighty. As willful people get older or otherwise lose<br/>their energy, they tend to become merely stubborn.  <br/>  <br/>**Thanks** to Sam Altman, Jessica Livingston, and Robert Morris for reading<br/>drafts of this.  <br/>  <br/><br/>Italian Translation  <br/><br/>Portuguese Translation  <br/><br/>Russian Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>April 2007  <br/>  <br/>A few days ago I suddenly realized Microsoft was dead. I was talking to a<br/>young startup founder about how Google was different from Yahoo. I said that<br/>Yahoo had been warped from the start by their fear of Microsoft. That was why<br/>they'd positioned themselves as a "media company" instead of a technology<br/>company. Then I looked at his face and realized he didn't understand. It was<br/>as if I'd told him how much girls liked Barry Manilow in the mid 80s. Barry<br/>who?  <br/>  <br/>Microsoft? He didn't say anything, but I could tell he didn't quite believe<br/>anyone would be frightened of them.  <br/>  <br/>Microsoft cast a shadow over the software world for almost 20 years starting<br/>in the late 80s. I can remember when it was IBM before them. I mostly ignored<br/>this shadow. I never used Microsoft software, so it only affected me<br/>indirectly—for example, in the spam I got from botnets. And because I wasn't<br/>paying attention, I didn't notice when the shadow disappeared.  <br/>  <br/>But it's gone now. I can sense that. No one is even afraid of Microsoft<br/>anymore. They still make a lot of money—so does IBM, for that matter. But<br/>they're not dangerous.  <br/>  <br/>When did Microsoft die, and of what? I know they seemed dangerous as late as<br/>2001, because I wrote an essay then about how they were less dangerous than<br/>they seemed. I'd guess they were dead by 2005. I know when we started Y<br/>Combinator we didn't worry about Microsoft as competition for the startups we<br/>funded. In fact, we've never even invited them to the demo days we organize<br/>for startups to present to investors. We invite Yahoo and Google and some<br/>other Internet companies, but we've never bothered to invite Microsoft. Nor<br/>has anyone there ever even sent us an email. They're in a different world.  <br/>  <br/>What killed them? Four things, I think, all of them occurring simultaneously<br/>in the mid 2000s.  <br/>  <br/>The most obvious is Google. There can only be one big man in town, and they're<br/>clearly it. Google is the most dangerous company now by far, in both the good<br/>and bad senses of the word. Microsoft can at best limp along afterward.  <br/>  <br/>When did Google take the lead? There will be a tendency to push it back to<br/>their IPO in August 2004, but they weren't setting the terms of the debate<br/>then. I'd say they took the lead in 2005\. Gmail was one of the things that<br/>put them over the edge. Gmail showed they could do more than search.  <br/>  <br/>Gmail also showed how much you could do with web-based software, if you took<br/>advantage of what later came to be called "Ajax." And that was the second<br/>cause of Microsoft's death: everyone can see the desktop is over. It now seems<br/>inevitable that applications will live on the web—not just email, but<br/>everything, right up to Photoshop. Even Microsoft sees that now.  <br/>  <br/>Ironically, Microsoft unintentionally helped create Ajax. The x in Ajax is<br/>from the XMLHttpRequest object, which lets the browser communicate with the<br/>server in the background while displaying a page. (Originally the only way to<br/>communicate with the server was to ask for a new page.) XMLHttpRequest was<br/>created by Microsoft in the late 90s because they needed it for Outlook. What<br/>they didn't realize was that it would be useful to a lot of other people<br/>too—in fact, to anyone who wanted to make web apps work like desktop ones.  <br/>  <br/>The other critical component of Ajax is Javascript, the programming language<br/>that runs in the browser. Microsoft saw the danger of Javascript and tried to<br/>keep it broken for as long as they could. [1] But eventually the open source<br/>world won, by producing Javascript libraries that grew over the brokenness of<br/>Explorer the way a tree grows over barbed wire.  <br/>  <br/>The third cause of Microsoft's death was broadband Internet. Anyone who cares<br/>can have fast Internet access now. And the bigger the pipe to the server, the<br/>less you need the desktop.  <br/>  <br/>The last nail in the coffin came, of all places, from Apple. Thanks to OS X,<br/>Apple has come back from the dead in a way that is extremely rare in<br/>technology. [2] Their victory is so complete that I'm now surprised when I<br/>come across a computer running Windows. Nearly all the people we fund at Y<br/>Combinator use Apple laptops. It was the same in the audience at startup<br/>school. All the computer people use Macs or Linux now. Windows is for<br/>grandmas, like Macs used to be in the 90s. So not only does the desktop no<br/>longer matter, no one who cares about computers uses Microsoft's anyway.  <br/>  <br/>And of course Apple has Microsoft on the run in music too, with TV and phones<br/>on the way.  <br/>  <br/>I'm glad Microsoft is dead. They were like Nero or Commodus—evil in the way<br/>only inherited power can make you. Because remember, the Microsoft monopoly<br/>didn't begin with Microsoft. They got it from IBM. The software business was<br/>overhung by a monopoly from about the mid-1950s to about 2005. For practically<br/>its whole existence, that is. One of the reasons "Web 2.0" has such an air of<br/>euphoria about it is the feeling, conscious or not, that this era of monopoly<br/>may finally be over.  <br/>  <br/>Of course, as a hacker I can't help thinking about how something broken could<br/>be fixed. Is there some way Microsoft could come back? In principle, yes. To<br/>see how, envision two things: (a) the amount of cash Microsoft now has on<br/>hand, and (b) Larry and Sergey making the rounds of all the search engines ten<br/>years ago trying to sell the idea for Google for a million dollars, and being<br/>turned down by everyone.  <br/>  <br/>The surprising fact is, brilliant hackers—dangerously brilliant hackers—can be<br/>had very cheaply, by the standards of a company as rich as Microsoft. They<br/>can't hire smart people anymore, but they could buy as many as they wanted for<br/>only an order of magnitude more. So if they wanted to be a contender again,<br/>this is how they could do it:<br/><br/>  1. Buy all the good "Web 2.0" startups. They could get substantially all of them for less than they'd have to pay for Facebook.  <br/>  <br/><br/>  2. Put them all in a building in Silicon Valley, surrounded by lead shielding to protect them from any contact with Redmond. <br/><br/>I feel safe suggesting this, because they'd never do it. Microsoft's biggest<br/>weakness is that they still don't realize how much they suck. They still think<br/>they can write software in house. Maybe they can, by the standards of the<br/>desktop world. But that world ended a few years ago.  <br/>  <br/>I already know what the reaction to this essay will be. Half the readers will<br/>say that Microsoft is still an enormously profitable company, and that I<br/>should be more careful about drawing conclusions based on what a few people<br/>think in our insular little "Web 2.0" bubble. The other half, the younger<br/>half, will complain that this is old news.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **See also:** Microsoft is Dead: the Cliffs Notes  <br/>  <br/> **Notes**  <br/>  <br/>[1] It doesn't take a conscious effort to make software incompatible. All you<br/>have to do is not work too hard at fixing bugs—which, if you're a big company,<br/>you produce in copious quantities. The situation is analogous to the writing<br/>of "literary theorists<br/><br/>Portuguese Translation  <br/>  <br/><br/>Simplified Chinese Translation  <br/>  <br/><br/>Korean Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>The United States of Entrepreneurs  <br/><br/>About Half of VC-Backed Company Founders are Immigrants  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>January 2015  <br/>  <br/>Corporate Development, aka corp dev, is the group within companies that buys<br/>other companies. If you're talking to someone from corp dev, that's why,<br/>whether you realize it yet or not.  <br/>  <br/>It's usually a mistake to talk to corp dev unless (a) you want to sell your<br/>company right now and (b) you're sufficiently likely to get an offer at an<br/>acceptable price. In practice that means startups should only talk to corp dev<br/>when they're either doing really well or really badly. If you're doing really<br/>badly, meaning the company is about to die, you may as well talk to them,<br/>because you have nothing to lose. And if you're doing really well, you can<br/>safely talk to them, because you both know the price will have to be high, and<br/>if they show the slightest sign of wasting your time, you'll be confident<br/>enough to tell them to get lost.  <br/>  <br/>The danger is to companies in the middle. Particularly to young companies that<br/>are growing fast, but haven't been doing it for long enough to have grown big<br/>yet. It's usually a mistake for a promising company less than a year old even<br/>to talk to corp dev.  <br/>  <br/>But it's a mistake founders constantly make. When someone from corp dev wants<br/>to meet, the founders tell themselves they should at least find out what they<br/>want. Besides, they don't want to offend Big Company by refusing to meet.  <br/>  <br/>Well, I'll tell you what they want. They want to talk about buying you. That's<br/>what the title "corp dev" means. So before agreeing to meet with someone from<br/>corp dev, ask yourselves, "Do we want to sell the company right now?" And if<br/>the answer is no, tell them "Sorry, but we're focusing on growing the<br/>company." They won't be offended. And certainly the founders of Big Company<br/>won't be offended. If anything they'll think more highly of you. You'll remind<br/>them of themselves. They didn't sell either; that's why they're in a position<br/>now to buy other companies. [1]  <br/>  <br/>Most founders who get contacted by corp dev already know what it means. And<br/>yet even when they know what corp dev does and know they don't want to sell,<br/>they take the meeting. Why do they do it? The same mix of denial and wishful<br/>thinking that underlies most mistakes founders make. It's flattering to talk<br/>to someone who wants to buy you. And who knows, maybe their offer will be<br/>surprisingly high. You should at least see what it is, right?  <br/>  <br/>No. If they were going to send you an offer immediately by email, sure, you<br/>might as well open it. But that is not how conversations with corp dev work.<br/>If you get an offer at all, it will be at the end of a long and unbelievably<br/>distracting process. And if the offer is surprising, it will be surprisingly<br/>low.  <br/>  <br/>Distractions are the thing you can least afford in a startup. And<br/>conversations with corp dev are the worst sort of distraction, because as well<br/>as consuming your attention they undermine your morale. One of the tricks to<br/>surviving a grueling process is not to stop and think how tired you are.<br/>Instead you get into a sort of flow. [2] Imagine what it would do to you if at<br/>mile 20 of a marathon, someone ran up beside you and said "You must feel<br/>really tired. Would you like to stop and take a rest?" Conversations with corp<br/>dev are like that but worse, because the suggestion of stopping gets combined<br/>in your mind with the imaginary high price you think they'll offer.  <br/>  <br/>And then you're really in trouble. If they can, corp dev people like to turn<br/>the tables on you. They like to get you to the point where you're trying to<br/>convince them to buy instead of them trying to convince you to sell. And<br/>surprisingly often they succeed.  <br/>  <br/>This is a very slippery slope, greased with some of the most powerful forces<br/>that can work on founders' minds, and attended by an experienced professional<br/>whose full time job is to push you down it.  <br/>  <br/>Their tactics in pushing you down that slope are usually fairly brutal. Corp<br/>dev people's whole job is to buy companies, and they don't even get to choose<br/>which. The only way their performance is measured is by how cheaply they can<br/>buy you, and the more ambitious ones will stop at nothing to achieve that. For<br/>example, they'll almost always start with a lowball offer, just to see if<br/>you'll take it. Even if you don't, a low initial offer will demoralize you and<br/>make you easier to manipulate.  <br/>  <br/>And that is the most innocent of their tactics. Just wait till you've agreed<br/>on a price and think you have a done deal, and then they come back and say<br/>their boss has vetoed the deal and won't do it for more than half the agreed<br/>upon price. Happens all the time. If you think investors can behave badly,<br/>it's nothing compared to what corp dev people can do. Even corp dev people at<br/>companies that are otherwise benevolent.  <br/>  <br/>I remember once complaining to a friend at Google about some nasty trick their<br/>corp dev people had pulled on a YC startup.  <br/>  <br/>"What happened to Don't be Evil?" I asked.  <br/>  <br/>"I don't think corp dev got the memo," he replied.  <br/>  <br/>The tactics you encounter in M&A conversations can be like nothing you've<br/>experienced in the otherwise comparatively upstanding world of Silicon Valley.<br/>It's as if a chunk of genetic material from the old-fashioned robber baron<br/>business world got incorporated into the startup world. [3]  <br/>  <br/>The simplest way to protect yourself is to use the trick that John D.<br/>Rockefeller, whose grandfather was an alcoholic, used to protect himself from<br/>becoming one. He once told a Sunday school class<br/><br/>> Boys, do you know why I never became a drunkard? Because I never took the<br/>> first drink.<br/><br/>Do you want to sell your company right now? Not eventually, right now. If not,<br/>just don't take the first meeting. They won't be offended. And you in turn<br/>will be guaranteed to be spared one of the worst experiences that can happen<br/>to a startup.  <br/>  <br/>If you do want to sell, there's another set of techniques  for doing that. But<br/>the biggest mistake founders make in dealing with corp dev is not doing a bad<br/>job of talking to them when they're ready to, but talking to them before they<br/>are. So if you remember only the title of this essay, you already know most of<br/>what you need to know about M&A in the first year.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] I'm not saying you should never sell. I'm saying you should be clear in<br/>your own mind about whether you want to sell or not, and not be led by<br/>manipulation or wishful thinking into trying to sell earlier than you<br/>otherwise would have.  <br/>  <br/>[2] In a startup, as in most competitive sports, the task at hand almost does<br/>this for you; you're too busy to feel tired. But when you lose that<br/>protection, e.g. at the final whistle, the fatigue hits you like a wave. To<br/>talk to corp dev is to let yourself feel it mid-game.  <br/>  <br/>[3] To be fair, the apparent misdeeds of corp dev people are magnified by the<br/>fact that they function as the face of a large organization that often doesn't<br/>know its own mind. Acquirers can be surprisingly indecisive about<br/>acquisitions, and their flakiness is indistinguishable from dishonesty by the<br/>time it filters down to you.  <br/>  <br/> **Thanks** to Marc Andreessen, Jessica Livingston, Geoff Ralston, and Qasar<br/>Younis for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>August 2005  <br/>  <br/> _(This essay is derived from a talk at Defcon 2005.)_  <br/>  <br/>Suppose you wanted to get rid of economic inequality. There are two ways to do<br/>it: give money to the poor, or take it away from the rich. But they amount to<br/>the same thing, because if you want to give money to the poor, you have to get<br/>it from somewhere. You can't get it from the poor, or they just end up where<br/>they started. You have to get it from the rich.  <br/>  <br/>There is of course a way to make the poor richer without simply shifting money<br/>from the rich. You could help the poor become more productive-- for example,<br/>by improving access to education. Instead of taking money from engineers and<br/>giving it to checkout clerks, you could enable people who would have become<br/>checkout clerks to become engineers.  <br/>  <br/>This is an excellent strategy for making the poor richer. But the evidence of<br/>the last 200 years shows that it doesn't reduce economic inequality, because<br/>it makes the rich richer too. If there are more engineers, then there are more<br/>opportunities to hire them and to sell them things. Henry Ford couldn't have<br/>made a fortune building cars in a society in which most people were still<br/>subsistence farmers; he would have had neither workers nor customers.  <br/>  <br/>If you want to reduce economic inequality instead of just improving the<br/>overall standard of living, it's not enough just to raise up the poor. What if<br/>one of your newly minted engineers gets ambitious and goes on to become<br/>another Bill Gates? Economic inequality will be as bad as ever. If you<br/>actually want to compress the gap between rich and poor, you have to push down<br/>on the top as well as pushing up on the bottom.  <br/>  <br/>How do you push down on the top? You could try to decrease the productivity of<br/>the people who make the most money: make the best surgeons operate with their<br/>left hands, force popular actors to overeat, and so on. But this approach is<br/>hard to implement. The only practical solution is to let people do the best<br/>work they can, and then (either by taxation or by limiting what they can<br/>charge) to confiscate whatever you deem to be surplus.  <br/>  <br/>So let's be clear what reducing economic inequality means. It is identical<br/>with taking money from the rich.  <br/>  <br/>When you transform a mathematical expression into another form, you often<br/>notice new things. So it is in this case. Taking money from the rich turns out<br/>to have consequences one might not foresee when one phrases the same idea in<br/>terms of "reducing inequality."  <br/>  <br/>The problem is, risk and reward have to be proportionate. A bet with only a<br/>10% chance of winning has to pay more than one with a 50% chance of winning,<br/>or no one will take it. So if you lop off the top of the possible rewards, you<br/>thereby decrease people's willingness to take risks.  <br/>  <br/>Transposing into our original expression, we get: decreasing economic<br/>inequality means decreasing the risk people are willing to take.  <br/>  <br/>There are whole classes of risks that are no longer worth taking if the<br/>maximum return is decreased. One reason high tax rates are disastrous is that<br/>this class of risks includes starting new companies.  <br/>  <br/> **Investors**  <br/>  <br/>Startups are intrinsically risky. A startup is like a small boat in the open<br/>sea. One big wave and you're sunk. A competing product, a downturn in the<br/>economy, a delay in getting funding or regulatory approval, a patent suit,<br/>changing technical standards, the departure of a key employee, the loss of a<br/>big account---any one of these can destroy you overnight. It seems only about<br/>1 in 10 startups succeeds. [1]  <br/>  <br/>Our startup paid its first round of outside investors 36x. Which meant, with<br/>current US tax rates, that it made sense to invest in us if we had better than<br/>a 1 in 24 chance of succeeding. That sounds about right. That's probably<br/>roughly how we looked when we were a couple of nerds with no business<br/>experience operating out of an apartment.  <br/>  <br/>If that kind of risk doesn't pay, venture investing, as we know it, doesn't<br/>happen.  <br/>  <br/>That might be ok if there were other sources of capital for new companies. Why<br/>not just have the government, or some large almost-government organization<br/>like Fannie Mae, do the venture investing instead of private funds?  <br/>  <br/>I'll tell you why that wouldn't work. Because then you're asking government or<br/>almost-government employees to do the one thing they are least able to do:<br/>take risks.  <br/>  <br/>As anyone who has worked for the government knows, the important thing is not<br/>to make the right choices, but to make choices that can be justified later if<br/>they fail. If there is a safe option, that's the one a bureaucrat will choose.<br/>But that is exactly the wrong way to do venture investing. The nature of the<br/>business means that you want to make terribly risky choices, if the upside<br/>looks good enough.  <br/>  <br/>VCs are currently paid in a way that makes them focus on the upside: they get<br/>a percentage of the fund's gains. And that helps overcome their understandable<br/>fear of investing in a company run by nerds who look like (and perhaps are)<br/>college students.  <br/>  <br/>If VCs weren't allowed to get rich, they'd behave like bureaucrats. Without<br/>hope of gain, they'd have only fear of loss. And so they'd make the wrong<br/>choices. They'd turn down the nerds in favor of the smooth-talking MBA in a<br/>suit, because that investment would be easier to justify later if it failed.  <br/>  <br/> **Founders**  <br/>  <br/>But even if you could somehow redesign venture funding to work without<br/>allowing VCs to become rich, there's another kind of investor you simply<br/>cannot replace: the startups' founders and early employees.  <br/>  <br/>What they invest is their time and ideas. But these are equivalent to money;<br/>the proof is that investors are willing (if forced) to treat them as<br/>interchangeable, granting the same status to "sweat equity" and the equity<br/>they've purchased with cash.  <br/>  <br/>The fact that you're investing time doesn't change the relationship between<br/>risk and reward. If you're going to invest your time in something with a small<br/>chance of succeeding, you'll only do it if there is a proportionately large<br/>payoff. [2] If large payoffs aren't allowed, you may as well play it safe.  <br/>  <br/>Like many startup founders, I did it to get rich. But not because I wanted to<br/>buy expensive things. What I wanted was security. I wanted to make enough<br/>money that I didn't have to worry about money. If I'd been forbidden to make<br/>enough from a startup to do this, I would have sought security by some other<br/>means: for example, by going to work for a big, stable organization from which<br/>it would be hard to get fired. Instead of busting my ass in a startup, I would<br/>have tried to get a nice, low-stress job at a big research lab, or tenure at a<br/>university.  <br/>  <br/>That's what everyone does in societies where risk isn't rewarded. If you can't<br/>ensure your own security, the next best thing is to make a nest for yourself<br/>in some large organization where your status depends mostly on seniority. [3]  <br/>  <br/>Even if we could somehow replace investors, I don't see how we could replace<br/>founders. Investors mainly contribute money, which in principle is the same no<br/>matter what the source. But the founders contribute ideas. You can't replace<br/>those.  <br/>  <br/>Let's rehearse the chain of argument so far. I'm heading for a conclusion to<br/>which many readers will have to be dragged kicking and screaming, so I've<br/>tried to make each link unbreakable. Decreasing economic inequality means<br/>taking money from the rich. Since risk and reward are equivalent, decreasing<br/>potential rewards automatically decreases people's appetite for risk. Startups<br/>are intrinsically risky. Without the prospect of rewards proportionate to the<br/>risk, founders will not invest their time in a startup. Founders are<br/>irreplaceable. So eliminating economic inequality means eliminating startups.  <br/>  <br/>Economic inequality is not just a consequence of startups. It's the engine<br/>that drives them, in the same way a fall of water drives a water mill. People<br/>start startups in the hope of becoming much richer than they were before. And<br/>if your society tries to prevent anyone from being much richer than anyone<br/>else, it will also prevent one person from being much richer at t2 than t1.  <br/>  <br/> **Growth**  <br/>  <br/>This argument applies proportionately. It's not just that if you eliminate<br/>economic inequality, you get no startups. To the extent you reduce economic<br/>inequality, you decrease the number of startups. [4] Increase taxes, and<br/>willingness to take risks decreases in proportion.  <br/>  <br/>And that seems bad for everyone. New technology and new jobs both come<br/>disproportionately from new companies. Indeed, if you don't have startups,<br/>pretty soon you won't have established companies either, just as, if you stop<br/>having kids, pretty soon you won't have any adults.  <br/>  <br/>It sounds benevolent to say we ought to reduce economic inequality. When you<br/>phrase it that way, who can argue with you? _Inequality_ has to be bad, right?<br/>It sounds a good deal less benevolent to say we ought to reduce the rate at<br/>which new companies are founded. And yet the one implies the other.  <br/>  <br/>Indeed, it may be that reducing investors' appetite for risk doesn't merely<br/>kill off larval startups, but kills off the most promising ones especially.<br/>Startups yield faster growth at greater risk than established companies. Does<br/>this trend also hold among startups? That is, are the riskiest startups the<br/>ones that generate most growth if they succeed? I suspect the answer is yes.<br/>And that's a chilling thought, because it means that if you cut investors'<br/>appetite for risk, the most beneficial startups are the first to go.  <br/>  <br/>Not all rich people got that way from startups, of course. What if we let<br/>people get rich by starting startups, but taxed away all other surplus wealth?<br/>Wouldn't that at least decrease inequality?  <br/>  <br/>Less than you might think. If you made it so that people could only get rich<br/>by starting startups, people who wanted to get rich would all start startups.<br/>And that might be a great thing. But I don't think it would have much effect<br/>on the distribution of wealth. People who want to get rich will do whatever<br/>they have to. If startups are the only way to do it, you'll just get far more<br/>people starting startups. (If you write the laws very carefully, that is. More<br/>likely, you'll just get a lot of people doing things that can be made to look<br/>on paper like startups.)  <br/>  <br/>If we're determined to eliminate economic inequality, there is still one way<br/>out: we could say that we're willing to go ahead and do without startups. What<br/>would happen if we did?  <br/>  <br/>At a minimum, we'd have to accept lower rates of technological growth. If you<br/>believe that large, established companies could somehow be made to develop new<br/>technology as fast as startups, the ball is in your court to explain how. (If<br/>you can come up with a remotely plausible story, you can make a fortune<br/>writing business books and consulting for large companies.) [5]  <br/>  <br/>Ok, so we get slower growth. Is that so bad? Well, one reason it's bad in<br/>practice is that other countries might not agree to slow down with us. If<br/>you're content to develop new technologies at a slower rate than the rest of<br/>the world, what happens is that you don't invent anything at all. Anything you<br/>might discover has already been invented elsewhere. And the only thing you can<br/>offer in return is raw materials and cheap labor. Once you sink that low,<br/>other countries can do whatever they like with you: install puppet<br/>governments, siphon off your best workers, use your women as prostitutes, dump<br/>their toxic waste on your territory-- all the things we do to poor countries<br/>now. The only defense is to isolate yourself, as communist countries did in<br/>the twentieth century. But the problem then is, you have to become a police<br/>state to enforce it.  <br/>  <br/>**Wealth and Power**  <br/>  <br/>I realize startups are not the main target of those who want to eliminate<br/>economic inequality. What they really dislike is the sort of wealth that<br/>becomes self-perpetuating through an alliance with power. For example,<br/>construction firms that fund politicians' campaigns in return for government<br/>contracts, or rich parents who get their children into good colleges by<br/>sending them to expensive schools designed for that purpose. But if you try to<br/>attack this type of wealth through _economic_ policy, it's hard to hit without<br/>destroying startups as collateral damage.  <br/>  <br/>The problem here is not wealth, but corruption. So why not go after<br/>corruption?  <br/>  <br/>We don't need to prevent people from being rich if we can prevent wealth from<br/>translating into power. And there has been progress on that front. Before he<br/>died of drink in 1925, Commodore Vanderbilt's wastrel grandson Reggie ran down<br/>pedestrians on five separate occasions, killing two of them. By 1969, when Ted<br/>Kennedy drove off the bridge at Chappaquiddick, the limit seemed to be down to<br/>one. Today it may well be zero. But what's changed is not variation in wealth.<br/>What's changed is the ability to translate wealth into power.  <br/>  <br/>How do you break the connection between wealth and power? Demand transparency.<br/>Watch closely how power is exercised, and demand an account of how decisions<br/>are made. Why aren't all police interrogations videotaped? Why did 36% of<br/>Princeton's class of 2007 come from prep schools, when only 1.7% of American<br/>kids attend them? Why did the US really invade Iraq? Why don't government<br/>officials disclose more about their finances, and why only during their term<br/>of office?  <br/>  <br/>A friend of mine who knows a lot about computer security says the single most<br/>important step is to log everything. Back when he was a kid trying to break<br/>into computers, what worried him most was the idea of leaving a trail. He was<br/>more inconvenienced by the need to avoid that than by any obstacle<br/>deliberately put in his path.  <br/>  <br/>Like all illicit connections, the connection between wealth and power<br/>flourishes in secret. Expose all transactions, and you will greatly reduce it.<br/>Log everything. That's a strategy that already seems to be working, and it<br/>doesn't have the side effect of making your whole country poor.  <br/>  <br/>I don't think many people realize there is a connection between economic<br/>inequality and risk. I didn't fully grasp it till recently. I'd known for<br/>years of course that if one didn't score in a startup, the other alternative<br/>was to get a cozy, tenured research job. But I didn't understand the equation<br/>governing my behavior. Likewise, it's obvious empirically that a country that<br/>doesn't let people get rich is headed for disaster, whether it's Diocletian's<br/>Rome or Harold Wilson's Britain. But I did not till recently understand the<br/>role risk played.  <br/>  <br/>If you try to attack wealth, you end up nailing risk as well, and with it<br/>growth. If we want a fairer world, I think we're better off attacking one step<br/>downstream, where wealth turns into power.  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Success here is defined from the initial investors' point of view: either<br/>an IPO, or an acquisition for more than the valuation at the last round of<br/>funding. The conventional 1 in 10 success rate is suspiciously neat, but<br/>conversations with VCs suggest it's roughly correct for startups overall. Top<br/>VC firms expect to do better.  <br/>  <br/>[2] I'm not claiming founders sit down and calculate the expected after-tax<br/>return from a startup. They're motivated by examples of other people who did<br/>it. And those examples do reflect after-tax returns.  <br/>  <br/>[3] Conjecture: The variation in wealth in a (non-corrupt) country or<br/>organization will be inversely proportional to the prevalence of systems of<br/>seniority. So if you suppress variation in wealth, seniority will become<br/>correspondingly more important. So far, I know of no counterexamples, though<br/>in very corrupt countries you may get both simultaneously. (Thanks to Daniel<br/>Sobral for pointing this out.)  <br/>  <br/>[4] In a country with a truly feudal economy, you might be able to<br/>redistribute wealth successfully, because there are no startups to kill.  <br/>  <br/>[5] The speed at which startups develop new techology is the other reason they<br/>pay so well. As I explained in "How to Make Wealth" (in Hackers & Painters),<br/>what you do in a startup is compress a lifetime's worth of work into a few<br/>years. It seems as dumb to discourage that as to discourage risk-taking.  <br/>  <br/>**Thanks** to Chris Anderson, Trevor Blackwell, Dan Giffin, Jessica<br/>Livingston, and Evan Williams for reading drafts of this essay, and to Langley<br/>Steinert, Sangam Pant, and Mike Moritz for information about venture<br/>investing.  <br/>  <br/><br/>Romanian Translation  <br/>  <br/><br/>Dutch Translation  <br/>  <br/><br/>Traditional Chinese Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Hebrew Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>May 2006  <br/>  <br/> _(This essay is derived from a keynote at Xtech.)_  <br/>  <br/>Could you reproduce Silicon Valley elsewhere, or is there something unique<br/>about it?  <br/>  <br/>It wouldn't be surprising if it were hard to reproduce in other countries,<br/>because you couldn't reproduce it in most of the US either. What does it take<br/>to make a silicon valley even here?  <br/>  <br/>What it takes is the right people. If you could get the right ten thousand<br/>people to move from Silicon Valley to Buffalo, Buffalo would become Silicon<br/>Valley. [1]  <br/>  <br/>That's a striking departure from the past. Up till a couple decades ago,<br/>geography was destiny for cities. All great cities were located on waterways,<br/>because cities made money by trade, and water was the only economical way to<br/>ship.  <br/>  <br/>Now you could make a great city anywhere, if you could get the right people to<br/>move there. So the question of how to make a silicon valley becomes: who are<br/>the right people, and how do you get them to move?  <br/>  <br/> **Two Types**  <br/>  <br/>I think you only need two kinds of people to create a technology hub: rich<br/>people and nerds. They're the limiting reagents in the reaction that produces<br/>startups, because they're the only ones present when startups get started.<br/>Everyone else will move.  <br/>  <br/>Observation bears this out: within the US, towns have become startup hubs if<br/>and only if they have both rich people and nerds. Few startups happen in<br/>Miami, for example, because although it's full of rich people, it has few<br/>nerds. It's not the kind of place nerds like.  <br/>  <br/>Whereas Pittsburgh has the opposite problem: plenty of nerds, but no rich<br/>people. The top US Computer Science departments are said to be MIT, Stanford,<br/>Berkeley, and Carnegie-Mellon. MIT yielded Route 128. Stanford and Berkeley<br/>yielded Silicon Valley. But Carnegie-Mellon? The record skips at that point.<br/>Lower down the list, the University of Washington yielded a high-tech<br/>community in Seattle, and the University of Texas at Austin yielded one in<br/>Austin. But what happened in Pittsburgh? And in Ithaca, home of Cornell, which<br/>is also high on the list?  <br/>  <br/>I grew up in Pittsburgh and went to college at Cornell, so I can answer for<br/>both. The weather is terrible, particularly in winter, and there's no<br/>interesting old city to make up for it, as there is in Boston. Rich people<br/>don't want to live in Pittsburgh or Ithaca. So while there are plenty of<br/>hackers who could start startups, there's no one to invest in them.  <br/>  <br/> **Not Bureaucrats**  <br/>  <br/>Do you really need the rich people? Wouldn't it work to have the government<br/>invest in the nerds? No, it would not. Startup investors are a distinct type<br/>of rich people. They tend to have a lot of experience themselves in the<br/>technology business. This (a) helps them pick the right startups, and (b)<br/>means they can supply advice and connections as well as money. And the fact<br/>that they have a personal stake in the outcome makes them really pay<br/>attention.  <br/>  <br/>Bureaucrats by their nature are the exact opposite sort of people from startup<br/>investors. The idea of them making startup investments is comic. It would be<br/>like mathematicians running _Vogue_ \-- or perhaps more accurately, _Vogue_<br/>editors running a math journal. [2]  <br/>  <br/>Though indeed, most things bureaucrats do, they do badly. We just don't notice<br/>usually, because they only have to compete against other bureaucrats. But as<br/>startup investors they'd have to compete against pros with a great deal more<br/>experience and motivation.  <br/>  <br/>Even corporations that have in-house VC groups generally forbid them to make<br/>their own investment decisions. Most are only allowed to invest in deals where<br/>some reputable private VC firm is willing to act as lead investor.  <br/>  <br/> **Not Buildings**  <br/>  <br/>If you go to see Silicon Valley, what you'll see are buildings. But it's the<br/>people that make it Silicon Valley, not the buildings. I read occasionally<br/>about attempts to set up "technology parks" in other places, as if the active<br/>ingredient of Silicon Valley were the office space. An article about Sophia<br/>Antipolis bragged that companies there included Cisco, Compaq, IBM, NCR, and<br/>Nortel. Don't the French realize these aren't startups?  <br/>  <br/>Building office buildings for technology companies won't get you a silicon<br/>valley, because the key stage in the life of a startup happens before they<br/>want that kind of space. The key stage is when they're three guys operating<br/>out of an apartment. Wherever the startup is when it gets funded, it will<br/>stay. The defining quality of Silicon Valley is not that Intel or Apple or<br/>Google have offices there, but that they were _started_ there.  <br/>  <br/>So if you want to reproduce Silicon Valley, what you need to reproduce is<br/>those two or three founders sitting around a kitchen table deciding to start a<br/>company. And to reproduce that you need those people.  <br/>  <br/> **Universities**  <br/>  <br/>The exciting thing is, _all_ you need are the people. If you could attract a<br/>critical mass of nerds and investors to live somewhere, you could reproduce<br/>Silicon Valley. And both groups are highly mobile. They'll go where life is<br/>good. So what makes a place good to them?  <br/>  <br/>What nerds like is other nerds. Smart people will go wherever other smart<br/>people are. And in particular, to great universities. In theory there could be<br/>other ways to attract them, but so far universities seem to be indispensable.<br/>Within the US, there are no technology hubs without first-rate universities--<br/>or at least, first-rate computer science departments.  <br/>  <br/>So if you want to make a silicon valley, you not only need a university, but<br/>one of the top handful in the world. It has to be good enough to act as a<br/>magnet, drawing the best people from thousands of miles away. And that means<br/>it has to stand up to existing magnets like MIT and Stanford.  <br/>  <br/>This sounds hard. Actually it might be easy. My professor friends, when<br/>they're deciding where they'd like to work, consider one thing above all: the<br/>quality of the other faculty. What attracts professors is good colleagues. So<br/>if you managed to recruit, en masse, a significant number of the best young<br/>researchers, you could create a first-rate university from nothing overnight.<br/>And you could do that for surprisingly little. If you paid 200 people hiring<br/>bonuses of $3 million apiece, you could put together a faculty that would bear<br/>comparison with any in the world. And from that point the chain reaction would<br/>be self-sustaining. So whatever it costs to establish a mediocre university,<br/>for an additional half billion or so you could have a great one. [3]  <br/>  <br/> **Personality**  <br/>  <br/>However, merely creating a new university would not be enough to start a<br/>silicon valley. The university is just the seed. It has to be planted in the<br/>right soil, or it won't germinate. Plant it in the wrong place, and you just<br/>create Carnegie-Mellon.  <br/>  <br/>To spawn startups, your university has to be in a town that has attractions<br/>other than the university. It has to be a place where investors want to live,<br/>and students want to stay after they graduate.  <br/>  <br/>The two like much the same things, because most startup investors are nerds<br/>themselves. So what do nerds look for in a town? Their tastes aren't<br/>completely different from other people's, because a lot of the towns they like<br/>most in the US are also big tourist destinations: San Francisco, Boston,<br/>Seattle. But their tastes can't be quite mainstream either, because they<br/>dislike other big tourist destinations, like New York, Los Angeles, and Las<br/>Vegas.  <br/>  <br/>There has been a lot written lately about the "creative class." The thesis<br/>seems to be that as wealth derives increasingly from ideas, cities will<br/>prosper only if they attract those who have them. That is certainly true; in<br/>fact it was the basis of Amsterdam's prosperity 400 years ago.  <br/>  <br/>A lot of nerd tastes they share with the creative class in general. For<br/>example, they like well-preserved old neighborhoods instead of cookie-cutter<br/>suburbs, and locally-owned shops and restaurants instead of national chains.<br/>Like the rest of the creative class, they want to live somewhere with<br/>personality.  <br/>  <br/>What exactly is personality? I think it's the feeling that each building is<br/>the work of a distinct group of people. A town with personality is one that<br/>doesn't feel mass-produced. So if you want to make a startup hub-- or any town<br/>to attract the "creative class"-- you probably have to ban large development<br/>projects. When a large tract has been developed by a single organization, you<br/>can always tell. [4]  <br/>  <br/>Most towns with personality are old, but they don't have to be. Old towns have<br/>two advantages: they're denser, because they were laid out before cars, and<br/>they're more varied, because they were built one building at a time. You could<br/>have both now. Just have building codes that ensure density, and ban large<br/>scale developments.  <br/>  <br/>A corollary is that you have to keep out the biggest developer of all: the<br/>government. A government that asks "How can we build a silicon valley?" has<br/>probably ensured failure by the way they framed the question. You don't build<br/>a silicon valley; you let one grow.  <br/>  <br/> **Nerds**  <br/>  <br/>If you want to attract nerds, you need more than a town with personality. You<br/>need a town with the right personality. Nerds are a distinct subset of the<br/>creative class, with different tastes from the rest. You can see this most<br/>clearly in New York, which attracts a lot of creative people, but few nerds.<br/>[5]  <br/>  <br/>What nerds like is the kind of town where people walk around smiling. This<br/>excludes LA, where no one walks at all, and also New York, where people walk,<br/>but not smiling. When I was in grad school in Boston, a friend came to visit<br/>from New York. On the subway back from the airport she asked "Why is everyone<br/>smiling?" I looked and they weren't smiling. They just looked like they were<br/>compared to the facial expressions she was used to.  <br/>  <br/>If you've lived in New York, you know where these facial expressions come<br/>from. It's the kind of place where your mind may be excited, but your body<br/>knows it's having a bad time. People don't so much enjoy living there as<br/>endure it for the sake of the excitement. And if you like certain kinds of<br/>excitement, New York is incomparable. It's a hub of glamour, a magnet for all<br/>the shorter half-life isotopes of style and fame.  <br/>  <br/>Nerds don't care about glamour, so to them the appeal of New York is a<br/>mystery. People who like New York will pay a fortune for a small, dark, noisy<br/>apartment in order to live in a town where the cool people are really cool. A<br/>nerd looks at that deal and sees only: pay a fortune for a small, dark, noisy<br/>apartment.  <br/>  <br/>Nerds _will_ pay a premium to live in a town where the smart people are really<br/>smart, but you don't have to pay as much for that. It's supply and demand:<br/>glamour is popular, so you have to pay a lot for it.  <br/>  <br/>Most nerds like quieter pleasures. They like cafes instead of clubs; used<br/>bookshops instead of fashionable clothing shops; hiking instead of dancing;<br/>sunlight instead of tall buildings. A nerd's idea of paradise is Berkeley or<br/>Boulder.  <br/>  <br/> **Youth**  <br/>  <br/>It's the young nerds who start startups, so it's those specifically the city<br/>has to appeal to. The startup hubs in the US are all young-feeling towns. This<br/>doesn't mean they have to be new. Cambridge has the oldest town plan in<br/>America, but it feels young because it's full of students.  <br/>  <br/>What you can't have, if you want to create a silicon valley, is a large,<br/>existing population of stodgy people. It would be a waste of time to try to<br/>reverse the fortunes of a declining industrial town like Detroit or<br/>Philadelphia by trying to encourage startups. Those places have too much<br/>momentum in the wrong direction. You're better off starting with a blank slate<br/>in the form of a small town. Or better still, if there's a town young people<br/>already flock to, that one.  <br/>  <br/>The Bay Area was a magnet for the young and optimistic for decades before it<br/>was associated with technology. It was a place people went in search of<br/>something new. And so it became synonymous with California nuttiness. There's<br/>still a lot of that there. If you wanted to start a new fad-- a new way to<br/>focus one's "energy," for example, or a new category of things not to eat--<br/>the Bay Area would be the place to do it. But a place that tolerates oddness<br/>in the search for the new is exactly what you want in a startup hub, because<br/>economically that's what startups are. Most good startup ideas seem a little<br/>crazy; if they were obviously good ideas, someone would have done them<br/>already.  <br/>  <br/>(How many people are going to want computers in their _houses_? What,<br/>_another_ search engine?)  <br/>  <br/>That's the connection between technology and liberalism. Without exception the<br/>high-tech cities in the US are also the most liberal. But it's not because<br/>liberals are smarter that this is so. It's because liberal cities tolerate odd<br/>ideas, and smart people by definition have odd ideas.  <br/>  <br/>Conversely, a town that gets praised for being "solid" or representing<br/>"traditional values" may be a fine place to live, but it's never going to<br/>succeed as a startup hub. The 2004 presidential election, though a disaster in<br/>other respects, conveniently supplied us with a county-by-county  map of such<br/>places. [6]  <br/>  <br/>To attract the young, a town must have an intact center. In most American<br/>cities the center has been abandoned, and the growth, if any, is in the<br/>suburbs. Most American cities have been turned inside out. But none of the<br/>startup hubs has: not San Francisco, or Boston, or Seattle. They all have<br/>intact centers. [7] My guess is that no city with a dead center could be<br/>turned into a startup hub. Young people don't want to live in the suburbs.  <br/>  <br/>Within the US, the two cities I think could most easily be turned into new<br/>silicon valleys are Boulder and Portland. Both have the kind of effervescent<br/>feel that attracts the young. They're each only a great university short of<br/>becoming a silicon valley, if they wanted to.  <br/>  <br/> **Time**  <br/>  <br/>A great university near an attractive town. Is that all it takes? That was all<br/>it took to make the original Silicon Valley. Silicon Valley traces its origins<br/>to William Shockley, one of the inventors of the transistor. He did the<br/>research that won him the Nobel Prize at Bell Labs, but when he started his<br/>own company in 1956 he moved to Palo Alto to do it. At the time that was an<br/>odd thing to do. Why did he? Because he had grown up there and remembered how<br/>nice it was. Now Palo Alto is suburbia, but then it was a charming college<br/>town-- a charming college town with perfect weather and San Francisco only an<br/>hour away.  <br/>  <br/>The companies that rule Silicon Valley now are all descended in various ways<br/>from Shockley Semiconductor. Shockley was a difficult man, and in 1957 his top<br/>people-- "the traitorous eight"-- left to start a new company, Fairchild<br/>Semiconductor. Among them were Gordon Moore and Robert Noyce, who went on to<br/>found Intel, and Eugene Kleiner, who founded the VC firm Kleiner Perkins.<br/>Forty-two years later, Kleiner Perkins funded Google, and the partner<br/>responsible for the deal was John Doerr, who came to Silicon Valley in 1974 to<br/>work for Intel.  <br/>  <br/>So although a lot of the newest companies in Silicon Valley don't make<br/>anything out of silicon, there always seem to be multiple links back to<br/>Shockley. There's a lesson here: startups beget startups. People who work for<br/>startups start their own. People who get rich from startups fund new ones. I<br/>suspect this kind of organic growth is the only way to produce a startup hub,<br/>because it's the only way to grow the expertise you need.  <br/>  <br/>That has two important implications. The first is that you need time to grow a<br/>silicon valley. The university you could create in a couple years, but the<br/>startup community around it has to grow organically. The cycle time is limited<br/>by the time it takes a company to succeed, which probably averages about five<br/>years.  <br/>  <br/>The other implication of the organic growth hypothesis is that you can't be<br/>somewhat of a startup hub. You either have a self-sustaining chain reaction,<br/>or not. Observation confirms this too: cities either have a startup scene, or<br/>they don't. There is no middle ground. Chicago has the third largest<br/>metropolitan area in America. As source of startups it's negligible compared<br/>to Seattle, number 15.  <br/>  <br/>The good news is that the initial seed can be quite small. Shockley<br/>Semiconductor, though itself not very successful, was big enough. It brought a<br/>critical mass of experts in an important new technology together in a place<br/>they liked enough to stay.  <br/>  <br/> **Competing**  <br/>  <br/>Of course, a would-be silicon valley faces an obstacle the original one<br/>didn't: it has to compete with Silicon Valley. Can that be done? Probably.  <br/>  <br/>One of Silicon Valley's biggest advantages is its venture capital firms. This<br/>was not a factor in Shockley's day, because VC funds didn't exist. In fact,<br/>Shockley Semiconductor and Fairchild Semiconductor were not startups at all in<br/>our sense. They were subsidiaries-- of Beckman Instruments and Fairchild<br/>Camera and Instrument respectively. Those companies were apparently willing to<br/>establish subsidiaries wherever the experts wanted to live.  <br/>  <br/>Venture investors, however, prefer to fund startups within an hour's drive.<br/>For one, they're more likely to notice startups nearby. But when they do<br/>notice startups in other towns they prefer them to move. They don't want to<br/>have to travel to attend board meetings, and in any case the odds of<br/>succeeding are higher in a startup hub.  <br/>  <br/>The centralizing effect of venture firms is a double one: they cause startups<br/>to form around them, and those draw in more startups through acquisitions. And<br/>although the first may be weakening because it's now so cheap to start some<br/>startups, the second seems as strong as ever. Three of the most admired "Web<br/>2.0" companies were started outside the usual startup hubs, but two of them<br/>have already been reeled in through acquisitions.  <br/>  <br/>Such centralizing forces make it harder for new silicon valleys to get<br/>started. But by no means impossible. Ultimately power rests with the founders.<br/>A startup with the best people will beat one with funding from famous VCs, and<br/>a startup that was sufficiently successful would never have to move. So a town<br/>that could exert enough pull over the right people could resist and perhaps<br/>even surpass Silicon Valley.  <br/>  <br/>For all its power, Silicon Valley has a great weakness: the paradise Shockley<br/>found in 1956 is now one giant parking lot. San Francisco and Berkeley are<br/>great, but they're forty miles away. Silicon Valley proper is soul-crushing<br/>suburban sprawl. It has fabulous weather, which makes it significantly better<br/>than the soul-crushing sprawl of most other American cities. But a competitor<br/>that managed to avoid sprawl would have real leverage. All a city needs is to<br/>be the kind of place the next traitorous eight look at and say "I want to stay<br/>here," and that would be enough to get the chain reaction started.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] It's interesting to consider how low this number could be made. I suspect<br/>five hundred would be enough, even if they could bring no assets with them.<br/>Probably just thirty, if I could pick them, would be enough to turn Buffalo<br/>into a significant startup hub.  <br/>  <br/>[2] Bureaucrats manage to allocate research funding moderately well, but only<br/>because (like an in-house VC fund) they outsource most of the work of<br/>selection. A professor at a famous university who is highly regarded by his<br/>peers will get funding, pretty much regardless of the proposal. That wouldn't<br/>work for startups, whose founders aren't sponsored by organizations, and are<br/>often unknowns.  <br/>  <br/>[3] You'd have to do it all at once, or at least a whole department at a time,<br/>because people would be more likely to come if they knew their friends were.<br/>And you should probably start from scratch, rather than trying to upgrade an<br/>existing university, or much energy would be lost in friction.  <br/>  <br/>[4] Hypothesis: Any plan in which multiple independent buildings are gutted or<br/>demolished to be "redeveloped" as a single project is a net loss of<br/>personality for the city, with the exception of the conversion of buildings<br/>not previously public, like warehouses.  <br/>  <br/>[5] A few startups get started in New York, but less than a tenth as many per<br/>capita as in Boston, and mostly in less nerdy fields like finance and media.  <br/>  <br/>[6] Some blue counties are false positives (reflecting the remaining power of<br/>Democractic party machines), but there are no false negatives. You can safely<br/>write off all the red counties.  <br/>  <br/>[7] Some "urban renewal" experts took a shot at destroying Boston's in the<br/>1960s, leaving the area around city hall a bleak wasteland, but most<br/>neighborhoods successfully resisted them.  <br/>  <br/> **Thanks** to Chris Anderson, Trevor Blackwell, Marc Hedlund, Jessica<br/>Livingston, Robert Morris, Greg Mcadoo, Fred Wilson, and Stephen Wolfram for<br/>reading drafts of this, and to Ed Dumbill for inviting me to speak.  <br/>  <br/>(The second part of this talk became Why Startups Condense in America.)  <br/>  <br/><br/>VC Deals by Region  <br/>  <br/><br/>Startup Jobs by Region  <br/>  <br/><br/>They Would Be Gods  <br/>  <br/><br/>Interview: Richard Hodgson  <br/>  <br/><br/>Santa Clara Valley, 1971  <br/>  <br/><br/>Scattered Abroad  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Portuguese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>December 2010  <br/>  <br/>Someone we funded is talking to VCs now, and asked me how common it was for a<br/>startup's founders to retain control of the board after a series A round. He<br/>said VCs told him this almost never happened.  <br/>  <br/>Ten years ago that was true. In the past, founders rarely kept control of the<br/>board through a series A. The traditional series A board consisted of two<br/>founders, two VCs, and one independent member. More recently the recipe is<br/>often one founder, one VC, and one independent. In either case the founders<br/>lose their majority.  <br/>  <br/>But not always. Mark Zuckerberg kept control of Facebook's board through the<br/>series A and still has it today. Mark Pincus has kept control of Zynga's too.<br/>But are these just outliers? How common is it for founders to keep control<br/>after an A round? I'd heard of several cases among the companies we've funded,<br/>but I wasn't sure how many there were, so I emailed the ycfounders list.  <br/>  <br/>The replies surprised me. In a dozen companies we've funded, the founders<br/>still had a majority of the board seats after the series A round.  <br/>  <br/>I feel like we're at a tipping point here. A lot of VCs still act as if<br/>founders retaining board control after a series A is unheard-of. A lot of them<br/>try to make you feel bad if you even ask — as if you're a noob or a control<br/>freak for wanting such a thing. But the founders I heard from aren't noobs or<br/>control freaks. Or if they are, they are, like Mark Zuckerberg, the kind of<br/>noobs and control freaks VCs should be trying to fund more of.  <br/>  <br/>Founders retaining control after a series A is clearly heard-of. And barring<br/>financial catastrophe, I think in the coming year it will become the norm.  <br/>  <br/>Control of a company is a more complicated matter than simply outvoting other<br/>parties in board meetings. Investors usually get vetos over certain big<br/>decisions, like selling the company, regardless of how many board seats they<br/>have. And board votes are rarely split. Matters are decided in the discussion<br/>preceding the vote, not in the vote itself, which is usually unanimous. But if<br/>opinion is divided in such discussions, the side that knows it would lose in a<br/>vote will tend to be less insistent. That's what board control means in<br/>practice. You don't simply get to do whatever you want; the board still has to<br/>act in the interest of the shareholders; but if you have a majority of board<br/>seats, then your opinion about what's in the interest of the shareholders will<br/>tend to prevail.  <br/>  <br/>So while board control is not total control, it's not imaginary either.<br/>There's inevitably a difference in how things feel within the company. Which<br/>means if it becomes the norm for founders to retain board control after a<br/>series A, that will change the way things feel in the whole startup world.  <br/>  <br/>The switch to the new norm may be surprisingly fast, because the startups that<br/>can retain control tend to be the best ones. They're the ones that set the<br/>trends, both for other startups and for VCs.  <br/>  <br/>A lot of the reason VCs are harsh when negotiating with startups is that<br/>they're embarrassed to go back to their partners looking like they got beaten.<br/>When they sign a termsheet, they want to be able to brag about the good terms<br/>they got. A lot of them don't care that much personally about whether founders<br/>keep board control. They just don't want to seem like they had to make<br/>concessions. Which means if letting the founders keep control stops being<br/>perceived as a concession, it will rapidly become much more common.  <br/>  <br/>Like a lot of changes that have been forced on VCs, this change won't turn out<br/>to be as big a problem as they might think. VCs will still be able to<br/>convince; they just won't be able to compel. And the startups where they have<br/>to resort to compulsion are not the ones that matter anyway. VCs make most of<br/>their money from a few big hits, and those aren't them.  <br/>  <br/>Knowing that founders will keep control of the board may even help VCs pick<br/>better. If they know they can't fire the founders, they'll have to choose<br/>founders they can trust. And that's who they should have been choosing all<br/>along.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Thanks** to Sam Altman, John Bautista, Trevor Blackwell, Paul Buchheit,<br/>Brian Chesky, Bill Clerico, Patrick Collison, Adam Goldstein, James<br/>Lindenbaum, Jessica Livingston, and Fred Wilson for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>December 2019  <br/>  <br/>I've seen the same pattern in many different fields: even though lots of<br/>people have worked hard in the field, only a small fraction of the space of<br/>possibilities has been explored, because they've all worked on similar things.  <br/>  <br/>Even the smartest, most imaginative people are surprisingly conservative when<br/>deciding what to work on. People who would never dream of being fashionable in<br/>any other way get sucked into working on fashionable problems.  <br/>  <br/>If you want to try working on unfashionable problems, one of the best places<br/>to look is in fields that people think have already been fully explored:<br/>essays, Lisp, venture funding  you may notice a pattern here. If you can find<br/>a new approach into a big but apparently played out field, the value of<br/>whatever you discover will be _multiplied_ by its enormous surface area.  <br/>  <br/>The best protection against getting drawn into working on the same things as<br/>everyone else may be to _genuinely love_ what you're doing. Then you'll<br/>continue to work on it even if you make the same mistake as other people and<br/>think that it's too marginal to matter.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>September 2012  <br/>  <br/>I've done several types of work over the years but I don't know another as<br/>counterintuitive as startup investing.  <br/>  <br/>The two most important things to understand about startup investing, as a<br/>business, are (1) that effectively all the returns are concentrated in a few<br/>big winners, and (2) that the best ideas look initially like bad ideas.  <br/>  <br/>The first rule I knew intellectually, but didn't really grasp till it happened<br/>to us. The total value of the companies we've funded is around 10 billion,<br/>give or take a few. But just two companies, Dropbox and Airbnb, account for<br/>about three quarters of it.  <br/>  <br/>In startups, the big winners are big to a degree that violates our<br/>expectations about variation. I don't know whether these expectations are<br/>innate or learned, but whatever the cause, we are just not prepared for the<br/>1000x variation in outcomes that one finds in startup investing.  <br/>  <br/>That yields all sorts of strange consequences. For example, in purely<br/>financial terms, there is probably at most one company in each YC batch that<br/>will have a significant effect on our returns, and the rest are just a cost of<br/>doing business. [1] I haven't really assimilated that fact, partly because<br/>it's so counterintuitive, and partly because we're not doing this just for<br/>financial reasons; YC would be a pretty lonely place if we only had one<br/>company per batch. And yet it's true.  <br/>  <br/>To succeed in a domain that violates your intuitions, you need to be able to<br/>turn them off the way a pilot does when flying through clouds. [2] You need to<br/>do what you know intellectually to be right, even though it feels wrong.  <br/>  <br/>It's a constant battle for us. It's hard to make ourselves take enough risks.<br/>When you interview a startup and think "they seem likely to succeed," it's<br/>hard not to fund them. And yet, financially at least, there is only one kind<br/>of success: they're either going to be one of the really big winners or not,<br/>and if not it doesn't matter whether you fund them, because even if they<br/>succeed the effect on your returns will be insignificant. In the same day of<br/>interviews you might meet some smart 19 year olds who aren't even sure what<br/>they want to work on. Their chances of succeeding seem small. But again, it's<br/>not their chances of succeeding that matter but their chances of succeeding<br/>really big. The probability that any group will succeed really big is<br/>microscopically small, but the probability that those 19 year olds will might<br/>be higher than that of the other, safer group.  <br/>  <br/>The probability that a startup will make it big is not simply a constant<br/>fraction of the probability that they will succeed at all. If it were, you<br/>could fund everyone who seemed likely to succeed at all, and you'd get that<br/>fraction of big hits. Unfortunately picking winners is harder than that. You<br/>have to ignore the elephant in front of you, the likelihood they'll succeed,<br/>and focus instead on the separate and almost invisibly intangible question of<br/>whether they'll succeed really big.  <br/>  <br/> **Harder**  <br/>  <br/>That's made harder by the fact that the best startup ideas seem at first like<br/>bad ideas. I've written about this before: if a good idea were obviously good,<br/>someone else would already have done it. So the most successful founders tend<br/>to work on ideas that few beside them realize are good. Which is not that far<br/>from a description of insanity, till you reach the point where you see<br/>results.  <br/>  <br/>The first time Peter Thiel spoke at YC he drew a Venn diagram that illustrates<br/>the situation perfectly. He drew two intersecting circles, one labelled "seems<br/>like a bad idea" and the other "is a good idea." The intersection is the sweet<br/>spot for startups.  <br/>  <br/>This concept is a simple one and yet seeing it as a Venn diagram is<br/>illuminating. It reminds you that there is an intersection—that there are good<br/>ideas that seem bad. It also reminds you that the vast majority of ideas that<br/>seem bad are bad.  <br/>  <br/>The fact that the best ideas seem like bad ideas makes it even harder to<br/>recognize the big winners. It means the probability of a startup making it<br/>really big is not merely not a constant fraction of the probability that it<br/>will succeed, but that the startups with a high probability of the former will<br/>seem to have a disproportionately low probability of the latter.  <br/>  <br/>History tends to get rewritten by big successes, so that in retrospect it<br/>seems obvious they were going to make it big. For that reason one of my most<br/>valuable memories is how lame Facebook sounded to me when I first heard about<br/>it. A site for college students to waste time? It seemed the perfect bad idea:<br/>a site (1) for a niche market (2) with no money (3) to do something that<br/>didn't matter.  <br/>  <br/>One could have described Microsoft and Apple in exactly the same terms. [3]  <br/>  <br/> **Harder Still**  <br/>  <br/>Wait, it gets worse. You not only have to solve this hard problem, but you<br/>have to do it with no indication of whether you're succeeding. When you pick a<br/>big winner, you won't know it for two years.  <br/>  <br/>Meanwhile, the one thing you _can_ measure is dangerously misleading. The one<br/>thing we can track precisely is how well the startups in each batch do at<br/>fundraising after Demo Day. But we know that's the wrong metric. There's no<br/>correlation between the percentage of startups that raise money and the metric<br/>that does matter financially, whether that batch of startups contains a big<br/>winner or not.  <br/>  <br/>Except an inverse one. That's the scary thing: fundraising is not merely a<br/>useless metric, but positively misleading. We're in a business where we need<br/>to pick unpromising-looking outliers, and the huge scale of the successes<br/>means we can afford to spread our net very widely. The big winners could<br/>generate 10,000x returns. That means for each big winner we could pick a<br/>thousand companies that returned nothing and still end up 10x ahead.  <br/>  <br/>If we ever got to the point where 100% of the startups we funded were able to<br/>raise money after Demo Day, it would almost certainly mean we were being too<br/>conservative. [4]  <br/>  <br/>It takes a conscious effort not to do that too. After 15 cycles of preparing<br/>startups for investors and then watching how they do, I can now look at a<br/>group we're interviewing through Demo Day investors' eyes. But those are the<br/>wrong eyes to look through!  <br/>  <br/>We can afford to take at least 10x as much risk as Demo Day investors. And<br/>since risk is usually proportionate to reward, if you can afford to take more<br/>risk you should. What would it mean to take 10x more risk than Demo Day<br/>investors? We'd have to be willing to fund 10x more startups than they would.<br/>Which means that even if we're generous to ourselves and assume that YC can on<br/>average triple a startup's expected value, we'd be taking the right amount of<br/>risk if only 30% of the startups were able to raise significant funding after<br/>Demo Day.  <br/>  <br/>I don't know what fraction of them currently raise more after Demo Day. I<br/>deliberately avoid calculating that number, because if you start measuring<br/>something you start optimizing it, and I know it's the wrong thing to<br/>optimize. [5] But the percentage is certainly way over 30%. And frankly the<br/>thought of a 30% success rate at fundraising makes my stomach clench. A Demo<br/>Day where only 30% of the startups were fundable would be a shambles. Everyone<br/>would agree that YC had jumped the shark. We ourselves would feel that YC had<br/>jumped the shark. And yet we'd all be wrong.  <br/>  <br/>For better or worse that's never going to be more than a thought experiment.<br/>We could never stand it. How about that for counterintuitive? I can lay out<br/>what I know to be the right thing to do, and still not do it. I can make up<br/>all sorts of plausible justifications. It would hurt YC's brand (at least<br/>among the innumerate) if we invested in huge numbers of risky startups that<br/>flamed out. It might dilute the value of the alumni network. Perhaps most<br/>convincingly, it would be demoralizing for us to be up to our chins in failure<br/>all the time. But I know the real reason we're so conservative is that we just<br/>haven't assimilated the fact of 1000x variation in returns.  <br/>  <br/>We'll probably never be able to bring ourselves to take risks proportionate to<br/>the returns in this business. The best we can hope for is that when we<br/>interview a group and find ourselves thinking "they seem like good founders,<br/>but what are investors going to think of this crazy idea?" we'll continue to<br/>be able to say "who cares what investors think?" That's what we thought about<br/>Airbnb, and if we want to fund more Airbnbs we have to stay good at thinking<br/>it.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] I'm not saying that the big winners are all that matters, just that<br/>they're all that matters financially for investors. Since we're not doing YC<br/>mainly for financial reasons, the big winners aren't all that matters to us.<br/>We're delighted to have funded Reddit, for example. Even though we made<br/>comparatively little from it, Reddit has had a big effect on the world, and it<br/>introduced us to Steve Huffman and Alexis Ohanian, both of whom have become<br/>good friends.  <br/>  <br/>Nor do we push founders to try to become one of the big winners if they don't<br/>want to. We didn't "swing for the fences" in our own startup (Viaweb, which<br/>was acquired for $50 million), and it would feel pretty bogus to press<br/>founders to do something we didn't do. Our rule is that it's up to the<br/>founders. Some want to take over the world, and some just want that first few<br/>million. But we invest in so many companies that we don't have to sweat any<br/>one outcome. In fact, we don't have to sweat whether startups have exits at<br/>all. The biggest exits are the only ones that matter financially, and those<br/>are guaranteed in the sense that if a company becomes big enough, a market for<br/>its shares will inevitably arise. Since the remaining outcomes don't have a<br/>significant effect on returns, it's cool with us if the founders want to sell<br/>early for a small amount, or grow slowly and never sell (i.e. become a so-<br/>called lifestyle business), or even shut the company down. We're sometimes<br/>disappointed when a startup we had high hopes for doesn't do well, but this<br/>disappointment is mostly the ordinary variety that anyone feels when that<br/>happens.  <br/>  <br/>[2] Without visual cues (e.g. the horizon) you can't distinguish between<br/>gravity and acceleration. Which means if you're flying through clouds you<br/>can't tell what the attitude of the aircraft is. You could feel like you're<br/>flying straight and level while in fact you're descending in a spiral. The<br/>solution is to ignore what your body is telling you and listen only to your<br/>instruments. But it turns out to be very hard to ignore what your body is<br/>telling you. Every pilot knows about this problem and yet it is still a<br/>leading cause of accidents.  <br/>  <br/>[3] Not all big hits follow this pattern though. The reason Google seemed a<br/>bad idea was that there were already lots of search engines and there didn't<br/>seem to be room for another.  <br/>  <br/>[4] A startup's success at fundraising is a function of two things: what<br/>they're selling and how good they are at selling it. And while we can teach<br/>startups a lot about how to appeal to investors, even the most convincing<br/>pitch can't sell an idea that investors don't like. I was genuinely worried<br/>that Airbnb, for example, would not be able to raise money after Demo Day. I<br/>couldn't convince Fred Wilson to fund them. They might not have raised money<br/>at all but for the coincidence that Greg Mcadoo, our contact at Sequoia, was<br/>one of a handful of VCs who understood the vacation rental business, having<br/>spent much of the previous two years investigating it.  <br/>  <br/>[5] I calculated it once for the last batch before a consortium of investors<br/>started offering investment automatically to every startup we funded, summer<br/>2010. At the time it was 94% (33 of 35 companies that tried to raise money<br/>succeeded, and one didn't try because they were already profitable).<br/>Presumably it's lower now because of that investment; in the old days it was<br/>raise after Demo Day or die.  <br/>  <br/> **Thanks** to Sam Altman, Paul Buchheit, Patrick Collison, Jessica<br/>Livingston, Geoff Ralston, and Harj Taggar for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>October 2007  <br/>  <br/>After the last talk I gave, one of the organizers got up on the stage to<br/>deliver an impromptu rebuttal. That never happened before. I only heard the<br/>first few sentences, but that was enough to tell what I said that upset him:<br/>that startups would do better if they moved to Silicon Valley.  <br/>  <br/>This conference was in London, and most of the audience seemed to be from the<br/>UK. So saying startups should move to Silicon Valley seemed like a<br/>nationalistic remark: an obnoxious American telling them that if they wanted<br/>to do things right they should all just move to America.  <br/>  <br/>Actually I'm less American than I seem. I didn't say so, but I'm British by<br/>birth. And just as Jews are ex officio allowed to tell Jewish jokes, I don't<br/>feel like I have to bother being diplomatic with a British audience.  <br/>  <br/>The idea that startups would do better to move to Silicon Valley is not even a<br/>nationalistic one. [1] It's the same thing I say to startups in the US. Y<br/>Combinator alternates between coasts every 6 months. Every other funding cycle<br/>is in Boston. And even though Boston is the second biggest startup hub in the<br/>US (and the world), we tell the startups from those cycles that their best bet<br/>is to move to Silicon Valley. If that's true of Boston, it's even more true of<br/>every other city.  <br/>  <br/>This is about cities, not countries.  <br/>  <br/>And I think I can prove I'm right. You can easily reduce the opposing argument<br/>ad what most people would agree was absurdum. Few would be willing to claim<br/>that it doesn't matter at all where a startup is—that a startup operating out<br/>of a small agricultural town wouldn't benefit from moving to a startup hub.<br/>Most people could see how it might be helpful to be in a place where there was<br/>infrastructure for startups, accumulated knowledge about how to make them<br/>work, and other people trying to do it. And yet whatever argument you use to<br/>prove that startups don't need to move from London to Silicon Valley could<br/>equally well be used to prove startups don't need to move from smaller towns<br/>to London.  <br/>  <br/>The difference between cities is a matter of degree. And if, as nearly<br/>everyone who knows agrees, startups are better off in Silicon Valley than<br/>Boston, then they're better off in Silicon Valley than everywhere else too.  <br/>  <br/>I realize I might seem to have a vested interest in this conclusion, because<br/>startups that move to the US might do it through Y Combinator. But the<br/>American startups we've funded will attest that I say the same thing to them.  <br/>  <br/>I'm not claiming of course that every startup has to go to Silicon Valley to<br/>succeed. Just that all other things being equal, the more of a startup hub a<br/>place is, the better startups will do there. But other considerations can<br/>outweigh the advantages of moving. I'm not saying founders with families<br/>should uproot them to move halfway around the world; that might be too much of<br/>a distraction.  <br/>  <br/>Immigration difficulties might be another reason to stay put. Dealing with<br/>immigration problems is like raising money: for some reason it seems to<br/>consume all your attention. A startup can't afford much of that. One Canadian<br/>startup we funded spent about 6 months working on moving to the US. Eventually<br/>they just gave up, because they couldn't afford to take so much time away from<br/>working on their software.  <br/>  <br/>(If another country wanted to establish a rival to Silicon Valley, the single<br/>best thing they could do might be to create a special visa for startup<br/>founders. US immigration policy is one of Silicon Valley's biggest<br/>weaknesses.)  <br/>  <br/>If your startup is connected to a specific industry, you may be better off in<br/>one of its centers. A startup doing something related to entertainment might<br/>want to be in New York or LA.  <br/>  <br/>And finally, if a good investor has committed to fund you if you stay where<br/>you are, you should probably stay. Finding investors is hard. You generally<br/>shouldn't pass up a definite funding offer to move. [2]  <br/>  <br/>In fact, the quality of the investors may be the main advantage of startup<br/>hubs. Silicon Valley investors are noticeably more aggressive than Boston<br/>ones. Over and over, I've seen startups we've funded snatched by west coast<br/>investors out from under the noses of Boston investors who saw them first but<br/>acted too slowly. At this year's Boston Demo Day, I told the audience that<br/>this happened every year, so if they saw a startup they liked, they should<br/>make them an offer. And yet within a month it had happened again: an<br/>aggressive west coast VC who had met the founder of a YC-funded startup a week<br/>before beat out a Boston VC who had known him for years. By the time the<br/>Boston VC grasped what was happening, the deal was already gone.  <br/>  <br/>Boston investors will admit they're more conservative. Some want to believe<br/>this comes from the city's prudent Yankee character. But Occam's razor<br/>suggests the truth is less flattering. Boston investors are probably more<br/>conservative than Silicon Valley investors for the same reason Chicago<br/>investors are more conservative than Boston ones. They don't understand<br/>startups as well.  <br/>  <br/>West coast investors aren't bolder because they're irresponsible cowboys, or<br/>because the good weather makes them optimistic. They're bolder because they<br/>know what they're doing. They're the skiers who ski on the diamond slopes.<br/>Boldness is the essence of venture investing. The way you get big returns is<br/>not by trying to avoid losses, but by trying to ensure you get some of the big<br/>hits. And the big hits often look risky at first.  <br/>  <br/>Like Facebook. Facebook was started in Boston. Boston VCs had the first shot<br/>at them. But they said no, so Facebook moved to Silicon Valley and raised<br/>money there. The partner who turned them down now says that "may turn out to<br/>have been a mistake."  <br/>  <br/>Empirically, boldness wins. If the aggressive ways of west coast investors are<br/>going to come back to bite them, it has been a long time coming. Silicon<br/>Valley has been pulling ahead of Boston since the 1970s. If there was going to<br/>be a comeuppance for the west coast investors, the bursting of the Bubble<br/>would have been it. But since then the west coast has just pulled further<br/>ahead.  <br/>  <br/>West coast investors are confident enough of their judgement to act boldly;<br/>east coast investors, not so much; but anyone who thinks east coast investors<br/>act that way out of prudence should see the frantic reactions of an east coast<br/>VC in the process of losing a deal to a west coast one.  <br/>  <br/>In addition to the concentration that comes from specialization, startup hubs<br/>are also markets. And markets are usually centralized. Even now, when traders<br/>could be anywhere, they cluster in a few cities. It's hard to say exactly what<br/>it is about face to face contact that makes deals happen, but whatever it is,<br/>it hasn't yet been duplicated by technology.  <br/>  <br/>Walk down University Ave at the right time, and you might overhear five<br/>different people talking on the phone about deals. In fact, this is part of<br/>the reason Y Combinator is in Boston half the time: it's hard to stand that<br/>year round. But though it can sometimes be annoying to be surrounded by people<br/>who only think about one thing, it's the place to be if that one thing is what<br/>you're trying to do.  <br/>  <br/>I was talking recently to someone who works on search at Google. He knew a lot<br/>of people at Yahoo, so he was in a good position to compare the two companies.<br/>I asked him why Google was better at search. He said it wasn't anything<br/>specific Google did, but simply that they understood search so much better.  <br/>  <br/>And that's why startups thrive in startup hubs like Silicon Valley. Startups<br/>are a very specialized business, as specialized as diamond cutting. And in<br/>startup hubs they understand it.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] The nationalistic idea is the converse: that startups should stay in a<br/>certain city because of the country it's in. If you really have a "one world"<br/>viewpoint, deciding to move from London to Silicon Valley is no different from<br/>deciding to move from Chicago to Silicon Valley.  <br/>  <br/>[2] An investor who merely seems like he will fund you, however, you can<br/>ignore. Seeming like they will fund you one day is the way investors say No.  <br/>  <br/> **Thanks** to Sam Altman, Jessica Livingston, Harjeet Taggar, and Kulveer<br/>Taggar for reading drafts of this.  <br/>  <br/>Comment on this essay.  <br/>  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>April 2001, rev. April 2003  <br/>  <br/> _(This article is derived from a talk given at the 2001 Franz Developer<br/>Symposium.)_  <br/>  <br/>In the summer of 1995, my friend Robert Morris and I started a startup called<br/>Viaweb. Our plan was to write software that would let end users build online<br/>stores. What was novel about this software, at the time, was that it ran on<br/>our server, using ordinary Web pages as the interface.  <br/>  <br/>A lot of people could have been having this idea at the same time, of course,<br/>but as far as I know, Viaweb was the first Web-based application. It seemed<br/>such a novel idea to us that we named the company after it: Viaweb, because<br/>our software worked via the Web, instead of running on your desktop computer.  <br/>  <br/>Another unusual thing about this software was that it was written primarily in<br/>a programming language called Lisp. It was one of the first big end-user<br/>applications to be written in Lisp, which up till then had been used mostly in<br/>universities and research labs. [1]  <br/>  <br/> **The Secret Weapon**  <br/>  <br/>Eric Raymond has written an essay called "How to Become a Hacker," and in it,<br/>among other things, he tells would-be hackers what languages they should<br/>learn. He suggests starting with Python and Java, because they are easy to<br/>learn. The serious hacker will also want to learn C, in order to hack Unix,<br/>and Perl for system administration and cgi scripts. Finally, the truly serious<br/>hacker should consider learning Lisp:<br/><br/>> Lisp is worth learning for the profound enlightenment experience you will<br/>> have when you finally get it; that experience will make you a better<br/>> programmer for the rest of your days, even if you never actually use Lisp<br/>> itself a lot.<br/><br/>This is the same argument you tend to hear for learning Latin. It won't get<br/>you a job, except perhaps as a classics professor, but it will improve your<br/>mind, and make you a better writer in languages you do want to use, like<br/>English.  <br/>  <br/>But wait a minute. This metaphor doesn't stretch that far. The reason Latin<br/>won't get you a job is that no one speaks it. If you write in Latin, no one<br/>can understand you. But Lisp is a computer language, and computers speak<br/>whatever language you, the programmer, tell them to.  <br/>  <br/>So if Lisp makes you a better programmer, like he says, why wouldn't you want<br/>to use it? If a painter were offered a brush that would make him a better<br/>painter, it seems to me that he would want to use it in all his paintings,<br/>wouldn't he? I'm not trying to make fun of Eric Raymond here. On the whole,<br/>his advice is good. What he says about Lisp is pretty much the conventional<br/>wisdom. But there is a contradiction in the conventional wisdom: Lisp will<br/>make you a better programmer, and yet you won't use it.  <br/>  <br/>Why not? Programming languages are just tools, after all. If Lisp really does<br/>yield better programs, you should use it. And if it doesn't, then who needs<br/>it?  <br/>  <br/>This is not just a theoretical question. Software is a very competitive<br/>business, prone to natural monopolies. A company that gets software written<br/>faster and better will, all other things being equal, put its competitors out<br/>of business. And when you're starting a startup, you feel this very keenly.<br/>Startups tend to be an all or nothing proposition. You either get rich, or you<br/>get nothing. In a startup, if you bet on the wrong technology, your<br/>competitors will crush you.  <br/>  <br/>Robert and I both knew Lisp well, and we couldn't see any reason not to trust<br/>our instincts and go with Lisp. We knew that everyone else was writing their<br/>software in C++ or Perl. But we also knew that that didn't mean anything. If<br/>you chose technology that way, you'd be running Windows. When you choose<br/>technology, you have to ignore what other people are doing, and consider only<br/>what will work the best.  <br/>  <br/>This is especially true in a startup. In a big company, you can do what all<br/>the other big companies are doing. But a startup can't do what all the other<br/>startups do. I don't think a lot of people realize this, even in startups.  <br/>  <br/>The average big company grows at about ten percent a year. So if you're<br/>running a big company and you do everything the way the average big company<br/>does it, you can expect to do as well as the average big company-- that is, to<br/>grow about ten percent a year.  <br/>  <br/>The same thing will happen if you're running a startup, of course. If you do<br/>everything the way the average startup does it, you should expect average<br/>performance. The problem here is, average performance means that you'll go out<br/>of business. The survival rate for startups is way less than fifty percent. So<br/>if you're running a startup, you had better be doing something odd. If not,<br/>you're in trouble.  <br/>  <br/>Back in 1995, we knew something that I don't think our competitors understood,<br/>and few understand even now: when you're writing software that only has to run<br/>on your own servers, you can use any language you want. When you're writing<br/>desktop software, there's a strong bias toward writing applications in the<br/>same language as the operating system. Ten years ago, writing applications<br/>meant writing applications in C. But with Web-based software, especially when<br/>you have the source code of both the language and the operating system, you<br/>can use whatever language you want.  <br/>  <br/>This new freedom is a double-edged sword, however. Now that you can use any<br/>language, you have to think about which one to use. Companies that try to<br/>pretend nothing has changed risk finding that their competitors do not.  <br/>  <br/>If you can use any language, which do you use? We chose Lisp. For one thing,<br/>it was obvious that rapid development would be important in this market. We<br/>were all starting from scratch, so a company that could get new features done<br/>before its competitors would have a big advantage. We knew Lisp was a really<br/>good language for writing software quickly, and server-based applications<br/>magnify the effect of rapid development, because you can release software the<br/>minute it's done.  <br/>  <br/>If other companies didn't want to use Lisp, so much the better. It might give<br/>us a technological edge, and we needed all the help we could get. When we<br/>started Viaweb, we had no experience in business. We didn't know anything<br/>about marketing, or hiring people, or raising money, or getting customers.<br/>Neither of us had ever even had what you would call a real job. The only thing<br/>we were good at was writing software. We hoped that would save us. Any<br/>advantage we could get in the software department, we would take.  <br/>  <br/>So you could say that using Lisp was an experiment. Our hypothesis was that if<br/>we wrote our software in Lisp, we'd be able to get features done faster than<br/>our competitors, and also to do things in our software that they couldn't do.<br/>And because Lisp was so high-level, we wouldn't need a big development team,<br/>so our costs would be lower. If this were so, we could offer a better product<br/>for less money, and still make a profit. We would end up getting all the<br/>users, and our competitors would get none, and eventually go out of business.<br/>That was what we hoped would happen, anyway.  <br/>  <br/>What were the results of this experiment? Somewhat surprisingly, it worked. We<br/>eventually had many competitors, on the order of twenty to thirty of them, but<br/>none of their software could compete with ours. We had a wysiwyg online store<br/>builder that ran on the server and yet felt like a desktop application. Our<br/>competitors had cgi scripts. And we were always far ahead of them in features.<br/>Sometimes, in desperation, competitors would try to introduce features that we<br/>didn't have. But with Lisp our development cycle was so fast that we could<br/>sometimes duplicate a new feature within a day or two of a competitor<br/>announcing it in a press release. By the time journalists covering the press<br/>release got round to calling us, we would have the new feature too.  <br/>  <br/>It must have seemed to our competitors that we had some kind of secret<br/>weapon-- that we were decoding their Enigma traffic or something. In fact we<br/>did have a secret weapon, but it was simpler than they realized. No one was<br/>leaking news of their features to us. We were just able to develop software<br/>faster than anyone thought possible.  <br/>  <br/>When I was about nine I happened to get hold of a copy of _The Day of the<br/>Jackal,_ by Frederick Forsyth. The main character is an assassin who is hired<br/>to kill the president of France. The assassin has to get past the police to<br/>get up to an apartment that overlooks the president's route. He walks right by<br/>them, dressed up as an old man on crutches, and they never suspect him.  <br/>  <br/>Our secret weapon was similar. We wrote our software in a weird AI language,<br/>with a bizarre syntax full of parentheses. For years it had annoyed me to hear<br/>Lisp described that way. But now it worked to our advantage. In business,<br/>there is nothing more valuable than a technical advantage your competitors<br/>don't understand. In business, as in war, surprise is worth as much as force.  <br/>  <br/>And so, I'm a little embarrassed to say, I never said anything publicly about<br/>Lisp while we were working on Viaweb. We never mentioned it to the press, and<br/>if you searched for Lisp on our Web site, all you'd find were the titles of<br/>two books in my bio. This was no accident. A startup should give its<br/>competitors as little information as possible. If they didn't know what<br/>language our software was written in, or didn't care, I wanted to keep it that<br/>way.[2]  <br/>  <br/>The people who understood our technology best were the customers. They didn't<br/>care what language Viaweb was written in either, but they noticed that it<br/>worked really well. It let them build great looking online stores literally in<br/>minutes. And so, by word of mouth mostly, we got more and more users. By the<br/>end of 1996 we had about 70 stores online. At the end of 1997 we had 500. Six<br/>months later, when Yahoo bought us, we had 1070 users. Today, as Yahoo Store,<br/>this software continues to dominate its market. It's one of the more<br/>profitable pieces of Yahoo, and the stores built with it are the foundation of<br/>Yahoo Shopping. I left Yahoo in 1999, so I don't know exactly how many users<br/>they have now, but the last I heard there were about 20,000.  <br/>  <br/>**The Blub Paradox**  <br/>  <br/>What's so great about Lisp? And if Lisp is so great, why doesn't everyone use<br/>it? These sound like rhetorical questions, but actually they have<br/>straightforward answers. Lisp is so great not because of some magic quality<br/>visible only to devotees, but because it is simply the most powerful language<br/>available. And the reason everyone doesn't use it is that programming<br/>languages are not merely technologies, but habits of mind as well, and nothing<br/>changes slower. Of course, both these answers need explaining.  <br/>  <br/>I'll begin with a shockingly controversial statement: programming languages<br/>vary in power.  <br/>  <br/>Few would dispute, at least, that high level languages are more powerful than<br/>machine language. Most programmers today would agree that you do not,<br/>ordinarily, want to program in machine language. Instead, you should program<br/>in a high-level language, and have a compiler translate it into machine<br/>language for you. This idea is even built into the hardware now: since the<br/>1980s, instruction sets have been designed for compilers rather than human<br/>programmers.  <br/>  <br/>Everyone knows it's a mistake to write your whole program by hand in machine<br/>language. What's less often understood is that there is a more general<br/>principle here: that if you have a choice of several languages, it is, all<br/>other things being equal, a mistake to program in anything but the most<br/>powerful one. [3]  <br/>  <br/>There are many exceptions to this rule. If you're writing a program that has<br/>to work very closely with a program written in a certain language, it might be<br/>a good idea to write the new program in the same language. If you're writing a<br/>program that only has to do something very simple, like number crunching or<br/>bit manipulation, you may as well use a less abstract language, especially<br/>since it may be slightly faster. And if you're writing a short, throwaway<br/>program, you may be better off just using whatever language has the best<br/>library functions for the task. But in general, for application software, you<br/>want to be using the most powerful (reasonably efficient) language you can<br/>get, and using anything else is a mistake, of exactly the same kind, though<br/>possibly in a lesser degree, as programming in machine language.  <br/>  <br/>You can see that machine language is very low level. But, at least as a kind<br/>of social convention, high-level languages are often all treated as<br/>equivalent. They're not. Technically the term "high-level language" doesn't<br/>mean anything very definite. There's no dividing line with machine languages<br/>on one side and all the high-level languages on the other. Languages fall<br/>along a continuum [4] of abstractness, from the most powerful all the way down<br/>to machine languages, which themselves vary in power.  <br/>  <br/>Consider Cobol. Cobol is a high-level language, in the sense that it gets<br/>compiled into machine language. Would anyone seriously argue that Cobol is<br/>equivalent in power to, say, Python? It's probably closer to machine language<br/>than Python.  <br/>  <br/>Or how about Perl 4? Between Perl 4 and Perl 5, lexical closures got added to<br/>the language. Most Perl hackers would agree that Perl 5 is more powerful than<br/>Perl 4. But once you've admitted that, you've admitted that one high level<br/>language can be more powerful than another. And it follows inexorably that,<br/>except in special cases, you ought to use the most powerful you can get.  <br/>  <br/>This idea is rarely followed to its conclusion, though. After a certain age,<br/>programmers rarely switch languages voluntarily. Whatever language people<br/>happen to be used to, they tend to consider just good enough.  <br/>  <br/>Programmers get very attached to their favorite languages, and I don't want to<br/>hurt anyone's feelings, so to explain this point I'm going to use a<br/>hypothetical language called Blub. Blub falls right in the middle of the<br/>abstractness continuum. It is not the most powerful language, but it is more<br/>powerful than Cobol or machine language.  <br/>  <br/>And in fact, our hypothetical Blub programmer wouldn't use either of them. Of<br/>course he wouldn't program in machine language. That's what compilers are for.<br/>And as for Cobol, he doesn't know how anyone can get anything done with it. It<br/>doesn't even have x (Blub feature of your choice).  <br/>  <br/>As long as our hypothetical Blub programmer is looking down the power<br/>continuum, he knows he's looking down. Languages less powerful than Blub are<br/>obviously less powerful, because they're missing some feature he's used to.<br/>But when our hypothetical Blub programmer looks in the other direction, up the<br/>power continuum, he doesn't realize he's looking up. What he sees are merely<br/>weird languages. He probably considers them about equivalent in power to Blub,<br/>but with all this other hairy stuff thrown in as well. Blub is good enough for<br/>him, because he thinks in Blub.  <br/>  <br/>When we switch to the point of view of a programmer using any of the languages<br/>higher up the power continuum, however, we find that he in turn looks down<br/>upon Blub. How can you get anything done in Blub? It doesn't even have y.  <br/>  <br/>By induction, the only programmers in a position to see all the differences in<br/>power between the various languages are those who understand the most powerful<br/>one. (This is probably what Eric Raymond meant about Lisp making you a better<br/>programmer.) You can't trust the opinions of the others, because of the Blub<br/>paradox: they're satisfied with whatever language they happen to use, because<br/>it dictates the way they think about programs.  <br/>  <br/>I know this from my own experience, as a high school kid writing programs in<br/>Basic. That language didn't even support recursion. It's hard to imagine<br/>writing programs without using recursion, but I didn't miss it at the time. I<br/>thought in Basic. And I was a whiz at it. Master of all I surveyed.  <br/>  <br/>The five languages that Eric Raymond recommends to hackers fall at various<br/>points on the power continuum. Where they fall relative to one another is a<br/>sensitive topic. What I will say is that I think Lisp is at the top. And to<br/>support this claim I'll tell you about one of the things I find missing when I<br/>look at the other four languages. How can you get anything done in them, I<br/>think, without macros? [5]  <br/>  <br/>Many languages have something called a macro. But Lisp macros are unique. And<br/>believe it or not, what they do is related to the parentheses. The designers<br/>of Lisp didn't put all those parentheses in the language just to be different.<br/>To the Blub programmer, Lisp code looks weird. But those parentheses are there<br/>for a reason. They are the outward evidence of a fundamental difference<br/>between Lisp and other languages.  <br/>  <br/>Lisp code is made out of Lisp data objects. And not in the trivial sense that<br/>the source files contain characters, and strings are one of the data types<br/>supported by the language. Lisp code, after it's read by the parser, is made<br/>of data structures that you can traverse.  <br/>  <br/>If you understand how compilers work, what's really going on is not so much<br/>that Lisp has a strange syntax as that Lisp has no syntax. You write programs<br/>in the parse trees that get generated within the compiler when other languages<br/>are parsed. But these parse trees are fully accessible to your programs. You<br/>can write programs that manipulate them. In Lisp, these programs are called<br/>macros. They are programs that write programs.  <br/>  <br/>Programs that write programs? When would you ever want to do that? Not very<br/>often, if you think in Cobol. All the time, if you think in Lisp. It would be<br/>convenient here if I could give an example of a powerful macro, and say there!<br/>how about that? But if I did, it would just look like gibberish to someone who<br/>didn't know Lisp; there isn't room here to explain everything you'd need to<br/>know to understand what it meant. In Ansi Common Lisp I tried to move things<br/>along as fast as I could, and even so I didn't get to macros until page 160.  <br/>  <br/>But I think I can give a kind of argument that might be convincing. The source<br/>code of the Viaweb editor was probably about 20-25% macros. Macros are harder<br/>to write than ordinary Lisp functions, and it's considered to be bad style to<br/>use them when they're not necessary. So every macro in that code is there<br/>because it has to be. What that means is that at least 20-25% of the code in<br/>this program is doing things that you can't easily do in any other language.<br/>However skeptical the Blub programmer might be about my claims for the<br/>mysterious powers of Lisp, this ought to make him curious. We weren't writing<br/>this code for our own amusement. We were a tiny startup, programming as hard<br/>as we could in order to put technical barriers between us and our competitors.  <br/>  <br/>A suspicious person might begin to wonder if there was some correlation here.<br/>A big chunk of our code was doing things that are very hard to do in other<br/>languages. The resulting software did things our competitors' software<br/>couldn't do. Maybe there was some kind of connection. I encourage you to<br/>follow that thread. There may be more to that old man hobbling along on his<br/>crutches than meets the eye.  <br/>  <br/> **Aikido for Startups**  <br/>  <br/>But I don't expect to convince anyone (over 25) to go out and learn Lisp. The<br/>purpose of this article is not to change anyone's mind, but to reassure people<br/>already interested in using Lisp-- people who know that Lisp is a powerful<br/>language, but worry because it isn't widely used. In a competitive situation,<br/>that's an advantage. Lisp's power is multiplied by the fact that your<br/>competitors don't get it.  <br/>  <br/>If you think of using Lisp in a startup, you shouldn't worry that it isn't<br/>widely understood. You should hope that it stays that way. And it's likely to.<br/>It's the nature of programming languages to make most people satisfied with<br/>whatever they currently use. Computer hardware changes so much faster than<br/>personal habits that programming practice is usually ten to twenty years<br/>behind the processor. At places like MIT they were writing programs in high-<br/>level languages in the early 1960s, but many companies continued to write code<br/>in machine language well into the 1980s. I bet a lot of people continued to<br/>write machine language until the processor, like a bartender eager to close up<br/>and go home, finally kicked them out by switching to a risc instruction set.  <br/>  <br/>Ordinarily technology changes fast. But programming languages are different:<br/>programming languages are not just technology, but what programmers think in.<br/>They're half technology and half religion.[6] And so the median language,<br/>meaning whatever language the median programmer uses, moves as slow as an<br/>iceberg. Garbage collection, introduced by Lisp in about 1960, is now widely<br/>considered to be a good thing. Runtime typing, ditto, is growing in<br/>popularity. Lexical closures, introduced by Lisp in the early 1970s, are now,<br/>just barely, on the radar screen. Macros, introduced by Lisp in the mid 1960s,<br/>are still terra incognita.  <br/>  <br/>Obviously, the median language has enormous momentum. I'm not proposing that<br/>you can fight this powerful force. What I'm proposing is exactly the opposite:<br/>that, like a practitioner of Aikido, you can use it against your opponents.  <br/>  <br/>If you work for a big company, this may not be easy. You will have a hard time<br/>convincing the pointy-haired boss to let you build things in Lisp, when he has<br/>just read in the paper that some other language is poised, like Ada was twenty<br/>years ago, to take over the world. But if you work for a startup that doesn't<br/>have pointy-haired bosses yet, you can, like we did, turn the Blub paradox to<br/>your advantage: you can use technology that your competitors, glued immovably<br/>to the median language, will never be able to match.  <br/>  <br/>If you ever do find yourself working for a startup, here's a handy tip for<br/>evaluating competitors. Read their job listings. Everything else on their site<br/>may be stock photos or the prose equivalent, but the job listings have to be<br/>specific about what they want, or they'll get the wrong candidates.  <br/>  <br/>During the years we worked on Viaweb I read a lot of job descriptions. A new<br/>competitor seemed to emerge out of the woodwork every month or so. The first<br/>thing I would do, after checking to see if they had a live online demo, was<br/>look at their job listings. After a couple years of this I could tell which<br/>companies to worry about and which not to. The more of an IT flavor the job<br/>descriptions had, the less dangerous the company was. The safest kind were the<br/>ones that wanted Oracle experience. You never had to worry about those. You<br/>were also safe if they said they wanted C++ or Java developers. If they wanted<br/>Perl or Python programmers, that would be a bit frightening-- that's starting<br/>to sound like a company where the technical side, at least, is run by real<br/>hackers. If I had ever seen a job posting looking for Lisp hackers, I would<br/>have been really worried.  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] Viaweb at first had two parts: the editor, written in Lisp, which people<br/>used to build their sites, and the ordering system, written in C, which<br/>handled orders. The first version was mostly Lisp, because the ordering system<br/>was small. Later we added two more modules, an image generator written in C,<br/>and a back-office manager written mostly in Perl.  <br/>  <br/>In January 2003, Yahoo released a new version of the editor written in C++ and<br/>Perl. It's hard to say whether the program is no longer written in Lisp,<br/>though, because to translate this program into C++ they literally had to write<br/>a Lisp interpreter: the source files of all the page-generating templates are<br/>still, as far as I know, Lisp code. (See Greenspun's Tenth Rule.)  <br/>  <br/>[2] Robert Morris says that I didn't need to be secretive, because even if our<br/>competitors had known we were using Lisp, they wouldn't have understood why:<br/>"If they were that smart they'd already be programming in Lisp."  <br/>  <br/>[3] All languages are equally powerful in the sense of being Turing<br/>equivalent, but that's not the sense of the word programmers care about. (No<br/>one wants to program a Turing machine.) The kind of power programmers care<br/>about may not be formally definable, but one way to explain it would be to say<br/>that it refers to features you could only get in the less powerful language by<br/>writing an interpreter for the more powerful language in it. If language A has<br/>an operator for removing spaces from strings and language B doesn't, that<br/>probably doesn't make A more powerful, because you can probably write a<br/>subroutine to do it in B. But if A supports, say, recursion, and B doesn't,<br/>that's not likely to be something you can fix by writing library functions.  <br/>  <br/>[4] Note to nerds: or possibly a lattice, narrowing toward the top; it's not<br/>the shape that matters here but the idea that there is at least a partial<br/>order.  <br/>  <br/>[5] It is a bit misleading to treat macros as a separate feature. In practice<br/>their usefulness is greatly enhanced by other Lisp features like lexical<br/>closures and rest parameters.  <br/>  <br/>[6] As a result, comparisons of programming languages either take the form of<br/>religious wars or undergraduate textbooks so determinedly neutral that they're<br/>really works of anthropology. People who value their peace, or want tenure,<br/>avoid the topic. But the question is only half a religious one; there is<br/>something there worth studying, especially if you want to design new<br/>languages.  <br/>  <br/><br/>More Technical Details  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Turkish Translation  <br/>  <br/><br/>Uzbek Translation  <br/>  <br/><br/>Orbitz Uses Lisp Too  <br/>  <br/><br/>How To Become A Hacker  <br/>  <br/><br/>A Scheme Story  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>March 2005  <br/>  <br/>_(In the process of answering an email, I accidentally wrote a tiny essay<br/>about writing. I usually spend weeks on an essay. This one took 67 minutes—23<br/>of writing, and  44 of rewriting.)_  <br/>  <br/>I think it's far more important to write well than most people realize.<br/>Writing doesn't just communicate ideas; it generates them. If you're bad at<br/>writing and don't like to do it, you'll miss out on most of the ideas writing<br/>would have generated.  <br/>  <br/>As for how to write well, here's the short version: Write a bad version 1 as<br/>fast as you can; rewrite it over and over; cut ~~out~~ everything unnecessary;<br/>write in a conversational tone; develop a nose for bad writing, so you can see<br/>and fix it in yours; imitate writers you like; if you can't get started, tell<br/>someone what you plan to write about, then write down what you said; expect<br/>80% of the ideas in an essay to happen after you start writing it, and 50% of<br/>those you start with to be wrong; be confident enough to cut; have friends you<br/>trust read your stuff and tell you which bits are confusing or drag; don't<br/>(always) make detailed outlines; mull ideas over for a few days before<br/>writing; carry a small notebook or scrap paper with you; start writing when<br/>you think of the first sentence; if a deadline forces you to start before<br/>that, just say the most important sentence first; write about stuff you like;<br/>don't try to sound impressive; don't hesitate to change the topic on the fly;<br/>use footnotes to contain digressions; use anaphora to knit sentences together;<br/>read your essays out loud to see (a) where you stumble over awkward phrases<br/>and (b) which bits are boring (the paragraphs you dread reading); try to tell<br/>the reader something new and useful; work in fairly big quanta of time; when<br/>you restart, begin by rereading what you have so far; when you finish, leave<br/>yourself something easy to start with; accumulate notes for topics you plan to<br/>cover at the bottom of the file; don't feel obliged to cover any of them;<br/>write for a reader who won't read the essay as carefully as you do, just as<br/>pop songs are designed to sound ok on crappy car radios;  if you say anything<br/>mistaken, fix it immediately; ask friends which sentence you'll regret most;<br/>go back and tone down harsh remarks; publish stuff online, because an audience<br/>makes you write more, and thus generate more ideas; print out drafts instead<br/>of just looking at them on the screen; use simple, germanic words; learn to<br/>distinguish surprises from digressions; learn to recognize the approach of an<br/>ending, and when one appears, grab it.  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Romanian Translation  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>German Translation  <br/>  <br/><br/>Chinese Translation  <br/>  <br/><br/>Hungarian Translation  <br/>  <br/><br/>Catalan Translation  <br/>  <br/><br/>Danish Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>January 2017  <br/>  <br/>People who are powerful but uncharismatic will tend to be disliked. Their<br/>power makes them a target for criticism that they don't have the charisma to<br/>disarm. That was Hillary Clinton's problem. It also tends to be a problem for<br/>any CEO who is more of a builder than a schmoozer. And yet the builder-type<br/>CEO is (like Hillary) probably the best person for the job.  <br/>  <br/>I don't think there is any solution to this problem. It's human nature. The<br/>best we can do is to recognize that it's happening, and to understand that<br/>being a magnet for criticism is sometimes a sign not that someone is the wrong<br/>person for a job, but that they're the right one.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>October 2010  <br/>  <br/>After barely changing at all for decades, the startup funding business is now<br/>in what could, at least by comparison, be called turmoil. At Y Combinator<br/>we've seen dramatic changes in the funding environment for startups.<br/>Fortunately one of them is much higher valuations.  <br/>  <br/>The trends we've been seeing are probably not YC-specific. I wish I could say<br/>they were, but the main cause is probably just that we see trends first—partly<br/>because the startups we fund are very plugged into the Valley and are quick to<br/>take advantage of anything new, and partly because we fund so many that we<br/>have enough data points to see patterns clearly.  <br/>  <br/>What we're seeing now, everyone's probably going to be seeing in the next<br/>couple years. So I'm going to explain what we're seeing, and what that will<br/>mean for you if you try to raise money.  <br/>  <br/> **Super-Angels**  <br/>  <br/>Let me start by describing what the world of startup funding used to look<br/>like. There used to be two sharply differentiated types of investors: angels<br/>and venture capitalists. Angels are individual rich people who invest small<br/>amounts of their own money, while VCs are employees of funds that invest large<br/>amounts of other people's.  <br/>  <br/>For decades there were just those two types of investors, but now a third type<br/>has appeared halfway between them: the so-called super-angels. [1] And VCs<br/>have been provoked by their arrival into making a lot of angel-style<br/>investments themselves. So the previously sharp line between angels and VCs<br/>has become hopelessly blurred.  <br/>  <br/>There used to be a no man's land between angels and VCs. Angels would invest<br/>$20k to $50k apiece, and VCs usually a million or more. So an angel round<br/>meant a collection of angel investments that combined to maybe $200k, and a VC<br/>round meant a series A round in which a single VC fund (or occasionally two)<br/>invested $1-5 million.  <br/>  <br/>The no man's land between angels and VCs was a very inconvenient one for<br/>startups, because it coincided with the amount many wanted to raise. Most<br/>startups coming out of Demo Day wanted to raise around $400k. But it was a<br/>pain to stitch together that much out of angel investments, and most VCs<br/>weren't interested in investments so small. That's the fundamental reason the<br/>super-angels have appeared. They're responding to the market.  <br/>  <br/>The arrival of a new type of investor is big news for startups, because there<br/>used to be only two and they rarely competed with one another. Super-angels<br/>compete with both angels and VCs. That's going to change the rules about how<br/>to raise money. I don't know yet what the new rules will be, but it looks like<br/>most of the changes will be for the better.  <br/>  <br/>A super-angel has some of the qualities of an angel, and some of the qualities<br/>of a VC. They're usually individuals, like angels. In fact many of the current<br/>super-angels were initially angels of the classic type. But like VCs, they<br/>invest other people's money. This allows them to invest larger amounts than<br/>angels: a typical super-angel investment is currently about $100k. They make<br/>investment decisions quickly, like angels. And they make a lot more<br/>investments per partner than VCs—up to 10 times as many.  <br/>  <br/>The fact that super-angels invest other people's money makes them doubly<br/>alarming to VCs. They don't just compete for startups; they also compete for<br/>investors. What super-angels really are is a new form of fast-moving,<br/>lightweight VC fund. And those of us in the technology world know what usually<br/>happens when something comes along that can be described in terms like that.<br/>Usually it's the replacement.  <br/>  <br/>Will it be? As of now, few of the startups that take money from super-angels<br/>are ruling out taking VC money. They're just postponing it. But that's still a<br/>problem for VCs. Some of the startups that postpone raising VC money may do so<br/>well on the angel money they raise that they never bother to raise more. And<br/>those who do raise VC rounds will be able to get higher valuations when they<br/>do. If the best startups get 10x higher valuations when they raise series A<br/>rounds, that would cut VCs' returns from winners at least tenfold. [2]  <br/>  <br/>So I think VC funds are seriously threatened by the super-angels. But one<br/>thing that may save them to some extent is the uneven distribution of startup<br/>outcomes: practically all the returns are concentrated in a few big successes.<br/>The expected value of a startup is the percentage chance it's Google. So to<br/>the extent that winning is a matter of absolute returns, the super-angels<br/>could win practically all the battles for individual startups and yet lose the<br/>war, if they merely failed to get those few big winners. And there's a chance<br/>that could happen, because the top VC funds have better brands, and can also<br/>do more for their portfolio companies. [3]  <br/>  <br/>Because super-angels make more investments per partner, they have less partner<br/>per investment. They can't pay as much attention to you as a VC on your board<br/>could. How much is that extra attention worth? It will vary enormously from<br/>one partner to another. There's no consensus yet in the general case. So for<br/>now this is something startups are deciding individually.  <br/>  <br/>Till now, VCs' claims about how much value they added were sort of like the<br/>government's. Maybe they made you feel better, but you had no choice in the<br/>matter, if you needed money on the scale only VCs could supply. Now that VCs<br/>have competitors, that's going to put a market price on the help they offer.<br/>The interesting thing is, no one knows yet what it will be.  <br/>  <br/>Do startups that want to get really big need the sort of advice and<br/>connections only the top VCs can supply? Or would super-angel money do just as<br/>well? The VCs will say you need them, and the super-angels will say you don't.<br/>But the truth is, no one knows yet, not even the VCs and super-angels<br/>themselves. All the super-angels know is that their new model seems promising<br/>enough to be worth trying, and all the VCs know is that it seems promising<br/>enough to worry about.  <br/>  <br/> **Rounds**  <br/>  <br/>Whatever the outcome, the conflict between VCs and super-angels is good news<br/>for founders. And not just for the obvious reason that more competition for<br/>deals means better terms. The whole shape of deals is changing.  <br/>  <br/>One of the biggest differences between angels and VCs is the amount of your<br/>company they want. VCs want a lot. In a series A round they want a third of<br/>your company, if they can get it. They don't care much how much they pay for<br/>it, but they want a lot because the number of series A investments they can do<br/>is so small. In a traditional series A investment, at least one partner from<br/>the VC fund takes a seat on your board. [4] Since board seats last about 5<br/>years and each partner can't handle more than about 10 at once, that means a<br/>VC fund can only do about 2 series A deals per partner per year. And that<br/>means they need to get as much of the company as they can in each one. You'd<br/>have to be a very promising startup indeed to get a VC to use up one of his 10<br/>board seats for only a few percent of you.  <br/>  <br/>Since angels generally don't take board seats, they don't have this<br/>constraint. They're happy to buy only a few percent of you. And although the<br/>super-angels are in most respects mini VC funds, they've retained this<br/>critical property of angels. They don't take board seats, so they don't need a<br/>big percentage of your company.  <br/>  <br/>Though that means you'll get correspondingly less attention from them, it's<br/>good news in other respects. Founders never really liked giving up as much<br/>equity as VCs wanted. It was a lot of the company to give up in one shot. Most<br/>founders doing series A deals would prefer to take half as much money for half<br/>as much stock, and then see what valuation they could get for the second half<br/>of the stock after using the first half of the money to increase its value.<br/>But VCs never offered that option.  <br/>  <br/>Now startups have another alternative. Now it's easy to raise angel rounds<br/>about half the size of series A rounds. Many of the startups we fund are<br/>taking this route, and I predict that will be true of startups in general.  <br/>  <br/>A typical big angel round might be $600k on a convertible note with a<br/>valuation cap of $4 million premoney. Meaning that when the note converts into<br/>stock (in a later round, or upon acquisition), the investors in that round<br/>will get .6 / 4.6, or 13% of the company. That's a lot less than the 30 to 40%<br/>of the company you usually give up in a series A round if you do it so early.<br/>[5]  <br/>  <br/>But the advantage of these medium-sized rounds is not just that they cause<br/>less dilution. You also lose less control. After an angel round, the founders<br/>almost always still have control of the company, whereas after a series A<br/>round they often don't. The traditional board structure after a series A round<br/>is two founders, two VCs, and a (supposedly) neutral fifth person. Plus series<br/>A terms usually give the investors a veto over various kinds of important<br/>decisions, including selling the company. Founders usually have a lot of de<br/>facto control after a series A, as long as things are going well. But that's<br/>not the same as just being able to do what you want, like you could before.  <br/>  <br/>A third and quite significant advantage of angel rounds is that they're less<br/>stressful to raise. Raising a traditional series A round has in the past taken<br/>weeks, if not months. When a VC firm can only do 2 deals per partner per year,<br/>they're careful about which they do. To get a traditional series A round you<br/>have to go through a series of meetings, culminating in a full partner meeting<br/>where the firm as a whole says yes or no. That's the really scary part for<br/>founders: not just that series A rounds take so long, but at the end of this<br/>long process the VCs might still say no. The chance of getting rejected after<br/>the full partner meeting averages about 25%. At some firms it's over 50%.  <br/>  <br/>Fortunately for founders, VCs have been getting a lot faster. Nowadays Valley<br/>VCs are more likely to take 2 weeks than 2 months. But they're still not as<br/>fast as angels and super-angels, the most decisive of whom sometimes decide in<br/>hours.  <br/>  <br/>Raising an angel round is not only quicker, but you get feedback as it<br/>progresses. An angel round is not an all or nothing thing like a series A.<br/>It's composed of multiple investors with varying degrees of seriousness,<br/>ranging from the upstanding ones who commit unequivocally to the jerks who<br/>give you lines like "come back to me to fill out the round." You usually start<br/>collecting money from the most committed investors and work your way out<br/>toward the ambivalent ones, whose interest increases as the round fills up.  <br/>  <br/>But at each point you know how you're doing. If investors turn cold you may<br/>have to raise less, but when investors in an angel round turn cold the process<br/>at least degrades gracefully, instead of blowing up in your face and leaving<br/>you with nothing, as happens if you get rejected by a VC fund after a full<br/>partner meeting. Whereas if investors seem hot, you can not only close the<br/>round faster, but now that convertible notes are becoming the norm, actually<br/>raise the price to reflect demand.  <br/>  <br/> **Valuation**  <br/>  <br/>However, the VCs have a weapon they can use against the super-angels, and they<br/>have started to use it. VCs have started making angel-sized investments too.<br/>The term "angel round" doesn't mean that all the investors in it are angels;<br/>it just describes the structure of the round. Increasingly the participants<br/>include VCs making investments of a hundred thousand or two. And when VCs<br/>invest in angel rounds they can do things that super-angels don't like. VCs<br/>are quite valuation-insensitive in angel rounds—partly because they are in<br/>general, and partly because they don't care that much about the returns on<br/>angel rounds, which they still view mostly as a way to recruit startups for<br/>series A rounds later. So VCs who invest in angel rounds can blow up the<br/>valuations for angels and super-angels who invest in them. [6]  <br/>  <br/>Some super-angels seem to care about valuations. Several turned down YC-funded<br/>startups after Demo Day because their valuations were too high. This was not a<br/>problem for the startups; by definition a high valuation means enough<br/>investors were willing to accept it. But it was mysterious to me that the<br/>super-angels would quibble about valuations. Did they not understand that the<br/>big returns come from a few big successes, and that it therefore mattered far<br/>more which startups you picked than how much you paid for them?  <br/>  <br/>After thinking about it for a while and observing certain other signs, I have<br/>a theory that explains why the super-angels may be smarter than they seem. It<br/>would make sense for super-angels to want low valuations if they're hoping to<br/>invest in startups that get bought early. If you're hoping to hit the next<br/>Google, you shouldn't care if the valuation is 20 million. But if you're<br/>looking for companies that are going to get bought for 30 million, you care.<br/>If you invest at 20 and the company gets bought for 30, you only get 1.5x. You<br/>might as well buy Apple.  <br/>  <br/>So if some of the super-angels were looking for companies that could get<br/>acquired quickly, that would explain why they'd care about valuations. But why<br/>would they be looking for those? Because depending on the meaning of<br/>"quickly," it could actually be very profitable. A company that gets acquired<br/>for 30 million is a failure to a VC, but it could be a 10x return for an<br/>angel, and moreover, a _quick_ 10x return. Rate of return is what matters in<br/>investing—not the multiple you get, but the multiple per year. If a super-<br/>angel gets 10x in one year, that's a higher rate of return than a VC could<br/>ever hope to get from a company that took 6 years to go public. To get the<br/>same rate of return, the VC would have to get a multiple of 10^6—one million<br/>x. Even Google didn't come close to that.  <br/>  <br/>So I think at least some super-angels are looking for companies that will get<br/>bought. That's the only rational explanation for focusing on getting the right<br/>valuations, instead of the right companies. And if so they'll be different to<br/>deal with than VCs. They'll be tougher on valuations, but more accommodating<br/>if you want to sell early.  <br/>  <br/> **Prognosis**  <br/>  <br/>Who will win, the super-angels or the VCs? I think the answer to that is, some<br/>of each. They'll each become more like one another. The super-angels will<br/>start to invest larger amounts, and the VCs will gradually figure out ways to<br/>make more, smaller investments faster. A decade from now the players will be<br/>hard to tell apart, and there will probably be survivors from each group.  <br/>  <br/>What does that mean for founders? One thing it means is that the high<br/>valuations startups are presently getting may not last forever. To the extent<br/>that valuations are being driven up by price-insensitive VCs, they'll fall<br/>again if VCs become more like super-angels and start to become more miserly<br/>about valuations. Fortunately if this does happen it will take years.  <br/>  <br/>The short term forecast is more competition between investors, which is good<br/>news for you. The super-angels will try to undermine the VCs by acting faster,<br/>and the VCs will try to undermine the super-angels by driving up valuations.<br/>Which for founders will result in the perfect combination: funding rounds that<br/>close fast, with high valuations.  <br/>  <br/>But remember that to get that combination, your startup will have to appeal to<br/>both super-angels and VCs. If you don't seem like you have the potential to go<br/>public, you won't be able to use VCs to drive up the valuation of an angel<br/>round.  <br/>  <br/>There is a danger of having VCs in an angel round: the so-called signalling<br/>risk. If VCs are only doing it in the hope of investing more later, what<br/>happens if they don't? That's a signal to everyone else that they think you're<br/>lame.  <br/>  <br/>How much should you worry about that? The seriousness of signalling risk<br/>depends on how far along you are. If by the next time you need to raise money,<br/>you have graphs showing rising revenue or traffic month after month, you don't<br/>have to worry about any signals your existing investors are sending. Your<br/>results will speak for themselves. [7]  <br/>  <br/>Whereas if the next time you need to raise money you won't yet have concrete<br/>results, you may need to think more about the message your investors might<br/>send if they don't invest more. I'm not sure yet how much you have to worry,<br/>because this whole phenomenon of VCs doing angel investments is so new. But my<br/>instincts tell me you don't have to worry much. Signalling risk smells like<br/>one of those things founders worry about that's not a real problem. As a rule,<br/>the only thing that can kill a good startup is the startup itself. Startups<br/>hurt themselves way more often than competitors hurt them, for example. I<br/>suspect signalling risk is in this category too.  <br/>  <br/>One thing YC-funded startups have been doing to mitigate the risk of taking<br/>money from VCs in angel rounds is not to take too much from any one VC. Maybe<br/>that will help, if you have the luxury of turning down money.  <br/>  <br/>Fortunately, more and more startups will. After decades of competition that<br/>could best be described as intramural, the startup funding business is finally<br/>getting some real competition. That should last several years at least, and<br/>maybe a lot longer. Unless there's some huge market crash, the next couple<br/>years are going to be a good time for startups to raise money. And that's<br/>exciting because it means lots more startups will happen.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] I've also heard them called "Mini-VCs" and "Micro-VCs." I don't know which<br/>name will stick.  <br/>  <br/>There were a couple predecessors. Ron Conway had angel funds starting in the<br/>1990s, and in some ways First Round Capital is closer to a super-angel than a<br/>VC fund.  <br/>  <br/>[2] It wouldn't cut their overall returns tenfold, because investing later<br/>would probably (a) cause them to lose less on investments that failed, and (b)<br/>not allow them to get as large a percentage of startups as they do now. So<br/>it's hard to predict precisely what would happen to their returns.  <br/>  <br/>[3] The brand of an investor derives mostly from the success of their<br/>portfolio companies. The top VCs thus have a big brand advantage over the<br/>super-angels. They could make it self-perpetuating if they used it to get all<br/>the best new startups. But I don't think they'll be able to. To get all the<br/>best startups, you have to do more than make them want you. You also have to<br/>want them; you have to recognize them when you see them, and that's much<br/>harder. Super-angels will snap up stars that VCs miss. And that will cause the<br/>brand gap between the top VCs and the super-angels gradually to erode.  <br/>  <br/>[4] Though in a traditional series A round VCs put two partners on your board,<br/>there are signs now that VCs may begin to conserve board seats by switching to<br/>what used to be considered an angel-round board, consisting of two founders<br/>and one VC. Which is also to the founders' advantage if it means they still<br/>control the company.  <br/>  <br/>[5] In a series A round, you usually have to give up more than the actual<br/>amount of stock the VCs buy, because they insist you dilute yourselves to set<br/>aside an "option pool" as well. I predict this practice will gradually<br/>disappear though.  <br/>  <br/>[6] The best thing for founders, if they can get it, is a convertible note<br/>with no valuation cap at all. In that case the money invested in the angel<br/>round just converts into stock at the valuation of the next round, no matter<br/>how large. Angels and super-angels tend not to like uncapped notes. They have<br/>no idea how much of the company they're buying. If the company does well and<br/>the valuation of the next round is high, they may end up with only a sliver of<br/>it. So by agreeing to uncapped notes, VCs who don't care about valuations in<br/>angel rounds can make offers that super-angels hate to match.  <br/>  <br/>[7] Obviously signalling risk is also not a problem if you'll never need to<br/>raise more money. But startups are often mistaken about that.  <br/>  <br/> **Thanks** to Sam Altman, John Bautista, Patrick Collison, James Lindenbaum,<br/>Reid Hoffman, Jessica Livingston and Harj Taggar for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>January 2007  <br/>  <br/> _(Foreword to Jessica Livingston'sFounders at Work.)_  <br/>  <br/>Apparently sprinters reach their highest speed right out of the blocks, and<br/>spend the rest of the race slowing down. The winners slow down the least. It's<br/>that way with most startups too. The earliest phase is usually the most<br/>productive. That's when they have the really big ideas. Imagine what Apple was<br/>like when 100% of its employees were either Steve Jobs or Steve Wozniak.  <br/>  <br/>The striking thing about this phase is that it's completely different from<br/>most people's idea of what business is like. If you looked in people's heads<br/>(or stock photo collections) for images representing "business," you'd get<br/>images of people dressed up in suits, groups sitting around conference tables<br/>looking serious, Powerpoint presentations, people producing thick reports for<br/>one another to read. Early stage startups are the exact opposite of this. And<br/>yet they're probably the most productive part of the whole economy.  <br/>  <br/>Why the disconnect? I think there's a general principle at work here: the less<br/>energy people expend on performance, the more they expend on appearances to<br/>compensate. More often than not the energy they expend on seeming impressive<br/>makes their actual performance worse. A few years ago I read an article in<br/>which a car magazine modified the "sports" model of some production car to get<br/>the fastest possible standing quarter mile. You know how they did it? They cut<br/>off all the crap the manufacturer had bolted onto the car to make it _look_<br/>fast.  <br/>  <br/>Business is broken the same way that car was. The effort that goes into<br/>looking productive is not merely wasted, but actually makes organizations less<br/>productive. Suits, for example. Suits do not help people to think better. I<br/>bet most executives at big companies do their best thinking when they wake up<br/>on Sunday morning and go downstairs in their bathrobe to make a cup of coffee.<br/>That's when you have ideas. Just imagine what a company would be like if<br/>people could think that well at work. People do in startups, at least some of<br/>the time. (Half the time you're in a panic because your servers are on fire,<br/>but the other half you're thinking as deeply as most people only get to<br/>sitting alone on a Sunday morning.)  <br/>  <br/>Ditto for most of the other differences between startups and what passes for<br/>productivity in big companies. And yet conventional ideas of professionalism<br/>have such an iron grip on our minds that even startup founders are affected by<br/>them. In our startup, when outsiders came to visit we tried hard to seem<br/>"professional." We'd clean up our offices, wear better clothes, try to arrange<br/>that a lot of people were there during conventional office hours. In fact,<br/>programming didn't get done by well-dressed people at clean desks during<br/>office hours. It got done by badly dressed people (I was notorious for<br/>programmming wearing just a towel) in offices strewn with junk at 2 in the<br/>morning. But no visitor would understand that. Not even investors, who are<br/>supposed to be able to recognize real productivity when they see it. Even we<br/>were affected by the conventional wisdom. We thought of ourselves as<br/>impostors, succeeding despite being totally unprofessional. It was as if we'd<br/>created a Formula 1 car but felt sheepish because it didn't look like a car<br/>was supposed to look.  <br/>  <br/>In the car world, there are at least some people who know that a high<br/>performance car looks like a Formula 1 racecar, not a sedan with giant rims<br/>and a fake spoiler bolted to the trunk. Why not in business? Probably because<br/>startups are so small. The really dramatic growth happens when a startup only<br/>has three or four people, so only three or four people see that, whereas tens<br/>of thousands see business as it's practiced by Boeing or Philip Morris.  <br/>  <br/>This book can help fix that problem, by showing everyone what, till now, only<br/>a handful people got to see: what happens in the first year of a startup. This<br/>is what real productivity looks like. This is the Formula 1 racecar. It looks<br/>weird, but it goes fast.  <br/>  <br/>Of course, big companies won't be able to do everything these startups do. In<br/>big companies there's always going to be more politics, and less scope for<br/>individual decisions. But seeing what startups are really like will at least<br/>show other organizations what to aim for. The time may soon be coming when<br/>instead of startups trying to seem more corporate, corporations will try to<br/>seem more like startups. That would be a good thing.  <br/>  <br/>  <br/>  <br/>Japanese Translation  <br/>  <br/><br/>* * *<br/><br/>  <br/>  <br/><br/>**Founders at Work**  <br/>  <br/>There can't be more than a couple thousand people who know first-hand what<br/>happens in the first month of a successful startup. Jessica Livingston got<br/>them to tell us. So despite the interview format, this is really a how-to<br/>book. It is probably the single most valuable book a startup founder could<br/>read.  <br/>  <br/><br/>January 2004  <br/>  <br/>Have you ever seen an old photo of yourself and been embarrassed at the way<br/>you looked? _Did we actually dress like that?_ We did. And we had no idea how<br/>silly we looked. It's the nature of fashion to be invisible, in the same way<br/>the movement of the earth is invisible to all of us riding on it.  <br/>  <br/>What scares me is that there are moral fashions too. They're just as<br/>arbitrary, and just as invisible to most people. But they're much more<br/>dangerous. Fashion is mistaken for good design; moral fashion is mistaken for<br/>good. Dressing oddly gets you laughed at. Violating moral fashions can get you<br/>fired, ostracized, imprisoned, or even killed.  <br/>  <br/>If you could travel back in a time machine, one thing would be true no matter<br/>where you went: you'd have to watch what you said. Opinions we consider<br/>harmless could have gotten you in big trouble. I've already said at least one<br/>thing that would have gotten me in big trouble in most of Europe in the<br/>seventeenth century, and did get Galileo in big trouble when he said it  that<br/>the earth moves. [1]  <br/>  <br/>It seems to be a constant throughout history: In every period, people believed<br/>things that were just ridiculous, and believed them so strongly that you would<br/>have gotten in terrible trouble for saying otherwise.  <br/>  <br/>Is our time any different? To anyone who has read any amount of history, the<br/>answer is almost certainly no. It would be a remarkable coincidence if ours<br/>were the first era to get everything just right.  <br/>  <br/>It's tantalizing to think we believe things that people in the future will<br/>find ridiculous. What _would_ someone coming back to visit us in a time<br/>machine have to be careful not to say? That's what I want to study here. But I<br/>want to do more than just shock everyone with the heresy du jour. I want to<br/>find general recipes for discovering what you can't say, in any era.  <br/>  <br/> **The Conformist Test**  <br/>  <br/>Let's start with a test: Do you have any opinions that you would be reluctant<br/>to express in front of a group of your peers?  <br/>  <br/>If the answer is no, you might want to stop and think about that. If<br/>everything you believe is something you're supposed to believe, could that<br/>possibly be a coincidence? Odds are it isn't. Odds are you just think what<br/>you're told.  <br/>  <br/>The other alternative would be that you independently considered every<br/>question and came up with the exact same answers that are now considered<br/>acceptable. That seems unlikely, because you'd also have to make the same<br/>mistakes. Mapmakers deliberately put slight mistakes in their maps so they can<br/>tell when someone copies them. If another map has the same mistake, that's<br/>very convincing evidence.  <br/>  <br/>Like every other era in history, our moral map almost certainly contains a few<br/>mistakes. And anyone who makes the same mistakes probably didn't do it by<br/>accident. It would be like someone claiming they had independently decided in<br/>1972 that bell-bottom jeans were a good idea.  <br/>  <br/>If you believe everything you're supposed to now, how can you be sure you<br/>wouldn't also have believed everything you were supposed to if you had grown<br/>up among the plantation owners of the pre-Civil War South, or in Germany in<br/>the 1930s  or among the Mongols in 1200, for that matter? Odds are you would<br/>have.  <br/>  <br/>Back in the era of terms like "well-adjusted," the idea seemed to be that<br/>there was something wrong with you if you thought things you didn't dare say<br/>out loud. This seems backward. Almost certainly, there is something wrong with<br/>you if you _don't_ think things you don't dare say out loud.  <br/>  <br/> **Trouble**  <br/>  <br/>What can't we say? One way to find these ideas is simply to look at things<br/>people do say, and get in trouble for. [2]  <br/>  <br/>Of course, we're not just looking for things we can't say. We're looking for<br/>things we can't say that are true, or at least have enough chance of being<br/>true that the question should remain open. But many of the things people get<br/>in trouble for saying probably do make it over this second, lower threshold.<br/>No one gets in trouble for saying that 2 + 2 is 5, or that people in<br/>Pittsburgh are ten feet tall. Such obviously false statements might be treated<br/>as jokes, or at worst as evidence of insanity, but they are not likely to make<br/>anyone mad. The statements that make people mad are the ones they worry might<br/>be believed. I suspect the statements that make people maddest are those they<br/>worry might be true.  <br/>  <br/>If Galileo had said that people in Padua were ten feet tall, he would have<br/>been regarded as a harmless eccentric. Saying the earth orbited the sun was<br/>another matter. The church knew this would set people thinking.  <br/>  <br/>Certainly, as we look back on the past, this rule of thumb works well. A lot<br/>of the statements people got in trouble for seem harmless now. So it's likely<br/>that visitors from the future would agree with at least some of the statements<br/>that get people in trouble today. Do we have no Galileos? Not likely.  <br/>  <br/>To find them, keep track of opinions that get people in trouble, and start<br/>asking, could this be true? Ok, it may be heretical (or whatever modern<br/>equivalent), but might it also be true?  <br/>  <br/> **Heresy**  <br/>  <br/>This won't get us all the answers, though. What if no one happens to have<br/>gotten in trouble for a particular idea yet? What if some idea would be so<br/>radioactively controversial that no one would dare express it in public? How<br/>can we find these too?  <br/>  <br/>Another approach is to follow that word, heresy. In every period of history,<br/>there seem to have been labels that got applied to statements to shoot them<br/>down before anyone had a chance to ask if they were true or not. "Blasphemy",<br/>"sacrilege", and "heresy" were such labels for a good part of western history,<br/>as in more recent times "indecent", "improper", and "unamerican" have been. By<br/>now these labels have lost their sting. They always do. By now they're mostly<br/>used ironically. But in their time, they had real force.  <br/>  <br/>The word "defeatist", for example, has no particular political connotations<br/>now. But in Germany in 1917 it was a weapon, used by Ludendorff in a purge of<br/>those who favored a negotiated peace. At the start of World War II it was used<br/>extensively by Churchill and his supporters to silence their opponents. In<br/>1940, any argument against Churchill's aggressive policy was "defeatist". Was<br/>it right or wrong? Ideally, no one got far enough to ask that.  <br/>  <br/>We have such labels today, of course, quite a lot of them, from the all-<br/>purpose "inappropriate" to the dreaded "divisive." In any period, it should be<br/>easy to figure out what such labels are, simply by looking at what people call<br/>ideas they disagree with besides untrue. When a politician says his opponent<br/>is mistaken, that's a straightforward criticism, but when he attacks a<br/>statement as "divisive" or "racially insensitive" instead of arguing that it's<br/>false, we should start paying attention.  <br/>  <br/>So another way to figure out which of our taboos future generations will laugh<br/>at is to start with the labels. Take a label  "sexist", for example  and try<br/>to think of some ideas that would be called that. Then for each ask, might<br/>this be true?  <br/>  <br/>Just start listing ideas at random? Yes, because they won't really be random.<br/>The ideas that come to mind first will be the most plausible ones. They'll be<br/>things you've already noticed but didn't let yourself think.  <br/>  <br/>In 1989 some clever researchers tracked the eye movements of radiologists as<br/>they scanned chest images for signs of lung cancer. [3] They found that even<br/>when the radiologists missed a cancerous lesion, their eyes had usually paused<br/>at the site of it. Part of their brain knew there was something there; it just<br/>didn't percolate all the way up into conscious knowledge. I think many<br/>interesting heretical thoughts are already mostly formed in our minds. If we<br/>turn off our self-censorship temporarily, those will be the first to emerge.  <br/>  <br/> **Time and Space**  <br/>  <br/>If we could look into the future it would be obvious which of our taboos<br/>they'd laugh at. We can't do that, but we can do something almost as good: we<br/>can look into the past. Another way to figure out what we're getting wrong is<br/>to look at what used to be acceptable and is now unthinkable.  <br/>  <br/>Changes between the past and the present sometimes do represent progress. In a<br/>field like physics, if we disagree with past generations it's because we're<br/>right and they're wrong. But this becomes rapidly less true as you move away<br/>from the certainty of the hard sciences. By the time you get to social<br/>questions, many changes are just fashion. The age of consent fluctuates like<br/>hemlines.  <br/>  <br/>We may imagine that we are a great deal smarter and more virtuous than past<br/>generations, but the more history you read, the less likely this seems. People<br/>in past times were much like us. Not heroes, not barbarians. Whatever their<br/>ideas were, they were ideas reasonable people could believe.  <br/>  <br/>So here is another source of interesting heresies. Diff present ideas against<br/>those of various past cultures, and see what you get. [4] Some will be<br/>shocking by present standards. Ok, fine; but which might also be true?  <br/>  <br/>You don't have to look into the past to find big differences. In our own time,<br/>different societies have wildly varying ideas of what's ok and what isn't. So<br/>you can try diffing other cultures' ideas against ours as well. (The best way<br/>to do that is to visit them.)  Any idea that's considered harmless in a<br/>significant percentage of times and places, and yet is taboo in ours, is a<br/>candidate for something we're mistaken about.  <br/>  <br/>For example, at the high water mark of political correctness in the early<br/>1990s, Harvard distributed to its faculty and staff a brochure saying, among<br/>other things, that it was inappropriate to compliment a colleague or student's<br/>clothes. No more "nice shirt." I think this principle is rare among the<br/>world's cultures, past or present. There are probably more where it's<br/>considered especially polite to compliment someone's clothing than where it's<br/>considered improper.  Odds are this is, in a mild form, an example of one of<br/>the taboos a visitor from the future would have to be careful to avoid if he<br/>happened to set his time machine for Cambridge, Massachusetts, 1992. [5]  <br/>  <br/> **Prigs**  <br/>  <br/>Of course, if they have time machines in the future they'll probably have a<br/>separate reference manual just for Cambridge. This has always been a fussy<br/>place, a town of i dotters and t crossers, where you're liable to get both<br/>your grammar and your ideas corrected in the same conversation. And that<br/>suggests another way to find taboos. Look for prigs, and see what's inside<br/>their heads.  <br/>  <br/>Kids' heads are repositories of all our taboos. It seems fitting to us that<br/>kids' ideas should be bright and clean. The picture we give them of the world<br/>is not merely simplified, to suit their developing minds, but sanitized as<br/>well, to suit our ideas of what kids ought to think. [6]  <br/>  <br/>You can see this on a small scale in the matter of dirty words. A lot of my<br/>friends are starting to have children now, and they're all trying not to use<br/>words like "fuck" and "shit" within baby's hearing, lest baby start using<br/>these words too. But these words are part of the language, and adults use them<br/>all the time. So parents are giving their kids an inaccurate idea of the<br/>language by not using them. Why do they do this? Because they don't think it's<br/>fitting that kids should use the whole language. We like children to seem<br/>innocent. [7]  <br/>  <br/>Most adults, likewise, deliberately give kids a misleading view of the world.<br/>One of the most obvious examples is Santa Claus. We think it's cute for little<br/>kids to believe in Santa Claus. I myself think it's cute for little kids to<br/>believe in Santa Claus. But one wonders, do we tell them this stuff for their<br/>sake, or for ours?  <br/>  <br/>I'm not arguing for or against this idea here. It is probably inevitable that<br/>parents should want to dress up their kids' minds in cute little baby outfits.<br/>I'll probably do it myself. The important thing for our purposes is that, as a<br/>result, a well brought-up teenage kid's brain is a more or less complete<br/>collection of all our taboos  and in mint condition, because they're<br/>untainted by experience. Whatever we think that will later turn out to be<br/>ridiculous, it's almost certainly inside that head.  <br/>  <br/>How do we get at these ideas? By the following thought experiment. Imagine a<br/>kind of latter-day Conrad character who has worked for a time as a mercenary<br/>in Africa, for a time as a doctor in Nepal, for a time as the manager of a<br/>nightclub in Miami. The specifics don't matter  just someone who has seen a<br/>lot. Now imagine comparing what's inside this guy's head with what's inside<br/>the head of a well-behaved sixteen year old girl from the suburbs. What does<br/>he think that would shock her? He knows the world; she knows, or at least<br/>embodies, present taboos. Subtract one from the other, and the result is what<br/>we can't say.  <br/>  <br/>**Mechanism**  <br/>  <br/>I can think of one more way to figure out what we can't say: to look at how<br/>taboos are created. How do moral fashions arise, and why are they adopted? If<br/>we can understand this mechanism, we may be able to see it at work in our own<br/>time.  <br/>  <br/>Moral fashions don't seem to be created the way ordinary fashions are.<br/>Ordinary fashions seem to arise by accident when everyone imitates the whim of<br/>some influential person. The fashion for broad-toed shoes in late fifteenth<br/>century Europe began because Charles VIII of France had six toes on one foot.<br/>The fashion for the name Gary began when the actor Frank Cooper adopted the<br/>name of a tough mill town in Indiana. Moral fashions more often seem to be<br/>created deliberately. When there's something we can't say, it's often because<br/>some group doesn't want us to.  <br/>  <br/>The prohibition will be strongest when the group is nervous. The irony of<br/>Galileo's situation was that he got in trouble for repeating Copernicus's<br/>ideas. Copernicus himself didn't. In fact, Copernicus was a canon of a<br/>cathedral, and dedicated his book to the pope. But by Galileo's time the<br/>church was in the throes of the Counter-Reformation and was much more worried<br/>about unorthodox ideas.  <br/>  <br/>To launch a taboo, a group has to be poised halfway between weakness and<br/>power. A confident group doesn't need taboos to protect it. It's not<br/>considered improper to make disparaging remarks about Americans, or the<br/>English. And yet a group has to be powerful enough to enforce a taboo.<br/>Coprophiles, as of this writing, don't seem to be numerous or energetic enough<br/>to have had their interests promoted to a lifestyle.  <br/>  <br/>I suspect the biggest source of moral taboos will turn out to be power<br/>struggles in which one side only barely has the upper hand. That's where<br/>you'll find a group powerful enough to enforce taboos, but weak enough to need<br/>them.  <br/>  <br/>Most struggles, whatever they're really about, will be cast as struggles<br/>between competing ideas. The English Reformation was at bottom a struggle for<br/>wealth and power, but it ended up being cast as a struggle to preserve the<br/>souls of Englishmen from the corrupting influence of Rome. It's easier to get<br/>people to fight for an idea. And whichever side wins, their ideas will also be<br/>considered to have triumphed, as if God wanted to signal his agreement by<br/>selecting that side as the victor.  <br/>  <br/>We often like to think of World War II as a triumph of freedom over<br/>totalitarianism. We conveniently forget that the Soviet Union was also one of<br/>the winners.  <br/>  <br/>I'm not saying that struggles are never about ideas, just that they will<br/>always be made to seem to be about ideas, whether they are or not. And just as<br/>there is nothing so unfashionable as the last, discarded fashion, there is<br/>nothing so wrong as the principles of the most recently defeated opponent.<br/>Representational art is only now recovering from the approval of both Hitler<br/>and Stalin. [8]  <br/>  <br/>Although moral fashions tend to arise from different sources than fashions in<br/>clothing, the mechanism of their adoption seems much the same. The early<br/>adopters will be driven by ambition: self-consciously cool people who want to<br/>distinguish themselves from the common herd. As the fashion becomes<br/>established they'll be joined by a second, much larger group, driven by fear.<br/>[9] This second group adopt the fashion not because they want to stand out but<br/>because they are afraid of standing out.  <br/>  <br/>So if you want to figure out what we can't say, look at the machinery of<br/>fashion and try to predict what it would make unsayable. What groups are<br/>powerful but nervous, and what ideas would they like to suppress? What ideas<br/>were tarnished by association when they ended up on the losing side of a<br/>recent struggle? If a self-consciously cool person wanted to differentiate<br/>himself from preceding fashions (e.g. from his parents), which of their ideas<br/>would he tend to reject? What are conventional-minded people afraid of saying?  <br/>  <br/>This technique won't find us all the things we can't say. I can think of some<br/>that aren't the result of any recent struggle. Many of our taboos are rooted<br/>deep in the past. But this approach, combined with the preceding four, will<br/>turn up a good number of unthinkable ideas.  <br/>  <br/> **Why**  <br/>  <br/>Some would ask, why would one want to do this? Why deliberately go poking<br/>around among nasty, disreputable ideas? Why look under rocks?  <br/>  <br/>I do it, first of all, for the same reason I did look under rocks as a kid:<br/>plain curiosity. And I'm especially curious about anything that's forbidden.<br/>Let me see and decide for myself.  <br/>  <br/>Second, I do it because I don't like the idea of being mistaken. If, like<br/>other eras, we believe things that will later seem ridiculous, I want to know<br/>what they are so that I, at least, can avoid believing them.  <br/>  <br/>Third, I do it because it's good for the brain. To do good work you need a<br/>brain that can go anywhere. And you especially need a brain that's in the<br/>habit of going where it's not supposed to.  <br/>  <br/>Great work tends to grow out of ideas that others have overlooked, and no idea<br/>is so overlooked as one that's unthinkable. Natural selection, for example.<br/>It's so simple. Why didn't anyone think of it before? Well, that is all too<br/>obvious. Darwin himself was careful to tiptoe around the implications of his<br/>theory. He wanted to spend his time thinking about biology, not arguing with<br/>people who accused him of being an atheist.  <br/>  <br/>In the sciences, especially, it's a great advantage to be able to question<br/>assumptions. The m.o. of scientists, or at least of the good ones, is<br/>precisely that: look for places where conventional wisdom is broken, and then<br/>try to pry apart the cracks and see what's underneath. That's where new<br/>theories come from.  <br/>  <br/>A good scientist, in other words, does not merely ignore conventional wisdom,<br/>but makes a special effort to break it. Scientists go looking for trouble.<br/>This should be the m.o. of any scholar, but scientists seem much more willing<br/>to look under rocks. [10]  <br/>  <br/>Why? It could be that the scientists are simply smarter; most physicists<br/>could, if necessary, make it through a PhD program in French literature, but<br/>few professors of French literature could make it through a PhD program in<br/>physics. Or it could be because it's clearer in the sciences whether theories<br/>are true or false, and this makes scientists bolder. (Or it could be that,<br/>because it's clearer in the sciences whether theories are true or false, you<br/>have to be smart to get jobs as a scientist, rather than just a good<br/>politician.)  <br/>  <br/>Whatever the reason, there seems a clear correlation between intelligence and<br/>willingness to consider shocking ideas. This isn't just because smart people<br/>actively work to find holes in conventional thinking. I think conventions also<br/>have less hold over them to start with. You can see that in the way they<br/>dress.  <br/>  <br/>It's not only in the sciences that heresy pays off. In any competitive field,<br/>you can win big by seeing things that others daren't. And in every field there<br/>are probably heresies few dare utter. Within the US car industry there is a<br/>lot of hand-wringing now about declining market share. Yet the cause is so<br/>obvious that any observant outsider could explain it in a second: they make<br/>bad cars. And they have for so long that by now the US car brands are<br/>antibrands  something you'd buy a car despite, not because of. Cadillac<br/>stopped being the Cadillac of cars in about 1970. And yet I suspect no one<br/>dares say this. [11] Otherwise these companies would have tried to fix the<br/>problem.  <br/>  <br/>Training yourself to think unthinkable thoughts has advantages beyond the<br/>thoughts themselves. It's like stretching. When you stretch before running,<br/>you put your body into positions much more extreme than any it will assume<br/>during the run. If you can think things so outside the box that they'd make<br/>people's hair stand on end, you'll have no trouble with the small trips<br/>outside the box that people call innovative.  <br/>  <br/> ** _Pensieri Stretti_**  <br/>  <br/>When you find something you can't say, what do you do with it? My advice is,<br/>don't say it. Or at least, pick your battles.  <br/>  <br/>Suppose in the future there is a movement to ban the color yellow. Proposals<br/>to paint anything yellow are denounced as "yellowist", as is anyone suspected<br/>of liking the color. People who like orange are tolerated but viewed with<br/>suspicion. Suppose you realize there is nothing wrong with yellow. If you go<br/>around saying this, you'll be denounced as a yellowist too, and you'll find<br/>yourself having a lot of arguments with anti-yellowists. If your aim in life<br/>is to rehabilitate the color yellow, that may be what you want. But if you're<br/>mostly interested in other questions, being labelled as a yellowist will just<br/>be a distraction. Argue with idiots, and you become an idiot.  <br/>  <br/>The most important thing is to be able to think what you want, not to say what<br/>you want. And if you feel you have to say everything you think, it may inhibit<br/>you from thinking improper thoughts. I think it's better to follow the<br/>opposite policy. Draw a sharp line between your thoughts and your speech.<br/>Inside your head, anything is allowed. Within my head I make a point of<br/>encouraging the most outrageous thoughts I can imagine. But, as in a secret<br/>society, nothing that happens within the building should be told to outsiders.<br/>The first rule of Fight Club is, you do not talk about Fight Club.  <br/>  <br/>When Milton was going to visit Italy in the 1630s, Sir Henry Wootton, who had<br/>been ambassador to Venice, told him his motto should be _"i pensieri stretti &<br/>il viso sciolto."_ Closed thoughts and an open face. Smile at everyone, and<br/>don't tell them what you're thinking. This was wise advice. Milton was an<br/>argumentative fellow, and the Inquisition was a bit restive at that time. But<br/>I think the difference between Milton's situation and ours is only a matter of<br/>degree. Every era has its heresies, and if you don't get imprisoned for them<br/>you will at least get in enough trouble that it becomes a complete<br/>distraction.  <br/>  <br/>I admit it seems cowardly to keep quiet. When I read about the harassment to<br/>which the Scientologists subject their critics [12], or that pro-Israel groups<br/>are "compiling dossiers" on those who speak out against Israeli human rights<br/>abuses [13], or about people being sued for violating the DMCA [14], part of<br/>me wants to say, "All right, you bastards, bring it on." The problem is, there<br/>are so many things you can't say. If you said them all you'd have no time left<br/>for your real work. You'd have to turn into Noam Chomsky. [15]  <br/>  <br/>The trouble with keeping your thoughts secret, though, is that you lose the<br/>advantages of discussion. Talking about an idea leads to more ideas. So the<br/>optimal plan, if you can manage it, is to have a few trusted friends you can<br/>speak openly to. This is not just a way to develop ideas; it's also a good<br/>rule of thumb for choosing friends. The people you can say heretical things to<br/>without getting jumped on are also the most interesting to know.  <br/>  <br/> ** _Viso Sciolto?_**  <br/>  <br/>I don't think we need the _viso sciolto_ so much as the _pensieri stretti._<br/>Perhaps the best policy is to make it plain that you don't agree with whatever<br/>zealotry is current in your time, but not to be too specific about what you<br/>disagree with. Zealots will try to draw you out, but you don't have to answer<br/>them. If they try to force you to treat a question on their terms by asking<br/>"are you with us or against us?" you can always just answer "neither".  <br/>  <br/>Better still, answer "I haven't decided." That's what Larry Summers did when a<br/>group tried to put him in this position. Explaining himself later, he said "I<br/>don't do litmus tests." [16] A lot of the questions people get hot about are<br/>actually quite complicated. There is no prize for getting the answer quickly.  <br/>  <br/>If the anti-yellowists seem to be getting out of hand and you want to fight<br/>back, there are ways to do it without getting yourself accused of being a<br/>yellowist. Like skirmishers in an ancient army, you want to avoid directly<br/>engaging the main body of the enemy's troops. Better to harass them with<br/>arrows from a distance.  <br/>  <br/>One way to do this is to ratchet the debate up one level of abstraction. If<br/>you argue against censorship in general, you can avoid being accused of<br/>whatever heresy is contained in the book or film that someone is trying to<br/>censor. You can attack labels with meta-labels: labels that refer to the use<br/>of labels to prevent discussion. The spread of the term "political<br/>correctness" meant the beginning of the end of political correctness, because<br/>it enabled one to attack the phenomenon as a whole without being accused of<br/>any of the specific heresies it sought to suppress.  <br/>  <br/>Another way to counterattack is with metaphor. Arthur Miller undermined the<br/>House Un-American Activities Committee by writing a play, "The Crucible,"<br/>about the Salem witch trials. He never referred directly to the committee and<br/>so gave them no way to reply. What could HUAC do, defend the Salem witch<br/>trials? And yet Miller's metaphor stuck so well that to this day the<br/>activities of the committee are often described as a "witch-hunt."  <br/>  <br/>Best of all, probably, is humor. Zealots, whatever their cause, invariably<br/>lack a sense of humor. They can't reply in kind to jokes. They're as unhappy<br/>on the territory of humor as a mounted knight on a skating rink. Victorian<br/>prudishness, for example, seems to have been defeated mainly by treating it as<br/>a joke. Likewise its reincarnation as political correctness. "I am glad that I<br/>managed to write 'The Crucible,'" Arthur Miller wrote, "but looking back I<br/>have often wished I'd had the temperament to do an absurd comedy, which is<br/>what the situation deserved." [17]  <br/>  <br/> **ABQ**  <br/>  <br/>A Dutch friend says I should use Holland as an example of a tolerant society.<br/>It's true they have a long tradition of comparative open-mindedness. For<br/>centuries the low countries were the place to go to say things you couldn't<br/>say anywhere else, and this helped to make the region a center of scholarship<br/>and industry (which have been closely tied for longer than most people<br/>realize). Descartes, though claimed by the French, did much of his thinking in<br/>Holland.  <br/>  <br/>And yet, I wonder. The Dutch seem to live their lives up to their necks in<br/>rules and regulations. There's so much you can't do there; is there really<br/>nothing you can't say?  <br/>  <br/>Certainly the fact that they value open-mindedness is no guarantee. Who thinks<br/>they're not open-minded? Our hypothetical prim miss from the suburbs thinks<br/>she's open-minded. Hasn't she been taught to be? Ask anyone, and they'll say<br/>the same thing: they're pretty open-minded, though they draw the line at<br/>things that are really wrong. (Some tribes may avoid "wrong" as judgemental,<br/>and may instead use a more neutral sounding euphemism like "negative" or<br/>"destructive".)  <br/>  <br/>When people are bad at math, they know it, because they get the wrong answers<br/>on tests. But when people are bad at open-mindedness they don't know it. In<br/>fact they tend to think the opposite. Remember, it's the nature of fashion to<br/>be invisible. It wouldn't work otherwise. Fashion doesn't seem like fashion to<br/>someone in the grip of it. It just seems like the right thing to do. It's only<br/>by looking from a distance that we see oscillations in people's idea of the<br/>right thing to do, and can identify them as fashions.  <br/>  <br/>Time gives us such distance for free. Indeed, the arrival of new fashions<br/>makes old fashions easy to see, because they seem so ridiculous by contrast.<br/>From one end of a pendulum's swing, the other end seems especially far away.  <br/>  <br/>To see fashion in your own time, though, requires a conscious effort. Without<br/>time to give you distance, you have to create distance yourself. Instead of<br/>being part of the mob, stand as far away from it as you can and watch what<br/>it's doing. And pay especially close attention whenever an idea is being<br/>suppressed. Web filters for children and employees often ban sites containing<br/>pornography, violence, and hate speech. What counts as pornography and<br/>violence? And what, exactly, is "hate speech?" This sounds like a phrase out<br/>of _1984._  <br/>  <br/>Labels like that are probably the biggest external clue. If a statement is<br/>false, that's the worst thing you can say about it. You don't need to say that<br/>it's heretical. And if it isn't false, it shouldn't be suppressed. So when you<br/>see statements being attacked as x-ist or y-ic (substitute your current values<br/>of x and y), whether in 1630 or 2030, that's a sure sign that something is<br/>wrong. When you hear such labels being used, ask why.  <br/>  <br/>Especially if you hear yourself using them. It's not just the mob you need to<br/>learn to watch from a distance. You need to be able to watch your own thoughts<br/>from a distance. That's not a radical idea, by the way; it's the main<br/>difference between children and adults. When a child gets angry because he's<br/>tired, he doesn't know what's happening. An adult can distance himself enough<br/>from the situation to say "never mind, I'm just tired." I don't see why one<br/>couldn't, by a similar process, learn to recognize and discount the effects of<br/>moral fashions.  <br/>  <br/>You have to take that extra step if you want to think clearly. But it's<br/>harder, because now you're working against social customs instead of with<br/>them. Everyone encourages you to grow up to the point where you can discount<br/>your own bad moods. Few encourage you to continue to the point where you can<br/>discount society's bad moods.  <br/>  <br/>How can you see the wave, when you're the water? Always be questioning. That's<br/>the only defence. What can't you say? And why?  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/> **Thanks** to Sarah Harlin, Trevor Blackwell, Jessica Livingston, Robert<br/>Morris, Eric Raymond and Bob van der Zwaan for reading drafts of this essay,<br/>and to Lisa Randall, Jackie McDonough, Ryan Stanley and Joel Rainey for<br/>conversations about heresy. Needless to say they bear no blame for opinions<br/>expressed in it, and especially for opinions _not_ expressed in it.  <br/>  <br/>  <br/><br/>Re: What You Can't Say  <br/>  <br/><br/>Labels  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>French Translation  <br/>  <br/><br/>German Translation  <br/>  <br/><br/>Dutch Translation  <br/>  <br/><br/>Romanian Translation  <br/>  <br/><br/>Hebrew Translation  <br/>  <br/><br/>Turkish Translation  <br/>  <br/><br/>Chinese Translation  <br/>  <br/><br/>Buttons  <br/>  <br/><br/>A Civic Duty to Annoy  <br/>  <br/><br/>The Perils of Obedience  <br/>  <br/><br/>Aliens Cause Global Warming  <br/>  <br/><br/>Hays Code  <br/>  <br/><br/>Stratagem 32  <br/>  <br/><br/>Conspiracy Theories  <br/>  <br/><br/>Mark Twain: Corn-pone Opinions  <br/>  <br/><br/>A Blacklist for "Excuse Makers"  <br/>  <br/><br/>What You Can't Say Will Hurt You  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>February 2009  <br/>  <br/>Hacker News was two years old last week. Initially it was supposed to be a<br/>side project—an application to sharpen Arc on, and a place for current and<br/>future Y Combinator founders to exchange news. It's grown bigger and taken up<br/>more time than I expected, but I don't regret that because I've learned so<br/>much from working on it.  <br/>  <br/> **Growth**  <br/>  <br/>When we launched in February 2007, weekday traffic was around 1600 daily<br/>uniques. It's since grown to around 22,000. This growth rate is a bit higher<br/>than I'd like. I'd like the site to grow, since a site that isn't growing at<br/>least slowly is probably dead. But I wouldn't want it to grow as large as Digg<br/>or Reddit—mainly because that would dilute the character of the site, but also<br/>because I don't want to spend all my time dealing with scaling.  <br/>  <br/>I already have problems enough with that. Remember, the original motivation<br/>for HN was to test a new programming language, and moreover one that's focused<br/>on experimenting with language design, not performance. Every time the site<br/>gets slow, I fortify myself by recalling McIlroy and Bentley's famous quote<br/><br/>> The key to performance is elegance, not battalions of special cases.<br/><br/>and look for the bottleneck I can remove with least code. So far I've been<br/>able to keep up, in the sense that performance has remained consistently<br/>mediocre despite 14x growth. I don't know what I'll do next, but I'll probably<br/>think of something.  <br/>  <br/>This is my attitude to the site generally. Hacker News is an experiment, and<br/>an experiment in a very young field. Sites of this type are only a few years<br/>old. Internet conversation generally is only a few decades old. So we've<br/>probably only discovered a fraction of what we eventually will.  <br/>  <br/>That's why I'm so optimistic about HN. When a technology is this young, the<br/>existing solutions are usually terrible; which means it must be possible to do<br/>much better; which means many problems that seem insoluble aren't. Including,<br/>I hope, the problem that has afflicted so many previous communities: being<br/>ruined by growth.  <br/>  <br/> **Dilution**  <br/>  <br/>Users have worried about that since the site was a few months old. So far<br/>these alarms have been false, but they may not always be. Dilution is a hard<br/>problem. But probably soluble; it doesn't mean much that open conversations<br/>have "always" been destroyed by growth when "always" equals 20 instances.  <br/>  <br/>But it's important to remember we're trying to solve a new problem, because<br/>that means we're going to have to try new things, most of which probably won't<br/>work. A couple weeks ago I tried displaying the names of users with the<br/>highest average comment scores in orange. [1] That was a mistake. Suddenly a<br/>culture that had been more or less united was divided into haves and have-<br/>nots. I didn't realize how united the culture had been till I saw it divided.<br/>It was painful to watch. [2]  <br/>  <br/>So orange usernames won't be back. (Sorry about that.) But there will be other<br/>equally broken-seeming ideas in the future, and the ones that turn out to work<br/>will probably seem just as broken as those that don't.  <br/>  <br/>Probably the most important thing I've learned about dilution is that it's<br/>measured more in behavior than users. It's bad behavior you want to keep out<br/>more than bad people. User behavior turns out to be surprisingly malleable. If<br/>people are expected to behave well, they tend to; and vice versa.  <br/>  <br/>Though of course forbidding bad behavior does tend to keep away bad people,<br/>because they feel uncomfortably constrained in a place where they have to<br/>behave well. But this way of keeping them out is gentler and probably also<br/>more effective than overt barriers.  <br/>  <br/>It's pretty clear now that the broken windows theory applies to community<br/>sites as well. The theory is that minor forms of bad behavior encourage worse<br/>ones: that a neighborhood with lots of graffiti and broken windows becomes one<br/>where robberies occur. I was living in New York when Giuliani introduced the<br/>reforms that made the broken windows theory famous, and the transformation was<br/>miraculous. And I was a Reddit user when the opposite happened there, and the<br/>transformation was equally dramatic.  <br/>  <br/>I'm not criticizing Steve and Alexis. What happened to Reddit didn't happen<br/>out of neglect. From the start they had a policy of censoring nothing except<br/>spam. Plus Reddit had different goals from Hacker News. Reddit was a startup,<br/>not a side project; its goal was to grow as fast as possible. Combine rapid<br/>growth and zero censorship, and the result is a free for all. But I don't<br/>think they'd do much differently if they were doing it again. Measured by<br/>traffic, Reddit is much more successful than Hacker News.  <br/>  <br/>But what happened to Reddit won't inevitably happen to HN. There are several<br/>local maxima. There can be places that are free for alls and places that are<br/>more thoughtful, just as there are in the real world; and people will behave<br/>differently depending on which they're in, just as they do in the real world.  <br/>  <br/>I've observed this in the wild. I've seen people cross-posting on Reddit and<br/>Hacker News who actually took the trouble to write two versions, a flame for<br/>Reddit and a more subdued version for HN.  <br/>  <br/> **Submissions**  <br/>  <br/>There are two major types of problems a site like Hacker News needs to avoid:<br/>bad stories and bad comments. So far the danger of bad stories seems smaller.<br/>The stories on the frontpage now are still roughly the ones that would have<br/>been there when HN started.  <br/>  <br/>I once thought I'd have to weight votes to keep crap off the frontpage, but I<br/>haven't had to yet. I wouldn't have predicted the frontpage would hold up so<br/>well, and I'm not sure why it has. Perhaps only the more thoughtful users care<br/>enough to submit and upvote links, so the marginal cost of one random new user<br/>approaches zero. Or perhaps the frontpage protects itself, by advertising what<br/>type of submission is expected.  <br/>  <br/>The most dangerous thing for the frontpage is stuff that's too easy to upvote.<br/>If someone proves a new theorem, it takes some work by the reader to decide<br/>whether or not to upvote it. An amusing cartoon takes less. A rant with a<br/>rallying cry as the title takes zero, because people vote it up without even<br/>reading it.  <br/>  <br/>Hence what I call the Fluff Principle: on a user-voted news site, the links<br/>that are easiest to judge will take over unless you take specific measures to<br/>prevent it.  <br/>  <br/>Hacker News has two kinds of protections against fluff. The most common types<br/>of fluff links are banned as off-topic. Pictures of kittens, political<br/>diatribes, and so on are explicitly banned. This keeps out most fluff, but not<br/>all of it. Some links are both fluff, in the sense of being very short, and<br/>also on topic.  <br/>  <br/>There's no single solution to that. If a link is just an empty rant, editors<br/>will sometimes kill it even if it's on topic in the sense of being about<br/>hacking, because it's not on topic by the real standard, which is to engage<br/>one's intellectual curiosity. If the posts on a site are characteristically of<br/>this type I sometimes ban it, which means new stuff at that url is auto-<br/>killed. If a post has a linkbait title, editors sometimes rephrase it to be<br/>more matter-of-fact. This is especially necessary with links whose titles are<br/>rallying cries, because otherwise they become implicit "vote up if you believe<br/>such-and-such" posts, which are the most extreme form of fluff.  <br/>  <br/>The techniques for dealing with links have to evolve, because the links do.<br/>The existence of aggregators has already affected what they aggregate. Writers<br/>now deliberately write things to draw traffic from aggregators—sometimes even<br/>specific ones. (No, the irony of this statement is not lost on me.) Then there<br/>are the more sinister mutations, like linkjacking—posting a paraphrase of<br/>someone else's article and submitting that instead of the original. These can<br/>get a lot of upvotes, because a lot of what's good in an article often<br/>survives; indeed, the closer the paraphrase is to plagiarism, the more<br/>survives. [3]  <br/>  <br/>I think it's important that a site that kills submissions provide a way for<br/>users to see what got killed if they want to. That keeps editors honest, and<br/>just as importantly, makes users confident they'd know if the editors stopped<br/>being honest. HN users can do this by flipping a switch called showdead in<br/>their profile. [4]  <br/>  <br/> **Comments**  <br/>  <br/>Bad comments seem to be a harder problem than bad submissions. While the<br/>quality of links on the frontpage of HN hasn't changed much, the quality of<br/>the median comment may have decreased somewhat.  <br/>  <br/>There are two main kinds of badness in comments: meanness and stupidity. There<br/>is a lot of overlap between the two—mean comments are disproportionately<br/>likely also to be dumb—but the strategies for dealing with them are different.<br/>Meanness is easier to control. You can have rules saying one shouldn't be<br/>mean, and if you enforce them it seems possible to keep a lid on meanness.  <br/>  <br/>Keeping a lid on stupidity is harder, perhaps because stupidity is not so<br/>easily distinguishable. Mean people are more likely to know they're being mean<br/>than stupid people are to know they're being stupid.  <br/>  <br/>The most dangerous form of stupid comment is not the long but mistaken<br/>argument, but the dumb joke. Long but mistaken arguments are actually quite<br/>rare. There is a strong correlation between comment quality and length; if you<br/>wanted to compare the quality of comments on community sites, average length<br/>would be a good predictor. Probably the cause is human nature rather than<br/>anything specific to comment threads. Probably it's simply that stupidity more<br/>often takes the form of having few ideas than wrong ones.  <br/>  <br/>Whatever the cause, stupid comments tend to be short. And since it's hard to<br/>write a short comment that's distinguished for the amount of information it<br/>conveys, people try to distinguish them instead by being funny. The most<br/>tempting format for stupid comments is the supposedly witty put-down, probably<br/>because put-downs are the easiest form of humor. [5] So one advantage of<br/>forbidding meanness is that it also cuts down on these.  <br/>  <br/>Bad comments are like kudzu: they take over rapidly. Comments have much more<br/>effect on new comments than submissions have on new submissions. If someone<br/>submits a lame article, the other submissions don't all become lame. But if<br/>someone posts a stupid comment on a thread, that sets the tone for the region<br/>around it. People reply to dumb jokes with dumb jokes.  <br/>  <br/>Maybe the solution is to add a delay before people can respond to a comment,<br/>and make the length of the delay inversely proportional to some prediction of<br/>its quality. Then dumb threads would grow slower. [6]  <br/>  <br/>**People**  <br/>  <br/>I notice most of the techniques I've described are conservative: they're aimed<br/>at preserving the character of the site rather than enhancing it. I don't<br/>think that's a bias of mine. It's due to the shape of the problem. Hacker News<br/>had the good fortune to start out good, so in this case it's literally a<br/>matter of preservation. But I think this principle would also apply to sites<br/>with different origins.  <br/>  <br/>The good things in a community site come from people more than technology;<br/>it's mainly in the prevention of bad things that technology comes into play.<br/>Technology certainly can enhance discussion. Nested comments do, for example.<br/>But I'd rather use a site with primitive features and smart, nice users than a<br/>more advanced one whose users were idiots or trolls.  <br/>  <br/>So the most important thing a community site can do is attract the kind of<br/>people it wants. A site trying to be as big as possible wants to attract<br/>everyone. But a site aiming at a particular subset of users has to attract<br/>just those—and just as importantly, repel everyone else. I've made a conscious<br/>effort to do this on HN. The graphic design is as plain as possible, and the<br/>site rules discourage dramatic link titles. The goal is that the only thing to<br/>interest someone arriving at HN for the first time should be the ideas<br/>expressed there.  <br/>  <br/>The downside of tuning a site to attract certain people is that, to those<br/>people, it can be too attractive. I'm all too aware how addictive Hacker News<br/>can be. For me, as for many users, it's a kind of virtual town square. When I<br/>want to take a break from working, I walk into the square, just as I might<br/>into Harvard Square or University Ave in the physical world. [7] But an online<br/>square is more dangerous than a physical one. If I spent half the day<br/>loitering on University Ave, I'd notice. I have to walk a mile to get there,<br/>and sitting in a cafe feels different from working. But visiting an online<br/>forum takes just a click, and feels superficially very much like working. You<br/>may be wasting your time, but you're not idle. Someone is wrong on the<br/>Internet, and you're fixing the problem.  <br/>  <br/>Hacker News is definitely useful. I've learned a lot from things I've read on<br/>HN. I've written several essays that began as comments there. So I wouldn't<br/>want the site to go away. But I would like to be sure it's not a net drag on<br/>productivity. What a disaster that would be, to attract thousands of smart<br/>people to a site that caused them to waste lots of time. I wish I could be<br/>100% sure that's not a description of HN.  <br/>  <br/>I feel like the addictiveness of games and social applications is still a<br/>mostly unsolved problem. The situation now is like it was with crack in the<br/>1980s: we've invented terribly addictive new things, and we haven't yet<br/>evolved ways to protect ourselves from them. We will eventually, and that's<br/>one of the problems I hope to focus on next.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] I tried ranking users by both average and median comment score, and<br/>average (with the high score thrown out) seemed the more accurate predictor of<br/>high quality. Median may be the more accurate predictor of low quality though.  <br/>  <br/>[2] Another thing I learned from this experiment is that if you're going to<br/>distinguish between people, you better be sure you do it right. This is one<br/>problem where rapid prototyping doesn't work.  <br/>  <br/>Indeed, that's the intellectually honest argument for not discriminating<br/>between various types of people. The reason not to do it is not that<br/>everyone's the same, but that it's bad to do wrong and hard to do right.  <br/>  <br/>[3] When I catch egregiously linkjacked posts I replace the url with that of<br/>whatever they copied. Sites that habitually linkjack get banned.  <br/>  <br/>[4] Digg is notorious for its lack of transparency. The root of the problem is<br/>not that the guys running Digg are especially sneaky, but that they use the<br/>wrong algorithm for generating their frontpage. Instead of bubbling up from<br/>the bottom as they get more votes, as on Reddit, stories start at the top and<br/>get pushed down by new arrivals.  <br/>  <br/>The reason for the difference is that Digg is derived from Slashdot, while<br/>Reddit is derived from Delicious/popular. Digg is Slashdot with voting instead<br/>of editors, and Reddit is Delicious/popular with voting instead of<br/>bookmarking. (You can still see fossils of their origins in their graphic<br/>design.)  <br/>  <br/>Digg's algorithm is very vulnerable to gaming, because any story that makes it<br/>onto the frontpage is the new top story. Which in turn forces Digg to respond<br/>with extreme countermeasures. A lot of startups have some kind of secret about<br/>the subterfuges they had to resort to in the early days, and I suspect Digg's<br/>is the extent to which the top stories were de facto chosen by human editors.  <br/>  <br/>[5] The dialog on Beavis and Butthead was composed largely of these, and when<br/>I read comments on really bad sites I can hear them in their voices.  <br/>  <br/>[6] I suspect most of the techniques for discouraging stupid comments have yet<br/>to be discovered. Xkcd implemented a particularly clever one in its IRC<br/>channel: don't allow the same thing twice. Once someone has said "fail," no<br/>one can ever say it again. This would penalize short comments especially,<br/>because they have less room to avoid collisions in.  <br/>  <br/>Another promising idea is the stupid filter, which is just like a<br/>probabilistic spam filter, but trained on corpora of stupid and non-stupid<br/>comments instead.  <br/>  <br/>You may not have to kill bad comments to solve the problem. Comments at the<br/>bottom of a long thread are rarely seen, so it may be enough to incorporate a<br/>prediction of quality in the comment sorting algorithm.  <br/>  <br/>[7] What makes most suburbs so demoralizing is that there's no center to walk<br/>to.  <br/>  <br/>**Thanks** to Justin Kan, Jessica Livingston, Robert Morris, Alexis Ohanian,<br/>Emmet Shear, and Fred Wilson for reading drafts of this.  <br/>  <br/>Comment on this essay.  <br/>  <br/>  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>September 2007  <br/>  <br/>In high school I decided I was going to study philosophy in college. I had<br/>several motives, some more honorable than others. One of the less honorable<br/>was to shock people. College was regarded as job training where I grew up, so<br/>studying philosophy seemed an impressively impractical thing to do. Sort of<br/>like slashing holes in your clothes or putting a safety pin through your ear,<br/>which were other forms of impressive impracticality then just coming into<br/>fashion.  <br/>  <br/>But I had some more honest motives as well. I thought studying philosophy<br/>would be a shortcut straight to wisdom. All the people majoring in other<br/>things would just end up with a bunch of domain knowledge. I would be learning<br/>what was really what.  <br/>  <br/>I'd tried to read a few philosophy books. Not recent ones; you wouldn't find<br/>those in our high school library. But I tried to read Plato and Aristotle. I<br/>doubt I believed I understood them, but they sounded like they were talking<br/>about something important. I assumed I'd learn what in college.  <br/>  <br/>The summer before senior year I took some college classes. I learned a lot in<br/>the calculus class, but I didn't learn much in Philosophy 101\. And yet my<br/>plan to study philosophy remained intact. It was my fault I hadn't learned<br/>anything. I hadn't read the books we were assigned carefully enough. I'd give<br/>Berkeley's _Principles of Human Knowledge_ another shot in college. Anything<br/>so admired and so difficult to read must have something in it, if one could<br/>only figure out what.  <br/>  <br/>Twenty-six years later, I still don't understand Berkeley. I have a nice<br/>edition of his collected works. Will I ever read it? Seems unlikely.  <br/>  <br/>The difference between then and now is that now I understand why Berkeley is<br/>probably not worth trying to understand. I think I see now what went wrong<br/>with philosophy, and how we might fix it.  <br/>  <br/> **Words**  <br/>  <br/>I did end up being a philosophy major for most of college. It didn't work out<br/>as I'd hoped. I didn't learn any magical truths compared to which everything<br/>else was mere domain knowledge. But I do at least know now why I didn't.<br/>Philosophy doesn't really have a subject matter in the way math or history or<br/>most other university subjects do. There is no core of knowledge one must<br/>master. The closest you come to that is a knowledge of what various individual<br/>philosophers have said about different topics over the years. Few were<br/>sufficiently correct that people have forgotten who discovered what they<br/>discovered.  <br/>  <br/>Formal logic has some subject matter. I took several classes in logic. I don't<br/>know if I learned anything from them. [1] It does seem to me very important to<br/>be able to flip ideas around in one's head: to see when two ideas don't fully<br/>cover the space of possibilities, or when one idea is the same as another but<br/>with a couple things changed. But did studying logic teach me the importance<br/>of thinking this way, or make me any better at it? I don't know.  <br/>  <br/>There are things I know I learned from studying philosophy. The most dramatic<br/>I learned immediately, in the first semester of freshman year, in a class<br/>taught by Sydney Shoemaker. I learned that I don't exist. I am (and you are) a<br/>collection of cells that lurches around driven by various forces, and calls<br/>itself _I_. But there's no central, indivisible thing that your identity goes<br/>with. You could conceivably lose half your brain and live. Which means your<br/>brain could conceivably be split into two halves and each transplanted into<br/>different bodies. Imagine waking up after such an operation. You have to<br/>imagine being two people.  <br/>  <br/>The real lesson here is that the concepts we use in everyday life are fuzzy,<br/>and break down if pushed too hard. Even a concept as dear to us as _I_. It<br/>took me a while to grasp this, but when I did it was fairly sudden, like<br/>someone in the nineteenth century grasping evolution and realizing the story<br/>of creation they'd been told as a child was all wrong. [2] Outside of math<br/>there's a limit to how far you can push words; in fact, it would not be a bad<br/>definition of math to call it the study of terms that have precise meanings.<br/>Everyday words are inherently imprecise. They work well enough in everyday<br/>life that you don't notice. Words seem to work, just as Newtonian physics<br/>seems to. But you can always make them break if you push them far enough.  <br/>  <br/>I would say that this has been, unfortunately for philosophy, the central fact<br/>of philosophy. Most philosophical debates are not merely afflicted by but<br/>driven by confusions over words. Do we have free will? Depends what you mean<br/>by "free." Do abstract ideas exist? Depends what you mean by "exist."  <br/>  <br/>Wittgenstein is popularly credited with the idea that most philosophical<br/>controversies are due to confusions over language. I'm not sure how much<br/>credit to give him. I suspect a lot of people realized this, but reacted<br/>simply by not studying philosophy, rather than becoming philosophy professors.  <br/>  <br/>How did things get this way? Can something people have spent thousands of<br/>years studying really be a waste of time? Those are interesting questions. In<br/>fact, some of the most interesting questions you can ask about philosophy. The<br/>most valuable way to approach the current philosophical tradition may be<br/>neither to get lost in pointless speculations like Berkeley, nor to shut them<br/>down like Wittgenstein, but to study it as an example of reason gone wrong.  <br/>  <br/> **History**  <br/>  <br/>Western philosophy really begins with Socrates, Plato, and Aristotle. What we<br/>know of their predecessors comes from fragments and references in later works;<br/>their doctrines could be described as speculative cosmology that occasionally<br/>strays into analysis. Presumably they were driven by whatever makes people in<br/>every other society invent cosmologies. [3]  <br/>  <br/>With Socrates, Plato, and particularly Aristotle, this tradition turned a<br/>corner. There started to be a lot more analysis. I suspect Plato and Aristotle<br/>were encouraged in this by progress in math. Mathematicians had by then shown<br/>that you could figure things out in a much more conclusive way than by making<br/>up fine sounding stories about them. [4]  <br/>  <br/>People talk so much about abstractions now that we don't realize what a leap<br/>it must have been when they first started to. It was presumably many thousands<br/>of years between when people first started describing things as hot or cold<br/>and when someone asked "what is heat?" No doubt it was a very gradual process.<br/>We don't know if Plato or Aristotle were the first to ask any of the questions<br/>they did. But their works are the oldest we have that do this on a large<br/>scale, and there is a freshness (not to say naivete) about them that suggests<br/>some of the questions they asked were new to them, at least.  <br/>  <br/>Aristotle in particular reminds me of the phenomenon that happens when people<br/>discover something new, and are so excited by it that they race through a huge<br/>percentage of the newly discovered territory in one lifetime. If so, that's<br/>evidence of how new this kind of thinking was. [5]  <br/>  <br/>This is all to explain how Plato and Aristotle can be very impressive and yet<br/>naive and mistaken. It was impressive even to ask the questions they did. That<br/>doesn't mean they always came up with good answers. It's not considered<br/>insulting to say that ancient Greek mathematicians were naive in some<br/>respects, or at least lacked some concepts that would have made their lives<br/>easier. So I hope people will not be too offended if I propose that ancient<br/>philosophers were similarly naive. In particular, they don't seem to have<br/>fully grasped what I earlier called the central fact of philosophy: that words<br/>break if you push them too far.  <br/>  <br/>"Much to the surprise of the builders of the first digital computers," Rod<br/>Brooks wrote, "programs written for them usually did not work." [6] Something<br/>similar happened when people first started trying to talk about abstractions.<br/>Much to their surprise, they didn't arrive at answers they agreed upon. In<br/>fact, they rarely seemed to arrive at answers at all.  <br/>  <br/>They were in effect arguing about artifacts induced by sampling at too low a<br/>resolution.  <br/>  <br/>The proof of how useless some of their answers turned out to be is how little<br/>effect they have. No one after reading Aristotle's _Metaphysics_ does anything<br/>differently as a result. [7]  <br/>  <br/>Surely I'm not claiming that ideas have to have practical applications to be<br/>interesting? No, they may not have to. Hardy's boast that number theory had no<br/>use whatsoever wouldn't disqualify it. But he turned out to be mistaken. In<br/>fact, it's suspiciously hard to find a field of math that truly has no<br/>practical use. And Aristotle's explanation of the ultimate goal of philosophy<br/>in Book A of the _Metaphysics_ implies that philosophy should be useful too.  <br/>  <br/> **Theoretical Knowledge**  <br/>  <br/>Aristotle's goal was to find the most general of general principles. The<br/>examples he gives are convincing: an ordinary worker builds things a certain<br/>way out of habit; a master craftsman can do more because he grasps the<br/>underlying principles. The trend is clear: the more general the knowledge, the<br/>more admirable it is. But then he makes a mistake—possibly the most important<br/>mistake in the history of philosophy. He has noticed that theoretical<br/>knowledge is often acquired for its own sake, out of curiosity, rather than<br/>for any practical need. So he proposes there are two kinds of theoretical<br/>knowledge: some that's useful in practical matters and some that isn't. Since<br/>people interested in the latter are interested in it for its own sake, it must<br/>be more noble. So he sets as his goal in the _Metaphysics_ the exploration of<br/>knowledge that has no practical use. Which means no alarms go off when he<br/>takes on grand but vaguely understood questions and ends up getting lost in a<br/>sea of words.  <br/>  <br/>His mistake was to confuse motive and result. Certainly, people who want a<br/>deep understanding of something are often driven by curiosity rather than any<br/>practical need. But that doesn't mean what they end up learning is useless.<br/>It's very valuable in practice to have a deep understanding of what you're<br/>doing; even if you're never called on to solve advanced problems, you can see<br/>shortcuts in the solution of simple ones, and your knowledge won't break down<br/>in edge cases, as it would if you were relying on formulas you didn't<br/>understand. Knowledge is power. That's what makes theoretical knowledge<br/>prestigious. It's also what causes smart people to be curious about certain<br/>things and not others; our DNA is not so disinterested as we might think.  <br/>  <br/>So while ideas don't have to have immediate practical applications to be<br/>interesting, the kinds of things we find interesting will surprisingly often<br/>turn out to have practical applications.  <br/>  <br/>The reason Aristotle didn't get anywhere in the _Metaphysics_ was partly that<br/>he set off with contradictory aims: to explore the most abstract ideas, guided<br/>by the assumption that they were useless. He was like an explorer looking for<br/>a territory to the north of him, starting with the assumption that it was<br/>located to the south.  <br/>  <br/>And since his work became the map used by generations of future explorers, he<br/>sent them off in the wrong direction as well. [8] Perhaps worst of all, he<br/>protected them from both the criticism of outsiders and the promptings of<br/>their own inner compass by establishing the principle that the most noble sort<br/>of theoretical knowledge had to be useless.  <br/>  <br/>The _Metaphysics_ is mostly a failed experiment. A few ideas from it turned<br/>out to be worth keeping; the bulk of it has had no effect at all. The<br/>_Metaphysics_ is among the least read of all famous books. It's not hard to<br/>understand the way Newton's _Principia_ is, but the way a garbled message is.  <br/>  <br/>Arguably it's an interesting failed experiment. But unfortunately that was not<br/>the conclusion Aristotle's successors derived from works like the<br/>_Metaphysics_. [9] Soon after, the western world fell on intellectual hard<br/>times. Instead of version 1s to be superseded, the works of Plato and<br/>Aristotle became revered texts to be mastered and discussed. And so things<br/>remained for a shockingly long time. It was not till around 1600 (in Europe,<br/>where the center of gravity had shifted by then) that one found people<br/>confident enough to treat Aristotle's work as a catalog of mistakes. And even<br/>then they rarely said so outright.  <br/>  <br/>If it seems surprising that the gap was so long, consider how little progress<br/>there was in math between Hellenistic times and the Renaissance.  <br/>  <br/>In the intervening years an unfortunate idea took hold: that it was not only<br/>acceptable to produce works like the _Metaphysics_ , but that it was a<br/>particularly prestigious line of work, done by a class of people called<br/>philosophers. No one thought to go back and debug Aristotle's motivating<br/>argument. And so instead of correcting the problem Aristotle discovered by<br/>falling into it—that you can easily get lost if you talk too loosely about<br/>very abstract ideas—they continued to fall into it.  <br/>  <br/> **The Singularity**  <br/>  <br/>Curiously, however, the works they produced continued to attract new readers.<br/>Traditional philosophy occupies a kind of singularity in this respect. If you<br/>write in an unclear way about big ideas, you produce something that seems<br/>tantalizingly attractive to inexperienced but intellectually ambitious<br/>students. Till one knows better, it's hard to distinguish something that's<br/>hard to understand because the writer was unclear in his own mind from<br/>something like a mathematical proof that's hard to understand because the<br/>ideas it represents are hard to understand. To someone who hasn't learned the<br/>difference, traditional philosophy seems extremely attractive: as hard (and<br/>therefore impressive) as math, yet broader in scope. That was what lured me in<br/>as a high school student.  <br/>  <br/>This singularity is even more singular in having its own defense built in.<br/>When things are hard to understand, people who suspect they're nonsense<br/>generally keep quiet. There's no way to prove a text is meaningless. The<br/>closest you can get is to show that the official judges of some class of texts<br/>can't distinguish them from placebos. [10]  <br/>  <br/>And so instead of denouncing philosophy, most people who suspected it was a<br/>waste of time just studied other things. That alone is fairly damning<br/>evidence, considering philosophy's claims. It's supposed to be about the<br/>ultimate truths. Surely all smart people would be interested in it, if it<br/>delivered on that promise.  <br/>  <br/>Because philosophy's flaws turned away the sort of people who might have<br/>corrected them, they tended to be self-perpetuating. Bertrand Russell wrote in<br/>a letter in 1912:<br/><br/>> Hitherto the people attracted to philosophy have been mostly those who loved<br/>> the big generalizations, which were all wrong, so that few people with exact<br/>> minds have taken up the subject. [11]<br/><br/>His response was to launch Wittgenstein at it, with dramatic results.  <br/>  <br/>I think Wittgenstein deserves to be famous not for the discovery that most<br/>previous philosophy was a waste of time, which judging from the circumstantial<br/>evidence must have been made by every smart person who studied a little<br/>philosophy and declined to pursue it further, but for how he acted in<br/>response. [12] Instead of quietly switching to another field, he made a fuss,<br/>from inside. He was Gorbachev.  <br/>  <br/>The field of philosophy is still shaken from the fright Wittgenstein gave it.<br/>[13] Later in life he spent a lot of time talking about how words worked.<br/>Since that seems to be allowed, that's what a lot of philosophers do now.<br/>Meanwhile, sensing a vacuum in the metaphysical speculation department, the<br/>people who used to do literary criticism have been edging Kantward, under new<br/>names like "literary theory," "critical theory," and when they're feeling<br/>ambitious, plain "theory." The writing is the familiar word salad:<br/><br/>> Gender is not like some of the other grammatical modes which express<br/>> precisely a mode of conception without any reality that corresponds to the<br/>> conceptual mode, and consequently do not express precisely something in<br/>> reality by which the intellect could be moved to conceive a thing the way it<br/>> does, even where that motive is not something in the thing as such. [14]<br/><br/>The singularity I've described is not going away. There's a market for writing<br/>that sounds impressive and can't be disproven. There will always be both<br/>supply and demand. So if one group abandons this territory, there will always<br/>be others ready to occupy it.  <br/>  <br/> **A Proposal**  <br/>  <br/>We may be able to do better. Here's an intriguing possibility. Perhaps we<br/>should do what Aristotle meant to do, instead of what he did. The goal he<br/>announces in the _Metaphysics_ seems one worth pursuing: to discover the most<br/>general truths. That sounds good. But instead of trying to discover them<br/>because they're useless, let's try to discover them because they're useful.  <br/>  <br/>I propose we try again, but that we use that heretofore despised criterion,<br/>applicability, as a guide to keep us from wondering off into a swamp of<br/>abstractions. Instead of trying to answer the question:<br/><br/>> What are the most general truths?<br/><br/>let's try to answer the question<br/><br/>> Of all the useful things we can say, which are the most general?<br/><br/>The test of utility I propose is whether we cause people who read what we've<br/>written to do anything differently afterward. Knowing we have to give definite<br/>(if implicit) advice will keep us from straying beyond the resolution of the<br/>words we're using.  <br/>  <br/>The goal is the same as Aristotle's; we just approach it from a different<br/>direction.  <br/>  <br/>As an example of a useful, general idea, consider that of the controlled<br/>experiment. There's an idea that has turned out to be widely applicable. Some<br/>might say it's part of science, but it's not part of any specific science;<br/>it's literally meta-physics (in our sense of "meta"). The idea of evolution is<br/>another. It turns out to have quite broad applications—for example, in genetic<br/>algorithms and even product design. Frankfurt's distinction between lying and<br/>bullshitting seems a promising recent example. [15]  <br/>  <br/>These seem to me what philosophy should look like: quite general observations<br/>that would cause someone who understood them to do something differently.  <br/>  <br/>Such observations will necessarily be about things that are imprecisely<br/>defined. Once you start using words with precise meanings, you're doing math.<br/>So starting from utility won't entirely solve the problem I described above—it<br/>won't flush out the metaphysical singularity. But it should help. It gives<br/>people with good intentions a new roadmap into abstraction. And they may<br/>thereby produce things that make the writing of the people with bad intentions<br/>look bad by comparison.  <br/>  <br/>One drawback of this approach is that it won't produce the sort of writing<br/>that gets you tenure. And not just because it's not currently the fashion. In<br/>order to get tenure in any field you must not arrive at conclusions that<br/>members of tenure committees can disagree with. In practice there are two<br/>kinds of solutions to this problem. In math and the sciences, you can prove<br/>what you're saying, or at any rate adjust your conclusions so you're not<br/>claiming anything false ("6 of 8 subjects had lower blood pressure after the<br/>treatment"). In the humanities you can either avoid drawing any definite<br/>conclusions (e.g. conclude that an issue is a complex one), or draw<br/>conclusions so narrow that no one cares enough to disagree with you.  <br/>  <br/>The kind of philosophy I'm advocating won't be able to take either of these<br/>routes. At best you'll be able to achieve the essayist's standard of proof,<br/>not the mathematician's or the experimentalist's. And yet you won't be able to<br/>meet the usefulness test without implying definite and fairly broadly<br/>applicable conclusions. Worse still, the usefulness test will tend to produce<br/>results that annoy people: there's no use in telling people things they<br/>already believe, and people are often upset to be told things they don't.  <br/>  <br/>Here's the exciting thing, though. Anyone can do this. Getting to general plus<br/>useful by starting with useful and cranking up the generality may be<br/>unsuitable for junior professors trying to get tenure, but it's better for<br/>everyone else, including professors who already have it. This side of the<br/>mountain is a nice gradual slope. You can start by writing things that are<br/>useful but very specific, and then gradually make them more general. Joe's has<br/>good burritos. What makes a good burrito? What makes good food? What makes<br/>anything good? You can take as long as you want. You don't have to get all the<br/>way to the top of the mountain. You don't have to tell anyone you're doing<br/>philosophy.  <br/>  <br/>If it seems like a daunting task to do philosophy, here's an encouraging<br/>thought. The field is a lot younger than it seems. Though the first<br/>philosophers in the western tradition lived about 2500 years ago, it would be<br/>misleading to say the field is 2500 years old, because for most of that time<br/>the leading practitioners weren't doing much more than writing commentaries on<br/>Plato or Aristotle while watching over their shoulders for the next invading<br/>army. In the times when they weren't, philosophy was hopelessly intermingled<br/>with religion. It didn't shake itself free till a couple hundred years ago,<br/>and even then was afflicted by the structural problems I've described above.<br/>If I say this, some will say it's a ridiculously overbroad and uncharitable<br/>generalization, and others will say it's old news, but here goes: judging from<br/>their works, most philosophers up to the present have been wasting their time.<br/>So in a sense the field is still at the first step. [16]  <br/>  <br/>That sounds a preposterous claim to make. It won't seem so preposterous in<br/>10,000 years. Civilization always seems old, because it's always the oldest<br/>it's ever been. The only way to say whether something is really old or not is<br/>by looking at structural evidence, and structurally philosophy is young; it's<br/>still reeling from the unexpected breakdown of words.  <br/>  <br/>Philosophy is as young now as math was in 1500. There is a lot more to<br/>discover.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] In practice formal logic is not much use, because despite some progress in<br/>the last 150 years we're still only able to formalize a small percentage of<br/>statements. We may never do that much better, for the same reason 1980s-style<br/>"knowledge representation" could never have worked; many statements may have<br/>no representation more concise than a huge, analog brain state.  <br/>  <br/>[2] It was harder for Darwin's contemporaries to grasp this than we can easily<br/>imagine. The story of creation in the Bible is not just a Judeo-Christian<br/>concept; it's roughly what everyone must have believed since before people<br/>were people. The hard part of grasping evolution was to realize that species<br/>weren't, as they seem to be, unchanging, but had instead evolved from<br/>different, simpler organisms over unimaginably long periods of time.  <br/>  <br/>Now we don't have to make that leap. No one in an industrialized country<br/>encounters the idea of evolution for the first time as an adult. Everyone's<br/>taught about it as a child, either as truth or heresy.  <br/>  <br/>[3] Greek philosophers before Plato wrote in verse. This must have affected<br/>what they said. If you try to write about the nature of the world in verse, it<br/>inevitably turns into incantation. Prose lets you be more precise, and more<br/>tentative.  <br/>  <br/>[4] Philosophy is like math's ne'er-do-well brother. It was born when Plato<br/>and Aristotle looked at the works of their predecessors and said in effect<br/>"why can't you be more like your brother?" Russell was still saying the same<br/>thing 2300 years later.  <br/>  <br/>Math is the precise half of the most abstract ideas, and philosophy the<br/>imprecise half. It's probably inevitable that philosophy will suffer by<br/>comparison, because there's no lower bound to its precision. Bad math is<br/>merely boring, whereas bad philosophy is nonsense. And yet there are _some_<br/>good ideas in the imprecise half.  <br/>  <br/>[5] Aristotle's best work was in logic and zoology, both of which he can be<br/>said to have invented. But the most dramatic departure from his predecessors<br/>was a new, much more analytical style of thinking. He was arguably the first<br/>scientist.  <br/>  <br/>[6] Brooks, Rodney, _Programming in Common Lisp_ , Wiley, 1985, p. 94.  <br/>  <br/>[7] Some would say we depend on Aristotle more than we realize, because his<br/>ideas were one of the ingredients in our common culture. Certainly a lot of<br/>the words we use have a connection with Aristotle, but it seems a bit much to<br/>suggest that we wouldn't have the concept of the essence of something or the<br/>distinction between matter and form if Aristotle hadn't written about them.  <br/>  <br/>One way to see how much we really depend on Aristotle would be to diff<br/>European culture with Chinese: what ideas did European culture have in 1800<br/>that Chinese culture didn't, in virtue of Aristotle's contribution?  <br/>  <br/>[8] The meaning of the word "philosophy" has changed over time. In ancient<br/>times it covered a broad range of topics, comparable in scope to our<br/>"scholarship" (though without the methodological implications). Even as late<br/>as Newton's time it included what we now call "science." But core of the<br/>subject today is still what seemed to Aristotle the core: the attempt to<br/>discover the most general truths.  <br/>  <br/>Aristotle didn't call this "metaphysics." That name got assigned to it because<br/>the books we now call the _Metaphysics_ came after (meta = after) the<br/>_Physics_ in the standard edition of Aristotle's works compiled by Andronicus<br/>of Rhodes three centuries later. What we call "metaphysics" Aristotle called<br/>"first philosophy."  <br/>  <br/>[9] Some of Aristotle's immediate successors may have realized this, but it's<br/>hard to say because most of their works are lost.  <br/>  <br/>[10] Sokal, Alan, "Transgressing the Boundaries: Toward a Transformative<br/>Hermeneutics of Quantum Gravity," _Social Text_ 46/47, pp. 217-252.  <br/>  <br/>Abstract-sounding nonsense seems to be most attractive when it's aligned with<br/>some axe the audience already has to grind. If this is so we should find it's<br/>most popular with groups that are (or feel) weak. The powerful don't need its<br/>reassurance.  <br/>  <br/>[11] Letter to Ottoline Morrell, December 1912. Quoted in:  <br/>  <br/>Monk, Ray, _Ludwig Wittgenstein: The Duty of Genius_ , Penguin, 1991, p. 75.  <br/>  <br/>[12] A preliminary result, that all metaphysics between Aristotle and 1783 had<br/>been a waste of time, is due to I. Kant.  <br/>  <br/>[13] Wittgenstein asserted a sort of mastery to which the inhabitants of early<br/>20th century Cambridge seem to have been peculiarly vulnerable—perhaps partly<br/>because so many had been raised religious and then stopped believing, so had a<br/>vacant space in their heads for someone to tell them what to do (others chose<br/>Marx or Cardinal Newman), and partly because a quiet, earnest place like<br/>Cambridge in that era had no natural immunity to messianic figures, just as<br/>European politics then had no natural immunity to dictators.  <br/>  <br/>[14] This is actually from the _Ordinatio_ of Duns Scotus (ca. 1300), with<br/>"number" replaced by "gender." Plus ca change.  <br/>  <br/>Wolter, Allan (trans), _Duns Scotus: Philosophical Writings_ , Nelson, 1963,<br/>p. 92.  <br/>  <br/>[15] Frankfurt, Harry, _On Bullshit_ , Princeton University Press, 2005.  <br/>  <br/>[16] Some introductions to philosophy now take the line that philosophy is<br/>worth studying as a process rather than for any particular truths you'll<br/>learn. The philosophers whose works they cover would be rolling in their<br/>graves at that. They hoped they were doing more than serving as examples of<br/>how to argue: they hoped they were getting results. Most were wrong, but it<br/>doesn't seem an impossible hope.  <br/>  <br/>This argument seems to me like someone in 1500 looking at the lack of results<br/>achieved by alchemy and saying its value was as a process. No, they were going<br/>about it wrong. It turns out it is possible to transmute lead into gold<br/>(though not economically at current energy prices), but the route to that<br/>knowledge was to backtrack and try another approach.  <br/>  <br/> **Thanks** to Trevor Blackwell, Paul Buchheit, Jessica Livingston, Robert<br/>Morris, Mark Nitzberg, and Peter Norvig for reading drafts of this.  <br/>  <br/>  <br/><br/>French Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>August 2015  <br/>  <br/>If you have a US startup called X and you don't have x.com, you should<br/>probably change your name.  <br/>  <br/>The reason is not just that people can't find you. For companies with mobile<br/>apps, especially, having the right domain name is not as critical as it used<br/>to be for getting users. The problem with not having the .com of your name is<br/>that it signals weakness. Unless you're so big that your reputation precedes<br/>you, a marginal domain suggests you're a marginal company. Whereas (as Stripe<br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>October 2007  <br/>  <br/> _(This essay is derived from a keynote at FOWA in October 2007.)_  <br/>  <br/>There's something interesting happening right now. Startups are undergoing the<br/>same transformation that technology does when it becomes cheaper.  <br/>  <br/>It's a pattern we see over and over in technology. Initially there's some<br/>device that's very expensive and made in small quantities. Then someone<br/>discovers how to make them cheaply; many more get built; and as a result they<br/>can be used in new ways.  <br/>  <br/>Computers are a familiar example. When I was a kid, computers were big,<br/>expensive machines built one at a time. Now they're a commodity. Now we can<br/>stick computers in everything.  <br/>  <br/>This pattern is very old. Most of the turning points in economic history are<br/>instances of it. It happened to steel in the 1850s, and to power in the 1780s.<br/>It happened to cloth manufacture in the thirteenth century, generating the<br/>wealth that later brought about the Renaissance. Agriculture itself was an<br/>instance of this pattern.  <br/>  <br/>Now as well as being produced by startups, this pattern is happening _to_<br/>startups. It's so cheap to start web startups that orders of magnitudes more<br/>will be started. If the pattern holds true, that should cause dramatic<br/>changes.  <br/>  <br/> **1\. Lots of Startups**  <br/>  <br/>So my first prediction about the future of web startups is pretty<br/>straightforward: there will be a lot of them. When starting a startup was<br/>expensive, you had to get the permission of investors to do it. Now the only<br/>threshold is courage.  <br/>  <br/>Even that threshold is getting lower, as people watch others take the plunge<br/>and survive. In the last batch of startups we funded, we had several founders<br/>who said they'd thought of applying before, but weren't sure and got jobs<br/>instead. It was only after hearing reports of friends who'd done it that they<br/>decided to try it themselves.  <br/>  <br/>Starting a startup is hard, but having a 9 to 5 job is hard too, and in some<br/>ways a worse kind of hard. In a startup you have lots of worries, but you<br/>don't have that feeling that your life is flying by like you do in a big<br/>company. Plus in a startup you could make much more money.  <br/>  <br/>As word spreads that startups work, the number may grow to a point that would<br/>now seem surprising.  <br/>  <br/>We now think of it as normal to have a job at a company, but this is the<br/>thinnest of historical veneers. Just two or three lifetimes ago, most people<br/>in what are now called industrialized countries lived by farming. So while it<br/>may seem surprising to propose that large numbers of people will change the<br/>way they make a living, it would be more surprising if they didn't.  <br/>  <br/> **2\. Standardization**  <br/>  <br/>When technology makes something dramatically cheaper, standardization always<br/>follows. When you make things in large volumes you tend to standardize<br/>everything that doesn't need to change.  <br/>  <br/>At Y Combinator we still only have four people, so we try to standardize<br/>everything. We could hire employees, but we want to be forced to figure out<br/>how to scale investing.  <br/>  <br/>We often tell startups to release a minimal version one quickly, then let the<br/>needs of the users determine what to do next. In essense, let the market<br/>design the product. We've done the same thing ourselves. We think of the<br/>techniques we're developing for dealing with large numbers of startups as like<br/>software. Sometimes it literally is software, like Hacker News and our<br/>application system.  <br/>  <br/>One of the most important things we've been working on standardizing are<br/>investment terms. Till now investment terms have been individually negotiated.<br/>This is a problem for founders, because it makes raising money take longer and<br/>cost more in legal fees. So as well as using the same paperwork for every deal<br/>we do, we've commissioned generic angel paperwork that all the startups we<br/>fund can use for future rounds.  <br/>  <br/>Some investors will still want to cook up their own deal terms. Series A<br/>rounds, where you raise a million dollars or more, will be custom deals for<br/>the forseeable future. But I think angel rounds will start to be done mostly<br/>with standardized agreements. An angel who wants to insert a bunch of<br/>complicated terms into the agreement is probably not one you want anyway.  <br/>  <br/> **3\. New Attitude to Acquisition**  <br/>  <br/>Another thing I see starting to get standardized is acquisitions. As the<br/>volume of startups increases, big companies will start to develop standardized<br/>procedures that make acquisitions little more work than hiring someone.  <br/>  <br/>Google is the leader here, as in so many areas of technology. They buy a lot<br/>of startups— more than most people realize, because they only announce a<br/>fraction of them. And being Google, they're figuring out how to do it<br/>efficiently.  <br/>  <br/>One problem they've solved is how to think about acquisitions. For most<br/>companies, acquisitions still carry some stigma of inadequacy. Companies do<br/>them because they have to, but there's usually some feeling they shouldn't<br/>have to—that their own programmers should be able to build everything they<br/>need.  <br/>  <br/>Google's example should cure the rest of the world of this idea. Google has by<br/>far the best programmers of any public technology company. If they don't have<br/>a problem doing acquisitions, the others should have even less problem.<br/>However many Google does, Microsoft should do ten times as many.  <br/>  <br/>One reason Google doesn't have a problem with acquisitions is that they know<br/>first-hand the quality of the people they can get that way. Larry and Sergey<br/>only started Google after making the rounds of the search engines trying to<br/>sell their idea and finding no takers. They've _been_ the guys coming in to<br/>visit the big company, so they know who might be sitting across that<br/>conference table from them.  <br/>  <br/> **4\. Riskier Strategies are Possible**  <br/>  <br/>Risk is always proportionate to reward. The way to get really big returns is<br/>to do things that seem crazy, like starting a new search engine in 1998, or<br/>turning down a billion dollar acquisition offer.  <br/>  <br/>This has traditionally been a problem in venture funding. Founders and<br/>investors have different attitudes to risk. Knowing that risk is on average<br/>proportionate to reward, investors like risky strategies, while founders, who<br/>don't have a big enough sample size to care what's true on average, tend to be<br/>more conservative.  <br/>  <br/>If startups are easy to start, this conflict goes away, because founders can<br/>start them younger, when it's rational to take more risk, and can start more<br/>startups total in their careers. When founders can do lots of startups, they<br/>can start to look at the world in the same portfolio-optimizing way as<br/>investors. And that means the overall amount of wealth created can be greater,<br/>because strategies can be riskier.  <br/>  <br/> **5\. Younger, Nerdier Founders**  <br/>  <br/>If startups become a cheap commodity, more people will be able to have them,<br/>just as more people could have computers once microprocessors made them cheap.<br/>And in particular, younger and more technical founders will be able to start<br/>startups than could before.  <br/>  <br/>Back when it cost a lot to start a startup, you had to convince investors to<br/>let you do it. And that required very different skills from actually doing the<br/>startup. If investors were perfect judges, the two would require exactly the<br/>same skills. But unfortunately most investors are terrible judges. I know<br/>because I see behind the scenes what an enormous amount of work it takes to<br/>raise money, and the amount of selling required in an industry is always<br/>inversely proportional to the judgement of the buyers.  <br/>  <br/>Fortunately, if startups get cheaper to start, there's another way to convince<br/>investors. Instead of going to venture capitalists with a business plan and<br/>trying to convince them to fund it, you can get a product launched on a few<br/>tens of thousands of dollars of seed money from us or your uncle, and approach<br/>them with a working company instead of a plan for one. Then instead of having<br/>to seem smooth and confident, you can just point them to Alexa.  <br/>  <br/>This way of convincing investors is better suited to hackers, who often went<br/>into technology in part because they felt uncomfortable with the amount of<br/>fakeness required in other fields.  <br/>  <br/> **6\. Startup Hubs Will Persist**  <br/>  <br/>It might seem that if startups get cheap to start, it will mean the end of<br/>startup hubs like Silicon Valley. If all you need to start a startup is rent<br/>money, you should be able to do it anywhere.  <br/>  <br/>This is kind of true and kind of false. It's true that you can now _start_ a<br/>startup anywhere. But you have to do more with a startup than just start it.<br/>You have to make it succeed. And that is more likely to happen in a startup<br/>hub.  <br/>  <br/>I've thought a lot about this question, and it seems to me the increasing<br/>cheapness of web startups will if anything increase the importance of startup<br/>hubs. The value of startup hubs, like centers for any kind of business, lies<br/>in something very old-fashioned: face to face meetings. No technology in the<br/>immediate future will replace walking down University Ave and running into a<br/>friend who tells you how to fix a bug that's been bothering you all weekend,<br/>or visiting a friend's startup down the street and ending up in a conversation<br/>with one of their investors.  <br/>  <br/>The question of whether to be in a startup hub is like the question of whether<br/>to take outside investment. The question is not whether you _need_ it, but<br/>whether it brings any advantage at all. Because anything that brings an<br/>advantage will give your competitors an advantage over you if they do it and<br/>you don't. So if you hear someone saying "we don't need to be in Silicon<br/>Valley," that use of the word "need" is a sign they're not even thinking about<br/>the question right.  <br/>  <br/>And while startup hubs are as powerful magnets as ever, the increasing<br/>cheapness of starting a startup means the particles they're attracting are<br/>getting lighter. A startup now can be just a pair of 22 year old guys. A<br/>company like that can move much more easily than one with 10 people, half of<br/>whom have kids.  <br/>  <br/>We know because we make people move for Y Combinator, and it doesn't seem to<br/>be a problem. The advantage of being able to work together face to face for<br/>three months outweighs the inconvenience of moving. Ask anyone who's done it.  <br/>  <br/>The mobility of seed-stage startups means that seed funding is a national<br/>business. One of the most common emails we get is from people asking if we can<br/>help them set up a local clone of Y Combinator. But this just wouldn't work.<br/>Seed funding isn't regional, just as big research universities aren't.  <br/>  <br/>Is seed funding not merely national, but international? Interesting question.<br/>There are signs it may be. We've had an ongoing stream of founders from<br/>outside the US, and they tend to do particularly well, because they're all<br/>people who were so determined to succeed that they were willing to move to<br/>another country to do it.  <br/>  <br/>The more mobile startups get, the harder it would be to start new silicon<br/>valleys. If startups are mobile, the best local talent will go to the real<br/>Silicon Valley, and all they'll get at the local one will be the people who<br/>didn't have the energy to move.  <br/>  <br/>This is not a nationalistic idea, incidentally. It's cities that compete, not<br/>countries. Atlanta is just as hosed as Munich.  <br/>  <br/> **7\. Better Judgement Needed**  <br/>  <br/>If the number of startups increases dramatically, then the people whose job is<br/>to judge them are going to have to get better at it. I'm thinking particularly<br/>of investors and acquirers. We now get on the order of 1000 applications a<br/>year. What are we going to do if we get 10,000?  <br/>  <br/>That's actually an alarming idea. But we'll figure out some kind of answer.<br/>We'll have to. It will probably involve writing some software, but fortunately<br/>we can do that.  <br/>  <br/>Acquirers will also have to get better at picking winners. They generally do<br/>better than investors, because they pick later, when there's more performance<br/>to measure. But even at the most advanced acquirers, identifying companies to<br/>buy is extremely ad hoc, and completing the acquisition often involves a great<br/>deal of unneccessary friction.  <br/>  <br/>I think acquirers may eventually have chief acquisition officers who will both<br/>identify good acquisitions and make the deals happen. At the moment those two<br/>functions are separate. Promising new startups are often discovered by<br/>developers. If someone powerful enough wants to buy them, the deal is handed<br/>over to corp dev guys to negotiate. It would be better if both were combined<br/>in one group, headed by someone with a technical background and some vision of<br/>what they wanted to accomplish. Maybe in the future big companies will have<br/>both a VP of Engineering responsible for technology developed in-house, and a<br/>CAO responsible for bringing technology in from outside.  <br/>  <br/>At the moment, there is no one within big companies who gets in trouble when<br/>they buy a startup for $200 million that they could have bought earlier for<br/>$20 million. There should start to be someone who gets in trouble for that.  <br/>  <br/> **8\. College Will Change**  <br/>  <br/>If the best hackers start their own companies after college instead of getting<br/>jobs, that will change what happens in college. Most of these changes will be<br/>for the better. I think the experience of college is warped in a bad way by<br/>the expectation that afterward you'll be judged by potential employers.  <br/>  <br/>One change will be in the meaning of "after college," which will switch from<br/>when one graduates from college to when one leaves it. If you're starting your<br/>own company, why do you need a degree? We don't encourage people to start<br/>startups during college, but the best founders are certainly capable of it.<br/>Some of the most successful companies we've funded were started by undergrads.  <br/>  <br/>I grew up in a time where college degrees seemed really important, so I'm<br/>alarmed to be saying things like this, but there's nothing magical about a<br/>degree. There's nothing that magically changes after you take that last exam.<br/>The importance of degrees is due solely to the administrative needs of large<br/>organizations. These can certainly affect your life—it's hard to get into grad<br/>school, or to get a work visa in the US, without an undergraduate degree—but<br/>tests like this will matter less and less.  <br/>  <br/>As well as mattering less whether students get degrees, it will also start to<br/>matter less where they go to college. In a startup you're judged by users, and<br/>they don't care where you went to college. So in a world of startups, elite<br/>universities will play less of a role as gatekeepers. In the US it's a<br/>national scandal how easily children of rich parents game college admissions.<br/>But the way this problem ultimately gets solved may not be by reforming the<br/>universities but by going around them. We in the technology world are used to<br/>that sort of solution: you don't beat the incumbents; you redefine the problem<br/>to make them irrelevant.  <br/>  <br/>The greatest value of universities is not the brand name or perhaps even the<br/>classes so much as the people you meet. If it becomes common to start a<br/>startup after college, students may start trying to maximize this. Instead of<br/>focusing on getting internships at companies they want to work for, they may<br/>start to focus on working with other students they want as cofounders.  <br/>  <br/>What students do in their classes will change too. Instead of trying to get<br/>good grades to impress future employers, students will try to learn things.<br/>We're talking about some pretty dramatic changes here.  <br/>  <br/> **9\. Lots of Competitors**  <br/>  <br/>If it gets easier to start a startup, it's easier for competitors too. That<br/>doesn't erase the advantage of increased cheapness, however. You're not all<br/>playing a zero-sum game. There's not some fixed number of startups that can<br/>succeed, regardless of how many are started.  <br/>  <br/>In fact, I don't think there's any limit to the number of startups that could<br/>succeed. Startups succeed by creating wealth, which is the satisfaction of<br/>people's desires. And people's desires seem to be effectively infinite, at<br/>least in the short term.  <br/>  <br/>What the increasing number of startups does mean is that you won't be able to<br/>sit on a good idea. Other people have your idea, and they'll be increasingly<br/>likely to do something about it.  <br/>  <br/> **10\. Faster Advances**  <br/>  <br/>There's a good side to that, at least for consumers of technology. If people<br/>get right to work implementing ideas instead of sitting on them, technology<br/>will evolve faster.  <br/>  <br/>Some kinds of innovations happen a company at a time, like the punctuated<br/>equilibrium model of evolution. There are some kinds of ideas that are so<br/>threatening that it's hard for big companies even to think of them. Look at<br/>what a hard time Microsoft is having discovering web apps. They're like a<br/>character in a movie that everyone in the audience can see something bad is<br/>about to happen to, but who can't see it himself. The big innovations that<br/>happen a company at a time will obviously happen faster if the rate of new<br/>companies increases.  <br/>  <br/>But in fact there will be a double speed increase. People won't wait as long<br/>to act on new ideas, but also those ideas will increasingly be developed<br/>within startups rather than big companies. Which means technology will evolve<br/>faster per company as well.  <br/>  <br/>Big companies are just not a good place to make things happen fast. I talked<br/>recently to a founder whose startup had been acquired by a big company. He was<br/>a precise sort of guy, so he'd measured their productivity before and after.<br/>He counted lines of code, which can be a dubious measure, but in this case was<br/>meaningful because it was the same group of programmers. He found they were<br/>one thirteenth as productive after the acquisition.  <br/>  <br/>The company that bought them was not a particularly stupid one. I think what<br/>he was measuring was mostly the cost of bigness. I experienced this myself,<br/>and his number sounds about right. There's something about big companies that<br/>just sucks the energy out of you.  <br/>  <br/>Imagine what all that energy could do if it were put to use. There is an<br/>enormous latent capacity in the world's hackers that most people don't even<br/>realize is there. That's the main reason we do Y Combinator: to let loose all<br/>this energy by making it easy for hackers to start their own startups.  <br/>  <br/> **A Series of Tubes**  <br/>  <br/>The process of starting startups is currently like the plumbing in an old<br/>house. The pipes are narrow and twisty, and there are leaks in every joint. In<br/>the future this mess will gradually be replaced by a single, huge pipe. The<br/>water will still have to get from A to B, but it will get there faster and<br/>without the risk of spraying out through some random leak.  <br/>  <br/>This will change a lot of things for the better. In a big, straight pipe like<br/>that, the force of being measured by one's performance will propagate back<br/>through the whole system. Performance is always the ultimate test, but there<br/>are so many kinks in the plumbing now that most people are insulated from it<br/>most of the time. So you end up with a world in which high school students<br/>think they need to get good grades to get into elite colleges, and college<br/>students think they need to get good grades to impress employers, within which<br/>the employees waste most of their time in political battles, and from which<br/>consumers have to buy anyway because there are so few choices. Imagine if that<br/>sequence became a big, straight pipe. Then the effects of being measured by<br/>performance would propagate all the way back to high school, flushing out all<br/>the arbitrary stuff people are measured by now. That is the future of web<br/>startups.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Thanks** to Brian Oberkirch and Simon Willison for inviting me to speak,<br/>and the crew at Carson Systems for making everything run smoothly.  <br/>  <br/><br/>Japanese Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>April 2009  <br/>  <br/> _Inc_ recently asked me who I thought were the 5 most interesting startup<br/>founders of the last 30 years. How do you decide who's the most interesting?<br/>The best test seemed to be influence: who are the 5 who've influenced me most?<br/>Who do I use as examples when I'm talking to companies we fund? Who do I find<br/>myself quoting?  <br/>  <br/> **1\. Steve Jobs**  <br/>  <br/>I'd guess Steve is the most influential founder not just for me but for most<br/>people you could ask. A lot of startup culture is Apple culture. He was the<br/>original young founder. And while the concept of "insanely great" already<br/>existed in the arts, it was a novel idea to introduce into a company in the<br/>1980s.  <br/>  <br/>More remarkable still, he's stayed interesting for 30 years. People await new<br/>Apple products the way they'd await new books by a popular novelist. Steve may<br/>not literally design them, but they wouldn't happen if he weren't CEO.  <br/>  <br/>Steve is clever and driven, but so are a lot of people in the Valley. What<br/>makes him unique is his sense of design. Before him, most companies treated<br/>design as a frivolous extra. Apple's competitors now know better.  <br/>  <br/> **2\. TJ Rodgers**  <br/>  <br/>TJ Rodgers isn't as famous as Steve Jobs, but he may be the best writer among<br/>Silicon Valley CEOs. I've probably learned more from him about the startup way<br/>of thinking than from anyone else. Not so much from specific things he's<br/>written as by reconstructing the mind that produced them: brutally candid;<br/>aggressively garbage-collecting outdated ideas; and yet driven by pragmatism<br/>rather than ideology.  <br/>  <br/>The first essay of his that I read was so electrifying that I remember exactly<br/>where I was at the time. It was High Technology Innovation: Free Markets or<br/>Government Subsidies? and I was downstairs in the Harvard Square T Station. It<br/>felt as if someone had flipped on a light switch inside my head.  <br/>  <br/> **3\. Larry & Sergey**  <br/>  <br/>I'm sorry to treat Larry and Sergey as one person. I've always thought that<br/>was unfair to them. But it does seem as if Google was a collaboration.  <br/>  <br/>Before Google, companies in Silicon Valley already knew it was important to<br/>have the best hackers. So they claimed, at least. But Google pushed this idea<br/>further than anyone had before. Their hypothesis seems to have been that, in<br/>the initial stages at least, _all_ you need is good hackers: if you hire all<br/>the smartest people and put them to work on a problem where their success can<br/>be measured, you win. All the other stuff—which includes all the stuff that<br/>business schools think business consists of—you can figure out along the way.<br/>The results won't be perfect, but they'll be optimal. If this was their<br/>hypothesis, it's now been verified experimentally.  <br/>  <br/> **4\. Paul Buchheit**  <br/>  <br/>Few know this, but one person, Paul Buchheit, is responsible for three of the<br/>best things Google has done. He was the original author of GMail, which is the<br/>most impressive thing Google has after search. He also wrote the first<br/>prototype of AdSense, and was the author of Google's mantra "Don't be evil."  <br/>  <br/>PB made a point in a talk once that I now mention to every startup we fund:<br/>that it's better, initially, to make a small number of users really love you<br/>than a large number kind of like you. If I could tell startups only ten<br/>sentences, this would be one of them.  <br/>  <br/>Now he's cofounder of a startup called Friendfeed. It's only a year old, but<br/>already everyone in the Valley is watching them. Someone responsible for three<br/>of the biggest ideas at Google is going to come up with more.  <br/>  <br/> **5\. Sam Altman**  <br/>  <br/>I was told I shouldn't mention founders of YC-funded companies in this list.<br/>But Sam Altman can't be stopped by such flimsy rules. If he wants to be on<br/>this list, he's going to be.  <br/>  <br/>Honestly, Sam is, along with Steve Jobs, the founder I refer to most when I'm<br/>advising startups. On questions of design, I ask "What would Steve do?" but on<br/>questions of strategy or ambition I ask "What would Sama do?"  <br/>  <br/>What I learned from meeting Sama is that the doctrine of the elect applies to<br/>startups. It applies way less than most people think: startup investing does<br/>not consist of trying to pick winners the way you might in a horse race. But<br/>there are a few people with such force of will that they're going to get<br/>whatever they want.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>Kevin Kelleher suggested an interesting way to compare programming languages:<br/>to describe each in terms of the problem it fixes. The surprising thing is how<br/>many, and how well, languages can be described this way.  <br/>  <br/><br/>**Algol:** Assembly language is too low-level.  <br/>  <br/> **Pascal:** Algol doesn't have enough data types.  <br/>  <br/> **Modula:** Pascal is too wimpy for systems programming.  <br/>  <br/>**Simula:** Algol isn't good enough at simulations.  <br/>  <br/> **Smalltalk:** Not everything in Simula is an object.  <br/>  <br/> **Fortran:** Assembly language is too low-level.  <br/>  <br/> **Cobol:** Fortran is scary.  <br/>  <br/> **PL/1:** Fortran doesn't have enough data types.  <br/>  <br/> **Ada:** Every existing language is missing something.  <br/>  <br/> **Basic:** Fortran is scary.  <br/>  <br/> **APL:** Fortran isn't good enough at manipulating arrays.  <br/>  <br/> **J:** APL requires its own character set.  <br/>  <br/> **C:** Assembly language is too low-level.  <br/>  <br/> **C++:** C is too low-level.  <br/>  <br/> **Java:** C++ is a kludge. And Microsoft is going to crush us.  <br/>  <br/> **C#:** Java is controlled by Sun.  <br/>  <br/>**Lisp:** Turing Machines are an awkward way to describe computation.  <br/>  <br/> **Scheme:** MacLisp is a kludge.  <br/>  <br/> **T:** Scheme has no libraries.  <br/>  <br/> **Common Lisp:** There are too many dialects of Lisp.  <br/>  <br/> **Dylan:** Scheme has no libraries, and Lisp syntax is scary.  <br/>  <br/>**Perl:** Shell scripts/awk/sed are not enough like programming languages.  <br/>  <br/> **Python:** Perl is a kludge.  <br/>  <br/> **Ruby:** Perl is a kludge, and Lisp syntax is scary.  <br/>  <br/> **Prolog:** Programming is not enough like logic.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>French Translation  <br/>  <br/><br/>Portuguese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>January 2017  <br/>  <br/>Because biographies of famous scientists tend to edit out their mistakes, we<br/>underestimate the degree of risk they were willing to take. And because<br/>anything a famous scientist did that wasn't a mistake has probably now become<br/>the conventional wisdom, those choices don't seem risky either.  <br/>  <br/>Biographies of Newton, for example, understandably focus more on physics than<br/>alchemy or theology. The impression we get is that his unerring judgment led<br/>him straight to truths no one else had noticed. How to explain all the time he<br/>spent on alchemy and theology? Well, smart people are often kind of crazy.  <br/>  <br/>But maybe there is a simpler explanation. Maybe the smartness and the<br/>craziness were not as separate as we think. Physics seems to us a promising<br/>thing to work on, and alchemy and theology obvious wastes of time. But that's<br/>because we know how things turned out. In Newton's day the three problems<br/>seemed roughly equally promising. No one knew yet what the payoff would be for<br/>inventing what we now call physics; if they had, more people would have been<br/>working on it. And alchemy and theology were still then in the category Marc<br/>Andreessen would describe as "huge, if true."  <br/>  <br/>Newton made three bets. One of them worked. But they were all risky.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>January 2016  <br/>  <br/>Since the 1970s, economic inequality in the US has increased dramatically. And<br/>in particular, the rich have gotten a lot richer.  <br/>  <br/>Nearly everyone who writes about economic inequality says that it should be<br/>decreased.  <br/>  <br/>I'm interested in this question because I was one of the founders of a company<br/>called Y Combinator that helps people start startups. Almost by definition, if<br/>a startup succeeds, its founders become rich. Which means by helping startup<br/>founders I've been helping to increase economic inequality. If economic<br/>inequality should be decreased, I shouldn't be helping founders. No one should<br/>be.  <br/>  <br/>But that doesn't sound right. What's going on here? What's going on is that<br/>while economic inequality is a single measure (or more precisely, two:<br/>variation in income, and variation in wealth), it has multiple causes. Many of<br/>these causes are bad, like tax loopholes and drug addiction. But some are<br/>good, like Larry Page and Sergey Brin starting the company you use to find<br/>things online.  <br/>  <br/>If you want to understand economic inequality — and more importantly, if you<br/>actually want to fix the bad aspects of it — you have to tease apart the<br/>components. And yet the trend in nearly everything written about the subject<br/>is to do the opposite: to squash together all the aspects of economic<br/>inequality as if it were a single phenomenon.  <br/>  <br/>Sometimes this is done for ideological reasons. Sometimes it's because the<br/>writer only has very high-level data and so draws conclusions from that, like<br/>the proverbial drunk who looks for his keys under the lamppost, instead of<br/>where he dropped them, because the light is better there. Sometimes it's<br/>because the writer doesn't understand critical aspects of inequality, like the<br/>role of technology in wealth creation. Much of the time, perhaps most of the<br/>time, writing about economic inequality combines all three.  <br/>  <br/>___  <br/>  <br/>The most common mistake people make about economic inequality is to treat it<br/>as a single phenomenon. The most naive version of which is the one based on<br/>the pie fallacy: that the rich get rich by taking money from the poor.  <br/>  <br/>Usually this is an assumption people start from rather than a conclusion they<br/>arrive at by examining the evidence. Sometimes the pie fallacy is stated<br/>explicitly:<br/><br/>> ...those at the top are grabbing an increasing fraction of the nation's<br/>> income — so much of a larger share that what's left over for the rest is<br/>> diminished.... [1]<br/><br/>Other times it's more unconscious. But the unconscious form is very<br/>widespread. I think because we grow up in a world where the pie fallacy is<br/>actually true. To kids, wealth _is_ a fixed pie that's shared out, and if one<br/>person gets more, it's at the expense of another. It takes a conscious effort<br/>to remind oneself that the real world doesn't work that way.  <br/>  <br/>In the real world you can create wealth as well as taking it from others. A<br/>woodworker creates wealth. He makes a chair, and you willingly give him money<br/>in return for it. A high-frequency trader does not. He makes a dollar only<br/>when someone on the other end of a trade loses a dollar.  <br/>  <br/>If the rich people in a society got that way by taking wealth from the poor,<br/>then you have the degenerate case of economic inequality, where the cause of<br/>poverty is the same as the cause of wealth. But instances of inequality don't<br/>have to be instances of the degenerate case. If one woodworker makes 5 chairs<br/>and another makes none, the second woodworker will have less money, but not<br/>because anyone took anything from him.  <br/>  <br/>Even people sophisticated enough to know about the pie fallacy are led toward<br/>it by the custom of describing economic inequality as a ratio of one<br/>quantile's income or wealth to another's. It's so easy to slip from talking<br/>about income shifting from one quantile to another, as a figure of speech,<br/>into believing that is literally what's happening.  <br/>  <br/>Except in the degenerate case, economic inequality can't be described by a<br/>ratio or even a curve. In the general case it consists of multiple ways people<br/>become poor, and multiple ways people become rich. Which means to understand<br/>economic inequality in a country, you have to go find individual people who<br/>are poor or rich and figure out why. [2]  <br/>  <br/>If you want to understand _change_ in economic inequality, you should ask what<br/>those people would have done when it was different. This is one way I know the<br/>rich aren't all getting richer simply from some new system for transferring<br/>wealth to them from everyone else. When you use the would-have method with<br/>startup founders, you find what most would have done _back in 1960_, when<br/>economic inequality was lower, was to join big companies or become professors.<br/>Before Mark Zuckerberg started Facebook, his default expectation was that he'd<br/>end up working at Microsoft. The reason he and most other startup founders are<br/>richer than they would have been in the mid 20th century is not because of<br/>some right turn the country took during the Reagan administration, but because<br/>progress in technology has made it much easier to start a new company that<br/>_grows fast_.  <br/>  <br/>Traditional economists seem strangely averse to studying individual humans. It<br/>seems to be a rule with them that everything has to start with statistics. So<br/>they give you very precise numbers about variation in wealth and income, then<br/>follow it with the most naive speculation about the underlying causes.  <br/>  <br/>But while there are a lot of people who get rich through rent-seeking of<br/>various forms, and a lot who get rich by playing zero-sum games, there are<br/>also a significant number who get rich by creating wealth. And creating<br/>wealth, as a source of economic inequality, is different from taking it — not<br/>just morally, but also practically, in the sense that it is harder to<br/>eradicate. One reason is that variation in productivity is accelerating. The<br/>rate at which individuals can create wealth depends on the technology<br/>available to them, and that grows exponentially. The other reason creating<br/>wealth is such a tenacious source of inequality is that it can expand to<br/>accommodate a lot of people.  <br/>  <br/>___  <br/>  <br/>I'm all for shutting down the crooked ways to get rich. But that won't<br/>eliminate great variations in wealth, because as long as you leave open the<br/>option of getting rich by creating wealth, people who want to get rich will do<br/>that instead.  <br/>  <br/>Most people who get rich tend to be fairly driven. Whatever their other flaws,<br/>laziness is usually not one of them. Suppose new policies make it hard to make<br/>a fortune in finance. Does it seem plausible that the people who currently go<br/>into finance to make their fortunes will continue to do so, but be content to<br/>work for ordinary salaries? The reason they go into finance is not because<br/>they love finance but because they want to get rich. If the only way left to<br/>get rich is to start startups, they'll start startups. They'll do well at it<br/>too, because determination is the main factor in the success of a startup. [3]<br/>And while it would probably be a good thing for the world if people who wanted<br/>to get rich switched from playing zero-sum games to creating wealth, that<br/>would not only not eliminate great variations in wealth, but might even<br/>exacerbate them. In a zero-sum game there is at least a limit to the upside.<br/>Plus a lot of the new startups would create new technology that further<br/>accelerated variation in productivity.  <br/>  <br/>Variation in productivity is far from the only source of economic inequality,<br/>but it is the irreducible core of it, in the sense that you'll have that left<br/>when you eliminate all other sources. And if you do, that core will be big,<br/>because it will have expanded to include the efforts of all the refugees. Plus<br/>it will have a large Baumol penumbra around it: anyone who could get rich by<br/>creating wealth on their own account will have to be paid enough to prevent<br/>them from doing it.  <br/>  <br/>You can't prevent great variations in wealth without preventing people from<br/>getting rich, and you can't do that without preventing them from starting<br/>startups.  <br/>  <br/>So let's be clear about that. Eliminating great variations in wealth would<br/>mean eliminating startups. And that doesn't seem a wise move. Especially since<br/>it would only mean you eliminated startups in your own country. Ambitious<br/>people already move halfway around the world to further their careers, and<br/>startups can operate from anywhere nowadays. So if you made it impossible to<br/>get rich by creating wealth in your country, people who wanted to do that<br/>would just leave and do it somewhere else. Which would certainly get you a<br/>lower Gini coefficient, along with a lesson in being careful what you ask for.<br/>[4]  <br/>  <br/>I think rising economic inequality is the inevitable fate of countries that<br/>don't choose something worse. We had a 40 year stretch in the middle of the<br/>20th century that convinced some people otherwise. But as I explained in _The<br/>Refragmentation_, that was an anomaly — a unique combination of circumstances<br/>that compressed American society not just economically but culturally too. [5]  <br/>  <br/>And while some of the growth in economic inequality we've seen since then has<br/>been due to bad behavior of various kinds, there has simultaneously been a<br/>huge increase in individuals' ability to create wealth. Startups are almost<br/>entirely a product of this period. And even within the startup world, there<br/>has been a qualitative change in the last 10 years. Technology has decreased<br/>the cost of starting a startup so much that founders now have the upper hand<br/>over investors. Founders get less diluted, and it is now common for them to<br/>retain _board control_ as well. Both further increase economic inequality, the<br/>former because founders own more stock, and the latter because, as investors<br/>have learned, founders tend to be better at running their companies than<br/>investors.  <br/>  <br/>While the surface manifestations change, the underlying forces are very, very<br/>old. The acceleration of productivity we see in Silicon Valley has been<br/>happening for thousands of years. If you look at the history of stone tools,<br/>technology was already accelerating in the Mesolithic. The acceleration would<br/>have been too slow to perceive in one lifetime. Such is the nature of the<br/>leftmost part of an exponential curve. But it was the same curve.  <br/>  <br/>You do not want to design your society in a way that's incompatible with this<br/>curve. The evolution of technology is one of the most powerful forces in<br/>history.  <br/>  <br/>Louis Brandeis said "We may have democracy, or we may have wealth concentrated<br/>in the hands of a few, but we can't have both." That sounds plausible. But if<br/>I have to choose between ignoring him and ignoring an exponential curve that<br/>has been operating for thousands of years, I'll bet on the curve. Ignoring any<br/>trend that has been operating for thousands of years is dangerous. But<br/>exponential growth, especially, tends to bite you.  <br/>  <br/>___  <br/>  <br/>If accelerating variation in productivity is always going to produce some<br/>baseline growth in economic inequality, it would be a good idea to spend some<br/>time thinking about that future. Can you have a healthy society with great<br/>variation in wealth? What would it look like?  <br/>  <br/>Notice how novel it feels to think about that. The public conversation so far<br/>has been exclusively about the need to decrease economic inequality. We've<br/>barely given a thought to how to live with it.  <br/>  <br/>I'm hopeful we'll be able to. Brandeis was a product of the Gilded Age, and<br/>things have changed since then. It's harder to hide wrongdoing now. And to get<br/>rich now you don't have to buy politicians the way railroad or oil magnates<br/>did. [6] The great concentrations of wealth I see around me in Silicon Valley<br/>don't seem to be destroying democracy.  <br/>  <br/>There are lots of things wrong with the US that have economic inequality as a<br/>symptom. We should fix those things. In the process we may decrease economic<br/>inequality. But we can't start from the symptom and hope to fix the underlying<br/>causes. [7]  <br/>  <br/>The most obvious is poverty. I'm sure most of those who want to decrease<br/>economic inequality want to do it mainly to help the poor, not to hurt the<br/>rich. [8] Indeed, a good number are merely being sloppy by speaking of<br/>decreasing economic inequality when what they mean is decreasing poverty. But<br/>this is a situation where it would be good to be precise about what we want.<br/>Poverty and economic inequality are not identical. When the city is turning<br/>off your _water_ because you can't pay the bill, it doesn't make any<br/>difference what Larry Page's net worth is compared to yours. He might only be<br/>a few times richer than you, and it would still be just as much of a problem<br/>that your water was getting turned off.  <br/>  <br/>Closely related to poverty is lack of social mobility. I've seen this myself:<br/>you don't have to grow up rich or even upper middle class to get rich as a<br/>startup founder, but few successful founders grew up desperately poor. But<br/>again, the problem here is not simply economic inequality. There is an<br/>enormous difference in wealth between the household Larry Page grew up in and<br/>that of a successful startup founder, but that didn't prevent him from joining<br/>their ranks. It's not economic inequality per se that's blocking social<br/>mobility, but some specific combination of things that go wrong when kids grow<br/>up sufficiently poor.  <br/>  <br/>One of the most important principles in Silicon Valley is that "you make what<br/>you measure." It means that if you pick some number to focus on, it will tend<br/>to improve, but that you have to choose the right number, because only the one<br/>you choose will improve; another that seems conceptually adjacent might not.<br/>For example, if you're a university president and you decide to focus on<br/>graduation rates, then you'll improve graduation rates. But only graduation<br/>rates, not how much students learn. Students could learn less, if to improve<br/>graduation rates you made classes easier.  <br/>  <br/>Economic inequality is sufficiently far from identical with the various<br/>problems that have it as a symptom that we'll probably only hit whichever of<br/>the two we aim at. If we aim at economic inequality, we won't fix these<br/>problems. So I say let's aim at the problems.  <br/>  <br/>For example, let's attack poverty, and if necessary damage wealth in the<br/>process. That's much more likely to work than attacking wealth in the hope<br/>that you will thereby fix poverty. [9] And if there are people getting rich by<br/>tricking consumers or lobbying the government for anti-competitive regulations<br/>or tax loopholes, then let's stop them. Not because it's causing economic<br/>inequality, but because it's stealing. [10]  <br/>  <br/>If all you have is statistics, it seems like that's what you need to fix. But<br/>behind a broad statistical measure like economic inequality there are some<br/>things that are good and some that are bad, some that are historical trends<br/>with immense momentum and others that are random accidents. If we want to fix<br/>the world behind the statistics, we have to understand it, and focus our<br/>efforts where they'll do the most good.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Stiglitz, Joseph. _The Price of Inequality_. Norton, 2012. p. 32.  <br/>  <br/>[2] Particularly since economic inequality is a matter of outliers, and<br/>outliers are disproportionately likely to have gotten where they are by ways<br/>that have little do with the sort of things economists usually think about,<br/>like wages and productivity, but rather by, say, ending up on the wrong side<br/>of the "War on Drugs."  <br/>  <br/>[3] Determination is the most important factor in deciding between success and<br/>failure, which in startups tend to be sharply differentiated. But it takes<br/>more than determination to create one of the hugely successful startups.<br/>Though most founders start out excited about the idea of getting rich, purely<br/>mercenary founders will usually take one of the big acquisition offers most<br/>successful startups get on the way up. The founders who go on to the next<br/>stage tend to be driven by a sense of mission. They have the same attachment<br/>to their companies that an artist or writer has to their work. But it is very<br/>hard to predict at the outset which founders will do that. It's not simply a<br/>function of their initial attitude. Starting a company changes people.  <br/>  <br/>[4] After reading a draft of this essay, Richard Florida told me how he had<br/>once talked to a group of Europeans "who said they wanted to make Europe more<br/>entrepreneurial and more like Silicon Valley. I said by definition this will<br/>give you more inequality. They thought I was insane — they could not process<br/>it."  <br/>  <br/>[5] Economic inequality has been decreasing globally. But this is mainly due<br/>to the erosion of the kleptocracies that formerly dominated all the poorer<br/>countries. Once the playing field is leveler politically, we'll see economic<br/>inequality start to rise again. The US is the bellwether. The situation we<br/>face here, the rest of the world will sooner or later.  <br/>  <br/>[6] Some people still get rich by buying politicians. My point is that it's no<br/>longer a precondition.  <br/>  <br/>[7] As well as problems that have economic inequality as a symptom, there are<br/>those that have it as a cause. But in most if not all, economic inequality is<br/>not the primary cause. There is usually some injustice that is allowing<br/>economic inequality to turn into other forms of inequality, and that injustice<br/>is what we need to fix. For example, the police in the US treat the poor worse<br/>than the rich. But the solution is not to make people richer. It's to make the<br/>police treat people more equitably. Otherwise they'll continue to maltreat<br/>people who are weak in other ways.  <br/>  <br/>[8] Some who read this essay will say that I'm clueless or even being<br/>deliberately misleading by focusing so much on the richer end of economic<br/>inequality — that economic inequality is really about poverty. But that is<br/>exactly the point I'm making, though sloppier language than I'd use to make<br/>it. The real problem is poverty, not economic inequality. And if you conflate<br/>them you're aiming at the wrong target.  <br/>  <br/>Others will say I'm clueless or being misleading by focusing on people who get<br/>rich by creating wealth — that startups aren't the problem, but corrupt<br/>practices in finance, healthcare, and so on. Once again, that is exactly my<br/>point. The problem is not economic inequality, but those specific abuses.  <br/>  <br/>It's a strange task to write an essay about why something isn't the problem,<br/>but that's the situation you find yourself in when so many people mistakenly<br/>think it is.  <br/>  <br/>[9] Particularly since many causes of poverty are only partially driven by<br/>people trying to make money from them. For example, America's abnormally high<br/>incarceration rate is a major cause of poverty. But although _for-profit<br/>prison companies_ and _prison guard unions_ both spend a lot lobbying for<br/>harsh sentencing laws, they are not the original source of them.  <br/>  <br/>[10] Incidentally, tax loopholes are definitely not a product of some power<br/>shift due to recent increases in economic inequality. The golden age of<br/>economic equality in the mid 20th century was also the golden age of tax<br/>avoidance. Indeed, it was so widespread and so effective that I'm skeptical<br/>whether economic inequality was really so low then as we think. In a period<br/>when people are trying to hide wealth from the government, it will tend to be<br/>hidden from statistics too. One sign of the potential magnitude of the problem<br/>is the discrepancy between government receipts as a percentage of GDP, which<br/>have remained more or less constant during the entire period from the end of<br/>World War II to the present, and tax rates, which have varied dramatically.  <br/>  <br/>**Thanks** to Sam Altman, Tiffani Ashley Bell, Patrick Collison, Ron Conway,<br/>Richard Florida, Ben Horowitz, Jessica Livingston, Robert Morris, Tim<br/>O'Reilly, Max Roser, and Alexia Tsotsis for reading drafts of this.  <br/>  <br/> **Note:** This is a new version from which I removed a pair of metaphors that<br/>made a lot of people mad, essentially by macroexpanding them. If anyone wants<br/>to see the old version, I put it _here_.  <br/>  <br/>  <br/>  <br/> **Related:**  <br/>  <br/><br/>Economic Inequality: The Short Version  <br/><br/>A Reply to Ezra Klein  <br/><br/>A Reply to Russell Okung  <br/><br/>French Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>July 2010  <br/>  <br/>When we sold our startup in 1998 I suddenly got a lot of money. I now had to<br/>think about something I hadn't had to think about before: how not to lose it.<br/>I knew it was possible to go from rich to poor, just as it was possible to go<br/>from poor to rich. But while I'd spent a lot of the past several years<br/>studying the paths from poor to rich, I knew practically nothing about the<br/>paths from rich to poor. Now, in order to avoid them, I had to learn where<br/>they were.  <br/>  <br/>So I started to pay attention to how fortunes are lost. If you'd asked me as a<br/>kid how rich people became poor, I'd have said by spending all their money.<br/>That's how it happens in books and movies, because that's the colorful way to<br/>do it. But in fact the way most fortunes are lost is not through excessive<br/>expenditure, but through bad investments.  <br/>  <br/>It's hard to spend a fortune without noticing. Someone with ordinary tastes<br/>would find it hard to blow through more than a few tens of thousands of<br/>dollars without thinking "wow, I'm spending a lot of money." Whereas if you<br/>start trading derivatives, you can lose a million dollars (as much as you<br/>want, really) in the blink of an eye.  <br/>  <br/>In most people's minds, spending money on luxuries sets off alarms that making<br/>investments doesn't. Luxuries seem self-indulgent. And unless you got the<br/>money by inheriting it or winning a lottery, you've already been thoroughly<br/>trained that self-indulgence leads to trouble. Investing bypasses those<br/>alarms. You're not spending the money; you're just moving it from one asset to<br/>another. Which is why people trying to sell you expensive things say "it's an<br/>investment."  <br/>  <br/>The solution is to develop new alarms. This can be a tricky business, because<br/>while the alarms that prevent you from overspending are so basic that they may<br/>even be in our DNA, the ones that prevent you from making bad investments have<br/>to be learned, and are sometimes fairly counterintuitive.  <br/>  <br/>A few days ago I realized something surprising: the situation with time is<br/>much the same as with money. The most dangerous way to lose time is not to<br/>spend it having fun, but to spend it doing fake work. When you spend time<br/>having fun, you know you're being self-indulgent. Alarms start to go off<br/>fairly quickly. If I woke up one morning and sat down on the sofa and watched<br/>TV all day, I'd feel like something was terribly wrong. Just thinking about it<br/>makes me wince. I'd start to feel uncomfortable after sitting on a sofa<br/>watching TV for 2 hours, let alone a whole day.  <br/>  <br/>And yet I've definitely had days when I might as well have sat in front of a<br/>TV all day—days at the end of which, if I asked myself what I got done that<br/>day, the answer would have been: basically, nothing. I feel bad after these<br/>days too, but nothing like as bad as I'd feel if I spent the whole day on the<br/>sofa watching TV. If I spent a whole day watching TV I'd feel like I was<br/>descending into perdition. But the same alarms don't go off on the days when I<br/>get nothing done, because I'm doing stuff that seems, superficially, like real<br/>work. Dealing with email, for example. You do it sitting at a desk. It's not<br/>fun. So it must be work.  <br/>  <br/>With time, as with money, avoiding pleasure is no longer enough to protect<br/>you. It probably was enough to protect hunter-gatherers, and perhaps all pre-<br/>industrial societies. So nature and nurture combine to make us avoid self-<br/>indulgence. But the world has gotten more complicated: the most dangerous<br/>traps now are new behaviors that bypass our alarms about self-indulgence by<br/>mimicking more virtuous types. And the worst thing is, they're not even fun.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Thanks** to Sam Altman, Trevor Blackwell, Patrick Collison, Jessica<br/>Livingston, and Robert Morris for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>October 2010<br/><br/>_(I wrote this for Forbes, who asked me to write something about the qualities<br/>we look for in founders. In print they had to cut the last item because they<br/>didn't have room.)_  <br/>  <br/> **1\. Determination**  <br/>  <br/>This has turned out to be the most important quality in startup founders. We<br/>thought when we started Y Combinator that the most important quality would be<br/>intelligence. That's the myth in the Valley. And certainly you don't want<br/>founders to be stupid. But as long as you're over a certain threshold of<br/>intelligence, what matters most is determination. You're going to hit a lot of<br/>obstacles. You can't be the sort of person who gets demoralized easily.  <br/>  <br/>Bill Clerico and Rich Aberman of WePay are a good example. They're doing a<br/>finance startup, which means endless negotiations with big, bureaucratic<br/>companies. When you're starting a startup that depends on deals with big<br/>companies to exist, it often feels like they're trying to ignore you out of<br/>existence. But when Bill Clerico starts calling you, you may as well do what<br/>he asks, because he is not going away.  <br/>  <br/>**2\. Flexibility**  <br/>  <br/>You do not however want the sort of determination implied by phrases like<br/>"don't give up on your dreams." The world of startups is so unpredictable that<br/>you need to be able to modify your dreams on the fly. The best metaphor I've<br/>found for the combination of determination and flexibility you need is a<br/>running back. He's determined to get downfield, but at any given moment he may<br/>need to go sideways or even backwards to get there.  <br/>  <br/>The current record holder for flexibility may be Daniel Gross of Greplin. He<br/>applied to YC with some bad ecommerce idea. We told him we'd fund him if he<br/>did something else. He thought for a second, and said ok. He then went through<br/>two more ideas before settling on Greplin. He'd only been working on it for a<br/>couple days when he presented to investors at Demo Day, but he got a lot of<br/>interest. He always seems to land on his feet.  <br/>  <br/>**3\. Imagination**  <br/>  <br/>Intelligence does matter a lot of course. It seems like the type that matters<br/>most is imagination. It's not so important to be able to solve predefined<br/>problems quickly as to be able to come up with surprising new ideas. In the<br/>startup world, most good ideas seem bad initially. If they were obviously<br/>good, someone would already be doing them. So you need the kind of<br/>intelligence that produces ideas with just the right level of craziness.  <br/>  <br/>Airbnb is that kind of idea. In fact, when we funded Airbnb, we thought it was<br/>too crazy. We couldn't believe large numbers of people would want to stay in<br/>other people's places. We funded them because we liked the founders so much.<br/>As soon as we heard they'd been supporting themselves by selling Obama and<br/>McCain branded breakfast cereal, they were in. And it turned out the idea was<br/>on the right side of crazy after all.  <br/>  <br/>**4\. Naughtiness**  <br/>  <br/>Though the most successful founders are usually good people, they tend to have<br/>a piratical gleam in their eye. They're not Goody Two-Shoes type good.<br/>Morally, they care about getting the big questions right, but not about<br/>observing proprieties. That's why I'd use the word naughty rather than evil.<br/>They delight in breaking rules, but not rules that matter. This quality may be<br/>redundant though; it may be implied by imagination.  <br/>  <br/>Sam Altman of Loopt is one of the most successful alumni, so we asked him what<br/>question we could put on the Y Combinator application that would help us<br/>discover more people like him. He said to ask about a time when they'd hacked<br/>something to their advantage—hacked in the sense of beating the system, not<br/>breaking into computers. It has become one of the questions we pay most<br/>attention to when judging applications.  <br/>  <br/>**5\. Friendship**  <br/>  <br/>Empirically it seems to be hard to start a startup with just one founder. Most<br/>of the big successes have two or three. And the relationship between the<br/>founders has to be strong. They must genuinely like one another, and work well<br/>together. Startups do to the relationship between the founders what a dog does<br/>to a sock: if it can be pulled apart, it will be.  <br/>  <br/>Emmett Shear and Justin Kan of Justin.tv are a good example of close friends<br/>who work well together. They've known each other since second grade. They can<br/>practically read one another's minds. I'm sure they argue, like all founders,<br/>but I have never once sensed any unresolved tension between them.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Thanks** to Jessica Livingston and Chris Steiner for reading drafts of<br/>this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>November 2005  <br/>  <br/>Venture funding works like gears. A typical startup goes through several<br/>rounds of funding, and at each round you want to take just enough money to<br/>reach the speed where you can shift into the next gear.  <br/>  <br/>Few startups get it quite right. Many are underfunded. A few are overfunded,<br/>which is like trying to start driving in third gear.  <br/>  <br/>I think it would help founders to understand funding better—not just the<br/>mechanics of it, but what investors are thinking. I was surprised recently<br/>when I realized that all the worst problems we faced in our startup were due<br/>not to competitors, but investors. Dealing with competitors was easy by<br/>comparison.  <br/>  <br/>I don't mean to suggest that our investors were nothing but a drag on us. They<br/>were helpful in negotiating deals, for example. I mean more that conflicts<br/>with investors are particularly nasty. Competitors punch you in the jaw, but<br/>investors have you by the balls.  <br/>  <br/>Apparently our situation was not unusual. And if trouble with investors is one<br/>of the biggest threats to a startup, managing them is one of the most<br/>important skills founders need to learn.  <br/>  <br/>Let's start by talking about the five sources of startup funding. Then we'll<br/>trace the life of a hypothetical (very fortunate) startup as it shifts gears<br/>through successive rounds.  <br/>  <br/> **Friends and Family**  <br/>  <br/>A lot of startups get their first funding from friends and family. Excite did,<br/>for example: after the founders graduated from college, they borrowed $15,000<br/>from their parents to start a company. With the help of some part-time jobs<br/>they made it last 18 months.  <br/>  <br/>If your friends or family happen to be rich, the line blurs between them and<br/>angel investors. At Viaweb we got our first $10,000 of seed money from our<br/>friend Julian, but he was sufficiently rich that it's hard to say whether he<br/>should be classified as a friend or angel. He was also a lawyer, which was<br/>great, because it meant we didn't have to pay legal bills out of that initial<br/>small sum.  <br/>  <br/>The advantage of raising money from friends and family is that they're easy to<br/>find. You already know them. There are three main disadvantages: you mix<br/>together your business and personal life; they will probably not be as well<br/>connected as angels or venture firms; and they may not be accredited<br/>investors, which could complicate your life later.  <br/>  <br/>The SEC defines an "accredited investor" as someone with over a million<br/>dollars in liquid assets or an income of over $200,000 a year. The regulatory<br/>burden is much lower if a company's shareholders are all accredited investors.<br/>Once you take money from the general public you're more restricted in what you<br/>can do. [1]  <br/>  <br/>A startup's life will be more complicated, legally, if any of the investors<br/>aren't accredited. In an IPO, it might not merely add expense, but change the<br/>outcome. A lawyer I asked about it said:<br/><br/>> When the company goes public, the SEC will carefully study all prior<br/>> issuances of stock by the company and demand that it take immediate action<br/>> to cure any past violations of securities laws. Those remedial actions can<br/>> delay, stall or even kill the IPO.<br/><br/>Of course the odds of any given startup doing an IPO are small. But not as<br/>small as they might seem. A lot of startups that end up going public didn't<br/>seem likely to at first. (Who could have guessed that the company Wozniak and<br/>Jobs started in their spare time selling plans for microcomputers would yield<br/>one of the biggest IPOs of the decade?) Much of the value of a startup<br/>consists of that tiny probability multiplied by the huge outcome.  <br/>  <br/>It wasn't because they weren't accredited investors that I didn't ask my<br/>parents for seed money, though. When we were starting Viaweb, I didn't know<br/>about the concept of an accredited investor, and didn't stop to think about<br/>the value of investors' connections. The reason I didn't take money from my<br/>parents was that I didn't want them to lose it.  <br/>  <br/> **Consulting**  <br/>  <br/>Another way to fund a startup is to get a job. The best sort of job is a<br/>consulting project in which you can build whatever software you wanted to sell<br/>as a startup. Then you can gradually transform yourself from a consulting<br/>company into a product company, and have your clients pay your development<br/>expenses.  <br/>  <br/>This is a good plan for someone with kids, because it takes most of the risk<br/>out of starting a startup. There never has to be a time when you have no<br/>revenues. Risk and reward are usually proportionate, however: you should<br/>expect a plan that cuts the risk of starting a startup also to cut the average<br/>return. In this case, you trade decreased financial risk for increased risk<br/>that your company won't succeed as a startup.  <br/>  <br/>But isn't the consulting company itself a startup? No, not generally. A<br/>company has to be more than small and newly founded to be a startup. There are<br/>millions of small businesses in America, but only a few thousand are startups.<br/>To be a startup, a company has to be a product business, not a service<br/>business. By which I mean not that it has to make something physical, but that<br/>it has to have one thing it sells to many people, rather than doing custom<br/>work for individual clients. Custom work doesn't scale. To be a startup you<br/>need to be the band that sells a million copies of a song, not the band that<br/>makes money by playing at individual weddings and bar mitzvahs.  <br/>  <br/>The trouble with consulting is that clients have an awkward habit of calling<br/>you on the phone. Most startups operate close to the margin of failure, and<br/>the distraction of having to deal with clients could be enough to put you over<br/>the edge. Especially if you have competitors who get to work full time on just<br/>being a startup.  <br/>  <br/>So you have to be very disciplined if you take the consulting route. You have<br/>to work actively to prevent your company growing into a "weed tree," dependent<br/>on this source of easy but low-margin money. [2]  <br/>  <br/>Indeed, the biggest danger of consulting may be that it gives you an excuse<br/>for failure. In a startup, as in grad school, a lot of what ends up driving<br/>you are the expectations of your family and friends. Once you start a startup<br/>and tell everyone that's what you're doing, you're now on a path labelled "get<br/>rich or bust." You now have to get rich, or you've failed.  <br/>  <br/>Fear of failure is an extraordinarily powerful force. Usually it prevents<br/>people from starting things, but once you publish some definite ambition, it<br/>switches directions and starts working in your favor. I think it's a pretty<br/>clever piece of jiujitsu to set this irresistible force against the slightly<br/>less immovable object of becoming rich. You won't have it driving you if your<br/>stated ambition is merely to start a consulting company that you will one day<br/>morph into a startup.  <br/>  <br/>An advantage of consulting, as a way to develop a product, is that you know<br/>you're making something at least one customer wants. But if you have what it<br/>takes to start a startup you should have sufficient vision not to need this<br/>crutch.  <br/>  <br/> **Angel Investors**  <br/>  <br/> _Angels_ are individual rich people. The word was first used for backers of<br/>Broadway plays, but now applies to individual investors generally. Angels<br/>who've made money in technology are preferable, for two reasons: they<br/>understand your situation, and they're a source of contacts and advice.  <br/>  <br/>The contacts and advice can be more important than the money. When del.icio.us<br/>took money from investors, they took money from, among others, Tim O'Reilly.<br/>The amount he put in was small compared to the VCs who led the round, but Tim<br/>is a smart and influential guy and it's good to have him on your side.  <br/>  <br/>You can do whatever you want with money from consulting or friends and family.<br/>With angels we're now talking about venture funding proper, so it's time to<br/>introduce the concept of _exit strategy_. Younger would-be founders are often<br/>surprised that investors expect them either to sell the company or go public.<br/>The reason is that investors need to get their capital back. They'll only<br/>consider companies that have an exit strategy—meaning companies that could get<br/>bought or go public.  <br/>  <br/>This is not as selfish as it sounds. There are few large, private technology<br/>companies. Those that don't fail all seem to get bought or go public. The<br/>reason is that employees are investors too—of their time—and they want just as<br/>much to be able to cash out. If your competitors offer employees stock options<br/>that might make them rich, while you make it clear you plan to stay private,<br/>your competitors will get the best people. So the principle of an "exit" is<br/>not just something forced on startups by investors, but part of what it means<br/>to be a startup.  <br/>  <br/>Another concept we need to introduce now is valuation. When someone buys<br/>shares in a company, that implicitly establishes a value for it. If someone<br/>pays $20,000 for 10% of a company, the company is in theory worth $200,000. I<br/>say "in theory" because in early stage investing, valuations are voodoo. As a<br/>company gets more established, its valuation gets closer to an actual market<br/>value. But in a newly founded startup, the valuation number is just an<br/>artifact of the respective contributions of everyone involved.  <br/>  <br/>Startups often "pay" investors who will help the company in some way by<br/>letting them invest at low valuations. If I had a startup and Steve Jobs<br/>wanted to invest in it, I'd give him the stock for $10, just to be able to<br/>brag that he was an investor. Unfortunately, it's impractical (if not illegal)<br/>to adjust the valuation of the company up and down for each investor.<br/>Startups' valuations are supposed to rise over time. So if you're going to<br/>sell cheap stock to eminent angels, do it early, when it's natural for the<br/>company to have a low valuation.  <br/>  <br/>Some angel investors join together in syndicates. Any city where people start<br/>startups will have one or more of them. In Boston the biggest is the Common<br/>Angels. In the Bay Area it's the Band of Angels. You can find groups near you<br/>through the Angel Capital Association. [3] However, most angel investors don't<br/>belong to these groups. In fact, the more prominent the angel, the less likely<br/>they are to belong to a group.  <br/>  <br/>Some angel groups charge you money to pitch your idea to them. Needless to<br/>say, you should never do this.  <br/>  <br/>One of the dangers of taking investment from individual angels, rather than<br/>through an angel group or investment firm, is that they have less reputation<br/>to protect. A big-name VC firm will not screw you too outrageously, because<br/>other founders would avoid them if word got out. With individual angels you<br/>don't have this protection, as we found to our dismay in our own startup. In<br/>many startups' lives there comes a point when you're at the investors'<br/>mercy—when you're out of money and the only place to get more is your existing<br/>investors. When we got into such a scrape, our investors took advantage of it<br/>in a way that a name-brand VC probably wouldn't have.  <br/>  <br/>Angels have a corresponding advantage, however: they're also not bound by all<br/>the rules that VC firms are. And so they can, for example, allow founders to<br/>cash out partially in a funding round, by selling some of their stock directly<br/>to the investors. I think this will become more common; the average founder is<br/>eager to do it, and selling, say, half a million dollars worth of stock will<br/>not, as VCs fear, cause most founders to be any less committed to the<br/>business.  <br/>  <br/>The same angels who tried to screw us also let us do this, and so on balance<br/>I'm grateful rather than angry. (As in families, relations between founders<br/>and investors can be complicated.)  <br/>  <br/>The best way to find angel investors is through personal introductions. You<br/>could try to cold-call angel groups near you, but angels, like VCs, will pay<br/>more attention to deals recommended by someone they respect.  <br/>  <br/>Deal terms with angels vary a lot. There are no generally accepted standards.<br/>Sometimes angels' deal terms are as fearsome as VCs'. Other angels,<br/>particularly in the earliest stages, will invest based on a two-page<br/>agreement.  <br/>  <br/>Angels who only invest occasionally may not themselves know what terms they<br/>want. They just want to invest in this startup. What kind of anti-dilution<br/>protection do they want? Hell if they know. In these situations, the deal<br/>terms tend to be random: the angel asks his lawyer to create a vanilla<br/>agreement, and the terms end up being whatever the lawyer considers vanilla.<br/>Which in practice usually means, whatever existing agreement he finds lying<br/>around his firm. (Few legal documents are created from scratch.)  <br/>  <br/>These heaps o' boilerplate are a problem for small startups, because they tend<br/>to grow into the union of all preceding documents. I know of one startup that<br/>got from an angel investor what amounted to a five hundred pound handshake:<br/>after deciding to invest, the angel presented them with a 70-page agreement.<br/>The startup didn't have enough money to pay a lawyer even to read it, let<br/>alone negotiate the terms, so the deal fell through.  <br/>  <br/>One solution to this problem would be to have the startup's lawyer produce the<br/>agreement, instead of the angel's. Some angels might balk at this, but others<br/>would probably welcome it.  <br/>  <br/>Inexperienced angels often get cold feet when the time comes to write that big<br/>check. In our startup, one of the two angels in the initial round took months<br/>to pay us, and only did after repeated nagging from our lawyer, who was also,<br/>fortunately, his lawyer.  <br/>  <br/>It's obvious why investors delay. Investing in startups is risky! When a<br/>company is only two months old, every _day_ you wait gives you 1.7% more data<br/>about their trajectory. But the investor is already being compensated for that<br/>risk in the low price of the stock, so it is unfair to delay.  <br/>  <br/>Fair or not, investors do it if you let them. Even VCs do it. And funding<br/>delays are a big distraction for founders, who ought to be working on their<br/>company, not worrying about investors. What's a startup to do? With both<br/>investors and acquirers, the only leverage you have is competition. If an<br/>investor knows you have other investors lined up, he'll be a lot more eager to<br/>close-- and not just because he'll worry about losing the deal, but because if<br/>other investors are interested, you must be worth investing in. It's the same<br/>with acquisitions. No one wants to buy you till someone else wants to buy you,<br/>and then everyone wants to buy you.  <br/>  <br/>The key to closing deals is never to stop pursuing alternatives. When an<br/>investor says he wants to invest in you, or an acquirer says they want to buy<br/>you, _don't believe it till you get the check._ Your natural tendency when an<br/>investor says yes will be to relax and go back to writing code. Alas, you<br/>can't; you have to keep looking for more investors, if only to get this one to<br/>act. [4]  <br/>  <br/> **Seed Funding Firms**  <br/>  <br/>Seed firms are like angels in that they invest relatively small amounts at<br/>early stages, but like VCs in that they're companies that do it as a business,<br/>rather than individuals making occasional investments on the side.  <br/>  <br/>Till now, nearly all seed firms have been so-called "incubators," so Y<br/>Combinator gets called one too, though the only thing we have in common is<br/>that we invest in the earliest phase.  <br/>  <br/>According to the National Association of Business Incubators, there are about<br/>800 incubators in the US. This is an astounding number, because I know the<br/>founders of a lot of startups, and I can't think of one that began in an<br/>incubator.  <br/>  <br/>What is an incubator? I'm not sure myself. The defining quality seems to be<br/>that you work in their space. That's where the name "incubator" comes from.<br/>They seem to vary a great deal in other respects. At one extreme is the sort<br/>of pork-barrel project where a town gets money from the state government to<br/>renovate a vacant building as a "high-tech incubator," as if it were merely<br/>lack of the right sort of office space that had till now prevented the town<br/>from becoming a startup hub. At the other extreme are places like Idealab,<br/>which generates ideas for new startups internally and hires people to work for<br/>them.  <br/>  <br/>The classic Bubble incubators, most of which now seem to be dead, were like VC<br/>firms except that they took a much bigger role in the startups they funded. In<br/>addition to working in their space, you were supposed to use their office<br/>staff, lawyers, accountants, and so on.  <br/>  <br/>Whereas incubators tend (or tended) to exert more control than VCs, Y<br/>Combinator exerts less.  And we think it's better if startups operate out of<br/>their own premises, however crappy, than the offices of their investors. So<br/>it's annoying that we keep getting called an "incubator," but perhaps<br/>inevitable, because there's only one of us so far and no word yet for what we<br/>are. If we have to be called something, the obvious name would be "excubator."<br/>(The name is more excusable if one considers it as meaning that we enable<br/>people to escape cubicles.)  <br/>  <br/>Because seed firms are companies rather than individual people, reaching them<br/>is easier than reaching angels. Just go to their web site and send them an<br/>email. The importance of personal introductions varies, but is less than with<br/>angels or VCs.  <br/>  <br/>The fact that seed firms are companies also means the investment process is<br/>more standardized. (This is generally true with angel groups too.) Seed firms<br/>will probably have set deal terms they use for every startup they fund. The<br/>fact that the deal terms are standard doesn't mean they're favorable to you,<br/>but if other startups have signed the same agreements and things went well for<br/>them, it's a sign the terms are reasonable.  <br/>  <br/>Seed firms differ from angels and VCs in that they invest exclusively in the<br/>earliest phases—often when the company is still just an idea. Angels and even<br/>VC firms occasionally do this, but they also invest at later stages.  <br/>  <br/>The problems are different in the early stages. For example, in the first<br/>couple months a startup may completely redefine their idea. So seed investors<br/>usually care less about the idea than the people. This is true of all venture<br/>funding, but especially so in the seed stage.  <br/>  <br/>Like VCs, one of the advantages of seed firms is the advice they offer. But<br/>because seed firms operate in an earlier phase, they need to offer different<br/>kinds of advice. For example, a seed firm should be able to give advice about<br/>how to approach VCs, which VCs obviously don't need to do; whereas VCs should<br/>be able to give advice about how to hire an "executive team," which is not an<br/>issue in the seed stage.  <br/>  <br/>In the earliest phases, a lot of the problems are technical, so seed firms<br/>should be able to help with technical as well as business problems.  <br/>  <br/>Seed firms and angel investors generally want to invest in the initial phases<br/>of a startup, then hand them off to VC firms for the next round. Occasionally<br/>startups go from seed funding direct to acquisition, however, and I expect<br/>this to become increasingly common.  <br/>  <br/>Google has been aggressively pursuing this route, and now Yahoo is too. Both<br/>now compete directly with VCs. And this is a smart move. Why wait for further<br/>funding rounds to jack up a startup's price? When a startup reaches the point<br/>where VCs have enough information to invest in it, the acquirer should have<br/>enough information to buy it. More information, in fact; with their technical<br/>depth, the acquirers should be better at picking winners than VCs.  <br/>  <br/> **Venture Capital Funds**  <br/>  <br/>VC firms are like seed firms in that they're actual companies, but they invest<br/>other people's money, and much larger amounts of it. VC investments average<br/>several million dollars. So they tend to come later in the life of a startup,<br/>are harder to get, and come with tougher terms.  <br/>  <br/>The word "venture capitalist" is sometimes used loosely for any venture<br/>investor, but there is a sharp difference between VCs and other investors: VC<br/>firms are organized as _funds_ , much like hedge funds or mutual funds. The<br/>fund managers, who are called "general partners," get about 2% of the fund<br/>annually as a management fee, plus about 20% of the fund's gains.  <br/>  <br/>There is a very sharp dropoff in performance among VC firms, because in the VC<br/>business both success and failure are self-perpetuating. When an investment<br/>scores spectacularly, as Google did for Kleiner and Sequoia, it generates a<br/>lot of good publicity for the VCs. And many founders prefer to take money from<br/>successful VC firms, because of the legitimacy it confers. Hence a vicious<br/>(for the losers) cycle: VC firms that have been doing badly will only get the<br/>deals the bigger fish have rejected, causing them to continue to do badly.  <br/>  <br/>As a result, of the thousand or so VC funds in the US now, only about 50 are<br/>likely to make money, and it is very hard for a new fund to break into this<br/>group.  <br/>  <br/>In a sense, the lower-tier VC firms are a bargain for founders. They may not<br/>be quite as smart or as well connected as the big-name firms, but they are<br/>much hungrier for deals. This means you should be able to get better terms<br/>from them.  <br/>  <br/>Better how? The most obvious is valuation: they'll take less of your company.<br/>But as well as money, there's power. I think founders will increasingly be<br/>able to stay on as CEO, and on terms that will make it fairly hard to fire<br/>them later.  <br/>  <br/>The most dramatic change, I predict, is that VCs will allow founders to cash<br/>out partially by selling some of their stock direct to the VC firm. VCs have<br/>traditionally resisted letting founders get anything before the ultimate<br/>"liquidity event." But they're also desperate for deals. And since I know from<br/>my own experience that the rule against buying stock from founders is a stupid<br/>one, this is a natural place for things to give as venture funding becomes<br/>more and more a seller's market.  <br/>  <br/>The disadvantage of taking money from less known firms is that people will<br/>assume, correctly or not, that you were turned down by the more exalted ones.<br/>But, like where you went to college, the name of your VC stops mattering once<br/>you have some performance to measure. So the more confident you are, the less<br/>you need a brand-name VC. We funded Viaweb entirely with angel money; it never<br/>occurred to us that the backing of a well known VC firm would make us seem<br/>more impressive. [5]  <br/>  <br/>Another danger of less known firms is that, like angels, they have less<br/>reputation to protect. I suspect it's the lower-tier firms that are<br/>responsible for most of the tricks that have given VCs such a bad reputation<br/>among hackers. They are doubly hosed: the general partners themselves are less<br/>able, and yet they have harder problems to solve, because the top VCs skim off<br/>all the best deals, leaving the lower-tier firms exactly the startups that are<br/>likely to blow up.  <br/>  <br/>For example, lower-tier firms are much more likely to pretend to want to do a<br/>deal with you just to lock you up while they decide if they really want to.<br/>One experienced CFO said:<br/><br/>> The better ones usually will not give a term sheet unless they really want<br/>> to do a deal. The second or third tier firms have a much higher break<br/>> rate—it could be as high as 50%.<br/><br/>It's obvious why: the lower-tier firms' biggest fear, when chance throws them<br/>a bone, is that one of the big dogs will notice and take it away. The big dogs<br/>don't have to worry about that.  <br/>  <br/>Falling victim to this trick could really hurt you. As one VC told me:<br/><br/>> If you were talking to four VCs, told three of them that you accepted a term<br/>> sheet, and then have to call them back to tell them you were just kidding,<br/>> you are absolutely damaged goods.<br/><br/>Here's a partial solution: when a VC offers you a term sheet, ask how many of<br/>their last 10 term sheets turned into deals. This will at least force them to<br/>lie outright if they want to mislead you.  <br/>  <br/>Not all the people who work at VC firms are partners. Most firms also have a<br/>handful of junior employees called something like associates or analysts. If<br/>you get a call from a VC firm, go to their web site and check whether the<br/>person you talked to is a partner. Odds are it will be a junior person; they<br/>scour the web looking for startups their bosses could invest in. The junior<br/>people will tend to seem very positive about your company. They're not<br/>pretending; they _want_ to believe you're a hot prospect, because it would be<br/>a huge coup for them if their firm invested in a company they discovered.<br/>Don't be misled by this optimism. It's the partners who decide, and they view<br/>things with a colder eye.  <br/>  <br/>Because VCs invest large amounts, the money comes with more restrictions. Most<br/>only come into effect if the company gets into trouble. For example, VCs<br/>generally write it into the deal that in any sale, they get their investment<br/>back first. So if the company gets sold at a low price, the founders could get<br/>nothing. Some VCs now require that in any sale they get 4x their investment<br/>back before the common stock holders (that is, you) get anything, but this is<br/>an abuse that should be resisted.  <br/>  <br/>Another difference with large investments is that the founders are usually<br/>required to accept "vesting"—to surrender their stock and earn it back over<br/>the next 4-5 years. VCs don't want to invest millions in a company the<br/>founders could just walk away from. Financially, vesting has little effect,<br/>but in some situations it could mean founders will have less power. If VCs got<br/>de facto control of the company and fired one of the founders, he'd lose any<br/>unvested stock unless there was specific protection against this. So vesting<br/>would in that situation force founders to toe the line.  <br/>  <br/>The most noticeable change when a startup takes serious funding is that the<br/>founders will no longer have complete control. Ten years ago VCs used to<br/>insist that founders step down as CEO and hand the job over to a business guy<br/>they supplied. This is less the rule now, partly because the disasters of the<br/>Bubble showed that generic business guys don't make such great CEOs.  <br/>  <br/>But while founders will increasingly be able to stay on as CEO, they'll have<br/>to cede some power, because the board of directors will become more powerful.<br/>In the seed stage, the board is generally a formality; if you want to talk to<br/>the other board members, you just yell into the next room. This stops with VC-<br/>scale money. In a typical VC funding deal, the board of directors might be<br/>composed of two VCs, two founders, and one outside person acceptable to both.<br/>The board will have ultimate power, which means the founders now have to<br/>convince instead of commanding.  <br/>  <br/>This is not as bad as it sounds, however. Bill Gates is in the same position;<br/>he doesn't have majority control of Microsoft; in principle he also has to<br/>convince instead of commanding. And yet he seems pretty commanding, doesn't<br/>he? As long as things are going smoothly, boards don't interfere much. The<br/>danger comes when there's a bump in the road, as happened to Steve Jobs at<br/>Apple.  <br/>  <br/>Like angels, VCs prefer to invest in deals that come to them through people<br/>they know. So while nearly all VC funds have some address you can send your<br/>business plan to, VCs privately admit the chance of getting funding by this<br/>route is near zero. One recently told me that he did not know a single startup<br/>that got funded this way.  <br/>  <br/>I suspect VCs accept business plans "over the transom" more as a way to keep<br/>tabs on industry trends than as a source of deals. In fact, I would strongly<br/>advise against mailing your business plan randomly to VCs, because they treat<br/>this as evidence of laziness. Do the extra work of getting personal<br/>introductions. As one VC put it:<br/><br/>> I'm not hard to find. I know a lot of people. If you can't find some way to<br/>> reach me, how are you going to create a successful company?<br/><br/>One of the most difficult problems for startup founders is deciding when to<br/>approach VCs. You really only get one chance, because they rely heavily on<br/>first impressions. And you can't approach some and save others for later,<br/>because (a) they ask who else you've talked to and when and (b) they talk<br/>among themselves. If you're talking to one VC and he finds out that you were<br/>rejected by another several months ago, you'll definitely seem shopworn.  <br/>  <br/>So when do you approach VCs? When you can convince them. If the founders have<br/>impressive resumes and the idea isn't hard to understand, you could approach<br/>VCs quite early. Whereas if the founders are unknown and the idea is very<br/>novel, you might have to launch the thing and show that users loved it before<br/>VCs would be convinced.  <br/>  <br/>If several VCs are interested in you, they will sometimes be willing to split<br/>the deal between them. They're more likely to do this if they're close in the<br/>VC pecking order. Such deals may be a net win for founders, because you get<br/>multiple VCs interested in your success, and you can ask each for advice about<br/>the other. One founder I know wrote:<br/><br/>> Two-firm deals are great. It costs you a little more equity, but being able<br/>> to play the two firms off each other (as well as ask one if the other is<br/>> being out of line) is invaluable.<br/><br/>When you do negotiate with VCs, remember that they've done this a lot more<br/>than you have. They've invested in dozens of startups, whereas this is<br/>probably the first you've founded. But don't let them or the situation<br/>intimidate you. The average founder is smarter than the average VC. So just do<br/>what you'd do in any complex, unfamiliar situation: proceed deliberately, and<br/>question anything that seems odd.  <br/>  <br/>It is, unfortunately, common for VCs to put terms in an agreement whose<br/>consequences surprise founders later, and also common for VCs to defend things<br/>they do by saying that they're standard in the industry. Standard, schmandard;<br/>the whole industry is only a few decades old, and rapidly evolving. The<br/>concept of "standard" is a useful one when you're operating on a small scale<br/>(Y Combinator uses identical terms for every deal because for tiny seed-stage<br/>investments it's not worth the overhead of negotiating individual deals), but<br/>it doesn't apply at the VC level. On that scale, every negotiation is unique.  <br/>  <br/>Most successful startups get money from more than one of the preceding five<br/>sources. [6] And, confusingly, the names of funding sources also tend to be<br/>used as the names of different rounds. The best way to explain how it all<br/>works is to follow the case of a hypothetical startup.  <br/>  <br/> **Stage 1: Seed Round**  <br/>  <br/>Our startup begins when a group of three friends have an idea-- either an idea<br/>for something they might build, or simply the idea "let's start a company."<br/>Presumably they already have some source of food and shelter. But if you have<br/>food and shelter, you probably also have something you're supposed to be<br/>working on: either classwork, or a job. So if you want to work full-time on a<br/>startup, your money situation will probably change too.  <br/>  <br/>A lot of startup founders say they started the company without any idea of<br/>what they planned to do. This is actually less common than it seems: many have<br/>to claim they thought of the idea after quitting because otherwise their<br/>former employer would own it.  <br/>  <br/>The three friends decide to take the leap. Since most startups are in<br/>competitive businesses, you not only want to work full-time on them, but more<br/>than full-time. So some or all of the friends quit their jobs or leave school.<br/>(Some of the founders in a startup can stay in grad school, but at least one<br/>has to make the company his full-time job.)  <br/>  <br/>They're going to run the company out of one of their apartments at first, and<br/>since they don't have any users they don't have to pay much for<br/>infrastructure. Their main expenses are setting up the company, which costs a<br/>couple thousand dollars in legal work and registration fees, and the living<br/>expenses of the founders.  <br/>  <br/>The phrase "seed investment" covers a broad range. To some VC firms it means<br/>$500,000, but to most startups it means several months' living expenses. We'll<br/>suppose our group of friends start with $15,000 from their friend's rich<br/>uncle, who they give 5% of the company in return. There's only common stock at<br/>this stage. They leave 20% as an options pool for later employees (but they<br/>set things up so that they can issue this stock to themselves if they get<br/>bought early and most is still unissued), and the three founders each get 25%.  <br/>  <br/>By living really cheaply they think they can make the remaining money last<br/>five months. When you have five months' runway left, how soon do you need to<br/>start looking for your next round? Answer: immediately. It takes time to find<br/>investors, and time (always more than you expect) for the deal to close even<br/>after they say yes. So if our group of founders know what they're doing<br/>they'll start sniffing around for angel investors right away. But of course<br/>their main job is to build version 1 of their software.  <br/>  <br/>The friends might have liked to have more money in this first phase, but being<br/>slightly underfunded teaches them an important lesson. For a startup,<br/>cheapness is power. The lower your costs, the more options you have—not just<br/>at this stage, but at every point till you're profitable. When you have a high<br/>"burn rate," you're always under time pressure, which means (a) you don't have<br/>time for your ideas to evolve, and (b) you're often forced to take deals you<br/>don't like.  <br/>  <br/>Every startup's rule should be: spend little, and work fast.  <br/>  <br/>After ten weeks' work the three friends have built a prototype that gives one<br/>a taste of what their product will do. It's not what they originally set out<br/>to do—in the process of writing it, they had some new ideas. And it only does<br/>a fraction of what the finished product will do, but that fraction includes<br/>stuff that no one else has done before.  <br/>  <br/>They've also written at least a skeleton business plan, addressing the five<br/>fundamental questions: what they're going to do, why users need it, how large<br/>the market is, how they'll make money, and who the competitors are and why<br/>this company is going to beat them. (That last has to be more specific than<br/>"they suck" or "we'll work really hard.")  <br/>  <br/>If you have to choose between spending time on the demo or the business plan,<br/>spend most on the demo. Software is not only more convincing, but a better way<br/>to explore ideas.  <br/>  <br/> **Stage 2: Angel Round**  <br/>  <br/>While writing the prototype, the group has been traversing their network of<br/>friends in search of angel investors. They find some just as the prototype is<br/>demoable. When they demo it, one of the angels is willing to invest. Now the<br/>group is looking for more money: they want enough to last for a year, and<br/>maybe to hire a couple friends. So they're going to raise $200,000.  <br/>  <br/>The angel agrees to invest at a pre-money valuation of $1 million. The company<br/>issues $200,000 worth of new shares to the angel; if there were 1000 shares<br/>before the deal, this means 200 additional shares. The angel now owns 200/1200<br/>shares, or a sixth of the company, and all the previous shareholders'<br/>percentage ownership is diluted by a sixth. After the deal, the capitalization<br/>table looks like this:  shareholder shares percent<br/>\------------------------------- angel 200 16.7 uncle 50 4.2 each founder 250<br/>20.8 option pool 200 16.7 \---- ----- total 1200 100  To keep things simple, I<br/>had the angel do a straight cash for stock deal. In reality the angel might be<br/>more likely to make the investment in the form of a convertible loan. A<br/>convertible loan is a loan that can be converted into stock later; it works<br/>out the same as a stock purchase in the end, but gives the angel more<br/>protection against being squashed by VCs in future rounds.  <br/>  <br/>Who pays the legal bills for this deal? The startup, remember, only has a<br/>couple thousand left. In practice this turns out to be a sticky problem that<br/>usually gets solved in some improvised way. Maybe the startup can find lawyers<br/>who will do it cheaply in the hope of future work if the startup succeeds.<br/>Maybe someone has a lawyer friend. Maybe the angel pays for his lawyer to<br/>represent both sides. (Make sure if you take the latter route that the lawyer<br/>is _representing_ you rather than merely advising you, or his only duty is to<br/>the investor.)  <br/>  <br/>An angel investing $200k would probably expect a seat on the board of<br/>directors. He might also want preferred stock, meaning a special class of<br/>stock that has some additional rights over the common stock everyone else has.<br/>Typically these rights include vetoes over major strategic decisions,<br/>protection against being diluted in future rounds, and the right to get one's<br/>investment back first if the company is sold.  <br/>  <br/>Some investors might expect the founders to accept vesting for a sum this<br/>size, and others wouldn't. VCs are more likely to require vesting than angels.<br/>At Viaweb we managed to raise $2.5 million from angels without ever accepting<br/>vesting, largely because we were so inexperienced that we were appalled at the<br/>idea. In practice this turned out to be good, because it made us harder to<br/>push around.  <br/>  <br/>Our experience was unusual; vesting is the norm for amounts that size. Y<br/>Combinator doesn't require vesting, because (a) we invest such small amounts,<br/>and (b) we think it's unnecessary, and that the hope of getting rich is enough<br/>motivation to keep founders at work. But maybe if we were investing millions<br/>we would think differently.  <br/>  <br/>I should add that vesting is also a way for founders to protect themselves<br/>against one another. It solves the problem of what to do if one of the<br/>founders quits. So some founders impose it on themselves when they start the<br/>company.  <br/>  <br/>The angel deal takes two weeks to close, so we are now three months into the<br/>life of the company.  <br/>  <br/>The point after you get the first big chunk of angel money will usually be the<br/>happiest phase in a startup's life. It's a lot like being a postdoc: you have<br/>no immediate financial worries, and few responsibilities. You get to work on<br/>juicy kinds of work, like designing software. You don't have to spend time on<br/>bureaucratic stuff, because you haven't hired any bureaucrats yet. Enjoy it<br/>while it lasts, and get as much done as you can, because you will never again<br/>be so productive.  <br/>  <br/>With an apparently inexhaustible sum of money sitting safely in the bank, the<br/>founders happily set to work turning their prototype into something they can<br/>release. They hire one of their friends—at first just as a consultant, so they<br/>can try him out—and then a month later as employee #1. They pay him the<br/>smallest salary he can live on, plus 3% of the company in restricted stock,<br/>vesting over four years. (So after this the option pool is down to 13.7%). [7]<br/>They also spend a little money on a freelance graphic designer.  <br/>  <br/>How much stock do you give early employees? That varies so much that there's<br/>no conventional number. If you get someone really good, really early, it might<br/>be wise to give him as much stock as the founders. The one universal rule is<br/>that the amount of stock an employee gets decreases polynomially with the age<br/>of the company. In other words, you get rich as a power of how early you were.<br/>So if some friends want you to come work for their startup, don't wait several<br/>months before deciding.  <br/>  <br/>A month later, at the end of month four, our group of founders have something<br/>they can launch. Gradually through word of mouth they start to get users.<br/>Seeing the system in use by real users—people they don't know—gives them lots<br/>of new ideas. Also they find they now worry obsessively about the status of<br/>their server. (How relaxing founders' lives must have been when startups wrote<br/>VisiCalc.)  <br/>  <br/>By the end of month six, the system is starting to have a solid core of<br/>features, and a small but devoted following. People start to write about it,<br/>and the founders are starting to feel like experts in their field.  <br/>  <br/>We'll assume that their startup is one that could put millions more to use.<br/>Perhaps they need to spend a lot on marketing, or build some kind of expensive<br/>infrastructure, or hire highly paid salesmen. So they decide to start talking<br/>to VCs. They get introductions to VCs from various sources: their angel<br/>investor connects them with a couple; they meet a few at conferences; a couple<br/>VCs call them after reading about them.  <br/>  <br/> **Step 3: Series A Round**  <br/>  <br/>Armed with their now somewhat fleshed-out business plan and able to demo a<br/>real, working system, the founders visit the VCs they have introductions to.<br/>They find the VCs intimidating and inscrutable. They all ask the same<br/>question: who else have you pitched to? (VCs are like high school girls:<br/>they're acutely aware of their position in the VC pecking order, and their<br/>interest in a company is a function of the interest other VCs show in it.)  <br/>  <br/>One of the VC firms says they want to invest and offers the founders a term<br/>sheet. A term sheet is a summary of what the deal terms will be when and if<br/>they do a deal; lawyers will fill in the details later. By accepting the term<br/>sheet, the startup agrees to turn away other VCs for some set amount of time<br/>while this firm does the "due diligence" required for the deal. Due diligence<br/>is the corporate equivalent of a background check: the purpose is to uncover<br/>any hidden bombs that might sink the company later, like serious design flaws<br/>in the product, pending lawsuits against the company, intellectual property<br/>issues, and so on. VCs' legal and financial due diligence is pretty thorough,<br/>but the technical due diligence is generally a joke. [8]  <br/>  <br/>The due diligence discloses no ticking bombs, and six weeks later they go<br/>ahead with the deal. Here are the terms: a $2 million investment at a pre-<br/>money valuation of $4 million, meaning that after the deal closes the VCs will<br/>own a third of the company (2 / (4 + 2)). The VCs also insist that prior to<br/>the deal the option pool be enlarged by an additional hundred shares. So the<br/>total number of new shares issued is 750, and the cap table becomes:<br/>shareholder shares percent \------------------------------- VCs 650 33.3 angel<br/>200 10.3 uncle 50 2.6 each founder 250 12.8 employee 36* 1.8 *unvested option<br/>pool 264 13.5 \---- ----- total 1950 100  This picture is unrealistic in<br/>several respects. For example, while the percentages might end up looking like<br/>this, it's unlikely that the VCs would keep the existing numbers of shares. In<br/>fact, every bit of the startup's paperwork would probably be replaced, as if<br/>the company were being founded anew. Also, the money might come in several<br/>tranches, the later ones subject to various conditions—though this is<br/>apparently more common in deals with lower-tier VCs (whose lot in life is to<br/>fund more dubious startups) than with the top firms.  <br/>  <br/>And of course any VCs reading this are probably rolling on the floor laughing<br/>at how my hypothetical VCs let the angel keep his 10.3 of the company. I<br/>admit, this is the Bambi version; in simplifying the picture, I've also made<br/>everyone nicer. In the real world, VCs regard angels the way a jealous husband<br/>feels about his wife's previous boyfriends. To them the company didn't exist<br/>before they invested in it. [9]  <br/>  <br/>I don't want to give the impression you have to do an angel round before going<br/>to VCs. In this example I stretched things out to show multiple sources of<br/>funding in action. Some startups could go directly from seed funding to a VC<br/>round; several of the companies we've funded have.  <br/>  <br/>The founders are required to vest their shares over four years, and the board<br/>is now reconstituted to consist of two VCs, two founders, and a fifth person<br/>acceptable to both. The angel investor cheerfully surrenders his board seat.  <br/>  <br/>At this point there is nothing new our startup can teach us about funding—or<br/>at least, nothing good. [10] The startup will almost certainly hire more<br/>people at this point; those millions must be put to work, after all. The<br/>company may do additional funding rounds, presumably at higher valuations.<br/>They may if they are extraordinarily fortunate do an IPO, which we should<br/>remember is also in principle a round of funding, regardless of its de facto<br/>purpose. But that, if not beyond the bounds of possibility, is beyond the<br/>scope of this article.  <br/>  <br/> **Deals Fall Through**  <br/>  <br/>Anyone who's been through a startup will find the preceding portrait to be<br/>missing something: disasters. If there's one thing all startups have in<br/>common, it's that something is always going wrong. And nowhere more than in<br/>matters of funding.  <br/>  <br/>For example, our hypothetical startup never spent more than half of one round<br/>before securing the next. That's more ideal than typical. Many startups—even<br/>successful ones—come close to running out of money at some point. Terrible<br/>things happen to startups when they run out of money, because they're designed<br/>for growth, not adversity.  <br/>  <br/>But the most unrealistic thing about the series of deals I've described is<br/>that they all closed. In the startup world, closing is not what deals do. What<br/>deals do is fall through. If you're starting a startup you would do well to<br/>remember that. Birds fly; fish swim; deals fall through.  <br/>  <br/>Why? Partly the reason deals seem to fall through so often is that you lie to<br/>yourself. You want the deal to close, so you start to believe it will. But<br/>even correcting for this, startup deals fall through alarmingly often—far more<br/>often than, say, deals to buy real estate. The reason is that it's such a<br/>risky environment. People about to fund or acquire a startup are prone to<br/>wicked cases of buyer's remorse. They don't really grasp the risk they're<br/>taking till the deal's about to close. And then they panic. And not just<br/>inexperienced angel investors, but big companies too.  <br/>  <br/>So if you're a startup founder wondering why some angel investor isn't<br/>returning your phone calls, you can at least take comfort in the thought that<br/>the same thing is happening to other deals a hundred times the size.  <br/>  <br/>The example of a startup's history that I've presented is like a<br/>skeleton—accurate so far as it goes, but needing to be fleshed out to be a<br/>complete picture. To get a complete picture, just add in every possible<br/>disaster.  <br/>  <br/>A frightening prospect? In a way. And yet also in a way encouraging. The very<br/>uncertainty of startups frightens away almost everyone. People overvalue<br/>stability—especially young people, who ironically need it least. And so in<br/>starting a startup, as in any really bold undertaking, merely deciding to do<br/>it gets you halfway there. On the day of the race, most of the other runners<br/>won't show up.  <br/>  <br/>  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>May 2008  <br/>  <br/>Adults lie constantly to kids. I'm not saying we should stop, but I think we<br/>should at least examine which lies we tell and why.  <br/>  <br/>There may also be a benefit to us. We were all lied to as kids, and some of<br/>the lies we were told still affect us. So by studying the ways adults lie to<br/>kids, we may be able to clear our heads of lies we were told.  <br/>  <br/>I'm using the word "lie" in a very general sense: not just overt falsehoods,<br/>but also all the more subtle ways we mislead kids. Though "lie" has negative<br/>connotations, I don't mean to suggest we should never do this—just that we<br/>should pay attention when we do. [1]  <br/>  <br/>One of the most remarkable things about the way we lie to kids is how broad<br/>the conspiracy is. All adults know what their culture lies to kids about:<br/>they're the questions you answer "Ask your parents." If a kid asked who won<br/>the World Series in 1982 or what the atomic weight of carbon was, you could<br/>just tell him. But if a kid asks you "Is there a God?" or "What's a<br/>prostitute?" you'll probably say "Ask your parents."  <br/>  <br/>Since we all agree, kids see few cracks in the view of the world presented to<br/>them. The biggest disagreements are between parents and schools, but even<br/>those are small. Schools are careful what they say about controversial topics,<br/>and if they do contradict what parents want their kids to believe, parents<br/>either pressure the school into keeping quiet or move their kids to a new<br/>school.  <br/>  <br/>The conspiracy is so thorough that most kids who discover it do so only by<br/>discovering internal contradictions in what they're told. It can be traumatic<br/>for the ones who wake up during the operation. Here's what happened to<br/>Einstein:<br/><br/>> Through the reading of popular scientific books I soon reached the<br/>> conviction that much in the stories of the Bible could not be true. The<br/>> consequence was a positively fanatic freethinking coupled with the<br/>> impression that youth is intentionally being deceived by the state through<br/>> lies: it was a crushing impression. [2]<br/><br/>I remember that feeling. By 15 I was convinced the world was corrupt from end<br/>to end. That's why movies like _The Matrix_ have such resonance. Every kid<br/>grows up in a fake world. In a way it would be easier if the forces behind it<br/>were as clearly differentiated as a bunch of evil machines, and one could make<br/>a clean break just by taking a pill.  <br/>  <br/>**Protection**  <br/>  <br/>If you ask adults why they lie to kids, the most common reason they give is to<br/>protect them. And kids do need protecting. The environment you want to create<br/>for a newborn child will be quite unlike the streets of a big city.  <br/>  <br/>That seems so obvious it seems wrong to call it a lie. It's certainly not a<br/>bad lie to tell, to give a baby the impression the world is quiet and warm and<br/>safe. But this harmless type of lie can turn sour if left unexamined.  <br/>  <br/>Imagine if you tried to keep someone in as protected an environment as a<br/>newborn till age 18. To mislead someone so grossly about the world would seem<br/>not protection but abuse. That's an extreme example, of course; when parents<br/>do that sort of thing it becomes national news. But you see the same problem<br/>on a smaller scale in the malaise teenagers feel in suburbia.  <br/>  <br/>The main purpose of suburbia is to provide a protected environment for<br/>children to grow up in. And it seems great for 10 year olds. I liked living in<br/>suburbia when I was 10. I didn't notice how sterile it was. My whole world was<br/>no bigger than a few friends' houses I bicycled to and some woods I ran around<br/>in. On a log scale I was midway between crib and globe. A suburban street was<br/>just the right size. But as I grew older, suburbia started to feel<br/>suffocatingly fake.  <br/>  <br/>Life can be pretty good at 10 or 20, but it's often frustrating at 15\. This<br/>is too big a problem to solve here, but certainly one reason life sucks at 15<br/>is that kids are trapped in a world designed for 10 year olds.  <br/>  <br/>What do parents hope to protect their children from by raising them in<br/>suburbia? A friend who moved out of Manhattan said merely that her 3 year old<br/>daughter "saw too much." Off the top of my head, that might include: people<br/>who are high or drunk, poverty, madness, gruesome medical conditions, sexual<br/>behavior of various degrees of oddness, and violent anger.  <br/>  <br/>I think it's the anger that would worry me most if I had a 3 year old. I was<br/>29 when I moved to New York and I was surprised even then. I wouldn't want a 3<br/>year old to see some of the disputes I saw. It would be too frightening. A lot<br/>of the things adults conceal from smaller children, they conceal because<br/>they'd be frightening, not because they want to conceal the existence of such<br/>things. Misleading the child is just a byproduct.  <br/>  <br/>This seems one of the most justifiable types of lying adults do to kids. But<br/>because the lies are indirect we don't keep a very strict accounting of them.<br/>Parents know they've concealed the facts about sex, and many at some point sit<br/>their kids down and explain more. But few tell their kids about the<br/>differences between the real world and the cocoon they grew up in. Combine<br/>this with the confidence parents try to instill in their kids, and every year<br/>you get a new crop of 18 year olds who think they know how to run the world.  <br/>  <br/>Don't all 18 year olds think they know how to run the world? Actually this<br/>seems to be a recent innovation, no more than about 100 years old. In<br/>preindustrial times teenage kids were junior members of the adult world and<br/>comparatively well aware of their shortcomings. They could see they weren't as<br/>strong or skillful as the village smith. In past times people lied to kids<br/>about some things more than we do now, but the lies implicit in an artificial,<br/>protected environment are a recent invention. Like a lot of new inventions,<br/>the rich got this first. Children of kings and great magnates were the first<br/>to grow up out of touch with the world. Suburbia means half the population can<br/>live like kings in that respect.  <br/>  <br/>**Sex (and Drugs)**  <br/>  <br/>I'd have different worries about raising teenage kids in New York. I'd worry<br/>less about what they'd see, and more about what they'd do. I went to college<br/>with a lot of kids who grew up in Manhattan, and as a rule they seemed pretty<br/>jaded. They seemed to have lost their virginity at an average of about 14 and<br/>by college had tried more drugs than I'd even heard of.  <br/>  <br/>The reasons parents don't want their teenage kids having sex are complex.<br/>There are some obvious dangers: pregnancy and sexually transmitted diseases.<br/>But those aren't the only reasons parents don't want their kids having sex.<br/>The average parents of a 14 year old girl would hate the idea of her having<br/>sex even if there were zero risk of pregnancy or sexually transmitted<br/>diseases.  <br/>  <br/>Kids can probably sense they aren't being told the whole story. After all,<br/>pregnancy and sexually transmitted diseases are just as much a problem for<br/>adults, and they have sex.  <br/>  <br/>What really bothers parents about their teenage kids having sex? Their dislike<br/>of the idea is so visceral it's probably inborn. But if it's inborn it should<br/>be universal, and there are plenty of societies where parents don't mind if<br/>their teenage kids have sex—indeed, where it's normal for 14 year olds to<br/>become mothers. So what's going on? There does seem to be a universal taboo<br/>against sex with prepubescent children. One can imagine evolutionary reasons<br/>for that. And I think this is the main reason parents in industrialized<br/>societies dislike teenage kids having sex. They still think of them as<br/>children, even though biologically they're not, so the taboo against child sex<br/>still has force.  <br/>  <br/>One thing adults conceal about sex they also conceal about drugs: that it can<br/>cause great pleasure. That's what makes sex and drugs so dangerous. The desire<br/>for them can cloud one's judgement—which is especially frightening when the<br/>judgement being clouded is the already wretched judgement of a teenage kid.  <br/>  <br/>Here parents' desires conflict. Older societies told kids they had bad<br/>judgement, but modern parents want their children to be confident. This may<br/>well be a better plan than the old one of putting them in their place, but it<br/>has the side effect that after having implicitly lied to kids about how good<br/>their judgement is, we then have to lie again about all the things they might<br/>get into trouble with if they believed us.  <br/>  <br/>If parents told their kids the truth about sex and drugs, it would be: the<br/>reason you should avoid these things is that you have lousy judgement. People<br/>with twice your experience still get burned by them. But this may be one of<br/>those cases where the truth wouldn't be convincing, because one of the<br/>symptoms of bad judgement is believing you have good judgement. When you're<br/>too weak to lift something, you can tell, but when you're making a decision<br/>impetuously, you're all the more sure of it.  <br/>  <br/>**Innocence**  <br/>  <br/>Another reason parents don't want their kids having sex is that they want to<br/>keep them innocent. Adults have a certain model of how kids are supposed to<br/>behave, and it's different from what they expect of other adults.  <br/>  <br/>One of the most obvious differences is the words kids are allowed to use. Most<br/>parents use words when talking to other adults that they wouldn't want their<br/>kids using. They try to hide even the existence of these words for as long as<br/>they can. And this is another of those conspiracies everyone participates in:<br/>everyone knows you're not supposed to swear in front of kids.  <br/>  <br/>I've never heard more different explanations for anything parents tell kids<br/>than why they shouldn't swear. Every parent I know forbids their children to<br/>swear, and yet no two of them have the same justification. It's clear most<br/>start with not wanting kids to swear, then make up the reason afterward.  <br/>  <br/>So my theory about what's going on is that the _function_ of swearwords is to<br/>mark the speaker as an adult. There's no difference in the meaning of "shit"<br/>and "poopoo." So why should one be ok for kids to say and one forbidden? The<br/>only explanation is: by definition. [3]  <br/>  <br/>Why does it bother adults so much when kids do things reserved for adults? The<br/>idea of a foul-mouthed, cynical 10 year old leaning against a lamppost with a<br/>cigarette hanging out of the corner of his mouth is very disconcerting. But<br/>why?  <br/>  <br/>One reason we want kids to be innocent is that we're programmed to like<br/>certain kinds of helplessness. I've several times heard mothers say they<br/>deliberately refrained from correcting their young children's<br/>mispronunciations because they were so cute. And if you think about it,<br/>cuteness is helplessness. Toys and cartoon characters meant to be cute always<br/>have clueless expressions and stubby, ineffectual limbs.  <br/>  <br/>It's not surprising we'd have an inborn desire to love and protect helpless<br/>creatures, considering human offspring are so helpless for so long. Without<br/>the helplessness that makes kids cute, they'd be very annoying. They'd merely<br/>seem like incompetent adults. But there's more to it than that. The reason our<br/>hypothetical jaded 10 year old bothers me so much is not just that he'd be<br/>annoying, but that he'd have cut off his prospects for growth so early. To be<br/>jaded you have to think you know how the world works, and any theory a 10 year<br/>old had about that would probably be a pretty narrow one.  <br/>  <br/>Innocence is also open-mindedness. We want kids to be innocent so they can<br/>continue to learn. Paradoxical as it sounds, there are some kinds of knowledge<br/>that get in the way of other kinds of knowledge. If you're going to learn that<br/>the world is a brutal place full of people trying to take advantage of one<br/>another, you're better off learning it last. Otherwise you won't bother<br/>learning much more.  <br/>  <br/>Very smart adults often seem unusually innocent, and I don't think this is a<br/>coincidence. I think they've deliberately avoided learning about certain<br/>things. Certainly I do. I used to think I wanted to know everything. Now I<br/>know I don't.  <br/>  <br/>**Death**  <br/>  <br/>After sex, death is the topic adults lie most conspicuously about to kids. Sex<br/>I believe they conceal because of deep taboos. But why do we conceal death<br/>from kids? Probably because small children are particularly horrified by it.<br/>They want to feel safe, and death is the ultimate threat.  <br/>  <br/>One of the most spectacular lies our parents told us was about the death of<br/>our first cat. Over the years, as we asked for more details, they were<br/>compelled to invent more, so the story grew quite elaborate. The cat had died<br/>at the vet's office. Of what? Of the anaesthesia itself. Why was the cat at<br/>the vet's office? To be fixed. And why had such a routine operation killed it?<br/>It wasn't the vet's fault; the cat had a congenitally weak heart; the<br/>anaesthesia was too much for it; but there was no way anyone could have known<br/>this in advance. It was not till we were in our twenties that the truth came<br/>out: my sister, then about three, had accidentally stepped on the cat and<br/>broken its back.  <br/>  <br/>They didn't feel the need to tell us the cat was now happily in cat heaven. My<br/>parents never claimed that people or animals who died had "gone to a better<br/>place," or that we'd meet them again. It didn't seem to harm us.  <br/>  <br/>My grandmother told us an edited version of the death of my grandfather. She<br/>said they'd been sitting reading one day, and when she said something to him,<br/>he didn't answer. He seemed to be asleep, but when she tried to rouse him, she<br/>couldn't. "He was gone." Having a heart attack sounded like falling asleep.<br/>Later I learned it hadn't been so neat, and the heart attack had taken most of<br/>a day to kill him.  <br/>  <br/>Along with such outright lies, there must have been a lot of changing the<br/>subject when death came up. I can't remember that, of course, but I can infer<br/>it from the fact that I didn't really grasp I was going to die till I was<br/>about 19. How could I have missed something so obvious for so long? Now that<br/>I've seen parents managing the subject, I can see how: questions about death<br/>are gently but firmly turned aside.  <br/>  <br/>On this topic, especially, they're met half-way by kids. Kids often want to be<br/>lied to. They want to believe they're living in a comfortable, safe world as<br/>much as their parents want them to believe it. [4]  <br/>  <br/>**Identity**  <br/>  <br/>Some parents feel a strong adherence to an ethnic or religious group and want<br/>their kids to feel it too. This usually requires two different kinds of lying:<br/>the first is to tell the child that he or she is an X, and the second is<br/>whatever specific lies Xes differentiate themselves by believing. [5]  <br/>  <br/>Telling a child they have a particular ethnic or religious identity is one of<br/>the stickiest things you can tell them. Almost anything else you tell a kid,<br/>they can change their mind about later when they start to think for<br/>themselves. But if you tell a kid they're a member of a certain group, that<br/>seems nearly impossible to shake.  <br/>  <br/>This despite the fact that it can be one of the most premeditated lies parents<br/>tell. When parents are of different religions, they'll often agree between<br/>themselves that their children will be "raised as Xes." And it works. The kids<br/>obligingly grow up considering themselves as Xes, despite the fact that if<br/>their parents had chosen the other way, they'd have grown up considering<br/>themselves as Ys.  <br/>  <br/>One reason this works so well is the second kind of lie involved. The truth is<br/>common property. You can't distinguish your group by doing things that are<br/>rational, and believing things that are true. If you want to set yourself<br/>apart from other people, you have to do things that are arbitrary, and believe<br/>things that are false. And after having spent their whole lives doing things<br/>that are arbitrary and believing things that are false, and being regarded as<br/>odd by "outsiders" on that account, the cognitive dissonance pushing children<br/>to regard themselves as Xes must be enormous. If they aren't an X, why are<br/>they attached to all these arbitrary beliefs and customs? If they aren't an X,<br/>why do all the non-Xes call them one?  <br/>  <br/>This form of lie is not without its uses. You can use it to carry a payload of<br/>beneficial beliefs, and they will also become part of the child's identity.<br/>You can tell the child that in addition to never wearing the color yellow,<br/>believing the world was created by a giant rabbit, and always snapping their<br/>fingers before eating fish, Xes are also particularly honest and industrious.<br/>Then X children will grow up feeling it's part of their identity to be honest<br/>and industrious.  <br/>  <br/>This probably accounts for a lot of the spread of modern religions, and<br/>explains why their doctrines are a combination of the useful and the bizarre.<br/>The bizarre half is what makes the religion stick, and the useful half is the<br/>payload. [6]  <br/>  <br/>**Authority**  <br/>  <br/>One of the least excusable reasons adults lie to kids is to maintain power<br/>over them. Sometimes these lies are truly sinister, like a child molester<br/>telling his victims they'll get in trouble if they tell anyone what happened<br/>to them. Others seem more innocent; it depends how badly adults lie to<br/>maintain their power, and what they use it for.  <br/>  <br/>Most adults make some effort to conceal their flaws from children. Usually<br/>their motives are mixed. For example, a father who has an affair generally<br/>conceals it from his children. His motive is partly that it would worry them,<br/>partly that this would introduce the topic of sex, and partly (a larger part<br/>than he would admit) that he doesn't want to tarnish himself in their eyes.  <br/>  <br/>If you want to learn what lies are told to kids, read almost any book written<br/>to teach them about "issues." [7] Peter Mayle wrote one called _Why Are We<br/>Getting a Divorce?_ It begins with the three most important things to remember<br/>about divorce, one of which is:<br/><br/>> You shouldn't put the blame on one parent, because divorce is never only one<br/>> person's fault. [8]<br/><br/>Really? When a man runs off with his secretary, is it always partly his wife's<br/>fault? But I can see why Mayle might have said this. Maybe it's more important<br/>for kids to respect their parents than to know the truth about them.  <br/>  <br/>But because adults conceal their flaws, and at the same time insist on high<br/>standards of behavior for kids, a lot of kids grow up feeling they fall<br/>hopelessly short. They walk around feeling horribly evil for having used a<br/>swearword, while in fact most of the adults around them are doing much worse<br/>things.  <br/>  <br/>This happens in intellectual as well as moral questions. The more confident<br/>people are, the more willing they seem to be to answer a question "I don't<br/>know." Less confident people feel they have to have an answer or they'll look<br/>bad. My parents were pretty good about admitting when they didn't know things,<br/>but I must have been told a lot of lies of this type by teachers, because I<br/>rarely heard a teacher say "I don't know" till I got to college. I remember<br/>because it was so surprising to hear someone say that in front of a class.  <br/>  <br/>The first hint I had that teachers weren't omniscient came in sixth grade,<br/>after my father contradicted something I'd learned in school. When I protested<br/>that the teacher had said the opposite, my father replied that the guy had no<br/>idea what he was talking about—that he was just an elementary school teacher,<br/>after all.  <br/>  <br/> _Just_ a teacher? The phrase seemed almost grammatically ill-formed. Didn't<br/>teachers know everything about the subjects they taught? And if not, why were<br/>they the ones teaching us?  <br/>  <br/>The sad fact is, US public school teachers don't generally understand the<br/>stuff they're teaching very well. There are some sterling exceptions, but as a<br/>rule people planning to go into teaching rank academically near the bottom of<br/>the college population. So the fact that I still thought at age 11 that<br/>teachers were infallible shows what a job the system must have done on my<br/>brain.  <br/>  <br/>**School**  <br/>  <br/>What kids get taught in school is a complex mix of lies. The most excusable<br/>are those told to simplify ideas to make them easy to learn. The problem is, a<br/>lot of propaganda gets slipped into the curriculum in the name of<br/>simplification.  <br/>  <br/>Public school textbooks represent a compromise between what various powerful<br/>groups want kids to be told. The lies are rarely overt. Usually they consist<br/>either of omissions or of over-emphasizing certain topics at the expense of<br/>others. The view of history we got in elementary school was a crude<br/>hagiography, with at least one representative of each powerful group.  <br/>  <br/>The famous scientists I remember were Einstein, Marie Curie, and George<br/>Washington Carver. Einstein was a big deal because his work led to the atom<br/>bomb. Marie Curie was involved with X-rays. But I was mystified about Carver.<br/>He seemed to have done stuff with peanuts.  <br/>  <br/>It's obvious now that he was on the list because he was black (and for that<br/>matter that Marie Curie was on it because she was a woman), but as a kid I was<br/>confused for years about him. I wonder if it wouldn't have been better just to<br/>tell us the truth: that there weren't any famous black scientists. Ranking<br/>George Washington Carver with Einstein misled us not only about science, but<br/>about the obstacles blacks faced in his time.  <br/>  <br/>As subjects got softer, the lies got more frequent. By the time you got to<br/>politics and recent history, what we were taught was pretty much pure<br/>propaganda. For example, we were taught to regard political leaders as<br/>saints—especially the recently martyred Kennedy and King. It was astonishing<br/>to learn later that they'd both been serial womanizers, and that Kennedy was a<br/>speed freak to boot. (By the time King's plagiarism emerged, I'd lost the<br/>ability to be surprised by the misdeeds of famous people.)  <br/>  <br/>I doubt you could teach kids recent history without teaching them lies,<br/>because practically everyone who has anything to say about it has some kind of<br/>spin to put on it. Much recent history _consists_ of spin. It would probably<br/>be better just to teach them metafacts like that.  <br/>  <br/>Probably the biggest lie told in schools, though, is that the way to succeed<br/>is through following "the rules." In fact most such rules are just hacks to<br/>manage large groups efficiently.  <br/>  <br/>**Peace**  <br/>  <br/>Of all the reasons we lie to kids, the most powerful is probably the same<br/>mundane reason they lie to us.  <br/>  <br/>Often when we lie to people it's not part of any conscious strategy, but<br/>because they'd react violently to the truth. Kids, almost by definition, lack<br/>self-control. They react violently to things—and so they get lied to a lot.<br/>[9]  <br/>  <br/>A few Thanksgivings ago, a friend of mine found himself in a situation that<br/>perfectly illustrates the complex motives we have when we lie to kids. As the<br/>roast turkey appeared on the table, his alarmingly perceptive 5 year old son<br/>suddenly asked if the turkey had wanted to die. Foreseeing disaster, my friend<br/>and his wife rapidly improvised: yes, the turkey had wanted to die, and in<br/>fact had lived its whole life with the aim of being their Thanksgiving dinner.<br/>And that (phew) was the end of that.  <br/>  <br/>Whenever we lie to kids to protect them, we're usually also lying to keep the<br/>peace.  <br/>  <br/>One consequence of this sort of calming lie is that we grow up thinking<br/>horrible things are normal. It's hard for us to feel a sense of urgency as<br/>adults over something we've literally been trained not to worry about. When I<br/>was about 10 I saw a documentary on pollution that put me into a panic. It<br/>seemed the planet was being irretrievably ruined. I went to my mother<br/>afterward to ask if this was so. I don't remember what she said, but she made<br/>me feel better, so I stopped worrying about it.  <br/>  <br/>That was probably the best way to handle a frightened 10 year old. But we<br/>should understand the price. This sort of lie is one of the main reasons bad<br/>things persist: we're all trained to ignore them.  <br/>  <br/>**Detox**  <br/>  <br/>A sprinter in a race almost immediately enters a state called "oxygen debt."<br/>His body switches to an emergency source of energy that's faster than regular<br/>aerobic respiration. But this process builds up waste products that ultimately<br/>require extra oxygen to break down, so at the end of the race he has to stop<br/>and pant for a while to recover.  <br/>  <br/>We arrive at adulthood with a kind of truth debt. We were told a lot of lies<br/>to get us (and our parents) through our childhood. Some may have been<br/>necessary. Some probably weren't. But we all arrive at adulthood with heads<br/>full of lies.  <br/>  <br/>There's never a point where the adults sit you down and explain all the lies<br/>they told you. They've forgotten most of them. So if you're going to clear<br/>these lies out of your head, you're going to have to do it yourself.  <br/>  <br/>Few do. Most people go through life with bits of packing material adhering to<br/>their minds and never know it. You probably never can completely undo the<br/>effects of lies you were told as a kid, but it's worth trying. I've found that<br/>whenever I've been able to undo a lie I was told, a lot of other things fell<br/>into place.  <br/>  <br/>Fortunately, once you arrive at adulthood you get a valuable new resource you<br/>can use to figure out what lies you were told. You're now one of the liars.<br/>You get to watch behind the scenes as adults spin the world for the next<br/>generation of kids.  <br/>  <br/>The first step in clearing your head is to realize how far you are from a<br/>neutral observer. When I left high school I was, I thought, a complete<br/>skeptic. I'd realized high school was crap. I thought I was ready to question<br/>everything I knew. But among the many other things I was ignorant of was how<br/>much debris there already was in my head. It's not enough to consider your<br/>mind a blank slate. You have to consciously erase it.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] One reason I stuck with such a brutally simple word is that the lies we<br/>tell kids are probably not quite as harmless as we think. If you look at what<br/>adults told children in the past, it's shocking how much they lied to them.<br/>Like us, they did it with the best intentions. So if we think we're as open as<br/>one could reasonably be with children, we're probably fooling ourselves. Odds<br/>are people in 100 years will be as shocked at some of the lies we tell as we<br/>are at some of the lies people told 100 years ago.  <br/>  <br/>I can't predict which these will be, and I don't want to write an essay that<br/>will seem dumb in 100 years. So instead of using special euphemisms for lies<br/>that seem excusable according to present fashions, I'm just going to call all<br/>our lies lies.  <br/>  <br/>(I have omitted one type: lies told to play games with kids' credulity. These<br/>range from "make-believe," which is not really a lie because it's told with a<br/>wink, to the frightening lies told by older siblings. There's not much to say<br/>about these: I wouldn't want the first type to go away, and wouldn't expect<br/>the second type to.)  <br/>  <br/>[2] Calaprice, Alice (ed.), _The Quotable Einstein_ , Princeton University<br/>Press, 1996.  <br/>  <br/>[3] If you ask parents why kids shouldn't swear, the less educated ones<br/>usually reply with some question-begging answer like "it's inappropriate,"<br/>while the more educated ones come up with elaborate rationalizations. In fact<br/>the less educated parents seem closer to the truth.  <br/>  <br/>[4] As a friend with small children pointed out, it's easy for small children<br/>to consider themselves immortal, because time seems to pass so slowly for<br/>them. To a 3 year old, a day feels like a month might to an adult. So 80 years<br/>sounds to him like 2400 years would to us.  <br/>  <br/>[5] I realize I'm going to get endless grief for classifying religion as a<br/>type of lie. Usually people skirt that issue with some equivocation implying<br/>that lies believed for a sufficiently long time by sufficiently large numbers<br/>of people are immune to the usual standards for truth. But because I can't<br/>predict which lies future generations will consider inexcusable, I can't<br/>safely omit any type we tell. Yes, it seems unlikely that religion will be out<br/>of fashion in 100 years, but no more unlikely than it would have seemed to<br/>someone in 1880 that schoolchildren in 1980 would be taught that masturbation<br/>was perfectly normal and not to feel guilty about it.  <br/>  <br/>[6] Unfortunately the payload can consist of bad customs as well as good ones.<br/>For example, there are certain qualities that some groups in America consider<br/>"acting white." In fact most of them could as accurately be called "acting<br/>Japanese." There's nothing specifically white about such customs. They're<br/>common to all cultures with long traditions of living in cities. So it is<br/>probably a losing bet for a group to consider behaving the opposite way as<br/>part of its identity.  <br/>  <br/>[7] In this context, "issues" basically means "things we're going to lie to<br/>them about." That's why there's a special name for these topics.  <br/>  <br/>[8] Mayle, Peter, _Why Are We Getting a Divorce?_ , Harmony, 1988.  <br/>  <br/>[9] The ironic thing is, this is also the main reason kids lie to adults. If<br/>you freak out when people tell you alarming things, they won't tell you them.<br/>Teenagers don't tell their parents what happened that night they were supposed<br/>to be staying at a friend's house for the same reason parents don't tell 5<br/>year olds the truth about the Thanksgiving turkey. They'd freak if they knew.  <br/>  <br/>**Thanks** to Sam Altman, Marc Andreessen, Trevor Blackwell, Patrick Collison,<br/>Jessica Livingston, Jackie McDonough, Robert Morris, and David Sloo for<br/>reading drafts of this. And since there are some controversial ideas here, I<br/>should add that none of them agreed with everything in it.  <br/>  <br/><br/>German Translation  <br/><br/>French Translation  <br/><br/>Russian Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>July 2009  <br/>  <br/>One reason programmers dislike meetings so much is that they're on a different<br/>type of schedule from other people. Meetings cost them more.  <br/>  <br/>There are two types of schedule, which I'll call the manager's schedule and<br/>the maker's schedule. The manager's schedule is for bosses. It's embodied in<br/>the traditional appointment book, with each day cut into one hour intervals.<br/>You can block off several hours for a single task if you need to, but by<br/>default you change what you're doing every hour.  <br/>  <br/>When you use time that way, it's merely a practical problem to meet with<br/>someone. Find an open slot in your schedule, book them, and you're done.  <br/>  <br/>Most powerful people are on the manager's schedule. It's the schedule of<br/>command. But there's another way of using time that's common among people who<br/>make things, like programmers and writers. They generally prefer to use time<br/>in units of half a day at least. You can't write or program well in units of<br/>an hour. That's barely enough time to get started.  <br/>  <br/>When you're operating on the maker's schedule, meetings are a disaster. A<br/>single meeting can blow a whole afternoon, by breaking it into two pieces each<br/>too small to do anything hard in. Plus you have to remember to go to the<br/>meeting. That's no problem for someone on the manager's schedule. There's<br/>always something coming on the next hour; the only question is what. But when<br/>someone on the maker's schedule has a meeting, they have to think about it.  <br/>  <br/>For someone on the maker's schedule, having a meeting is like throwing an<br/>exception. It doesn't merely cause you to switch from one task to another; it<br/>changes the mode in which you work.  <br/>  <br/>I find one meeting can sometimes affect a whole day. A meeting commonly blows<br/>at least half a day, by breaking up a morning or afternoon. But in addition<br/>there's sometimes a cascading effect. If I know the afternoon is going to be<br/>broken up, I'm slightly less likely to start something ambitious in the<br/>morning. I know this may sound oversensitive, but if you're a maker, think of<br/>your own case. Don't your spirits rise at the thought of having an entire day<br/>free to work, with no appointments at all? Well, that means your spirits are<br/>correspondingly depressed when you don't. And ambitious projects are by<br/>definition close to the limits of your capacity. A small decrease in morale is<br/>enough to kill them off.  <br/>  <br/>Each type of schedule works fine by itself. Problems arise when they meet.<br/>Since most powerful people operate on the manager's schedule, they're in a<br/>position to make everyone resonate at their frequency if they want to. But the<br/>smarter ones restrain themselves, if they know that some of the people working<br/>for them need long chunks of time to work in.  <br/>  <br/>Our case is an unusual one. Nearly all investors, including all VCs I know,<br/>operate on the manager's schedule. But Y Combinator runs on the maker's<br/>schedule. Rtm and Trevor and I do because we always have, and Jessica does<br/>too, mostly, because she's gotten into sync with us.  <br/>  <br/>I wouldn't be surprised if there start to be more companies like us. I suspect<br/>founders may increasingly be able to resist, or at least postpone, turning<br/>into managers, just as a few decades ago they started to be able to resist<br/>switching from jeans to suits.  <br/>  <br/>How do we manage to advise so many startups on the maker's schedule? By using<br/>the classic device for simulating the manager's schedule within the maker's:<br/>office hours. Several times a week I set aside a chunk of time to meet<br/>founders we've funded. These chunks of time are at the end of my working day,<br/>and I wrote a signup program that ensures all the appointments within a given<br/>set of office hours are clustered at the end. Because they come at the end of<br/>my day these meetings are never an interruption. (Unless their working day<br/>ends at the same time as mine, the meeting presumably interrupts theirs, but<br/>since they made the appointment it must be worth it to them.) During busy<br/>periods, office hours sometimes get long enough that they compress the day,<br/>but they never interrupt it.  <br/>  <br/>When we were working on our own startup, back in the 90s, I evolved another<br/>trick for partitioning the day. I used to program from dinner till about 3 am<br/>every day, because at night no one could interrupt me. Then I'd sleep till<br/>about 11 am, and come in and work until dinner on what I called "business<br/>stuff." I never thought of it in these terms, but in effect I had two workdays<br/>each day, one on the manager's schedule and one on the maker's.  <br/>  <br/>When you're operating on the manager's schedule you can do something you'd<br/>never want to do on the maker's: you can have speculative meetings. You can<br/>meet someone just to get to know one another. If you have an empty slot in<br/>your schedule, why not? Maybe it will turn out you can help one another in<br/>some way.  <br/>  <br/>Business people in Silicon Valley (and the whole world, for that matter) have<br/>speculative meetings all the time. They're effectively free if you're on the<br/>manager's schedule. They're so common that there's distinctive language for<br/>proposing them: saying that you want to "grab coffee," for example.  <br/>  <br/>Speculative meetings are terribly costly if you're on the maker's schedule,<br/>though. Which puts us in something of a bind. Everyone assumes that, like<br/>other investors, we run on the manager's schedule. So they introduce us to<br/>someone they think we ought to meet, or send us an email proposing we grab<br/>coffee. At this point we have two options, neither of them good: we can meet<br/>with them, and lose half a day's work; or we can try to avoid meeting them,<br/>and probably offend them.  <br/>  <br/>Till recently we weren't clear in our own minds about the source of the<br/>problem. We just took it for granted that we had to either blow our schedules<br/>or offend people. But now that I've realized what's going on, perhaps there's<br/>a third option: to write something explaining the two types of schedule. Maybe<br/>eventually, if the conflict between the manager's schedule and the maker's<br/>schedule starts to be more widely understood, it will become less of a<br/>problem.  <br/>  <br/>Those of us on the maker's schedule are willing to compromise. We know we have<br/>to have some number of meetings. All we ask from those on the manager's<br/>schedule is that they understand the cost.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Thanks** to Sam Altman, Trevor Blackwell, Paul Buchheit, Jessica Livingston,<br/>and Robert Morris for reading drafts of this.  <br/>  <br/>  <br/>  <br/> **Related:**  <br/>  <br/><br/>How to Do What You Love  <br/><br/>Good and Bad Procrastination  <br/><br/>Turkish Translation  <br/><br/>French Translation  <br/><br/>Korean Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>March 2012  <br/>  <br/>As a child I read a book of stories about a famous judge in eighteenth century<br/>Japan called Ooka Tadasuke. One of the cases he decided was brought by the<br/>owner of a food shop. A poor student who could afford only rice was eating his<br/>rice while enjoying the delicious cooking smells coming from the food shop.<br/>The owner wanted the student to pay for the smells he was enjoying.  <br/>  <br/>The student was stealing his smells!  <br/>  <br/>This story often comes to mind when I hear the RIAA and MPAA accusing people<br/>of stealing music and movies.  <br/>  <br/>It sounds ridiculous to us to treat smells as property. But I can imagine<br/>scenarios in which one could charge for smells. Imagine we were living on a<br/>moon base where we had to buy air by the liter. I could imagine air suppliers<br/>adding scents at an extra charge.  <br/>  <br/>The reason it seems ridiculous to us to treat smells as property is that it<br/>wouldn't work to. It would work on a moon base, though.  <br/>  <br/>What counts as property depends on what works to treat as property. And that<br/>not only can change, but has changed. Humans may always (for some definition<br/>of human and always) have treated small items carried on one's person as<br/>property. But hunter gatherers didn't treat land, for example, as property in<br/>the way we do. [1]  <br/>  <br/>The reason so many people think of property as having a single unchanging<br/>definition is that its definition changes very slowly. [2] But we are in the<br/>midst of such a change now. The record labels and movie studios used to<br/>distribute what they made like air shipped through tubes on a moon base. But<br/>with the arrival of networks, it's as if we've moved to a planet with a<br/>breathable atmosphere. Data moves like smells now. And through a combination<br/>of wishful thinking and short-term greed, the labels and studios have put<br/>themselves in the position of the food shop owner, accusing us all of stealing<br/>their smells.  <br/>  <br/>(The reason I say short-term greed is that the underlying problem with the<br/>labels and studios is that the people who run them are driven by bonuses<br/>rather than equity. If they were driven by equity they'd be looking for ways<br/>to take advantage of technological change instead of fighting it. But building<br/>new things takes too long. Their bonuses depend on this year's revenues, and<br/>the best way to increase those is to extract more money from stuff they do<br/>already.)  <br/>  <br/>So what does this mean? Should people not be able to charge for content?<br/>There's not a single yes or no answer to that question. People should be able<br/>to charge for content when it works to charge for content.  <br/>  <br/>But by "works" I mean something more subtle than "when they can get away with<br/>it." I mean when people can charge for content without warping society in<br/>order to do it. After all, the companies selling smells on the moon base could<br/>continue to sell them on the Earth, if they lobbied successfully for laws<br/>requiring us all to continue to breathe through tubes down here too, even<br/>though we no longer needed to.  <br/>  <br/>The crazy legal measures that the labels and studios have been taking have a<br/>lot of that flavor. Newspapers and magazines are just as screwed, but they are<br/>at least declining gracefully. The RIAA and MPAA would make us breathe through<br/>tubes if they could.  <br/>  <br/>Ultimately it comes down to common sense. When you're abusing the legal system<br/>by trying to use mass lawsuits against randomly chosen people as a form of<br/>exemplary punishment, or lobbying for laws that would break the Internet if<br/>they passed, that's ipso facto evidence you're using a definition of property<br/>that doesn't work.  <br/>  <br/>This is where it's helpful to have working democracies and multiple sovereign<br/>countries. If the world had a single, autocratic government, the labels and<br/>studios could buy laws making the definition of property be whatever they<br/>wanted. But fortunately there are still some countries that are not copyright<br/>colonies of the US, and even in the US, politicians still seem to be afraid of<br/>actual voters, in sufficient numbers. [3]  <br/>  <br/>The people running the US may not like it when voters or other countries<br/>refuse to bend to their will, but ultimately it's in all our interest that<br/>there's not a single point of attack for people trying to warp the law to<br/>serve their own purposes. Private property is an extremely useful idea —<br/>arguably one of our greatest inventions. So far, each new definition of it has<br/>brought us increasing material wealth. [4] It seems reasonable to suppose the<br/>newest one will too. It would be a disaster if we all had to keep running an<br/>obsolete version just because a few powerful people were too lazy to upgrade.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] If you want to learn more about hunter gatherers I strongly recommend<br/>Elizabeth Marshall Thomas's _The Harmless People_ and _The Old Way_.  <br/>  <br/>[2] Change in the definition of property is driven mostly by technological<br/>progress, however, and since technological progress is accelerating, so<br/>presumably will the rate of change in the definition of property. Which means<br/>it's all the more important for societies to be able to respond gracefully to<br/>such changes, because they will come at an ever increasing rate.  <br/>  <br/>[3] As far as I know, the term "copyright colony" was first used by Myles<br/>Peterson.  <br/>  <br/>[4] The state of technology isn't simply a function of the definition of<br/>property. They each constrain the other. But that being so, you can't mess<br/>with the definition of property without affecting (and probably harming) the<br/>state of technology. The history of the USSR offers a vivid illustration of<br/>that.  <br/>  <br/> **Thanks** to Sam Altman and Geoff Ralston for reading drafts of this.  <br/>  <br/><br/>Japanese Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>September 2009  <br/>  <br/>When meeting people you don't know very well, the convention is to seem extra<br/>friendly. You smile and say "pleased to meet you," whether you are or not.<br/>There's nothing dishonest about this. Everyone knows that these little social<br/>lies aren't meant to be taken literally, just as everyone knows that "Can you<br/>pass the salt?" is only grammatically a question.  <br/>  <br/>I'm perfectly willing to smile and say "pleased to meet you" when meeting new<br/>people. But there is another set of customs for being ingratiating in print<br/>that are not so harmless.  <br/>  <br/>The reason there's a convention of being ingratiating in print is that most<br/>essays are written to persuade. And as any politician could tell you, the way<br/>to persuade people is not just to baldly state the facts. You have to add a<br/>spoonful of sugar to make the medicine go down.  <br/>  <br/>For example, a politician announcing the cancellation of a government program<br/>will not merely say "The program is canceled." That would seem offensively<br/>curt. Instead he'll spend most of his time talking about the noble effort made<br/>by the people who worked on it.  <br/>  <br/>The reason these conventions are more dangerous is that they interact with the<br/>ideas. Saying "pleased to meet you" is just something you prepend to a<br/>conversation, but the sort of spin added by politicians is woven through it.<br/>We're starting to move from social lies to real lies.  <br/>  <br/>Here's an example of a paragraph from an essay I wrote about labor unions. As<br/>written, it tends to offend people who like unions.<br/><br/>> People who think the labor movement was the creation of heroic union<br/>> organizers have a problem to explain: why are unions shrinking now? The best<br/>> they can do is fall back on the default explanation of people living in<br/>> fallen civilizations. Our ancestors were giants. The workers of the early<br/>> twentieth century must have had a moral courage that's lacking today.<br/><br/>Now here's the same paragraph rewritten to please instead of offending them:<br/><br/>> Early union organizers made heroic sacrifices to improve conditions for<br/>> workers. But though labor unions are shrinking now, it's not because present<br/>> union leaders are any less courageous. An employer couldn't get away with<br/>> hiring thugs to beat up union leaders today, but if they did, I see no<br/>> reason to believe today's union leaders would shrink from the challenge. So<br/>> I think it would be a mistake to attribute the decline of unions to some<br/>> kind of decline in the people who run them. Early union leaders were heroic,<br/>> certainly, but we should not suppose that if unions have declined, it's<br/>> because present union leaders are somehow inferior. The cause must be<br/>> external. [1]<br/><br/>It makes the same point: that it can't have been the personal qualities of<br/>early union organizers that made unions successful, but must have been some<br/>external factor, or otherwise present-day union leaders would have to be<br/>inferior people. But written this way it seems like a defense of present-day<br/>union organizers rather than an attack on early ones. That makes it more<br/>persuasive to people who like unions, because it seems sympathetic to their<br/>cause.  <br/>  <br/>I believe everything I wrote in the second version. Early union leaders did<br/>make heroic sacrifices. And present union leaders probably would rise to the<br/>occasion if necessary. People tend to; I'm skeptical about the idea of "the<br/>greatest generation." [2]  <br/>  <br/>If I believe everything I said in the second version, why didn't I write it<br/>that way? Why offend people needlessly?  <br/>  <br/>Because I'd rather offend people than pander to them, and if you write about<br/>controversial topics you have to choose one or the other. The degree of<br/>courage of past or present union leaders is beside the point; all that matters<br/>for the argument is that they're the same. But if you want to please people<br/>who are mistaken, you can't simply tell the truth. You're always going to have<br/>to add some sort of padding to protect their misconceptions from bumping<br/>against reality.  <br/>  <br/>Most writers do. Most writers write to persuade, if only out of habit or<br/>politeness. But I don't write to persuade; I write to figure out. I write to<br/>persuade a hypothetical perfectly unbiased reader.  <br/>  <br/>Since the custom is to write to persuade the actual reader, someone who<br/>doesn't will seem arrogant. In fact, worse than arrogant: since readers are<br/>used to essays that try to please someone, an essay that displeases one side<br/>in a dispute reads as an attempt to pander to the other. To a lot of pro-union<br/>readers, the first paragraph sounds like the sort of thing a right-wing radio<br/>talk show host would say to stir up his followers. But it's not. Something<br/>that curtly contradicts one's beliefs can be hard to distinguish from a<br/>partisan attack on them, but though they can end up in the same place they<br/>come from different sources.  <br/>  <br/>Would it be so bad to add a few extra words, to make people feel better? Maybe<br/>not. Maybe I'm excessively attached to conciseness. I write code the same way<br/>I write essays, making pass after pass looking for anything I can cut. But I<br/>have a legitimate reason for doing this. You don't know what the ideas are<br/>until you get them down to the fewest words. [3]  <br/>  <br/>The danger of the second paragraph is not merely that it's longer. It's that<br/>you start to lie to yourself. The ideas start to get mixed together with the<br/>spin you've added to get them past the readers' misconceptions.  <br/>  <br/>I think the goal of an essay should be to discover surprising things. That's<br/>my goal, at least. And most surprising means most different from what people<br/>currently believe. So writing to persuade and writing to discover are<br/>diametrically opposed. The more your conclusions disagree with readers'<br/>present beliefs, the more effort you'll have to expend on selling your ideas<br/>rather than having them. As you accelerate, this drag increases, till<br/>eventually you reach a point where 100% of your energy is devoted to<br/>overcoming it and you can't go any faster.  <br/>  <br/>It's hard enough to overcome one's own misconceptions without having to think<br/>about how to get the resulting ideas past other people's. I worry that if I<br/>wrote to persuade, I'd start to shy away unconsciously from ideas I knew would<br/>be hard to sell. When I notice something surprising, it's usually very faint<br/>at first. There's nothing more than a slight stirring of discomfort. I don't<br/>want anything to get in the way of noticing it consciously.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] I had a strange feeling of being back in high school writing this. To get<br/>a good grade you had to both write the sort of pious crap you were expected<br/>to, but also seem to be writing with conviction. The solution was a kind of<br/>method acting. It was revoltingly familiar to slip back into it.  <br/>  <br/>[2] Exercise for the reader: rephrase that thought to please the same people<br/>the first version would offend.  <br/>  <br/>[3] Come to think of it, there is one way in which I deliberately pander to<br/>readers, because it doesn't change the number of words: I switch person. This<br/>flattering distinction seems so natural to the average reader that they<br/>probably don't notice even when I switch in mid-sentence, though you tend to<br/>notice when it's done as conspicuously as this.  <br/>  <br/> **Thanks** to Jessica Livingston and Robert Morris for reading drafts of<br/>this.  <br/>  <br/> **Note:** An earlier version of this essay began by talking about why people<br/>dislike Michael Arrington. I now believe that was mistaken, and that most<br/>people don't dislike him for the same reason I did when I first met him, but<br/>simply because he writes about controversial things.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>March 2005  <br/>  <br/>All the best hackers I know are gradually switching to Macs. My friend Robert<br/>said his whole research group at MIT recently bought themselves Powerbooks.<br/>These guys are not the graphic designers and grandmas who were buying Macs at<br/>Apple's low point in the mid 1990s. They're about as hardcore OS hackers as<br/>you can get.  <br/>  <br/>The reason, of course, is OS X. Powerbooks are beautifully designed and run<br/>FreeBSD. What more do you need to know?  <br/>  <br/>I got a Powerbook at the end of last year. When my IBM Thinkpad's hard disk<br/>died soon after, it became my only laptop. And when my friend Trevor showed up<br/>at my house recently, he was carrying a Powerbook identical to mine.  <br/>  <br/>For most of us, it's not a switch to Apple, but a return. Hard as this was to<br/>believe in the mid 90s, the Mac was in its time the canonical hacker's<br/>computer.  <br/>  <br/>In the fall of 1983, the professor in one of my college CS classes got up and<br/>announced, like a prophet, that there would soon be a computer with half a<br/>MIPS of processing power that would fit under an airline seat and cost so<br/>little that we could save enough to buy one from a summer job. The whole room<br/>gasped. And when the Mac appeared, it was even better than we'd hoped. It was<br/>small and powerful and cheap, as promised. But it was also something we'd<br/>never considered a computer could be: fabulously well designed.  <br/>  <br/>I had to have one. And I wasn't alone. In the mid to late 1980s, all the<br/>hackers I knew were either writing software for the Mac, or wanted to. Every<br/>futon sofa in Cambridge seemed to have the same fat white book lying open on<br/>it. If you turned it over, it said "Inside Macintosh."  <br/>  <br/>Then came Linux and FreeBSD, and hackers, who follow the most powerful OS<br/>wherever it leads, found themselves switching to Intel boxes. If you cared<br/>about design, you could buy a Thinkpad, which was at least not actively<br/>repellent, if you could get the Intel and Microsoft stickers off the front.<br/>[1]  <br/>  <br/>With OS X, the hackers are back. When I walked into the Apple store in<br/>Cambridge, it was like coming home. Much was changed, but there was still that<br/>Apple coolness in the air, that feeling that the show was being run by someone<br/>who really cared, instead of random corporate deal-makers.  <br/>  <br/>So what, the business world may say. Who cares if hackers like Apple again?<br/>How big is the hacker market, after all?  <br/>  <br/>Quite small, but important out of proportion to its size. When it comes to<br/>computers, what hackers are doing now, everyone will be doing in ten years.<br/>Almost all technology, from Unix to bitmapped displays to the Web, became<br/>popular first within CS departments and research labs, and gradually spread to<br/>the rest of the world.  <br/>  <br/>I remember telling my father back in 1986 that there was a new kind of<br/>computer called a Sun that was a serious Unix machine, but so small and cheap<br/>that you could have one of your own to sit in front of, instead of sitting in<br/>front of a VT100 connected to a single central Vax. Maybe, I suggested, he<br/>should buy some stock in this company. I think he really wishes he'd listened.  <br/>  <br/>In 1994 my friend Koling wanted to talk to his girlfriend in Taiwan, and to<br/>save long-distance bills he wrote some software that would convert sound to<br/>data packets that could be sent over the Internet. We weren't sure at the time<br/>whether this was a proper use of the Internet, which was still then a quasi-<br/>government entity. What he was doing is now called VoIP, and it is a huge and<br/>rapidly growing business.  <br/>  <br/>If you want to know what ordinary people will be doing with computers in ten<br/>years, just walk around the CS department at a good university. Whatever<br/>they're doing, you'll be doing.  <br/>  <br/>In the matter of "platforms" this tendency is even more pronounced, because<br/>novel software originates with great hackers, and they tend to write it first<br/>for whatever computer they personally use. And software sells hardware. Many<br/>if not most of the initial sales of the Apple II came from people who bought<br/>one to run VisiCalc. And why did Bricklin and Frankston write VisiCalc for the<br/>Apple II? Because they personally liked it. They could have chosen any machine<br/>to make into a star.  <br/>  <br/>If you want to attract hackers to write software that will sell your hardware,<br/>you have to make it something that they themselves use. It's not enough to<br/>make it "open." It has to be open and good.  <br/>  <br/>And open and good is what Macs are again, finally. The intervening years have<br/>created a situation that is, as far as I know, without precedent: Apple is<br/>popular at the low end and the high end, but not in the middle. My seventy<br/>year old mother has a Mac laptop. My friends with PhDs in computer science<br/>have Mac laptops. [2] And yet Apple's overall market share is still small.  <br/>  <br/>Though unprecedented, I predict this situation is also temporary.  <br/>  <br/>So Dad, there's this company called Apple. They make a new kind of computer<br/>that's as well designed as a Bang & Olufsen stereo system, and underneath is<br/>the best Unix machine you can buy. Yes, the price to earnings ratio is kind of<br/>high, but I think a lot of people are going to want these.  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] These horrible stickers are much like the intrusive ads popular on pre-<br/>Google search engines. They say to the customer: you are unimportant. We care<br/>about Intel and Microsoft, not you.  <br/>  <br/>[2] Y Combinator is (we hope) visited mostly by hackers. The proportions of<br/>OSes are: Windows 66.4%, Macintosh 18.8%, Linux 11.4%, and FreeBSD 1.5%. The<br/>Mac number is a big change from what it would have been five years ago.  <br/>  <br/>  <br/>  <br/><br/>Italian Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Chinese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>April 2006  <br/>  <br/> _(This essay is derived from a talk at the 2006Startup School.)_  <br/>  <br/>The startups we've funded so far are pretty quick, but they seem quicker to<br/>learn some lessons than others. I think it's because some things about<br/>startups are kind of counterintuitive.  <br/>  <br/>We've now invested in enough companies that I've learned a trick for<br/>determining which points are the counterintuitive ones: they're the ones I<br/>have to keep repeating.  <br/>  <br/>So I'm going to number these points, and maybe with future startups I'll be<br/>able to pull off a form of Huffman coding. I'll make them all read this, and<br/>then instead of nagging them in detail, I'll just be able to say: _number<br/>four!_  <br/>  <br/>**1\. Release Early.**  <br/>  <br/>The thing I probably repeat most is this recipe for a startup: get a version 1<br/>out fast, then improve it based on users' reactions.  <br/>  <br/>By "release early" I don't mean you should release something full of bugs, but<br/>that you should release something minimal. Users hate bugs, but they don't<br/>seem to mind a minimal version 1, if there's more coming soon.  <br/>  <br/>There are several reasons it pays to get version 1 done fast. One is that this<br/>is simply the right way to write software, whether for a startup or not. I've<br/>been repeating that since 1993, and I haven't seen much since to contradict<br/>it. I've seen a lot of startups die because they were too slow to release<br/>stuff, and none because they were too quick. [1]  <br/>  <br/>One of the things that will surprise you if you build something popular is<br/>that you won't know your users. Reddit now has almost half a million unique<br/>visitors a month. Who are all those people? They have no idea. No web startup<br/>does. And since you don't know your users, it's dangerous to guess what<br/>they'll like. Better to release something and let them tell you.  <br/>  <br/>Wufoo took this to heart and released their form-builder before the underlying<br/>database. You can't even drive the thing yet, but 83,000 people came to sit in<br/>the driver's seat and hold the steering wheel. And Wufoo got valuable feedback<br/>from it: Linux users complained they used too much Flash, so they rewrote<br/>their software not to. If they'd waited to release everything at once, they<br/>wouldn't have discovered this problem till it was more deeply wired in.  <br/>  <br/>Even if you had no users, it would still be important to release quickly,<br/>because for a startup the initial release acts as a shakedown cruise. If<br/>anything major is broken-- if the idea's no good, for example, or the founders<br/>hate one another-- the stress of getting that first version out will expose<br/>it. And if you have such problems you want to find them early.  <br/>  <br/>Perhaps the most important reason to release early, though, is that it makes<br/>you work harder. When you're working on something that isn't released,<br/>problems are intriguing. In something that's out there, problems are alarming.<br/>There is a lot more urgency once you release. And I think that's precisely why<br/>people put it off. They know they'll have to work a lot harder once they do.<br/>[2]  <br/>  <br/>**2\. Keep Pumping Out Features.**  <br/>  <br/>Of course, "release early" has a second component, without which it would be<br/>bad advice. If you're going to start with something that doesn't do much, you<br/>better improve it fast.  <br/>  <br/>What I find myself repeating is "pump out features." And this rule isn't just<br/>for the initial stages. This is something all startups should do for as long<br/>as they want to be considered startups.  <br/>  <br/>I don't mean, of course, that you should make your application ever more<br/>complex. By "feature" I mean one unit of hacking-- one quantum of making<br/>users' lives better.  <br/>  <br/>As with exercise, improvements beget improvements. If you run every day,<br/>you'll probably feel like running tomorrow. But if you skip running for a<br/>couple weeks, it will be an effort to drag yourself out. So it is with<br/>hacking: the more ideas you implement, the more ideas you'll have. You should<br/>make your system better at least in some small way every day or two.  <br/>  <br/>This is not just a good way to get development done; it is also a form of<br/>marketing. Users love a site that's constantly improving. In fact, users<br/>expect a site to improve. Imagine if you visited a site that seemed very good,<br/>and then returned two months later and not one thing had changed. Wouldn't it<br/>start to seem lame? [3]  <br/>  <br/>They'll like you even better when you improve in response to their comments,<br/>because customers are used to companies ignoring them. If you're the rare<br/>exception-- a company that actually listens-- you'll generate fanatical<br/>loyalty. You won't need to advertise, because your users will do it for you.  <br/>  <br/>This seems obvious too, so why do I have to keep repeating it? I think the<br/>problem here is that people get used to how things are. Once a product gets<br/>past the stage where it has glaring flaws, you start to get used to it, and<br/>gradually whatever features it happens to have become its identity. For<br/>example, I doubt many people at Yahoo (or Google for that matter) realized how<br/>much better web mail could be till Paul Buchheit showed them.  <br/>  <br/>I think the solution is to assume that anything you've made is far short of<br/>what it could be. Force yourself, as a sort of intellectual exercise, to keep<br/>thinking of improvements. Ok, sure, what you have is perfect. But if you had<br/>to change something, what would it be?  <br/>  <br/>If your product seems finished, there are two possible explanations: (a) it is<br/>finished, or (b) you lack imagination. Experience suggests (b) is a thousand<br/>times more likely.  <br/>  <br/>**3\. Make Users Happy.**  <br/>  <br/>Improving constantly is an instance of a more general rule: make users happy.<br/>One thing all startups have in common is that they can't force anyone to do<br/>anything. They can't force anyone to use their software, and they can't force<br/>anyone to do deals with them. A startup has to sing for its supper. That's why<br/>the successful ones make great things. They have to, or die.  <br/>  <br/>When you're running a startup you feel like a little bit of debris blown about<br/>by powerful winds. The most powerful wind is users. They can either catch you<br/>and loft you up into the sky, as they did with Google, or leave you flat on<br/>the pavement, as they do with most startups. Users are a fickle wind, but more<br/>powerful than any other. If they take you up, no competitor can keep you down.  <br/>  <br/>As a little piece of debris, the rational thing for you to do is not to lie<br/>flat, but to curl yourself into a shape the wind will catch.  <br/>  <br/>I like the wind metaphor because it reminds you how impersonal the stream of<br/>traffic is. The vast majority of people who visit your site will be casual<br/>visitors. It's them you have to design your site for. The people who really<br/>care will find what they want by themselves.  <br/>  <br/>The median visitor will arrive with their finger poised on the Back button.<br/>Think about your own experience: most links you follow lead to something lame.<br/>Anyone who has used the web for more than a couple weeks has been _trained_ to<br/>click on Back after following a link. So your site has to say "Wait! Don't<br/>click on Back. This site isn't lame. Look at this, for example."  <br/>  <br/>There are two things you have to do to make people pause. The most important<br/>is to explain, as concisely as possible, what the hell your site is about. How<br/>often have you visited a site that seemed to assume you already knew what they<br/>did? For example, the corporate site<br/><br/>Romanian Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>French Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>May 2004  <br/>  <br/>When people care enough about something to do it well, those who do it best<br/>tend to be far better than everyone else. There's a huge gap between Leonardo<br/>and second-rate contemporaries like Borgognone. You see the same gap between<br/>Raymond Chandler and the average writer of detective novels. A top-ranked<br/>professional chess player could play ten thousand games against an ordinary<br/>club player without losing once.  <br/>  <br/>Like chess or painting or writing novels, making money is a very specialized<br/>skill. But for some reason we treat this skill differently. No one complains<br/>when a few people surpass all the rest at playing chess or writing novels, but<br/>when a few people make more money than the rest, we get editorials saying this<br/>is wrong.  <br/>  <br/>Why? The pattern of variation seems no different than for any other skill.<br/>What causes people to react so strongly when the skill is making money?  <br/>  <br/>I think there are three reasons we treat making money as different: the<br/>misleading model of wealth we learn as children; the disreputable way in<br/>which, till recently, most fortunes were accumulated; and the worry that great<br/>variations in income are somehow bad for society. As far as I can tell, the<br/>first is mistaken, the second outdated, and the third empirically false. Could<br/>it be that, in a modern democracy, variation in income is actually a sign of<br/>health?  <br/>  <br/> **The Daddy Model of Wealth**  <br/>  <br/>When I was five I thought electricity was created by electric sockets. I<br/>didn't realize there were power plants out there generating it. Likewise, it<br/>doesn't occur to most kids that wealth is something that has to be generated.<br/>It seems to be something that flows from parents.  <br/>  <br/>Because of the circumstances in which they encounter it, children tend to<br/>misunderstand wealth. They confuse it with money. They think that there is a<br/>fixed amount of it. And they think of it as something that's distributed by<br/>authorities (and so should be distributed equally), rather than something that<br/>has to be created (and might be created unequally).  <br/>  <br/>In fact, wealth is not money. Money is just a convenient way of trading one<br/>form of wealth for another. Wealth is the underlying stuff—the goods and<br/>services we buy. When you travel to a rich or poor country, you don't have to<br/>look at people's bank accounts to tell which kind you're in. You can _see_<br/>wealth—in buildings and streets, in the clothes and the health of the people.  <br/>  <br/>Where does wealth come from? People make it. This was easier to grasp when<br/>most people lived on farms, and made many of the things they wanted with their<br/>own hands. Then you could see in the house, the herds, and the granary the<br/>wealth that each family created. It was obvious then too that the wealth of<br/>the world was not a fixed quantity that had to be shared out, like slices of a<br/>pie. If you wanted more wealth, you could make it.  <br/>  <br/>This is just as true today, though few of us create wealth directly for<br/>ourselves (except for a few vestigial domestic tasks). Mostly we create wealth<br/>for other people in exchange for money, which we then trade for the forms of<br/>wealth we want. [1]  <br/>  <br/>Because kids are unable to create wealth, whatever they have has to be given<br/>to them. And when wealth is something you're given, then of course it seems<br/>that it should be distributed equally. [2] As in most families it is. The kids<br/>see to that. "Unfair," they cry, when one sibling gets more than another.  <br/>  <br/>In the real world, you can't keep living off your parents. If you want<br/>something, you either have to make it, or do something of equivalent value for<br/>someone else, in order to get them to give you enough money to buy it. In the<br/>real world, wealth is (except for a few specialists like thieves and<br/>speculators) something you have to create, not something that's distributed by<br/>Daddy. And since the ability and desire to create it vary from person to<br/>person, it's not made equally.  <br/>  <br/>You get paid by doing or making something people want, and those who make more<br/>money are often simply better at doing what people want. Top actors make a lot<br/>more money than B-list actors. The B-list actors might be almost as<br/>charismatic, but when people go to the theater and look at the list of movies<br/>playing, they want that extra oomph that the big stars have.  <br/>  <br/>Doing what people want is not the only way to get money, of course. You could<br/>also rob banks, or solicit bribes, or establish a monopoly. Such tricks<br/>account for some variation in wealth, and indeed for some of the biggest<br/>individual fortunes, but they are not the root cause of variation in income.<br/>The root cause of variation in income, as Occam's Razor implies, is the same<br/>as the root cause of variation in every other human skill.  <br/>  <br/>In the United States, the CEO of a large public company makes about 100 times<br/>as much as the average person. [3] Basketball players make about 128 times as<br/>much, and baseball players 72 times as much. Editorials quote this kind of<br/>statistic with horror. But I have no trouble imagining that one person could<br/>be 100 times as productive as another. In ancient Rome the price of _slaves_<br/>varied by a factor of 50 depending on their skills. [4] And that's without<br/>considering motivation, or the extra leverage in productivity that you can get<br/>from modern technology.  <br/>  <br/>Editorials about athletes' or CEOs' salaries remind me of early Christian<br/>writers, arguing from first principles about whether the Earth was round, when<br/>they could just walk outside and check. [5] How much someone's work is worth<br/>is not a policy question. It's something the market already determines.  <br/>  <br/>"Are they really worth 100 of us?" editorialists ask. Depends on what you mean<br/>by worth. If you mean worth in the sense of what people will pay for their<br/>skills, the answer is yes, apparently.  <br/>  <br/>A few CEOs' incomes reflect some kind of wrongdoing. But are there not others<br/>whose incomes really do reflect the wealth they generate? Steve Jobs saved a<br/>company that was in a terminal decline. And not merely in the way a turnaround<br/>specialist does, by cutting costs; he had to decide what Apple's next products<br/>should be. Few others could have done it. And regardless of the case with<br/>CEOs, it's hard to see how anyone could argue that the salaries of<br/>professional basketball players don't reflect supply and demand.  <br/>  <br/>It may seem unlikely in principle that one individual could really generate so<br/>much more wealth than another. The key to this mystery is to revisit that<br/>question, are they really worth 100 of us? _Would_ a basketball team trade one<br/>of their players for 100 random people? What would Apple's next product look<br/>like if you replaced Steve Jobs with a committee of 100 random people? [6]<br/>These things don't scale linearly. Perhaps the CEO or the professional athlete<br/>has only ten times (whatever that means) the skill and determination of an<br/>ordinary person. But it makes all the difference that it's concentrated in one<br/>individual.  <br/>  <br/>When we say that one kind of work is overpaid and another underpaid, what are<br/>we really saying? In a free market, prices are determined by what buyers want.<br/>People like baseball more than poetry, so baseball players make more than<br/>poets. To say that a certain kind of work is underpaid is thus identical with<br/>saying that people want the wrong things.  <br/>  <br/>Well, of course people want the wrong things. It seems odd to be surprised by<br/>that. And it seems even odder to say that it's _unjust_ that certain kinds of<br/>work are underpaid. [7] Then you're saying that it's unjust that people want<br/>the wrong things. It's lamentable that people prefer reality TV and corndogs<br/>to Shakespeare and steamed vegetables, but unjust? That seems like saying that<br/>blue is heavy, or that up is circular.  <br/>  <br/>The appearance of the word "unjust" here is the unmistakable spectral<br/>signature of the Daddy Model. Why else would this idea occur in this odd<br/>context? Whereas if the speaker were still operating on the Daddy Model, and<br/>saw wealth as something that flowed from a common source and had to be shared<br/>out, rather than something generated by doing what other people wanted, this<br/>is exactly what you'd get on noticing that some people made much more than<br/>others.  <br/>  <br/>When we talk about "unequal distribution of income," we should also ask, where<br/>does that income come from? [8] Who made the wealth it represents? Because to<br/>the extent that income varies simply according to how much wealth people<br/>create, the distribution may be unequal, but it's hardly unjust.  <br/>  <br/> **Stealing It**  <br/>  <br/>The second reason we tend to find great disparities of wealth alarming is that<br/>for most of human history the usual way to accumulate a fortune was to steal<br/>it: in pastoral societies by cattle raiding; in agricultural societies by<br/>appropriating others' estates in times of war, and taxing them in times of<br/>peace.  <br/>  <br/>In conflicts, those on the winning side would receive the estates confiscated<br/>from the losers. In England in the 1060s, when William the Conqueror<br/>distributed the estates of the defeated Anglo-Saxon nobles to his followers,<br/>the conflict was military. By the 1530s, when Henry VIII distributed the<br/>estates of the monasteries to his followers, it was mostly political. [9] But<br/>the principle was the same. Indeed, the same principle is at work now in<br/>Zimbabwe.  <br/>  <br/>In more organized societies, like China, the ruler and his officials used<br/>taxation instead of confiscation. But here too we see the same principle: the<br/>way to get rich was not to create wealth, but to serve a ruler powerful enough<br/>to appropriate it.  <br/>  <br/>This started to change in Europe with the rise of the middle class. Now we<br/>think of the middle class as people who are neither rich nor poor, but<br/>originally they were a distinct group. In a feudal society, there are just two<br/>classes: a warrior aristocracy, and the serfs who work their estates. The<br/>middle class were a new, third group who lived in towns and supported<br/>themselves by manufacturing and trade.  <br/>  <br/>Starting in the tenth and eleventh centuries, petty nobles and former serfs<br/>banded together in towns that gradually became powerful enough to ignore the<br/>local feudal lords. [10] Like serfs, the middle class made a living largely by<br/>creating wealth. (In port cities like Genoa and Pisa, they also engaged in<br/>piracy.) But unlike serfs they had an incentive to create a lot of it. Any<br/>wealth a serf created belonged to his master. There was not much point in<br/>making more than you could hide. Whereas the independence of the townsmen<br/>allowed them to keep whatever wealth they created.  <br/>  <br/>Once it became possible to get rich by creating wealth, society as a whole<br/>started to get richer very rapidly. Nearly everything we have was created by<br/>the middle class. Indeed, the other two classes have effectively disappeared<br/>in industrial societies, and their names been given to either end of the<br/>middle class. (In the original sense of the word, Bill Gates is middle class.)  <br/>  <br/>But it was not till the Industrial Revolution that wealth creation<br/>definitively replaced corruption as the best way to get rich. In England, at<br/>least, corruption only became unfashionable (and in fact only started to be<br/>called "corruption") when there started to be other, faster ways to get rich.  <br/>  <br/>Seventeenth-century England was much like the third world today, in that<br/>government office was a recognized route to wealth. The great fortunes of that<br/>time still derived more from what we would now call corruption than from<br/>commerce. [11] By the nineteenth century that had changed. There continued to<br/>be bribes, as there still are everywhere, but politics had by then been left<br/>to men who were driven more by vanity than greed. Technology had made it<br/>possible to create wealth faster than you could steal it. The prototypical<br/>rich man of the nineteenth century was not a courtier but an industrialist.  <br/>  <br/>With the rise of the middle class, wealth stopped being a zero-sum game. Jobs<br/>and Wozniak didn't have to make us poor to make themselves rich. Quite the<br/>opposite: they created things that made our lives materially richer. They had<br/>to, or we wouldn't have paid for them.  <br/>  <br/>But since for most of the world's history the main route to wealth was to<br/>steal it, we tend to be suspicious of rich people. Idealistic undergraduates<br/>find their unconsciously preserved child's model of wealth confirmed by<br/>eminent writers of the past. It is a case of the mistaken meeting the<br/>outdated.  <br/>  <br/>"Behind every great fortune, there is a crime," Balzac wrote. Except he<br/>didn't. What he actually said was that a great fortune with no apparent cause<br/>was probably due to a crime well enough executed that it had been forgotten.<br/>If we were talking about Europe in 1000, or most of the third world today, the<br/>standard misquotation would be spot on. But Balzac lived in nineteenth-century<br/>France, where the Industrial Revolution was well advanced. He knew you could<br/>make a fortune without stealing it. After all, he did himself, as a popular<br/>novelist. [12]  <br/>  <br/>Only a few countries (by no coincidence, the richest ones) have reached this<br/>stage. In most, corruption still has the upper hand. In most, the fastest way<br/>to get wealth is by stealing it. And so when we see increasing differences in<br/>income in a rich country, there is a tendency to worry that it's sliding back<br/>toward becoming another Venezuela. I think the opposite is happening. I think<br/>you're seeing a country a full step ahead of Venezuela.  <br/>  <br/> **The Lever of Technology**  <br/>  <br/>Will technology increase the gap between rich and poor? It will certainly<br/>increase the gap between the productive and the unproductive. That's the whole<br/>point of technology. With a tractor an energetic farmer could plow six times<br/>as much land in a day as he could with a team of horses. But only if he<br/>mastered a new kind of farming.  <br/>  <br/>I've seen the lever of technology grow visibly in my own time. In high school<br/>I made money by mowing lawns and scooping ice cream at Baskin-Robbins. This<br/>was the only kind of work available at the time. Now high school kids could<br/>write software or design web sites. But only some of them will; the rest will<br/>still be scooping ice cream.  <br/>  <br/>I remember very vividly when in 1985 improved technology made it possible for<br/>me to buy a computer of my own. Within months I was using it to make money as<br/>a freelance programmer. A few years before, I couldn't have done this. A few<br/>years before, there was no such _thing_ as a freelance programmer. But Apple<br/>created wealth, in the form of powerful, inexpensive computers, and<br/>programmers immediately set to work using it to create more.  <br/>  <br/>As this example suggests, the rate at which technology increases our<br/>productive capacity is probably exponential, rather than linear. So we should<br/>expect to see ever-increasing variation in individual productivity as time<br/>goes on. Will that increase the gap between rich and the poor? Depends which<br/>gap you mean.  <br/>  <br/>Technology should increase the gap in income, but it seems to decrease other<br/>gaps. A hundred years ago, the rich led a different _kind_ of life from<br/>ordinary people. They lived in houses full of servants, wore elaborately<br/>uncomfortable clothes, and travelled about in carriages drawn by teams of<br/>horses which themselves required their own houses and servants. Now, thanks to<br/>technology, the rich live more like the average person.  <br/>  <br/>Cars are a good example of why. It's possible to buy expensive, handmade cars<br/>that cost hundreds of thousands of dollars. But there is not much point.<br/>Companies make more money by building a large number of ordinary cars than a<br/>small number of expensive ones. So a company making a mass-produced car can<br/>afford to spend a lot more on its design. If you buy a custom-made car,<br/>something will always be breaking. The only point of buying one now is to<br/>advertise that you can.  <br/>  <br/>Or consider watches. Fifty years ago, by spending a lot of money on a watch<br/>you could get better performance. When watches had mechanical movements,<br/>expensive watches kept better time. Not any more. Since the invention of the<br/>quartz movement, an ordinary Timex is more accurate than a Patek Philippe<br/>costing hundreds of thousands of dollars. [13] Indeed, as with expensive cars,<br/>if you're determined to spend a lot of money on a watch, you have to put up<br/>with some inconvenience to do it: as well as keeping worse time, mechanical<br/>watches have to be wound.  <br/>  <br/>The only thing technology can't cheapen is brand. Which is precisely why we<br/>hear ever more about it. Brand is the residue left as the substantive<br/>differences between rich and poor evaporate. But what label you have on your<br/>stuff is a much smaller matter than having it versus not having it. In 1900,<br/>if you kept a carriage, no one asked what year or brand it was. If you had<br/>one, you were rich. And if you weren't rich, you took the omnibus or walked.<br/>Now even the poorest Americans drive cars, and it is only because we're so<br/>well trained by advertising that we can even recognize the especially<br/>expensive ones. [14]  <br/>  <br/>The same pattern has played out in industry after industry. If there is enough<br/>demand for something, technology will make it cheap enough to sell in large<br/>volumes, and the mass-produced versions will be, if not better, at least more<br/>convenient. [15] And there is nothing the rich like more than convenience. The<br/>rich people I know drive the same cars, wear the same clothes, have the same<br/>kind of furniture, and eat the same foods as my other friends. Their houses<br/>are in different neighborhoods, or if in the same neighborhood are different<br/>sizes, but within them life is similar. The houses are made using the same<br/>construction techniques and contain much the same objects. It's inconvenient<br/>to do something expensive and custom.  <br/>  <br/>The rich spend their time more like everyone else too. Bertie Wooster seems<br/>long gone. Now, most people who are rich enough not to work do anyway. It's<br/>not just social pressure that makes them; idleness is lonely and demoralizing.  <br/>  <br/>Nor do we have the social distinctions there were a hundred years ago. The<br/>novels and etiquette manuals of that period read now like descriptions of some<br/>strange tribal society. "With respect to the continuance of friendships..."<br/>hints _Mrs. Beeton's Book of Household Management_ (1880), "it may be found<br/>necessary, in some cases, for a mistress to relinquish, on assuming the<br/>responsibility of a household, many of those commenced in the earlier part of<br/>her life." A woman who married a rich man was expected to drop friends who<br/>didn't. You'd seem a barbarian if you behaved that way today. You'd also have<br/>a very boring life. People still tend to segregate themselves somewhat, but<br/>much more on the basis of education than wealth. [16]  <br/>  <br/>Materially and socially, technology seems to be decreasing the gap between the<br/>rich and the poor, not increasing it. If Lenin walked around the offices of a<br/>company like Yahoo or Intel or Cisco, he'd think communism had won. Everyone<br/>would be wearing the same clothes, have the same kind of office (or rather,<br/>cubicle) with the same furnishings, and address one another by their first<br/>names instead of by honorifics. Everything would seem exactly as he'd<br/>predicted, until he looked at their bank accounts. Oops.  <br/>  <br/>Is it a problem if technology increases that gap? It doesn't seem to be so<br/>far. As it increases the gap in income, it seems to decrease most other gaps.  <br/>  <br/> **Alternative to an Axiom**  <br/>  <br/>One often hears a policy criticized on the grounds that it would increase the<br/>income gap between rich and poor. As if it were an axiom that this would be<br/>bad. It might be true that increased variation in income would be bad, but I<br/>don't see how we can say it's _axiomatic._  <br/>  <br/>Indeed, it may even be false, in industrial democracies. In a society of serfs<br/>and warlords, certainly, variation in income is a sign of an underlying<br/>problem. But serfdom is not the only cause of variation in income. A 747 pilot<br/>doesn't make 40 times as much as a checkout clerk because he is a warlord who<br/>somehow holds her in thrall. His skills are simply much more valuable.  <br/>  <br/>I'd like to propose an alternative idea: that in a modern society, increasing<br/>variation in income is a sign of health. Technology seems to increase the<br/>variation in productivity at faster than linear rates. If we don't see<br/>corresponding variation in income, there are three possible explanations: (a)<br/>that technical innovation has stopped, (b) that the people who would create<br/>the most wealth aren't doing it, or (c) that they aren't getting paid for it.  <br/>  <br/>I think we can safely say that (a) and (b) would be bad. If you disagree, try<br/>living for a year using only the resources available to the average Frankish<br/>nobleman in 800, and report back to us. (I'll be generous and not send you<br/>back to the stone age.)  <br/>  <br/>The only option, if you're going to have an increasingly prosperous society<br/>without increasing variation in income, seems to be (c), that people will<br/>create a lot of wealth without being paid for it. That Jobs and Wozniak, for<br/>example, will cheerfully work 20-hour days to produce the Apple computer for a<br/>society that allows them, after taxes, to keep just enough of their income to<br/>match what they would have made working 9 to 5 at a big company.  <br/>  <br/>Will people create wealth if they can't get paid for it? Only if it's fun.<br/>People will write operating systems for free. But they won't install them, or<br/>take support calls, or train customers to use them. And at least 90% of the<br/>work that even the highest tech companies do is of this second, unedifying<br/>kind.  <br/>  <br/>All the unfun kinds of wealth creation slow dramatically in a society that<br/>confiscates private fortunes. We can confirm this empirically. Suppose you<br/>hear a strange noise that you think may be due to a nearby fan. You turn the<br/>fan off, and the noise stops. You turn the fan back on, and the noise starts<br/>again. Off, quiet. On, noise. In the absence of other information, it would<br/>seem the noise is caused by the fan.  <br/>  <br/>At various times and places in history, whether you could accumulate a fortune<br/>by creating wealth has been turned on and off. Northern Italy in 800, off<br/>(warlords would steal it). Northern Italy in 1100, on. Central France in 1100,<br/>off (still feudal). England in 1800, on. England in 1974, off (98% tax on<br/>investment income). United States in 1974, on. We've even had a twin study:<br/>West Germany, on; East Germany, off. In every case, the creation of wealth<br/>seems to appear and disappear like the noise of a fan as you switch on and off<br/>the prospect of keeping it.  <br/>  <br/>There is some momentum involved. It probably takes at least a generation to<br/>turn people into East Germans (luckily for England). But if it were merely a<br/>fan we were studying, without all the extra baggage that comes from the<br/>controversial topic of wealth, no one would have any doubt that the fan was<br/>causing the noise.  <br/>  <br/>If you suppress variations in income, whether by stealing private fortunes, as<br/>feudal rulers used to do, or by taxing them away, as some modern governments<br/>have done, the result always seems to be the same. Society as a whole ends up<br/>poorer.  <br/>  <br/>If I had a choice of living in a society where I was materially much better<br/>off than I am now, but was among the poorest, or in one where I was the<br/>richest, but much worse off than I am now, I'd take the first option. If I had<br/>children, it would arguably be immoral not to. It's absolute poverty you want<br/>to avoid, not relative poverty. If, as the evidence so far implies, you have<br/>to have one or the other in your society, take relative poverty.  <br/>  <br/>You need rich people in your society not so much because in spending their<br/>money they create jobs, but because of what they have to do to _get_ rich. I'm<br/>not talking about the trickle-down effect here. I'm not saying that if you let<br/>Henry Ford get rich, he'll hire you as a waiter at his next party. I'm saying<br/>that he'll make you a tractor to replace your horse.  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Part of the reason this subject is so contentious is that some of those<br/>most vocal on the subject of wealth—university students, heirs, professors,<br/>politicians, and journalists—have the least experience creating it. (This<br/>phenomenon will be familiar to anyone who has overheard conversations about<br/>sports in a bar.)  <br/>  <br/>Students are mostly still on the parental dole, and have not stopped to think<br/>about where that money comes from. Heirs will be on the parental dole for<br/>life. Professors and politicians live within socialist eddies of the economy,<br/>at one remove from the creation of wealth, and are paid a flat rate regardless<br/>of how hard they work. And journalists as part of their professional code<br/>segregate themselves from the revenue-collecting half of the businesses they<br/>work for (the ad sales department). Many of these people never come face to<br/>face with the fact that the money they receive represents wealth—wealth that,<br/>except in the case of journalists, someone else created earlier. They live in<br/>a world in which income _is_ doled out by a central authority according to<br/>some abstract notion of fairness (or randomly, in the case of heirs), rather<br/>than given by other people in return for something they wanted, so it may seem<br/>to them unfair that things don't work the same in the rest of the economy.  <br/>  <br/>(Some professors do create a great deal of wealth for society. But the money<br/>they're paid isn't a _quid pro quo_. It's more in the nature of an<br/>investment.)  <br/>  <br/>[2] When one reads about the origins of the Fabian Society, it sounds like<br/>something cooked up by the high-minded Edwardian child-heroes of Edith<br/>Nesbit's _The Wouldbegoods_.  <br/>  <br/>[3] According to a study by the Corporate Library, the median total<br/>compensation, including salary, bonus, stock grants, and the exercise of stock<br/>options, of S&P 500 CEOs in 2002 was $3.65 million. According to _Sports<br/>Illustrated_ , the average NBA player's salary during the 2002-03 season was<br/>$4.54 million, and the average major league baseball player's salary at the<br/>start of the 2003 season was $2.56 million. According to the Bureau of Labor<br/>Statistics, the mean annual wage in the US in 2002 was $35,560.  <br/>  <br/>[4] In the early empire the price of an ordinary adult slave seems to have<br/>been about 2,000 sestertii (e.g. Horace, _Sat._ ii.7.43). A servant girl cost<br/>600 (Martial vi.66), while Columella (iii.3.8) says that a skilled vine-<br/>dresser was worth 8,000. A doctor, P. Decimus Eros Merula, paid 50,000<br/>sestertii for his freedom (Dessau, _Inscriptiones_ 7812). Seneca ( _Ep._<br/>xxvii.7) reports that one Calvisius Sabinus paid 100,000 sestertii apiece for<br/>slaves learned in the Greek classics. Pliny ( _Hist. Nat._ vii.39) says that<br/>the highest price paid for a slave up to his time was 700,000 sestertii, for<br/>the linguist (and presumably teacher) Daphnis, but that this had since been<br/>exceeded by actors buying their own freedom.  <br/>  <br/>Classical Athens saw a similar variation in prices. An ordinary laborer was<br/>worth about 125 to 150 drachmae. Xenophon ( _Mem._ ii.5) mentions prices<br/>ranging from 50 to 6,000 drachmae (for the manager of a silver mine).  <br/>  <br/>For more on the economics of ancient slavery see:  <br/>  <br/>Jones, A. H. M., "Slavery in the Ancient World," _Economic History Review_ ,<br/>2:9 (1956), 185-199, reprinted in Finley, M. I. (ed.), _Slavery in Classical<br/>Antiquity_ , Heffer, 1964.  <br/>  <br/>[5] Eratosthenes (276—195 BC) used shadow lengths in different cities to<br/>estimate the Earth's circumference. He was off by only about 2%.  <br/>  <br/>[6] No, and Windows, respectively.  <br/>  <br/>[7] One of the biggest divergences between the Daddy Model and reality is the<br/>valuation of hard work. In the Daddy Model, hard work is in itself deserving.<br/>In reality, wealth is measured by what one delivers, not how much effort it<br/>costs. If I paint someone's house, the owner shouldn't pay me extra for doing<br/>it with a toothbrush.  <br/>  <br/>It will seem to someone still implicitly operating on the Daddy Model that it<br/>is unfair when someone works hard and doesn't get paid much. To help clarify<br/>the matter, get rid of everyone else and put our worker on a desert island,<br/>hunting and gathering fruit. If he's bad at it he'll work very hard and not<br/>end up with much food. Is this unfair? Who is being unfair to him?  <br/>  <br/>[8] Part of the reason for the tenacity of the Daddy Model may be the dual<br/>meaning of "distribution." When economists talk about "distribution of<br/>income," they mean statistical distribution. But when you use the phrase<br/>frequently, you can't help associating it with the other sense of the word (as<br/>in e.g. "distribution of alms"), and thereby subconsciously seeing wealth as<br/>something that flows from some central tap. The word "regressive" as applied<br/>to tax rates has a similar effect, at least on me; how can anything<br/>_regressive_ be good?  <br/>  <br/>[9] "From the beginning of the reign Thomas Lord Roos was an assiduous<br/>courtier of the young Henry VIII and was soon to reap the rewards. In 1525 he<br/>was made a Knight of the Garter and given the Earldom of Rutland. In the<br/>thirties his support of the breach with Rome, his zeal in crushing the<br/>Pilgrimage of Grace, and his readiness to vote the death-penalty in the<br/>succession of spectacular treason trials that punctuated Henry's erratic<br/>matrimonial progress made him an obvious candidate for grants of monastic<br/>property."  <br/>  <br/>Stone, Lawrence, _Family and Fortune: Studies in Aristocratic Finance in the<br/>Sixteenth and Seventeenth Centuries_ , Oxford University Press, 1973, p. 166.  <br/>  <br/>[10] There is archaeological evidence for large settlements earlier, but it's<br/>hard to say what was happening in them.  <br/>  <br/>Hodges, Richard and David Whitehouse, _Mohammed, Charlemagne and the Origins<br/>of Europe_ , Cornell University Press, 1983.  <br/>  <br/>[11] William Cecil and his son Robert were each in turn the most powerful<br/>minister of the crown, and both used their position to amass fortunes among<br/>the largest of their times. Robert in particular took bribery to the point of<br/>treason. "As Secretary of State and the leading advisor to King James on<br/>foreign policy, [he] was a special recipient of favour, being offered large<br/>bribes by the Dutch not to make peace with Spain, and large bribes by Spain to<br/>make peace." (Stone, _op. cit._ , p. 17.)  <br/>  <br/>[12] Though Balzac made a lot of money from writing, he was notoriously<br/>improvident and was troubled by debts all his life.  <br/>  <br/>[13] A Timex will gain or lose about .5 seconds per day. The most accurate<br/>mechanical watch, the Patek Philippe 10 Day Tourbillon, is rated at -1.5 to +2<br/>seconds. Its retail price is about $220,000.  <br/>  <br/>[14] If asked to choose which was more expensive, a well-preserved 1989<br/>Lincoln Town Car ten-passenger limousine ($5,000) or a 2004 Mercedes S600<br/>sedan ($122,000), the average Edwardian might well guess wrong.  <br/>  <br/>[15] To say anything meaningful about income trends, you have to talk about<br/>real income, or income as measured in what it can buy. But the usual way of<br/>calculating real income ignores much of the growth in wealth over time,<br/>because it depends on a consumer price index created by bolting end to end a<br/>series of numbers that are only locally accurate, and that don't include the<br/>prices of new inventions until they become so common that their prices<br/>stabilize.  <br/>  <br/>So while we might think it was very much better to live in a world with<br/>antibiotics or air travel or an electric power grid than without, real income<br/>statistics calculated in the usual way will prove to us that we are only<br/>slightly richer for having these things.  <br/>  <br/>Another approach would be to ask, if you were going back to the year x in a<br/>time machine, how much would you have to spend on trade goods to make your<br/>fortune? For example, if you were going back to 1970 it would certainly be<br/>less than $500, because the processing power you can get for $500 today would<br/>have been worth at least $150 million in 1970. The function goes asymptotic<br/>fairly quickly, because for times over a hundred years or so you could get all<br/>you needed in present-day trash. In 1800 an empty plastic drink bottle with a<br/>screw top would have seemed a miracle of workmanship.  <br/>  <br/>[16] Some will say this amounts to the same thing, because the rich have<br/>better opportunities for education. That's a valid point. It is still<br/>possible, to a degree, to buy your kids' way into top colleges by sending them<br/>to private schools that in effect hack the college admissions process.  <br/>  <br/>According to a 2002 report by the National Center for Education Statistics,<br/>about 1.7% of American kids attend private, non-sectarian schools. At<br/>Princeton, 36% of the class of 2007 came from such schools. (Interestingly,<br/>the number at Harvard is significantly lower, about 28%.) Obviously this is a<br/>huge loophole. It does at least seem to be closing, not widening.  <br/>  <br/>Perhaps the designers of admissions processes should take a lesson from the<br/>example of computer security, and instead of just assuming that their system<br/>can't be hacked, measure the degree to which it is.  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>July 2013  <br/>  <br/>One of the most common types of advice we give at Y Combinator is to do things<br/>that don't scale. A lot of would-be founders believe that startups either take<br/>off or don't. You build something, make it available, and if you've made a<br/>better mousetrap, people beat a path to your door as promised. Or they don't,<br/>in which case the market must not exist. [1]  <br/>  <br/>Actually startups take off because the founders make them take off. There may<br/>be a handful that just grew by themselves, but usually it takes some sort of<br/>push to get them going. A good metaphor would be the cranks that car engines<br/>had before they got electric starters. Once the engine was going, it would<br/>keep going, but there was a separate and laborious process to get it going.  <br/>  <br/> **Recruit**  <br/>  <br/>The most common unscalable thing founders have to do at the start is to<br/>recruit users manually. Nearly all startups have to. You can't wait for users<br/>to come to you. You have to go out and get them.  <br/>  <br/>Stripe is one of the most successful startups we've funded, and the problem<br/>they solved was an urgent one. If anyone could have sat back and waited for<br/>users, it was Stripe. But in fact they're famous within YC for aggressive<br/>early user acquisition.  <br/>  <br/>Startups building things for other startups have a big pool of potential users<br/>in the other companies we've funded, and none took better advantage of it than<br/>Stripe. At YC we use the term "Collison installation" for the technique they<br/>invented. More diffident founders ask "Will you try our beta?" and if the<br/>answer is yes, they say "Great, we'll send you a link." But the Collison<br/>brothers weren't going to wait. When anyone agreed to try Stripe they'd say<br/>"Right then, give me your laptop" and set them up on the spot.  <br/>  <br/>There are two reasons founders resist going out and recruiting users<br/>individually. One is a combination of shyness and laziness. They'd rather sit<br/>at home writing code than go out and talk to a bunch of strangers and probably<br/>be rejected by most of them. But for a startup to succeed, at least one<br/>founder (usually the CEO) will have to spend a lot of time on sales and<br/>marketing. [2]  <br/>  <br/>The other reason founders ignore this path is that the absolute numbers seem<br/>so small at first. This can't be how the big, famous startups got started,<br/>they think. The mistake they make is to underestimate the power of compound<br/>growth. We encourage every startup to measure their progress by weekly growth<br/>rate. If you have 100 users, you need to get 10 more next week to grow 10% a<br/>week. And while 110 may not seem much better than 100, if you keep growing at<br/>10% a week you'll be surprised how big the numbers get. After a year you'll<br/>have 14,000 users, and after 2 years you'll have 2 million.  <br/>  <br/>You'll be doing different things when you're acquiring users a thousand at a<br/>time, and growth has to slow down eventually. But if the market exists you can<br/>usually start by recruiting users manually and then gradually switch to less<br/>manual methods. [3]  <br/>  <br/>Airbnb is a classic example of this technique. Marketplaces are so hard to get<br/>rolling that you should expect to take heroic measures at first. In Airbnb's<br/>case, these consisted of going door to door in New York, recruiting new users<br/>and helping existing ones improve their listings. When I remember the Airbnbs<br/>during YC, I picture them with rolly bags, because when they showed up for<br/>tuesday dinners they'd always just flown back from somewhere.  <br/>  <br/> **Fragile**  <br/>  <br/>Airbnb now seems like an unstoppable juggernaut, but early on it was so<br/>fragile that about 30 days of going out and engaging in person with users made<br/>the difference between success and failure.  <br/>  <br/>That initial fragility was not a unique feature of Airbnb. Almost all startups<br/>are fragile initially. And that's one of the biggest things inexperienced<br/>founders and investors (and reporters and know-it-alls on forums) get wrong<br/>about them. They unconsciously judge larval startups by the standards of<br/>established ones. They're like someone looking at a newborn baby and<br/>concluding "there's no way this tiny creature could ever accomplish anything."  <br/>  <br/>It's harmless if reporters and know-it-alls dismiss your startup. They always<br/>get things wrong. It's even ok if investors dismiss your startup; they'll<br/>change their minds when they see growth. The big danger is that you'll dismiss<br/>your startup yourself. I've seen it happen. I often have to encourage founders<br/>who don't see the full potential of what they're building. Even Bill Gates<br/>made that mistake. He returned to Harvard for the fall semester after starting<br/>Microsoft. He didn't stay long, but he wouldn't have returned at all if he'd<br/>realized Microsoft was going to be even a fraction of the size it turned out<br/>to be. [4]  <br/>  <br/>The question to ask about an early stage startup is not "is this company<br/>taking over the world?" but "how big could this company get if the founders<br/>did the right things?" And the right things often seem both laborious and<br/>inconsequential at the time. Microsoft can't have seemed very impressive when<br/>it was just a couple guys in Albuquerque writing Basic interpreters for a<br/>market of a few thousand hobbyists (as they were then called), but in<br/>retrospect that was the optimal path to dominating microcomputer software. And<br/>I know Brian Chesky and Joe Gebbia didn't feel like they were en route to the<br/>big time as they were taking "professional" photos of their first hosts'<br/>apartments. They were just trying to survive. But in retrospect that too was<br/>the optimal path to dominating a big market.  <br/>  <br/>How do you find users to recruit manually? If you build something to solve<br/>your own problems, then you only have to find your peers, which is usually<br/>straightforward. Otherwise you'll have to make a more deliberate effort to<br/>locate the most promising vein of users. The usual way to do that is to get<br/>some initial set of users by doing a comparatively untargeted launch, and then<br/>to observe which kind seem most enthusiastic, and seek out more like them. For<br/>example, Ben Silbermann noticed that a lot of the earliest Pinterest users<br/>were interested in design, so he went to a conference of design bloggers to<br/>recruit users, and that worked well. [5]  <br/>  <br/> **Delight**  <br/>  <br/>You should take extraordinary measures not just to acquire users, but also to<br/>make them happy. For as long as they could (which turned out to be<br/>surprisingly long), Wufoo sent each new user a hand-written thank you note.<br/>Your first users should feel that signing up with you was one of the best<br/>choices they ever made. And you in turn should be racking your brains to think<br/>of new ways to delight them.  <br/>  <br/>Why do we have to teach startups this? Why is it counterintuitive for<br/>founders? Three reasons, I think.  <br/>  <br/>One is that a lot of startup founders are trained as engineers, and customer<br/>service is not part of the training of engineers. You're supposed to build<br/>things that are robust and elegant, not be slavishly attentive to individual<br/>users like some kind of salesperson. Ironically, part of the reason<br/>engineering is traditionally averse to handholding is that its traditions date<br/>from a time when engineers were less powerful — when they were only in charge<br/>of their narrow domain of building things, rather than running the whole show.<br/>You can be ornery when you're Scotty, but not when you're Kirk.  <br/>  <br/>Another reason founders don't focus enough on individual customers is that<br/>they worry it won't scale. But when founders of larval startups worry about<br/>this, I point out that in their current state they have nothing to lose. Maybe<br/>if they go out of their way to make existing users super happy, they'll one<br/>day have too many to do so much for. That would be a great problem to have.<br/>See if you can make it happen. And incidentally, when it does, you'll find<br/>that delighting customers scales better than you expected. Partly because you<br/>can usually find ways to make anything scale more than you would have<br/>predicted, and partly because delighting customers will by then have permeated<br/>your culture.  <br/>  <br/>I have never once seen a startup lured down a blind alley by trying too hard<br/>to make their initial users happy.  <br/>  <br/>But perhaps the biggest thing preventing founders from realizing how attentive<br/>they could be to their users is that they've never experienced such attention<br/>themselves. Their standards for customer service have been set by the<br/>companies they've been customers of, which are mostly big ones. Tim Cook<br/>doesn't send you a hand-written note after you buy a laptop. He can't. But you<br/>can. That's one advantage of being small: you can provide a level of service<br/>no big company can. [6]  <br/>  <br/>Once you realize that existing conventions are not the upper bound on user<br/>experience, it's interesting in a very pleasant way to think about how far you<br/>could go to delight your users.  <br/>  <br/> **Experience**  <br/>  <br/>I was trying to think of a phrase to convey how extreme your attention to<br/>users should be, and I realized Steve Jobs had already done it: insanely<br/>great. Steve wasn't just using "insanely" as a synonym for "very." He meant it<br/>more literally — that one should focus on quality of execution to a degree<br/>that in everyday life would be considered pathological.  <br/>  <br/>All the most successful startups we've funded have, and that probably doesn't<br/>surprise would-be founders. What novice founders don't get is what insanely<br/>great translates to in a larval startup. When Steve Jobs started using that<br/>phrase, Apple was already an established company. He meant the Mac (and its<br/>documentation and even packaging — such is the nature of obsession) should be<br/>insanely well designed and manufactured. That's not hard for engineers to<br/>grasp. It's just a more extreme version of designing a robust and elegant<br/>product.  <br/>  <br/>What founders have a hard time grasping (and Steve himself might have had a<br/>hard time grasping) is what insanely great morphs into as you roll the time<br/>slider back to the first couple months of a startup's life. It's not the<br/>product that should be insanely great, but the experience of being your user.<br/>The product is just one component of that. For a big company it's necessarily<br/>the dominant one. But you can and should give users an insanely great<br/>experience with an early, incomplete, buggy product, if you make up the<br/>difference with attentiveness.  <br/>  <br/>Can, perhaps, but should? Yes. Over-engaging with early users is not just a<br/>permissible technique for getting growth rolling. For most successful startups<br/>it's a necessary part of the feedback loop that makes the product good. Making<br/>a better mousetrap is not an atomic operation. Even if you start the way most<br/>successful startups have, by building something you yourself need, the first<br/>thing you build is never quite right. And except in domains with big penalties<br/>for making mistakes, it's often better not to aim for perfection initially. In<br/>software, especially, it usually works best to get something in front of users<br/>as soon as it has a quantum of utility, and then see what they do with it.<br/>Perfectionism is often an excuse for procrastination, and in any case your<br/>initial model of users is always inaccurate, even if you're one of them. [7]  <br/>  <br/>The feedback you get from engaging directly with your earliest users will be<br/>the best you ever get. When you're so big you have to resort to focus groups,<br/>you'll wish you could go over to your users' homes and offices and watch them<br/>use your stuff like you did when there were only a handful of them.  <br/>  <br/> **Fire**  <br/>  <br/>Sometimes the right unscalable trick is to focus on a deliberately narrow<br/>market. It's like keeping a fire contained at first to get it really hot<br/>before adding more logs.  <br/>  <br/>That's what Facebook did. At first it was just for Harvard students. In that<br/>form it only had a potential market of a few thousand people, but because they<br/>felt it was really for them, a critical mass of them signed up. After Facebook<br/>stopped being for Harvard students, it remained for students at specific<br/>colleges for quite a while. When I interviewed Mark Zuckerberg at Startup<br/>School, he said that while it was a lot of work creating course lists for each<br/>school, doing that made students feel the site was their natural home.  <br/>  <br/>Any startup that could be described as a marketplace usually has to start in a<br/>subset of the market, but this can work for other startups as well. It's<br/>always worth asking if there's a subset of the market in which you can get a<br/>critical mass of users quickly. [8]  <br/>  <br/>Most startups that use the contained fire strategy do it unconsciously. They<br/>build something for themselves and their friends, who happen to be the early<br/>adopters, and only realize later that they could offer it to a broader market.<br/>The strategy works just as well if you do it unconsciously. The biggest danger<br/>of not being consciously aware of this pattern is for those who naively<br/>discard part of it. E.g. if you don't build something for yourself and your<br/>friends, or even if you do, but you come from the corporate world and your<br/>friends are not early adopters, you'll no longer have a perfect initial market<br/>handed to you on a platter.  <br/>  <br/>Among companies, the best early adopters are usually other startups. They're<br/>more open to new things both by nature and because, having just been started,<br/>they haven't made all their choices yet. Plus when they succeed they grow<br/>fast, and you with them. It was one of many unforeseen advantages of the YC<br/>model (and specifically of making YC big) that B2B startups now have an<br/>instant market of hundreds of other startups ready at hand.  <br/>  <br/> **Meraki**  <br/>  <br/>For hardware startups there's a variant of doing things that don't scale that<br/>we call "pulling a Meraki." Although we didn't fund Meraki, the founders were<br/>Robert Morris's grad students, so we know their history. They got started by<br/>doing something that really doesn't scale: assembling their routers<br/>themselves.  <br/>  <br/>Hardware startups face an obstacle that software startups don't. The minimum<br/>order for a factory production run is usually several hundred thousand<br/>dollars. Which can put you in a catch-22: without a product you can't generate<br/>the growth you need to raise the money to manufacture your product. Back when<br/>hardware startups had to rely on investors for money, you had to be pretty<br/>convincing to overcome this. The arrival of crowdfunding (or more precisely,<br/>preorders) has helped a lot. But even so I'd advise startups to pull a Meraki<br/>initially if they can. That's what Pebble did. The Pebbles assembled the first<br/>several hundred watches themselves. If they hadn't gone through that phase,<br/>they probably wouldn't have sold $10 million worth of watches when they did go<br/>on Kickstarter.  <br/>  <br/>Like paying excessive attention to early customers, fabricating things<br/>yourself turns out to be valuable for hardware startups. You can tweak the<br/>design faster when you're the factory, and you learn things you'd never have<br/>known otherwise. Eric Migicovsky of Pebble said one of things he learned was<br/>"how valuable it was to source good screws." Who knew?  <br/>  <br/> **Consult**  <br/>  <br/>Sometimes we advise founders of B2B startups to take over-engagement to an<br/>extreme, and to pick a single user and act as if they were consultants<br/>building something just for that one user. The initial user serves as the form<br/>for your mold; keep tweaking till you fit their needs perfectly, and you'll<br/>usually find you've made something other users want too. Even if there aren't<br/>many of them, there are probably adjacent territories that have more. As long<br/>as you can find just one user who really needs something and can act on that<br/>need, you've got a toehold in making something people want, and that's as much<br/>as any startup needs initially. [9]  <br/>  <br/>Consulting is the canonical example of work that doesn't scale. But (like<br/>other ways of bestowing one's favors liberally) it's safe to do it so long as<br/>you're not being paid to. That's where companies cross the line. So long as<br/>you're a product company that's merely being extra attentive to a customer,<br/>they're very grateful even if you don't solve all their problems. But when<br/>they start paying you specifically for that attentiveness — when they start<br/>paying you by the hour — they expect you to do everything.  <br/>  <br/>Another consulting-like technique for recruiting initially lukewarm users is<br/>to use your software yourselves on their behalf. We did that at Viaweb. When<br/>we approached merchants asking if they wanted to use our software to make<br/>online stores, some said no, but they'd let us make one for them. Since we<br/>would do anything to get users, we did. We felt pretty lame at the time.<br/>Instead of organizing big strategic e-commerce partnerships, we were trying to<br/>sell luggage and pens and men's shirts. But in retrospect it was exactly the<br/>right thing to do, because it taught us how it would feel to merchants to use<br/>our software. Sometimes the feedback loop was near instantaneous: in the<br/>middle of building some merchant's site I'd find I needed a feature we didn't<br/>have, so I'd spend a couple hours implementing it and then resume building the<br/>site.  <br/>  <br/> **Manual**  <br/>  <br/>There's a more extreme variant where you don't just use your software, but are<br/>your software. When you only have a small number of users, you can sometimes<br/>get away with doing by hand things that you plan to automate later. This lets<br/>you launch faster, and when you do finally automate yourself out of the loop,<br/>you'll know exactly what to build because you'll have muscle memory from doing<br/>it yourself.  <br/>  <br/>When manual components look to the user like software, this technique starts<br/>to have aspects of a practical joke. For example, the way Stripe delivered<br/>"instant" merchant accounts to its first users was that the founders manually<br/>signed them up for traditional merchant accounts behind the scenes.  <br/>  <br/>Some startups could be entirely manual at first. If you can find someone with<br/>a problem that needs solving and you can solve it manually, go ahead and do<br/>that for as long as you can, and then gradually automate the bottlenecks. It<br/>would be a little frightening to be solving users' problems in a way that<br/>wasn't yet automatic, but less frightening than the far more common case of<br/>having something automatic that doesn't yet solve anyone's problems.  <br/>  <br/> **Big**  <br/>  <br/>I should mention one sort of initial tactic that usually doesn't work: the Big<br/>Launch. I occasionally meet founders who seem to believe startups are<br/>projectiles rather than powered aircraft, and that they'll make it big if and<br/>only if they're launched with sufficient initial velocity. They want to launch<br/>simultaneously in 8 different publications, with embargoes. And on a tuesday,<br/>of course, since they read somewhere that's the optimum day to launch<br/>something.  <br/>  <br/>It's easy to see how little launches matter. Think of some successful<br/>startups. How many of their launches do you remember? All you need from a<br/>launch is some initial core of users. How well you're doing a few months later<br/>will depend more on how happy you made those users than how many there were of<br/>them. [10]  <br/>  <br/>So why do founders think launches matter? A combination of solipsism and<br/>laziness. They think what they're building is so great that everyone who hears<br/>about it will immediately sign up. Plus it would be so much less work if you<br/>could get users merely by broadcasting your existence, rather than recruiting<br/>them one at a time. But even if what you're building really is great, getting<br/>users will always be a gradual process — partly because great things are<br/>usually also novel, but mainly because users have other things to think about.  <br/>  <br/>Partnerships too usually don't work. They don't work for startups in general,<br/>but they especially don't work as a way to get growth started. It's a common<br/>mistake among inexperienced founders to believe that a partnership with a big<br/>company will be their big break. Six months later they're all saying the same<br/>thing: that was way more work than we expected, and we ended up getting<br/>practically nothing out of it. [11]  <br/>  <br/>It's not enough just to do something extraordinary initially. You have to make<br/>an extraordinary _effort_ initially. Any strategy that omits the effort —<br/>whether it's expecting a big launch to get you users, or a big partner — is<br/>ipso facto suspect.  <br/>  <br/> **Vector**  <br/>  <br/>The need to do something unscalably laborious to get started is so nearly<br/>universal that it might be a good idea to stop thinking of startup ideas as<br/>scalars. Instead we should try thinking of them as pairs of what you're going<br/>to build, plus the unscalable thing(s) you're going to do initially to get the<br/>company going.  <br/>  <br/>It could be interesting to start viewing startup ideas this way, because now<br/>that there are two components you can try to be imaginative about the second<br/>as well as the first. But in most cases the second component will be what it<br/>usually is — recruit users manually and give them an overwhelmingly good<br/>experience — and the main benefit of treating startups as vectors will be to<br/>remind founders they need to work hard in two dimensions. [12]  <br/>  <br/>In the best case, both components of the vector contribute to your company's<br/>DNA: the unscalable things you have to do to get started are not merely a<br/>necessary evil, but change the company permanently for the better. If you have<br/>to be aggressive about user acquisition when you're small, you'll probably<br/>still be aggressive when you're big. If you have to manufacture your own<br/>hardware, or use your software on users's behalf, you'll learn things you<br/>couldn't have learned otherwise. And most importantly, if you have to work<br/>hard to delight users when you only have a handful of them, you'll keep doing<br/>it when you have a lot.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Actually Emerson never mentioned mousetraps specifically. He wrote "If a<br/>man has good corn or wood, or boards, or pigs, to sell, or can make better<br/>chairs or knives, crucibles or church organs, than anybody else, you will find<br/>a broad hard-beaten road to his house, though it be in the woods."  <br/>  <br/>[2] Thanks to Sam Altman for suggesting I make this explicit. And no, you<br/>can't avoid doing sales by hiring someone to do it for you. You have to do<br/>sales yourself initially. Later you can hire a real salesperson to replace<br/>you.  <br/>  <br/>[3] The reason this works is that as you get bigger, your size helps you grow.<br/>Patrick Collison wrote "At some point, there was a very noticeable change in<br/>how Stripe felt. It tipped from being this boulder we had to push to being a<br/>train car that in fact had its own momentum."  <br/>  <br/>[4] One of the more subtle ways in which YC can help founders is by<br/>calibrating their ambitions, because we know exactly how a lot of successful<br/>startups looked when they were just getting started.  <br/>  <br/>[5] If you're building something for which you can't easily get a small set of<br/>users to observe — e.g. enterprise software — and in a domain where you have<br/>no connections, you'll have to rely on cold calls and introductions. But<br/>should you even be working on such an idea?  <br/>  <br/>[6] Garry Tan pointed out an interesting trap founders fall into in the<br/>beginning. They want so much to seem big that they imitate even the flaws of<br/>big companies, like indifference to individual users. This seems to them more<br/>"professional." Actually it's better to embrace the fact that you're small and<br/>use whatever advantages that brings.  <br/>  <br/>[7] Your user model almost couldn't be perfectly accurate, because users'<br/>needs often change in response to what you build for them. Build them a<br/>microcomputer, and suddenly they need to run spreadsheets on it, because the<br/>arrival of your new microcomputer causes someone to invent the spreadsheet.  <br/>  <br/>[8] If you have to choose between the subset that will sign up quickest and<br/>those that will pay the most, it's usually best to pick the former, because<br/>those are probably the early adopters. They'll have a better influence on your<br/>product, and they won't make you expend as much effort on sales. And though<br/>they have less money, you don't need that much to maintain your target growth<br/>rate early on.  <br/>  <br/>[9] Yes, I can imagine cases where you could end up making something that was<br/>really only useful for one user. But those are usually obvious, even to<br/>inexperienced founders. So if it's not obvious you'd be making something for a<br/>market of one, don't worry about that danger.  <br/>  <br/>[10] There may even be an inverse correlation between launch magnitude and<br/>success. The only launches I remember are famous flops like the Segway and<br/>Google Wave. Wave is a particularly alarming example, because I think it was<br/>actually a great idea that was killed partly by its overdone launch.  <br/>  <br/>[11] Google grew big on the back of Yahoo, but that wasn't a partnership.<br/>Yahoo was their customer.  <br/>  <br/>[12] It will also remind founders that an idea where the second component is<br/>empty — an idea where there is nothing you can do to get going, e.g. because<br/>you have no way to find users to recruit manually — is probably a bad idea, at<br/>least for those founders.  <br/>  <br/> **Thanks** to Sam Altman, Paul Buchheit, Patrick Collison, Kevin Hale, Steven<br/>Levy, Jessica Livingston, Geoff Ralston, and Garry Tan for reading drafts of<br/>this.  <br/>  <br/><br/>Japanese Translation  <br/><br/>Russian Translation  <br/><br/>French Translation  <br/><br/>Arabic Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>January 2015  <br/>  <br/>No one, VC or angel, has invested in more of the top startups than Ron Conway.<br/>He knows what happened in every deal in the Valley, half the time because he<br/>arranged it.  <br/>  <br/>And yet he's a super nice guy. In fact, nice is not the word. Ronco is good. I<br/>know of zero instances in which he has behaved badly. It's hard even to<br/>imagine.  <br/>  <br/>When I first came to Silicon Valley I thought "How lucky that someone so<br/>powerful is so benevolent." But gradually I realized it wasn't luck. It was by<br/>being benevolent that Ronco became so powerful. All the deals he gets to<br/>invest in come to him through referrals. Google did. Facebook did. Twitter was<br/>a referral from Evan Williams himself. And the reason so many people refer<br/>deals to him is that he's proven himself to be a good guy.  <br/>  <br/>Good does not mean being a pushover. I would not want to face an angry Ronco.<br/>But if Ron's angry at you, it's because you did something wrong. Ron is so old<br/>school he's Old Testament. He will smite you in his just wrath, but there's no<br/>malice in it.  <br/>  <br/>In almost every domain there are advantages to seeming good. It makes people<br/>trust you. But actually being good is an expensive way to seem good. To an<br/>amoral person it might seem to be overkill.  <br/>  <br/>In some fields it might be, but apparently not in the startup world. Though<br/>plenty of investors are jerks, there is a clear trend among them: the most<br/>successful investors are also the most upstanding. [1]  <br/>  <br/>It was not always this way. I would not feel confident saying that about<br/>investors twenty years ago.  <br/>  <br/>What changed? The startup world became more transparent and more<br/>unpredictable. Both make it harder to seem good without actually being good.  <br/>  <br/>It's obvious why transparency has that effect. When an investor maltreats a<br/>founder now, it gets out. Maybe not all the way to the press, but other<br/>founders hear about it, and that investor starts to lose deals. [2]  <br/>  <br/>The effect of unpredictability is more subtle. It increases the work of being<br/>inconsistent. If you're going to be two-faced, you have to know who you should<br/>be nice to and who you can get away with being nasty to. In the startup world,<br/>things change so rapidly that you can't tell. The random college kid you talk<br/>to today might in a couple years be the CEO of the hottest startup in the<br/>Valley. If you can't tell who to be nice to, you have to be nice to everyone.<br/>And probably the only people who can manage that are the people who are<br/>genuinely good.  <br/>  <br/>In a sufficiently connected and unpredictable world, you can't seem good<br/>without being good.  <br/>  <br/>As often happens, Ron discovered how to be the investor of the future by<br/>accident. He didn't foresee the future of startup investing, realize it would<br/>pay to be upstanding, and force himself to behave that way. It would feel<br/>unnatural to him to behave any other way. He was already living in the future.  <br/>  <br/>Fortunately that future is not limited to the startup world. The startup world<br/>is more transparent and unpredictable than most, but almost everywhere the<br/>trend is in that direction.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] I'm not saying that if you sort investors by benevolence you've also<br/>sorted them by returns, but rather that if you do a scatterplot with<br/>benevolence on the x axis and returns on the y, you'd see a clear upward<br/>trend.  <br/>  <br/>[2] Y Combinator in particular, because it aggregates data from so many<br/>startups, has a pretty comprehensive view of investor behavior.  <br/>  <br/>**Thanks** to Sam Altman and Jessica Livingston for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>March 2012  <br/>  <br/>One of the more surprising things I've noticed while working on Y Combinator<br/>is how frightening the most ambitious startup ideas are. In this essay I'm<br/>going to demonstrate this phenomenon by describing some. Any one of them could<br/>make you a billionaire. That might sound like an attractive prospect, and yet<br/>when I describe these ideas you may notice you find yourself shrinking away<br/>from them.  <br/>  <br/>Don't worry, it's not a sign of weakness. Arguably it's a sign of sanity. The<br/>biggest startup ideas are terrifying. And not just because they'd be a lot of<br/>work. The biggest ideas seem to threaten your identity: you wonder if you'd<br/>have enough ambition to carry them through.  <br/>  <br/>There's a scene in _Being John Malkovich_ where the nerdy hero encounters a<br/>very attractive, sophisticated woman. She says to him:<br/><br/>> Here's the thing: If you ever got me, you wouldn't have a clue what to do<br/>> with me.<br/><br/>That's what these ideas say to us.  <br/>  <br/>This phenomenon is one of the most important things you can understand about<br/>startups. [1] You'd expect big startup ideas to be attractive, but actually<br/>they tend to repel you. And that has a bunch of consequences. It means these<br/>ideas are invisible to most people who try to think of startup ideas, because<br/>their subconscious filters them out. Even the most ambitious people are<br/>probably best off approaching them obliquely.  <br/>  <br/> **1\. A New Search Engine**  <br/>  <br/>The best ideas are just on the right side of impossible. I don't know if this<br/>one is possible, but there are signs it might be. Making a new search engine<br/>means competing with Google, and recently I've noticed some cracks in their<br/>fortress.  <br/>  <br/>The point when it became clear to me that Microsoft had lost their way was<br/>when they decided to get into the search business. That was not a natural move<br/>for Microsoft. They did it because they were afraid of Google, and Google was<br/>in the search business. But this meant (a) Google was now setting Microsoft's<br/>agenda, and (b) Microsoft's agenda consisted of stuff they weren't good at.  <br/>  <br/>Microsoft : Google :: Google : Facebook.  <br/>  <br/>That does not by itself mean there's room for a new search engine, but lately<br/>when using Google search I've found myself nostalgic for the old days, when<br/>Google was true to its own slightly aspy self. Google used to give me a page<br/>of the right answers, fast, with no clutter. Now the results seem inspired by<br/>the Scientologist principle that what's true is what's true for you. And the<br/>pages don't have the clean, sparse feel they used to. Google search results<br/>used to look like the output of a Unix utility. Now if I accidentally put the<br/>cursor in the wrong place, anything might happen.  <br/>  <br/>The way to win here is to build the search engine all the hackers use. A<br/>search engine whose users consisted of the top 10,000 hackers and no one else<br/>would be in a very powerful position despite its small size, just as Google<br/>was when it was that search engine. And for the first time in over a decade<br/>the idea of switching seems thinkable to me.  <br/>  <br/>Since anyone capable of starting this company is one of those 10,000 hackers,<br/>the route is at least straightforward: make the search engine you yourself<br/>want. Feel free to make it excessively hackerish. Make it really good for code<br/>search, for example. Would you like search queries to be Turing complete?<br/>Anything that gets you those 10,000 users is ipso facto good.  <br/>  <br/>Don't worry if something you want to do will constrain you in the long term,<br/>because if you don't get that initial core of users, there won't be a long<br/>term. If you can just build something that you and your friends genuinely<br/>prefer to Google, you're already about 10% of the way to an IPO, just as<br/>Facebook was (though they probably didn't realize it) when they got all the<br/>Harvard undergrads.  <br/>  <br/> **2\. Replace Email**  <br/>  <br/>Email was not designed to be used the way we use it now. Email is not a<br/>messaging protocol. It's a todo list. Or rather, my inbox is a todo list, and<br/>email is the way things get onto it. But it is a disastrously bad todo list.  <br/>  <br/>I'm open to different types of solutions to this problem, but I suspect that<br/>tweaking the inbox is not enough, and that email has to be replaced with a new<br/>protocol. This new protocol should be a todo list protocol, not a messaging<br/>protocol, although there is a degenerate case where what someone wants you to<br/>do is: read the following text.  <br/>  <br/>As a todo list protocol, the new protocol should give more power to the<br/>recipient than email does. I want there to be more restrictions on what<br/>someone can put on my todo list. And when someone can put something on my todo<br/>list, I want them to tell me more about what they want from me. Do they want<br/>me to do something beyond just reading some text? How important is it? (There<br/>obviously has to be some mechanism to prevent people from saying everything is<br/>important.) When does it have to be done?  <br/>  <br/>This is one of those ideas that's like an irresistible force meeting an<br/>immovable object. On one hand, entrenched protocols are impossible to replace.<br/>On the other, it seems unlikely that people in 100 years will still be living<br/>in the same email hell we do now. And if email is going to get replaced<br/>eventually, why not now?  <br/>  <br/>If you do it right, you may be able to avoid the usual chicken and egg problem<br/>new protocols face, because some of the most powerful people in the world will<br/>be among the first to switch to it. They're all at the mercy of email too.  <br/>  <br/>Whatever you build, make it fast. GMail has become painfully slow. [2] If you<br/>made something no better than GMail, but fast, that alone would let you start<br/>to pull users away from GMail.  <br/>  <br/>GMail is slow because Google can't afford to spend a lot on it. But people<br/>will pay for this. I'd have no problem paying $50 a month. Considering how<br/>much time I spend in email, it's kind of scary to think how much I'd be<br/>justified in paying. At least $1000 a month. If I spend several hours a day<br/>reading and writing email, that would be a cheap way to make my life better.  <br/>  <br/> **3\. Replace Universities**  <br/>  <br/>People are all over this idea lately, and I think they're onto something. I'm<br/>reluctant to suggest that an institution that's been around for a millennium<br/>is finished just because of some mistakes they made in the last few decades,<br/>but certainly in the last few decades US universities seem to have been headed<br/>down the wrong path. One could do a lot better for a lot less money.  <br/>  <br/>I don't think universities will disappear. They won't be replaced wholesale.<br/>They'll just lose the de facto monopoly on certain types of learning that they<br/>once had. There will be many different ways to learn different things, and<br/>some may look quite different from universities. Y Combinator itself is<br/>arguably one of them.  <br/>  <br/>Learning is such a big problem that changing the way people do it will have a<br/>wave of secondary effects. For example, the name of the university one went to<br/>is treated by a lot of people (correctly or not) as a credential in its own<br/>right. If learning breaks up into many little pieces, credentialling may<br/>separate from it. There may even need to be replacements for campus social<br/>life (and oddly enough, YC even has aspects of that).  <br/>  <br/>You could replace high schools too, but there you face bureaucratic obstacles<br/>that would slow down a startup. Universities seem the place to start.  <br/>  <br/> **4\. Internet Drama**  <br/>  <br/>Hollywood has been slow to embrace the Internet. That was a mistake, because I<br/>think we can now call a winner in the race between delivery mechanisms, and it<br/>is the Internet, not cable.  <br/>  <br/>A lot of the reason is the horribleness of cable clients, also known as TVs.<br/>Our family didn't wait for Apple TV. We hated our last TV so much that a few<br/>months ago we replaced it with an iMac bolted to the wall. It's a little<br/>inconvenient to control it with a wireless mouse, but the overall experience<br/>is much better than the nightmare UI we had to deal with before.  <br/>  <br/>Some of the attention people currently devote to watching movies and TV can be<br/>stolen by things that seem completely unrelated, like social networking apps.<br/>More can be stolen by things that are a little more closely related, like<br/>games. But there will probably always remain some residual demand for<br/>conventional drama, where you sit passively and watch as a plot happens. So<br/>how do you deliver drama via the Internet? Whatever you make will have to be<br/>on a larger scale than Youtube clips. When people sit down to watch a show,<br/>they want to know what they're going to get: either part of a series with<br/>familiar characters, or a single longer "movie" whose basic premise they know<br/>in advance.  <br/>  <br/>There are two ways delivery and payment could play out. Either some company<br/>like Netflix or Apple will be the app store for entertainment, and you'll<br/>reach audiences through them. Or the would-be app stores will be too<br/>overreaching, or too technically inflexible, and companies will arise to<br/>supply payment and streaming a la carte to the producers of drama. If that's<br/>the way things play out, there will also be a need for such infrastructure<br/>companies.  <br/>  <br/> **5\. The Next Steve Jobs**  <br/>  <br/>I was talking recently to someone who knew Apple well, and I asked him if the<br/>people now running the company would be able to keep creating new things the<br/>way Apple had under Steve Jobs. His answer was simply "no." I already feared<br/>that would be the answer. I asked more to see how he'd qualify it. But he<br/>didn't qualify it at all. No, there will be no more great new stuff beyond<br/>whatever's currently in the pipeline. Apple's revenues may continue to rise<br/>for a long time, but as Microsoft shows, revenue is a lagging indicator in the<br/>technology business.  <br/>  <br/>So if Apple's not going to make the next iPad, who is? None of the existing<br/>players. None of them are run by product visionaries, and empirically you<br/>can't seem to get those by hiring them. Empirically the way you get a product<br/>visionary as CEO is for him to found the company and not get fired. So the<br/>company that creates the next wave of hardware is probably going to have to be<br/>a startup.  <br/>  <br/>I realize it sounds preposterously ambitious for a startup to try to become as<br/>big as Apple. But no more ambitious than it was for Apple to become as big as<br/>Apple, and they did it. Plus a startup taking on this problem now has an<br/>advantage the original Apple didn't: the example of Apple. Steve Jobs has<br/>shown us what's possible. That helps would-be successors both directly, as<br/>Roger Bannister did, by showing how much better you can do than people did<br/>before, and indirectly, as Augustus did, by lodging the idea in users' minds<br/>that a single person could unroll the future for them. [3]  <br/>  <br/>Now Steve is gone there's a vacuum we can all feel. If a new company led<br/>boldly into the future of hardware, users would follow. The CEO of that<br/>company, the "next Steve Jobs," might not measure up to Steve Jobs. But he<br/>wouldn't have to. He'd just have to do a better job than Samsung and HP and<br/>Nokia, and that seems pretty doable.  <br/>  <br/> **6\. Bring Back Moore's Law**  <br/>  <br/>The last 10 years have reminded us what Moore's Law actually says. Till about<br/>2002 you could safely misinterpret it as promising that clock speeds would<br/>double every 18 months. Actually what it says is that circuit densities will<br/>double every 18 months. It used to seem pedantic to point that out. Not any<br/>more. Intel can no longer give us faster CPUs, just more of them.  <br/>  <br/>This Moore's Law is not as good as the old one. Moore's Law used to mean that<br/>if your software was slow, all you had to do was wait, and the inexorable<br/>progress of hardware would solve your problems. Now if your software is slow<br/>you have to rewrite it to do more things in parallel, which is a lot more work<br/>than waiting.  <br/>  <br/>It would be great if a startup could give us something of the old Moore's Law<br/>back, by writing software that could make a large number of CPUs look to the<br/>developer like one very fast CPU. There are several ways to approach this<br/>problem. The most ambitious is to try to do it automatically: to write a<br/>compiler that will parallelize our code for us. There's a name for this<br/>compiler, _the sufficiently smart compiler,_ and it is a byword for<br/>impossibility. But is it really impossible? Is there no configuration of the<br/>bits in memory of a present day computer that is this compiler? If you really<br/>think so, you should try to prove it, because that would be an interesting<br/>result. And if it's not impossible but simply very hard, it might be worth<br/>trying to write it. The expected value would be high even if the chance of<br/>succeeding was low.  <br/>  <br/>The reason the expected value is so high is web services. If you could write<br/>software that gave programmers the convenience of the way things were in the<br/>old days, you could offer it to them as a web service. And that would in turn<br/>mean that you got practically all the users.  <br/>  <br/>Imagine there was another processor manufacturer that could still translate<br/>increased circuit densities into increased clock speeds. They'd take most of<br/>Intel's business. And since web services mean that no one sees their<br/>processors anymore, by writing the sufficiently smart compiler you could<br/>create a situation indistinguishable from you being that manufacturer, at<br/>least for the server market.  <br/>  <br/>The least ambitious way of approaching the problem is to start from the other<br/>end, and offer programmers more parallelizable Lego blocks to build programs<br/>out of, like Hadoop and MapReduce. Then the programmer still does much of the<br/>work of optimization.  <br/>  <br/>There's an intriguing middle ground where you build a semi-automatic<br/>weapon—where there's a human in the loop. You make something that looks to the<br/>user like the sufficiently smart compiler, but inside has people, using highly<br/>developed optimization tools to find and eliminate bottlenecks in users'<br/>programs. These people might be your employees, or you might create a<br/>marketplace for optimization.  <br/>  <br/>An optimization marketplace would be a way to generate the sufficiently smart<br/>compiler piecemeal, because participants would immediately start writing bots.<br/>It would be a curious state of affairs if you could get to the point where<br/>everything could be done by bots, because then you'd have made the<br/>sufficiently smart compiler, but no one person would have a complete copy of<br/>it.  <br/>  <br/>I realize how crazy all this sounds. In fact, what I like about this idea is<br/>all the different ways in which it's wrong. The whole idea of focusing on<br/>optimization is counter to the general trend in software development for the<br/>last several decades. Trying to write the sufficiently smart compiler is by<br/>definition a mistake. And even if it weren't, compilers are the sort of<br/>software that's supposed to be created by open source projects, not companies.<br/>Plus if this works it will deprive all the programmers who take pleasure in<br/>making multithreaded apps of so much amusing complexity. The forum troll I<br/>have by now internalized doesn't even know where to begin in raising<br/>objections to this project. Now that's what I call a startup idea.  <br/>  <br/> **7\. Ongoing Diagnosis**  <br/>  <br/>But wait, here's another that could face even greater resistance: ongoing,<br/>automatic medical diagnosis.  <br/>  <br/>One of my tricks for generating startup ideas is to imagine the ways in which<br/>we'll seem backward to future generations. And I'm pretty sure that to people<br/>50 or 100 years in the future, it will seem barbaric that people in our era<br/>waited till they had symptoms to be diagnosed with conditions like heart<br/>disease and cancer.  <br/>  <br/>For example, in 2004 Bill Clinton found he was feeling short of breath.<br/>Doctors discovered that several of his arteries were over 90% blocked and 3<br/>days later he had a quadruple bypass. It seems reasonable to assume Bill<br/>Clinton has the best medical care available. And yet even he had to wait till<br/>his arteries were over 90% blocked to learn that the number was over 90%.<br/>Surely at some point in the future we'll know these numbers the way we now<br/>know something like our weight. Ditto for cancer. It will seem preposterous to<br/>future generations that we wait till patients have physical symptoms to be<br/>diagnosed with cancer. Cancer will show up on some sort of radar screen<br/>immediately.  <br/>  <br/>(Of course, what shows up on the radar screen may be different from what we<br/>think of now as cancer. I wouldn't be surprised if at any given time we have<br/>ten or even hundreds of microcancers going at once, none of which normally<br/>amount to anything.)  <br/>  <br/>A lot of the obstacles to ongoing diagnosis will come from the fact that it's<br/>going against the grain of the medical profession. The way medicine has always<br/>worked is that patients come to doctors with problems, and the doctors figure<br/>out what's wrong. A lot of doctors don't like the idea of going on the medical<br/>equivalent of what lawyers call a "fishing expedition," where you go looking<br/>for problems without knowing what you're looking for. They call the things<br/>that get discovered this way "incidentalomas," and they are something of a<br/>nuisance.  <br/>  <br/>For example, a friend of mine once had her brain scanned as part of a study.<br/>She was horrified when the doctors running the study discovered what appeared<br/>to be a large tumor. After further testing, it turned out to be a harmless<br/>cyst. But it cost her a few days of terror. A lot of doctors worry that if you<br/>start scanning people with no symptoms, you'll get this on a giant scale: a<br/>huge number of false alarms that make patients panic and require expensive and<br/>perhaps even dangerous tests to resolve. But I think that's just an artifact<br/>of current limitations. If people were scanned all the time and we got better<br/>at deciding what was a real problem, my friend would have known about this<br/>cyst her whole life and known it was harmless, just as we do a birthmark.  <br/>  <br/>There is room for a lot of startups here. In addition to the technical<br/>obstacles all startups face, and the bureaucratic obstacles all medical<br/>startups face, they'll be going against thousands of years of medical<br/>tradition. But it will happen, and it will be a great thing—so great that<br/>people in the future will feel as sorry for us as we do for the generations<br/>that lived before anaesthesia and antibiotics.  <br/>  <br/> **Tactics**  <br/>  <br/>Let me conclude with some tactical advice. If you want to take on a problem as<br/>big as the ones I've discussed, don't make a direct frontal attack on it.<br/>Don't say, for example, that you're going to replace email. If you do that you<br/>raise too many expectations. Your employees and investors will constantly be<br/>asking "are we there yet?" and you'll have an army of haters waiting to see<br/>you fail. Just say you're building todo-list software. That sounds harmless.<br/>People can notice you've replaced email when it's a _fait accompli_. [4]  <br/>  <br/>Empirically, the way to do really big things seems to be to start with<br/>deceptively small things. Want to dominate microcomputer software? Start by<br/>writing a Basic interpreter for a machine with a few thousand users. Want to<br/>make the universal web site? Start by building a site for Harvard undergrads<br/>to stalk one another.  <br/>  <br/>Empirically, it's not just for other people that you need to start small. You<br/>need to for your own sake. Neither Bill Gates nor Mark Zuckerberg knew at<br/>first how big their companies were going to get. All they knew was that they<br/>were onto something. Maybe it's a bad idea to have really big ambitions<br/>initially, because the bigger your ambition, the longer it's going to take,<br/>and the further you project into the future, the more likely you'll get it<br/>wrong.  <br/>  <br/>I think the way to use these big ideas is not to try to identify a precise<br/>point in the future and then ask yourself how to get from here to there, like<br/>the popular image of a visionary. You'll be better off if you operate like<br/>Columbus and just head in a general westerly direction. Don't try to construct<br/>the future like a building, because your current blueprint is almost certainly<br/>mistaken. Start with something you know works, and when you expand, expand<br/>westward.  <br/>  <br/>The popular image of the visionary is someone with a clear view of the future,<br/>but empirically it may be better to have a blurry one.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] It's also one of the most important things VCs fail to understand about<br/>startups. Most expect founders to walk in with a clear plan for the future,<br/>and judge them based on that. Few consciously realize that in the biggest<br/>successes there is the least correlation between the initial plan and what the<br/>startup eventually becomes.  <br/>  <br/>[2] This sentence originally read "GMail is painfully slow." Thanks to Paul<br/>Buchheit for the correction.  <br/>  <br/>[3] Roger Bannister is famous as the first person to run a mile in under 4<br/>minutes. But his world record only lasted 46 days. Once he showed it could be<br/>done, lots of others followed. Ten years later Jim Ryun ran a 3:59 mile as a<br/>high school junior.  <br/>  <br/>[4] If you want to be the next Apple, maybe you don't even want to start with<br/>consumer electronics. Maybe at first you make something hackers use. Or you<br/>make something popular but apparently unimportant, like a headset or router.<br/>All you need is a bridgehead.  <br/>  <br/>**Thanks** to Sam Altman, Trevor Blackwell, Paul Buchheit, Patrick Collison,<br/>Aaron Iba, Jessica Livingston, Robert Morris, Harj Taggar and Garry Tan for<br/>reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>July 2009  <br/>  <br/>The Segway hasn't delivered on its initial promise, to put it mildly. There<br/>are several reasons why, but one is that people don't want to be seen riding<br/>them. Someone riding a Segway looks like a dork.  <br/>  <br/>My friend Trevor Blackwell built his own Segway, which we called the Segwell.<br/>He also built a one-wheeled version, the Eunicycle, which looks exactly like a<br/>regular unicycle till you realize the rider isn't pedaling. He has ridden them<br/>both to downtown Mountain View to get coffee. When he rides the Eunicycle,<br/>people smile at him. But when he rides the Segwell, they shout abuse from<br/>their cars: "Too lazy to walk, ya fuckin homo?"  <br/>  <br/>Why do Segways provoke this reaction? The reason you look like a dork riding a<br/>Segway is that you look _smug_. You don't seem to be working hard enough.  <br/>  <br/>Someone riding a motorcycle isn't working any harder. But because he's sitting<br/>astride it, he seems to be making an effort. When you're riding a Segway<br/>you're just standing there. And someone who's being whisked along while<br/>seeming to do no work—someone in a sedan chair, for example—can't help but<br/>look smug.  <br/>  <br/>Try this thought experiment and it becomes clear: imagine something that<br/>worked like the Segway, but that you rode with one foot in front of the other,<br/>like a skateboard. That wouldn't seem nearly as uncool.  <br/>  <br/>So there may be a way to capture more of the market Segway hoped to reach:<br/>make a version that doesn't look so easy for the rider. It would also be<br/>helpful if the styling was in the tradition of skateboards or bicycles rather<br/>than medical devices.  <br/>  <br/>Curiously enough, what got Segway into this problem was that the company was<br/>itself a kind of Segway. It was too easy for them; they were too successful<br/>raising money. If they'd had to grow the company gradually, by iterating<br/>through several versions they sold to real users, they'd have learned pretty<br/>quickly that people looked stupid riding them. Instead they had enough to work<br/>in secret. They had focus groups aplenty, I'm sure, but they didn't have the<br/>people yelling insults out of cars. So they never realized they were zooming<br/>confidently down a blind alley.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>July 2009  <br/>  <br/>Now that the term "ramen profitable" has become widespread, I ought to explain<br/>precisely what the idea entails.  <br/>  <br/>Ramen profitable means a startup makes just enough to pay the founders' living<br/>expenses. This is a different form of profitability than startups have<br/>traditionally aimed for. Traditional profitability means a big bet is finally<br/>paying off, whereas the main importance of ramen profitability is that it buys<br/>you time. [1]  <br/>  <br/>In the past, a startup would usually become profitable only after raising and<br/>spending quite a lot of money. A company making computer hardware might not<br/>become profitable for 5 years, during which they spent $50 million. But when<br/>they did they might have revenues of $50 million a year. This kind of<br/>profitability means the startup has succeeded.  <br/>  <br/>Ramen profitability is the other extreme: a startup that becomes profitable<br/>after 2 months, even though its revenues are only $3000 a month, because the<br/>only employees are a couple 25 year old founders who can live on practically<br/>nothing. Revenues of $3000 a month do not mean the company has succeeded. But<br/>it does share something with the one that's profitable in the traditional way:<br/>they don't need to raise money to survive.  <br/>  <br/>Ramen profitability is an unfamiliar idea to most people because it only<br/>recently became feasible. It's still not feasible for a lot of startups; it<br/>would not be for most biotech startups, for example; but it is for many<br/>software startups because they're now so cheap. For many, the only real cost<br/>is the founders' living expenses.  <br/>  <br/>The main significance of this type of profitability is that you're no longer<br/>at the mercy of investors. If you're still losing money, then eventually<br/>you'll either have to raise more or shut down. Once you're ramen profitable<br/>this painful choice goes away. You can still raise money, but you don't have<br/>to do it now.  <br/>  <br/>* * *  <br/>  <br/>The most obvious advantage of not needing money is that you can get better<br/>terms. If investors know you need money, they'll sometimes take advantage of<br/>you. Some may even deliberately stall, because they know that as you run out<br/>of money you'll become increasingly pliable.  <br/>  <br/>But there are also three less obvious advantages of ramen profitability. One<br/>is that it makes you more attractive to investors. If you're already<br/>profitable, on however small a scale, it shows that (a) you can get at least<br/>someone to pay you, (b) you're serious about building things people want, and<br/>(c) you're disciplined enough to keep expenses low.  <br/>  <br/>This is reassuring to investors, because you've addressed three of their<br/>biggest worries. It's common for them to fund companies that have smart<br/>founders and a big market, and yet still fail. When these companies fail, it's<br/>usually because (a) people wouldn't pay for what they made, e.g. because it<br/>was too hard to sell to them, or the market wasn't ready yet, (b) the founders<br/>solved the wrong problem, instead of paying attention to what users needed, or<br/>(c) the company spent too much and burned through their funding before they<br/>started to make money. If you're ramen profitable, you're already avoiding<br/>these mistakes.  <br/>  <br/>Another advantage of ramen profitability is that it's good for morale. A<br/>company tends to feel rather theoretical when you first start it. It's legally<br/>a company, but you feel like you're lying when you call it one. When people<br/>start to pay you significant amounts, the company starts to feel real. And<br/>your own living expenses are the milestone you feel most, because at that<br/>point the future flips state. Now survival is the default, instead of dying.  <br/>  <br/>A morale boost on that scale is very valuable in a startup, because the moral<br/>weight of running a startup is what makes it hard. Startups are still very<br/>rare. Why don't more people do it? The financial risk? Plenty of 25 year olds<br/>save nothing anyway. The long hours? Plenty of people work just as long hours<br/>in regular jobs. What keeps people from starting startups is the fear of<br/>having so much responsibility. And this is not an irrational fear: it really<br/>is hard to bear. Anything that takes some of that weight off you will greatly<br/>increase your chances of surviving.  <br/>  <br/>A startup that reaches ramen profitability may be more likely to succeed than<br/>not. Which is pretty exciting, considering the bimodal distribution of<br/>outcomes in startups: you either fail or make a lot of money.  <br/>  <br/>The fourth advantage of ramen profitability is the least obvious but may be<br/>the most important. If you don't need to raise money, you don't have to<br/>interrupt working on the company to do it.  <br/>  <br/>Raising money is terribly distracting. You're lucky if your productivity is a<br/>third of what it was before. And it can last for months.  <br/>  <br/>I didn't understand (or rather, remember) precisely why raising money was so<br/>distracting till earlier this year. I'd noticed that startups we funded would<br/>usually grind to a halt when they switched to raising money, but I didn't<br/>remember exactly why till YC raised money itself. We had a comparatively easy<br/>time of it; the first people I asked said yes; but it took months to work out<br/>the details, and during that time I got hardly any real work done. Why?<br/>Because I thought about it all the time.  <br/>  <br/>At any given time there tends to be one problem that's the most urgent for a<br/>startup. This is what you think about as you fall asleep at night and when you<br/>take a shower in the morning. And when you start raising money, that becomes<br/>the problem you think about. You only take one shower in the morning, and if<br/>you're thinking about investors during it, then you're not thinking about the<br/>product.  <br/>  <br/>Whereas if you can choose when you raise money, you can pick a time when<br/>you're not in the middle of something else, and you can probably also insist<br/>that the round close fast. You may even be able to avoid having the round<br/>occupy your thoughts, if you don't care whether it closes.  <br/>  <br/>* * *  <br/>  <br/>Ramen profitable means no more than the definition implies. It does not, for<br/>example, imply that you're "bootstrapping" the startup—that you're never going<br/>to take money from investors. Empirically that doesn't seem to work very well.<br/>Few startups succeed without taking investment. Maybe as startups get cheaper<br/>it will become more common. On the other hand, the money is there, waiting to<br/>be invested. If startups need it less, they'll be able to get it on better<br/>terms, which will make them more inclined to take it. That will tend to<br/>produce an equilibrium. [2]  <br/>  <br/>Another thing ramen profitability doesn't imply is Joe Kraus's idea that you<br/>should put your business model in beta when you put your product in beta. He<br/>believes you should get people to pay you from the beginning. I think that's<br/>too constraining. Facebook didn't, and they've done better than most startups.<br/>Making money right away was not only unnecessary for them, but probably would<br/>have been harmful. I do think Joe's rule could be useful for many startups,<br/>though. When founders seem unfocused, I sometimes suggest they try to get<br/>customers to pay them for something, in the hope that this constraint will<br/>prod them into action.  <br/>  <br/>The difference between Joe's idea and ramen profitability is that a ramen<br/>profitable company doesn't have to be making money the way it ultimately will.<br/>It just has to be making money. The most famous example is Google, which<br/>initially made money by licensing search to sites like Yahoo.  <br/>  <br/>Is there a downside to ramen profitability? Probably the biggest danger is<br/>that it might turn you into a consulting firm. Startups have to be product<br/>companies, in the sense of making a single thing that everyone uses. The<br/>defining quality of startups is that they grow fast, and consulting just can't<br/>scale the way a product can. [3] But it's pretty easy to make $3000 a month<br/>consulting; in fact, that would be a low rate for contract programming. So<br/>there could be a temptation to slide into consulting, and telling yourselves<br/>you're a ramen profitable startup, when in fact you're not a startup at all.  <br/>  <br/>It's ok to do a little consulting-type work at first. Startups usually have to<br/>do something weird at first. But remember that ramen profitability is not the<br/>destination. A startup's destination is to grow really big; ramen<br/>profitability is a trick for not dying en route.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] The "ramen" in "ramen profitable" refers to instant ramen, which is just<br/>about the cheapest food available.  <br/>  <br/>Please do not take the term literally. Living on instant ramen would be very<br/>unhealthy. Rice and beans are a better source of food. Start by investing in a<br/>rice cooker, if you don't have one.  <br/>  <br/>Rice and Beans for 2n<br/><br/>    <br/>    <br/>      olive oil or butter<br/>      n yellow onions<br/>      other fresh vegetables; experiment<br/>      3n cloves garlic<br/>      n 12-oz cans white, kidney, or black beans<br/>      n cubes Knorr beef or vegetable bouillon<br/>      n teaspoons freshly ground black pepper<br/>      3n teaspoons ground cumin<br/>      n cups dry rice, preferably brown<br/>    <br/><br/>Put rice in rice cooker. Add water as specified on rice package. (Default: 2<br/>cups water per cup of rice.) Turn on rice cooker and forget about it.  <br/>  <br/>Chop onions and other vegetables and fry in oil, over fairly low heat, till<br/>onions are glassy. Put in chopped garlic, pepper, cumin, and a little more<br/>fat, and stir. Keep heat low. Cook another 2 or 3 minutes, then add beans<br/>(don't drain the beans), and stir. Throw in the bouillon cube(s), cover, and<br/>cook on lowish heat for at least 10 minutes more. Stir vigilantly to avoid<br/>sticking.  <br/>  <br/>If you want to save money, buy beans in giant cans from discount stores.<br/>Spices are also much cheaper when bought in bulk. If there's an Indian grocery<br/>store near you, they'll have big bags of cumin for the same price as the<br/>little jars in supermarkets.  <br/>  <br/>[2] There's a good chance that a shift in power from investors to founders<br/>would actually increase the size of the venture business. I think investors<br/>currently err too far on the side of being harsh to founders. If they were<br/>forced to stop, the whole venture business would work better, and you might<br/>see something like the increase in trade you always see when restrictive laws<br/>are removed.  <br/>  <br/>Investors are one of the biggest sources of pain for founders; if they stopped<br/>causing so much pain, it would be better to be a founder; and if it were<br/>better to be a founder, more people would do it.  <br/>  <br/>[3] It's conceivable that a startup could grow big by transforming consulting<br/>into a form that would scale. But if they did that they'd really be a product<br/>company.  <br/>  <br/> **Thanks** to Jessica Livingston for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>October 2004  <br/>  <br/>As E. B. White said, "good writing is rewriting." I didn't realize this when I<br/>was in school. In writing, as in math and science, they only show you the<br/>finished product. You don't see all the false starts. This gives students a<br/>misleading view of how things get made.  <br/>  <br/>Part of the reason it happens is that writers don't want people to see their<br/>mistakes. But I'm willing to let people see an early draft if it will show how<br/>much you have to rewrite to beat an essay into shape.  <br/>  <br/>Below is the oldest version I can find of The Age of the Essay (probably the<br/>second or third day), with text that ultimately survived in red and text that<br/>later got deleted in gray. There seem to be several categories of cuts: things<br/>I got wrong, things that seem like bragging, flames, digressions, stretches of<br/>awkward prose, and unnecessary words.  <br/>  <br/>I discarded more from the beginning. That's not surprising; it takes a while<br/>to hit your stride. There are more digressions at the start, because I'm not<br/>sure where I'm heading.  <br/>  <br/>The amount of cutting is about average. I probably write three to four words<br/>for every one that appears in the final version of an essay.  <br/>  <br/>(Before anyone gets mad at me for opinions expressed here, remember that<br/>anything you see here that's not in the final version is obviously something I<br/>chose not to publish, often because I disagree with it.)  <br/>  <br/>  <br/>  <br/>Recently a friend said that what he liked about my essays was that they<br/>weren't written the way we'd been taught to write essays in school. You<br/>remember: topic sentence, introductory paragraph, supporting paragraphs,<br/>conclusion. It hadn't occurred to me till then that those horrible things we<br/>had to write in school were even connected to what I was doing now. But sure<br/>enough, I thought, they did call them "essays," didn't they?  <br/>  <br/>Well, they're not. Those things you have to write in school are not only not<br/>essays, they're one of the most pointless of all the pointless hoops you have<br/>to jump through in school. And I worry that they not only teach students the<br/>wrong things about writing, but put them off writing entirely.  <br/>  <br/>So I'm going to give the other side of the story: what an essay really is, and<br/>how you write one. Or at least, how I write one. Students be forewarned: if<br/>you actually write the kind of essay I describe, you'll probably get bad<br/>grades. But knowing how it's really done should at least help you to<br/>understand the feeling of futility you have when you're writing the things<br/>they tell you to.  <br/>  <br/>The most obvious difference between real essays and the things one has to<br/>write in school is that real essays are not exclusively about English<br/>literature. It's a fine thing for schools to  teach students how to write. But<br/>for some bizarre reason (actually, a very specific bizarre reason that I'll<br/>explain in a moment),  the teaching of writing has gotten mixed together with<br/>the study of literature. And so all over the country, students are writing not<br/>about how a baseball team with a small budget might compete with the Yankees,<br/>or the role of color in fashion, or what constitutes a good dessert, but about<br/>symbolism in Dickens.  <br/>  <br/>With obvious results. Only a few people really  care about symbolism in<br/>Dickens. The teacher doesn't. The students don't. Most of the people who've<br/>had to write PhD disserations about Dickens don't. And certainly  Dickens<br/>himself would be more interested in an essay about color or baseball.  <br/>  <br/>How did things get this way? To answer that we have to go back almost a<br/>thousand years. Between about 500 and 1000, life was not very good in Europe.<br/>The term "dark ages" is presently out of fashion as too judgemental (the<br/>period wasn't dark; it was just _different_ ), but if this label didn't<br/>already exist, it would seem an inspired metaphor. What little original<br/>thought there was took place in lulls between constant wars and had something<br/>of the character of the thoughts of parents with a new baby. The most amusing<br/>thing written during this period, Liudprand of Cremona's Embassy to<br/>Constantinople, is, I suspect, mostly inadvertantly so.  <br/>  <br/>Around 1000 Europe began to catch its breath. And once they had the luxury of<br/>curiosity, one of the first things they discovered was what we call "the<br/>classics." Imagine if we were visited by aliens. If they could even get here<br/>they'd presumably know a few things we don't. Immediately Alien Studies would<br/>become the most dynamic field of scholarship: instead of painstakingly<br/>discovering things for ourselves, we could simply suck up everything they'd<br/>discovered. So it was in Europe in 1200. When classical texts began to<br/>circulate in Europe, they contained not just new answers, but new questions.<br/>(If anyone proved a theorem in christian Europe before 1200, for example,<br/>there is no record of it.)  <br/>  <br/>For a couple centuries, some of the most important work being done was<br/>intellectual archaelogy. Those were also the centuries during which schools<br/>were first established. And since reading ancient texts was the essence of<br/>what scholars did then, it became the basis of the curriculum.  <br/>  <br/>By 1700, someone who wanted to learn about physics didn't need to start by<br/>mastering Greek in order to read Aristotle. But schools change slower than<br/>scholarship: the study of ancient texts had such prestige that it remained the<br/>backbone of education until the late 19th century. By then it was merely a<br/>tradition. It did serve some purposes: reading a foreign language was<br/>difficult, and thus taught discipline, or at least, kept students busy; it<br/>introduced students to cultures quite different from their own; and its very<br/>uselessness made it function (like white gloves) as a social bulwark. But it<br/>certainly wasn't true, and hadn't been true for centuries, that students were<br/>serving apprenticeships in the hottest area of scholarship.  <br/>  <br/>Classical scholarship had also changed. In the early era, philology actually<br/>mattered. The texts that filtered into Europe were all corrupted to some<br/>degree by the errors of translators and copyists. Scholars had to figure out<br/>what Aristotle said before they could figure out what he meant. But by the<br/>modern era such questions were answered as well as they were ever going to be.<br/>And so the study of ancient texts became less about ancientness and more about<br/>texts.  <br/>  <br/>The time was then ripe for the question: if the study of ancient texts is a<br/>valid field for scholarship, why not modern texts? The answer, of course, is<br/>that the raison d'etre of classical scholarship was a kind of intellectual<br/>archaelogy that does not need to be done in the case of contemporary authors.<br/>But for obvious reasons no one wanted to give that answer. The archaeological<br/>work being mostly done, it implied that the people studying the classics were,<br/>if not wasting their time, at least working on problems of minor importance.  <br/>  <br/>And so began the study of modern literature. There was some initial<br/>resistance, but it didn't last long. The limiting reagent in the growth of<br/>university departments is what parents will let undergraduates study. If<br/>parents will let their children major in x, the rest follows<br/>straightforwardly. There will be jobs teaching x, and professors to fill them.<br/>The professors will establish scholarly journals and publish one another's<br/>papers. Universities with x departments will subscribe to the journals.<br/>Graduate students who want jobs as professors of x will write dissertations<br/>about it. It may take a good long while for the more prestigious universities<br/>to cave in and establish departments in cheesier xes, but at the other end of<br/>the scale there are so many universities competing to attract students that<br/>the mere establishment of a discipline requires little more than the desire to<br/>do it.  <br/>  <br/>High schools imitate universities. And so once university English departments<br/>were established in the late nineteenth century, the 'riting component of the<br/>3 Rs was morphed into English. With the bizarre consequence that high school<br/>students now had to write about English literature-- to write, without even<br/>realizing it, imitations of whatever English professors had been publishing in<br/>their journals a few decades before. It's no wonder if this seems to the<br/>student a pointless exercise, because we're now three steps removed from real<br/>work: the students are imitating English professors, who are imitating<br/>classical scholars, who are merely the inheritors of a tradition growing out<br/>of what was, 700 years ago, fascinating and urgently needed work.  <br/>  <br/>Perhaps high schools should drop English and just teach writing. The valuable<br/>part of English classes is learning to write, and that could be taught better<br/>by itself. Students learn better when they're interested in what they're<br/>doing, and it's hard to imagine a topic less interesting than symbolism in<br/>Dickens. Most of the people who write about that sort of thing professionally<br/>are not really interested in it. (Though indeed, it's been a while since they<br/>were writing about symbolism; now they're writing about gender.)  <br/>  <br/>I have no illusions about how eagerly this suggestion will be adopted. Public<br/>schools probably couldn't stop teaching English even if they wanted to;<br/>they're probably required to by law. But here's a related suggestion that goes<br/>with the grain instead of against it: that universities establish a writing<br/>major. Many of the students who now major in English would major in writing if<br/>they could, and most would be better off.  <br/>  <br/>It will be argued that it is a good thing for students to be exposed to their<br/>literary heritage. Certainly. But is that more important than that they learn<br/>to write well? And are English classes even the place to do it? After all, the<br/>average public high school student gets zero exposure to his artistic<br/>heritage. No disaster results. The people who are interested in art learn<br/>about it for themselves, and those who aren't don't. I find that American<br/>adults are no better or worse informed about literature than art, despite the<br/>fact that they spent years studying literature in high school and no time at<br/>all studying art. Which presumably means that what they're taught in school is<br/>rounding error compared to what they pick up on their own.  <br/>  <br/>Indeed, English classes may even be harmful. In my case they were effectively<br/>aversion therapy. Want to make someone dislike a book? Force him to read it<br/>and write an essay about it. And make the topic so intellectually bogus that<br/>you could not, if asked, explain why one ought to write about it. I love to<br/>read more than anything, but by the end of high school I never read the books<br/>we were assigned. I was so disgusted with what we were doing that it became a<br/>point of honor with me to write nonsense at least as good at the other<br/>students' without having more than glanced over the book to learn the names of<br/>the characters and a few random events in it.  <br/>  <br/>I hoped this might be fixed in college, but I found the same problem there. It<br/>was not the teachers. It was English. We were supposed to read novels and<br/>write essays about them. About what, and why? That no one seemed to be able to<br/>explain. Eventually by trial and error I found that what the teacher wanted us<br/>to do was pretend that the story had really taken place, and to analyze based<br/>on what the characters said and did (the subtler clues, the better) what their<br/>motives must have been. One got extra credit for motives having to do with<br/>class, as I suspect one must now for those involving gender and sexuality. I<br/>learned how to churn out such stuff well enough to get an A, but I never took<br/>another English class.  <br/>  <br/>And the books we did these disgusting things to, like those we mishandled in<br/>high school, I find still have black marks against them in my mind. The one<br/>saving grace was that English courses tend to favor pompous, dull writers like<br/>Henry James, who deserve black marks against their names anyway. One of the<br/>principles the IRS uses in deciding whether to allow deductions is that, if<br/>something is fun, it isn't work. Fields that are intellectually unsure of<br/>themselves rely on a similar principle. Reading P.G. Wodehouse or Evelyn Waugh<br/>or Raymond Chandler is too obviously pleasing to seem like serious work, as<br/>reading Shakespeare would have been before English evolved enough to make it<br/>an effort to understand him. [sh] And so good writers (just you wait and see<br/>who's still in print in 300 years) are less likely to have readers turned<br/>against them by clumsy, self-appointed tour guides.  <br/>  <br/>The other big difference between a real essay and the things they make you<br/>write in school is that a real essay doesn't take a position and then defend<br/>it. That principle, like the idea that we ought to be writing about<br/>literature, turns out to be another intellectual hangover of long forgotten<br/>origins. It's often mistakenly believed that medieval universities were mostly<br/>seminaries. In fact they were more law schools. And at least in our tradition<br/>lawyers are advocates: they are trained to be able to take either side of an<br/>argument and make as good a case for it as they can.  <br/>  <br/>Whether or not this is a good idea (in the case of prosecutors, it probably<br/>isn't), it tended to pervade the atmosphere of early universities. After the<br/>lecture the most common form of discussion was the disputation. This idea is<br/>at least nominally preserved in our present-day thesis defense\-- indeed, in<br/>the very word thesis. Most people treat the words thesis and dissertation as<br/>interchangeable, but originally, at least, a thesis was a position one took<br/>and the dissertation was the argument by which one defended it.  <br/>  <br/>I'm not complaining that we blur these two words together. As far as I'm<br/>concerned, the sooner we lose the original sense of the word thesis, the<br/>better. For many, perhaps most, graduate students, it is stuffing a square peg<br/>into a round hole to try to recast one's work as a single thesis. And as for<br/>the disputation, that seems clearly a net lose. Arguing two sides of a case<br/>may be a necessary evil in a legal dispute, but it's not the best way to get<br/>at the truth, as I think lawyers would be the first to admit.  <br/>  <br/>And yet this principle is built into the very structure of the essays they<br/>teach you to write in high school. The topic sentence is your thesis, chosen<br/>in advance, the supporting paragraphs the blows you strike in the conflict,<br/>and the conclusion--- uh, what it the conclusion? I was never sure about that<br/>in high school. If your thesis was well expressed, what need was there to<br/>restate it? In theory it seemed that the conclusion of a really good essay<br/>ought not to need to say any more than QED. But when you understand the<br/>origins of this sort of "essay", you can see where the conclusion comes from.<br/>It's the concluding remarks to the jury.  <br/>  <br/>What other alternative is there? To answer that we have to reach back into<br/>history again, though this time not so far. To Michel de Montaigne, inventor<br/>of the essay. He was doing something quite different from what a lawyer does,<br/>and the difference is embodied in the name. Essayer is the French verb meaning<br/>"to try" (the cousin of our word assay),  and an "essai" is an effort. An<br/>essay is something you write in order to figure something out.  <br/>  <br/>Figure out what? You don't know yet. And so you can't begin with a thesis,<br/>because you don't have one, and may never have one. An essay doesn't begin<br/>with a statement, but with a question. In a real essay, you don't take a<br/>position and defend it. You see a door that's ajar, and you open it and walk<br/>in to see what's inside.  <br/>  <br/>If all you want to do is figure things out, why do you need to write anything,<br/>though? Why not just sit and think? Well, there precisely is Montaigne's great<br/>discovery. Expressing ideas helps to form them. Indeed, helps is far too weak<br/>a word. 90% of what ends up in my essays was stuff I only thought of when I<br/>sat down to write them. That's why I write them.  <br/>  <br/>So there's another difference between essays and the things you have to write<br/>in school. In school  you are, in theory, explaining yourself to someone else.<br/>In the best case---if you're really organized---you're just writing it _down._<br/>In a real essay you're writing for yourself. You're thinking out loud.  <br/>  <br/>But not quite. Just as inviting people over forces you to clean up your<br/>apartment, writing something that you know  other people will read forces you<br/>to think well. So it does matter to have an audience. The things I've written<br/>just for myself are no good. Indeed, they're bad in a particular way: they<br/>tend to peter out. When I run into difficulties, I notice that I tend to<br/>conclude with a few vague questions and then drift off to get a cup of tea.  <br/>  <br/>This seems a common problem. It's practically the standard ending in blog<br/>entries--- with the addition of a "heh" or an emoticon, prompted by the all<br/>too accurate sense that something is missing.  <br/>  <br/>And indeed, a lot of published essays peter out in this same way. Particularly<br/>the sort written by the staff writers of newsmagazines. Outside writers tend<br/>to supply editorials of the defend-a-position variety, which make a beeline<br/>toward a rousing (and foreordained) conclusion. But the staff writers feel<br/>obliged to write something more balanced, which in practice ends up meaning<br/>blurry. Since they're writing for a popular magazine, they start with the most<br/>radioactively controversial questions, from which (because they're writing for<br/>a popular magazine) they then proceed to recoil from in terror. Gay marriage,<br/>for or against? This group says one thing. That group says another. One thing<br/>is certain: the question is a complex one. (But don't get mad at us. We didn't<br/>draw any conclusions.)  <br/>  <br/>Questions aren't enough. An essay has to come up with answers. They don't<br/>always, of course. Sometimes you start with a promising question and get<br/>nowhere. But those you don't publish. Those are like experiments that get<br/>inconclusive results. Something you publish ought to tell the reader something<br/>he didn't already know.  <br/>  <br/>But _what_ you tell him doesn't matter, so long as it's interesting. I'm<br/>sometimes accused of meandering. In defend-a-position writing that would be a<br/>flaw. There you're not concerned with truth. You already know where you're<br/>going, and you want to go straight there, blustering through obstacles, and<br/>hand-waving your way across swampy ground. But that's not what you're trying<br/>to do in an essay. An essay is supposed to be a search for truth. It would be<br/>suspicious if it didn't meander.  <br/>  <br/>The Meander is a river in Asia Minor (aka Turkey). As you might expect, it<br/>winds all over the place. But does it do this out of frivolity? Quite the<br/>opposite. Like all rivers, it's rigorously following the laws of physics. The<br/>path it has discovered, winding as it is, represents the most economical route<br/>to the sea.  <br/>  <br/>The river's algorithm is simple. At each step, flow down. For the essayist<br/>this translates to: flow interesting. Of all the places to go next, choose<br/>whichever seems most interesting.  <br/>  <br/>I'm pushing this metaphor a bit. An essayist can't have quite as little<br/>foresight as a river. In fact what you do (or what I do) is somewhere between<br/>a river and a roman road-builder. I have a general idea of the direction I<br/>want to go in, and I choose the next topic with that in mind. This essay is<br/>about writing, so I do occasionally yank it back in that direction, but it is<br/>not all the sort of essay I thought I was going to write about writing.  <br/>  <br/>Note too that hill-climbing (which is what this algorithm is called) can get<br/>you in trouble. Sometimes, just like a river, you run up against a blank wall.<br/>What I do then is just what the river does: backtrack. At one point in this<br/>essay I found that after following a certain thread I ran out of ideas. I had<br/>to go back n paragraphs and start over in another direction. For illustrative<br/>purposes I've left the abandoned branch as a footnote.  <br/>  <br/>Err on the side of the river. An essay is not a reference work. It's not<br/>something you read looking for a specific answer, and feel cheated if you<br/>don't find it. I'd much rather read an essay that went off in an unexpected<br/>but interesting direction than one that plodded dutifully along a prescribed<br/>course.  <br/>  <br/>So what's interesting? For me, interesting means surprise. Design, as Matz has<br/>said, should follow the principle of least surprise. A button that looks like<br/>it will make a machine stop should make it stop, not speed up. Essays should<br/>do the opposite. Essays should aim for maximum surprise.  <br/>  <br/>I was afraid of flying for a long time and could only travel vicariously. When<br/>friends came back from faraway places, it wasn't just out of politeness that I<br/>asked them about their trip. I really wanted to know. And I found that the<br/>best way to get information out of them was to ask what surprised them. How<br/>was the place different from what they expected? This is an extremely useful<br/>question. You can ask it of even the most unobservant people, and it will<br/>extract information they didn't even know they were recording.  <br/>  <br/>Indeed, you can ask it in real time. Now when I go somewhere new, I make a<br/>note of what surprises me about it. Sometimes I even make a conscious effort<br/>to visualize the place beforehand, so I'll have a detailed image to diff with<br/>reality.  <br/>  <br/>Surprises are facts you didn't already know. But they're more than that.<br/>They're facts that contradict things you thought you knew. And so they're the<br/>most valuable sort of fact you can get. They're like a food that's not merely<br/>healthy, but counteracts the unhealthy effects of things you've already eaten.  <br/>  <br/>How do you find surprises? Well, therein lies half the work of essay writing.<br/>(The other half is expressing yourself well.) You can at least use yourself as<br/>a proxy for the reader. You should only write about things you've thought<br/>about a lot. And anything you come across that surprises you, who've thought<br/>about the topic a lot, will probably surprise most readers.  <br/>  <br/>For example, in a recent essay I pointed out that because you can only judge<br/>computer programmers by working with them, no one knows in programming who the<br/>heroes should be. I certainly didn't realize this when I started writing the<br/>essay, and even now I find it kind of weird. That's what you're looking for.  <br/>  <br/>So if you want to write essays, you need two ingredients: you need a few<br/>topics that you think about a lot, and you need some ability to ferret out the<br/>unexpected.  <br/>  <br/>What should you think about? My guess is that it doesn't matter. Almost<br/>everything is interesting if you get deeply enough into it. The one possible<br/>exception are things like working in fast food, which have deliberately had<br/>all the variation sucked out of them. In retrospect, was there anything<br/>interesting about working in Baskin-Robbins? Well, it was interesting to<br/>notice how important color was to the customers. Kids a certain age would<br/>point into the case and say that they wanted yellow. Did they want French<br/>Vanilla or Lemon? They would just look at you blankly. They wanted yellow. And<br/>then there was the mystery of why the perennial favorite Pralines n' Cream was<br/>so appealing. I'm inclined now to think it was the salt. And the mystery of<br/>why Passion Fruit tasted so disgusting. People would order it because of the<br/>name, and were always disappointed. It should have been called In-sink-erator<br/>Fruit. And there was the difference in the way fathers and mothers bought ice<br/>cream for their kids. Fathers tended to adopt the attitude of benevolent kings<br/>bestowing largesse, and mothers that of harried bureaucrats, giving in to<br/>pressure against their better judgement. So, yes, there does seem to be<br/>material, even in fast food.  <br/>  <br/>What about the other half, ferreting out the unexpected? That may require some<br/>natural ability. I've noticed for a long time that I'm pathologically<br/>observant. ....  <br/>  <br/>[That was as far as I'd gotten at the time.]  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[sh] In Shakespeare's own time, serious writing meant theological discourses,<br/>not the bawdy plays acted over on the other side of the river among the bear<br/>gardens and whorehouses.  <br/>  <br/>The other extreme, the work that seems formidable from the moment it's created<br/>(indeed, is deliberately intended to be) is represented by Milton. Like the<br/>Aeneid, Paradise Lost is a rock imitating a butterfly that happened to get<br/>fossilized. Even Samuel Johnson seems to have balked at this, on the one hand<br/>paying Milton the compliment of an extensive biography, and on the other<br/>writing of Paradise Lost that "none who read it ever wished it longer."  <br/>  <br/>  <br/>  <br/>  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>July 2007  <br/>  <br/>I have too much stuff. Most people in America do. In fact, the poorer people<br/>are, the more stuff they seem to have. Hardly anyone is so poor that they<br/>can't afford a front yard full of old cars.  <br/>  <br/>It wasn't always this way. Stuff used to be rare and valuable. You can still<br/>see evidence of that if you look for it. For example, in my house in<br/>Cambridge, which was built in 1876, the bedrooms don't have closets. In those<br/>days people's stuff fit in a chest of drawers. Even as recently as a few<br/>decades ago there was a lot less stuff. When I look back at photos from the<br/>1970s, I'm surprised how empty houses look. As a kid I had what I thought was<br/>a huge fleet of toy cars, but they'd be dwarfed by the number of toys my<br/>nephews have. All together my Matchboxes and Corgis took up about a third of<br/>the surface of my bed. In my nephews' rooms the bed is the only clear space.  <br/>  <br/>Stuff has gotten a lot cheaper, but our attitudes toward it haven't changed<br/>correspondingly. We overvalue stuff.  <br/>  <br/>That was a big problem for me when I had no money. I felt poor, and stuff<br/>seemed valuable, so almost instinctively I accumulated it. Friends would leave<br/>something behind when they moved, or I'd see something as I was walking down<br/>the street on trash night (beware of anything you find yourself describing as<br/>"perfectly good"), or I'd find something in almost new condition for a tenth<br/>its retail price at a garage sale. And pow, more stuff.  <br/>  <br/>In fact these free or nearly free things weren't bargains, because they were<br/>worth even less than they cost. Most of the stuff I accumulated was worthless,<br/>because I didn't need it.  <br/>  <br/>What I didn't understand was that the value of some new acquisition wasn't the<br/>difference between its retail price and what I paid for it. It was the value I<br/>derived from it. Stuff is an extremely illiquid asset. Unless you have some<br/>plan for selling that valuable thing you got so cheaply, what difference does<br/>it make what it's "worth?" The only way you're ever going to extract any value<br/>from it is to use it. And if you don't have any immediate use for it, you<br/>probably never will.  <br/>  <br/>Companies that sell stuff have spent huge sums training us to think stuff is<br/>still valuable. But it would be closer to the truth to treat stuff as<br/>worthless.  <br/>  <br/>In fact, worse than worthless, because once you've accumulated a certain<br/>amount of stuff, it starts to own you rather than the other way around. I know<br/>of one couple who couldn't retire to the town they preferred because they<br/>couldn't afford a place there big enough for all their stuff. Their house<br/>isn't theirs; it's their stuff's.  <br/>  <br/>And unless you're extremely organized, a house full of stuff can be very<br/>depressing. A cluttered room saps one's spirits. One reason, obviously, is<br/>that there's less room for people in a room full of stuff. But there's more<br/>going on than that. I think humans constantly scan their environment to build<br/>a mental model of what's around them. And the harder a scene is to parse, the<br/>less energy you have left for conscious thoughts. A cluttered room is<br/>literally exhausting.  <br/>  <br/>(This could explain why clutter doesn't seem to bother kids as much as adults.<br/>Kids are less perceptive. They build a coarser model of their surroundings,<br/>and this consumes less energy.)  <br/>  <br/>I first realized the worthlessness of stuff when I lived in Italy for a year.<br/>All I took with me was one large backpack of stuff. The rest of my stuff I<br/>left in my landlady's attic back in the US. And you know what? All I missed<br/>were some of the books. By the end of the year I couldn't even remember what<br/>else I had stored in that attic.  <br/>  <br/>And yet when I got back I didn't discard so much as a box of it. Throw away a<br/>perfectly good rotary telephone? I might need that one day.  <br/>  <br/>The really painful thing to recall is not just that I accumulated all this<br/>useless stuff, but that I often spent money I desperately needed on stuff that<br/>I didn't.  <br/>  <br/>Why would I do that? Because the people whose job is to sell you stuff are<br/>really, really good at it. The average 25 year old is no match for companies<br/>that have spent years figuring out how to get you to spend money on stuff.<br/>They make the experience of buying stuff so pleasant that "shopping" becomes a<br/>leisure activity.  <br/>  <br/>How do you protect yourself from these people? It can't be easy. I'm a fairly<br/>skeptical person, and their tricks worked on me well into my thirties. But one<br/>thing that might work is to ask yourself, before buying something, "is this<br/>going to make my life noticeably better?"  <br/>  <br/>A friend of mine cured herself of a clothes buying habit by asking herself<br/>before she bought anything "Am I going to wear this all the time?" If she<br/>couldn't convince herself that something she was thinking of buying would<br/>become one of those few things she wore all the time, she wouldn't buy it. I<br/>think that would work for any kind of purchase. Before you buy anything, ask<br/>yourself: will this be something I use constantly? Or is it just something<br/>nice? Or worse still, a mere bargain?  <br/>  <br/>The worst stuff in this respect may be stuff you don't use much because it's<br/>too good. Nothing owns you like fragile stuff. For example, the "good china"<br/>so many households have, and whose defining quality is not so much that it's<br/>fun to use, but that one must be especially careful not to break it.  <br/>  <br/>Another way to resist acquiring stuff is to think of the overall cost of<br/>owning it. The purchase price is just the beginning. You're going to have to<br/>_think_ about that thing for years—perhaps for the rest of your life. Every<br/>thing you own takes energy away from you. Some give more than they take. Those<br/>are the only things worth having.  <br/>  <br/>I've now stopped accumulating stuff. Except books—but books are different.<br/>Books are more like a fluid than individual objects. It's not especially<br/>inconvenient to own several thousand books, whereas if you owned several<br/>thousand random possessions you'd be a local celebrity. But except for books,<br/>I now actively avoid stuff. If I want to spend money on some kind of treat,<br/>I'll take services<br/><br/>Spanish Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Italian Translation  <br/>  <br/><br/>Polish Translation  <br/>  <br/><br/>Turkish Translation  <br/>  <br/><br/>French Translation  <br/>  <br/><br/>Slovak Translation  <br/>  <br/><br/>Romanian Translation  <br/>  <br/><br/>German Translation  <br/>  <br/><br/>December 2014  <br/>  <br/>I've read Villehardouin's chronicle of the Fourth Crusade at least two times,<br/>maybe three. And yet if I had to write down everything I remember from it, I<br/>doubt it would amount to much more than a page. Multiply this times several<br/>hundred, and I get an uneasy feeling when I look at my bookshelves. What use<br/>is it to read all these books if I remember so little from them?  <br/>  <br/>A few months ago, as I was reading Constance Reid's excellent biography of<br/>Hilbert, I figured out if not the answer to this question, at least something<br/>that made me feel better about it. She writes:<br/><br/>> Hilbert had no patience with mathematical lectures which filled the students<br/>> with facts but did not teach them how to frame a problem and solve it. He<br/>> often used to tell them that "a perfect formulation of a problem is already<br/>> half its solution."<br/><br/>That has always seemed to me an important point, and I was even more convinced<br/>of it after hearing it confirmed by Hilbert.  <br/>  <br/>But how had I come to believe in this idea in the first place? A combination<br/>of my own experience and other things I'd read. None of which I could at that<br/>moment remember! And eventually I'd forget that Hilbert had confirmed it too.<br/>But my increased belief in the importance of this idea would remain something<br/>I'd learned from this book, even after I'd forgotten I'd learned it.  <br/>  <br/>Reading and experience train your model of the world. And even if you forget<br/>the experience or what you read, its effect on your model of the world<br/>persists. Your mind is like a compiled program you've lost the source of. It<br/>works, but you don't know why.  <br/>  <br/>The place to look for what I learned from Villehardouin's chronicle is not<br/>what I remember from it, but my mental models of the crusades, Venice,<br/>medieval culture, siege warfare, and so on. Which doesn't mean I couldn't have<br/>read more attentively, but at least the harvest of reading is not so miserably<br/>small as it might seem.  <br/>  <br/>This is one of those things that seem obvious in retrospect. But it was a<br/>surprise to me and presumably would be to anyone else who felt uneasy about<br/>(apparently) forgetting so much they'd read.  <br/>  <br/>Realizing it does more than make you feel a little better about forgetting,<br/>though. There are specific implications.  <br/>  <br/>For example, reading and experience are usually "compiled" at the time they<br/>happen, using the state of your brain at that time. The same book would get<br/>compiled differently at different points in your life. Which means it is very<br/>much worth reading important books multiple times. I always used to feel some<br/>misgivings about rereading books. I unconsciously lumped reading together with<br/>work like carpentry, where having to do something again is a sign you did it<br/>wrong the first time. Whereas now the phrase "already read" seems almost ill-<br/>formed.  <br/>  <br/>Intriguingly, this implication isn't limited to books. Technology will<br/>increasingly make it possible to relive our experiences. When people do that<br/>today it's usually to enjoy them again (e.g. when looking at pictures of a<br/>trip) or to find the origin of some bug in their compiled code (e.g. when<br/>Stephen Fry succeeded in remembering the childhood trauma that prevented him<br/>from singing). But as technologies for recording and playing back your life<br/>improve, it may become common for people to relive experiences without any<br/>goal in mind, simply to learn from them again as one might when rereading a<br/>book.  <br/>  <br/>Eventually we may be able not just to play back experiences but also to index<br/>and even edit them. So although not knowing how you know things may seem part<br/>of being human, it may not be.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Thanks** to Sam Altman, Jessica Livingston, and Robert Morris for reading<br/>drafts of this.  <br/>  <br/><br/>Japanese Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>There is a kind of mania for object-oriented programming at the moment, but<br/>some of the smartest programmers I know are some of the least excited about<br/>it.  <br/>  <br/>My own feeling is that object-oriented programming is a useful technique in<br/>some cases, but it isn't something that has to pervade every program you<br/>write. You should be able to define new types, but you shouldn't have to<br/>express every program as the definition of new types.  <br/>  <br/>I think there are five reasons people like object-oriented programming, and<br/>three and a half of them are bad:  <br/>  <br/><br/>  1. Object-oriented programming is exciting if you have a statically-typed language without lexical closures or macros. To some degree, it offers a way around these limitations. (See Greenspun's Tenth Rule.)  <br/>  <br/><br/>  2. Object-oriented programming is popular in big companies, because it suits the way they write software. At big companies, software tends to be written by large (and frequently changing) teams of mediocre programmers. Object-oriented programming imposes a discipline on these programmers that prevents any one of them from doing too much damage. The price is that the resulting code is bloated with protocols and full of duplication. This is not too high a price for big companies, because their software is probably going to be bloated and full of duplication anyway.  <br/>  <br/><br/>  3. Object-oriented programming generates a lot of what looks like work. Back in the days of fanfold, there was a type of programmer who would only put five or ten lines of code on a page, preceded by twenty lines of elaborately formatted comments. Object-oriented programming is like crack for these people: it lets you incorporate all this scaffolding right into your source code. Something that a Lisp hacker might handle by pushing a symbol onto a list becomes a whole file of classes and methods. So it is a good tool if you want to convince yourself, or someone else, that you are doing a lot of work.  <br/>  <br/><br/>  4. If a language is itself an object-oriented program, it can be extended by users. Well, maybe. Or maybe you can do even better by offering the sub-concepts of object-oriented programming a la carte. Overloading, for example, is not intrinsically tied to classes. We'll see.  <br/>  <br/><br/>  5. Object-oriented abstractions map neatly onto the domains of certain specific kinds of programs, like simulations and CAD systems. <br/><br/>I personally have never needed object-oriented abstractions. Common Lisp has<br/>an enormously powerful object system and I've never used it once. I've done a<br/>lot of things (e.g. making hash tables full of closures) that would have<br/>required object-oriented techniques to do in wimpier languages, but I have<br/>never had to use CLOS.  <br/>  <br/>Maybe I'm just stupid, or have worked on some limited subset of applications.<br/>There is a danger in designing a language based on one's own experience of<br/>programming. But it seems more dangerous to put stuff in that you've never<br/>needed because it's thought to be a good idea.  <br/>  <br/><br/>Rees Re: OO  <br/><br/>Spanish Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>September 2012  <br/>  <br/>A startup is a company designed to grow fast. Being newly founded does not in<br/>itself make a company a startup. Nor is it necessary for a startup to work on<br/>technology, or take venture funding, or have some sort of "exit." The only<br/>essential thing is growth. Everything else we associate with startups follows<br/>from growth.  <br/>  <br/>If you want to start one it's important to understand that. Startups are so<br/>hard that you can't be pointed off to the side and hope to succeed. You have<br/>to know that growth is what you're after. The good news is, if you get growth,<br/>everything else tends to fall into place. Which means you can use growth like<br/>a compass to make almost every decision you face.  <br/>  <br/>**Redwoods**  <br/>  <br/>Let's start with a distinction that should be obvious but is often overlooked:<br/>not every newly founded company is a startup. Millions of companies are<br/>started every year in the US. Only a tiny fraction are startups. Most are<br/>service businesses — restaurants, barbershops, plumbers, and so on. These are<br/>not startups, except in a few unusual cases. A barbershop isn't designed to<br/>grow fast. Whereas a search engine, for example, is.  <br/>  <br/>When I say startups are designed to grow fast, I mean it in two senses. Partly<br/>I mean designed in the sense of intended, because most startups fail. But I<br/>also mean startups are different by nature, in the same way a redwood seedling<br/>has a different destiny from a bean sprout.  <br/>  <br/>That difference is why there's a distinct word, "startup," for companies<br/>designed to grow fast. If all companies were essentially similar, but some<br/>through luck or the efforts of their founders ended up growing very fast, we<br/>wouldn't need a separate word. We could just talk about super-successful<br/>companies and less successful ones. But in fact startups do have a different<br/>sort of DNA from other businesses. Google is not just a barbershop whose<br/>founders were unusually lucky and hard-working. Google was different from the<br/>beginning.  <br/>  <br/>To grow rapidly, you need to make something you can sell to a big market.<br/>That's the difference between Google and a barbershop. A barbershop doesn't<br/>scale.  <br/>  <br/>For a company to grow really big, it must (a) make something lots of people<br/>want, and (b) reach and serve all those people. Barbershops are doing fine in<br/>the (a) department. Almost everyone needs their hair cut. The problem for a<br/>barbershop, as for any retail establishment, is (b). A barbershop serves<br/>customers in person, and few will travel far for a haircut. And even if they<br/>did, the barbershop couldn't accomodate them. [1]  <br/>  <br/>Writing software is a great way to solve (b), but you can still end up<br/>constrained in (a). If you write software to teach Tibetan to Hungarian<br/>speakers, you'll be able to reach most of the people who want it, but there<br/>won't be many of them. If you make software to teach English to Chinese<br/>speakers, however, you're in startup territory.  <br/>  <br/>Most businesses are tightly constrained in (a) or (b). The distinctive feature<br/>of successful startups is that they're not.  <br/>  <br/>**Ideas**  <br/>  <br/>It might seem that it would always be better to start a startup than an<br/>ordinary business. If you're going to start a company, why not start the type<br/>with the most potential? The catch is that this is a (fairly) efficient<br/>market. If you write software to teach Tibetan to Hungarians, you won't have<br/>much competition. If you write software to teach English to Chinese speakers,<br/>you'll face ferocious competition, precisely because that's such a larger<br/>prize. [2]  <br/>  <br/>The constraints that limit ordinary companies also protect them. That's the<br/>tradeoff. If you start a barbershop, you only have to compete with other local<br/>barbers. If you start a search engine you have to compete with the whole<br/>world.  <br/>  <br/>The most important thing that the constraints on a normal business protect it<br/>from is not competition, however, but the difficulty of coming up with new<br/>ideas. If you open a bar in a particular neighborhood, as well as limiting<br/>your potential and protecting you from competitors, that geographic constraint<br/>also helps define your company. Bar + neighborhood is a sufficient idea for a<br/>small business. Similarly for companies constrained in (a). Your niche both<br/>protects and defines you.  <br/>  <br/>Whereas if you want to start a startup, you're probably going to have to think<br/>of something fairly novel. A startup has to make something it can deliver to a<br/>large market, and ideas of that type are so valuable that all the obvious ones<br/>are already taken.  <br/>  <br/>That space of ideas has been so thoroughly picked over that a startup<br/>generally has to work on something everyone else has overlooked. I was going<br/>to write that one has to make a conscious effort to find ideas everyone else<br/>has overlooked. But that's not how most startups get started. Usually<br/>successful startups happen because the founders are sufficiently different<br/>from other people that ideas few others can see seem obvious to them. Perhaps<br/>later they step back and notice they've found an idea in everyone else's blind<br/>spot, and from that point make a deliberate effort to stay there. [3] But at<br/>the moment when successful startups get started, much of the innovation is<br/>unconscious.  <br/>  <br/>What's different about successful founders is that they can see different<br/>problems. It's a particularly good combination both to be good at technology<br/>and to face problems that can be solved by it, because technology changes so<br/>rapidly that formerly bad ideas often become good without anyone noticing.<br/>Steve Wozniak's problem was that he wanted his own computer. That was an<br/>unusual problem to have in 1975. But technological change was about to make it<br/>a much more common one. Because he not only wanted a computer but knew how to<br/>build them, Wozniak was able to make himself one. And the problem he solved<br/>for himself became one that Apple solved for millions of people in the coming<br/>years. But by the time it was obvious to ordinary people that this was a big<br/>market, Apple was already established.  <br/>  <br/>Google has similar origins. Larry Page and Sergey Brin wanted to search the<br/>web. But unlike most people they had the technical expertise both to notice<br/>that existing search engines were not as good as they could be, and to know<br/>how to improve them. Over the next few years their problem became everyone's<br/>problem, as the web grew to a size where you didn't have to be a picky search<br/>expert to notice the old algorithms weren't good enough. But as happened with<br/>Apple, by the time everyone else realized how important search was, Google was<br/>entrenched.  <br/>  <br/>That's one connection between startup ideas and technology. Rapid change in<br/>one area uncovers big, soluble problems in other areas. Sometimes the changes<br/>are advances, and what they change is solubility. That was the kind of change<br/>that yielded Apple; advances in chip technology finally let Steve Wozniak<br/>design a computer he could afford. But in Google's case the most important<br/>change was the growth of the web. What changed there was not solubility but<br/>bigness.  <br/>  <br/>The other connection between startups and technology is that startups create<br/>new ways of doing things, and new ways of doing things are, in the broader<br/>sense of the word, new technology. When a startup both begins with an idea<br/>exposed by technological change and makes a product consisting of technology<br/>in the narrower sense (what used to be called "high technology"), it's easy to<br/>conflate the two. But the two connections are distinct and in principle one<br/>could start a startup that was neither driven by technological change, nor<br/>whose product consisted of technology except in the broader sense. [4]  <br/>  <br/> **Rate**  <br/>  <br/>How fast does a company have to grow to be considered a startup? There's no<br/>precise answer to that. "Startup" is a pole, not a threshold. Starting one is<br/>at first no more than a declaration of one's ambitions. You're committing not<br/>just to starting a company, but to starting a fast growing one, and you're<br/>thus committing to search for one of the rare ideas of that type. But at first<br/>you have no more than commitment. Starting a startup is like being an actor in<br/>that respect. "Actor" too is a pole rather than a threshold. At the beginning<br/>of his career, an actor is a waiter who goes to auditions. Getting work makes<br/>him a successful actor, but he doesn't only become an actor when he's<br/>successful.  <br/>  <br/>So the real question is not what growth rate makes a company a startup, but<br/>what growth rate successful startups tend to have. For founders that's more<br/>than a theoretical question, because it's equivalent to asking if they're on<br/>the right path.  <br/>  <br/>The growth of a successful startup usually has three phases:<br/><br/>  1. There's an initial period of slow or no growth while the startup tries to figure out what it's doing.  <br/>  <br/><br/>  2. As the startup figures out how to make something lots of people want and how to reach those people, there's a period of rapid growth.  <br/>  <br/><br/>  3. Eventually a successful startup will grow into a big company. Growth will slow, partly due to internal limits and partly because the company is starting to bump up against the limits of the markets it serves. [5]<br/><br/>Together these three phases produce an S-curve. The phase whose growth defines<br/>the startup is the second one, the ascent. Its length and slope determine how<br/>big the company will be.  <br/>  <br/>The slope is the company's growth rate. If there's one number every founder<br/>should always know, it's the company's growth rate. That's the measure of a<br/>startup. If you don't know that number, you don't even know if you're doing<br/>well or badly.  <br/>  <br/>When I first meet founders and ask what their growth rate is, sometimes they<br/>tell me "we get about a hundred new customers a month." That's not a rate.<br/>What matters is not the absolute number of new customers, but the ratio of new<br/>customers to existing ones. If you're really getting a constant number of new<br/>customers every month, you're in trouble, because that means your growth rate<br/>is decreasing.  <br/>  <br/>During Y Combinator we measure growth rate per week, partly because there is<br/>so little time before Demo Day, and partly because startups early on need<br/>frequent feedback from their users to tweak what they're doing. [6]  <br/>  <br/>A good growth rate during YC is 5-7% a week. If you can hit 10% a week you're<br/>doing exceptionally well. If you can only manage 1%, it's a sign you haven't<br/>yet figured out what you're doing.  <br/>  <br/>The best thing to measure the growth rate of is revenue. The next best, for<br/>startups that aren't charging initially, is active users. That's a reasonable<br/>proxy for revenue growth because whenever the startup does start trying to<br/>make money, their revenues will probably be a constant multiple of active<br/>users. [7]  <br/>  <br/>**Compass**  <br/>  <br/>We usually advise startups to pick a growth rate they think they can hit, and<br/>then just try to hit it every week. The key word here is "just." If they<br/>decide to grow at 7% a week and they hit that number, they're successful for<br/>that week. There's nothing more they need to do. But if they don't hit it,<br/>they've failed in the only thing that mattered, and should be correspondingly<br/>alarmed.  <br/>  <br/>Programmers will recognize what we're doing here. We're turning starting a<br/>startup into an optimization problem. And anyone who has tried optimizing code<br/>knows how wonderfully effective that sort of narrow focus can be. Optimizing<br/>code means taking an existing program and changing it to use less of<br/>something, usually time or memory. You don't have to think about what the<br/>program should do, just make it faster. For most programmers this is very<br/>satisfying work. The narrow focus makes it a sort of puzzle, and you're<br/>generally surprised how fast you can solve it.  <br/>  <br/>Focusing on hitting a growth rate reduces the otherwise bewilderingly<br/>multifarious problem of starting a startup to a single problem. You can use<br/>that target growth rate to make all your decisions for you; anything that gets<br/>you the growth you need is ipso facto right. Should you spend two days at a<br/>conference? Should you hire another programmer? Should you focus more on<br/>marketing? Should you spend time courting some big customer? Should you add x<br/>feature? Whatever gets you your target growth rate. [8]  <br/>  <br/>Judging yourself by weekly growth doesn't mean you can look no more than a<br/>week ahead. Once you experience the pain of missing your target one week (it<br/>was the only thing that mattered, and you failed at it), you become interested<br/>in anything that could spare you such pain in the future. So you'll be willing<br/>for example to hire another programmer, who won't contribute to this week's<br/>growth but perhaps in a month will have implemented some new feature that will<br/>get you more users. But only if (a) the distraction of hiring someone won't<br/>make you miss your numbers in the short term, and (b) you're sufficiently<br/>worried about whether you can keep hitting your numbers without hiring someone<br/>new.  <br/>  <br/>It's not that you don't think about the future, just that you think about it<br/>no more than necessary.  <br/>  <br/>In theory this sort of hill-climbing could get a startup into trouble. They<br/>could end up on a local maximum. But in practice that never happens. Having to<br/>hit a growth number every week forces founders to act, and acting versus not<br/>acting is the high bit of succeeding. Nine times out of ten, sitting around<br/>strategizing is just a form of procrastination. Whereas founders' intuitions<br/>about which hill to climb are usually better than they realize. Plus the<br/>maxima in the space of startup ideas are not spiky and isolated. Most fairly<br/>good ideas are adjacent to even better ones.  <br/>  <br/>The fascinating thing about optimizing for growth is that it can actually<br/>discover startup ideas. You can use the need for growth as a form of<br/>evolutionary pressure. If you start out with some initial plan and modify it<br/>as necessary to keep hitting, say, 10% weekly growth, you may end up with a<br/>quite different company than you meant to start. But anything that grows<br/>consistently at 10% a week is almost certainly a better idea than you started<br/>with.  <br/>  <br/>There's a parallel here to small businesses. Just as the constraint of being<br/>located in a particular neighborhood helps define a bar, the constraint of<br/>growing at a certain rate can help define a startup.  <br/>  <br/>You'll generally do best to follow that constraint wherever it leads rather<br/>than being influenced by some initial vision, just as a scientist is better<br/>off following the truth wherever it leads rather than being influenced by what<br/>he wishes were the case. When Richard Feynman said that the imagination of<br/>nature was greater than the imagination of man, he meant that if you just keep<br/>following the truth you'll discover cooler things than you could ever have<br/>made up. For startups, growth is a constraint much like truth. Every<br/>successful startup is at least partly a product of the imagination of growth.<br/>[9]  <br/>  <br/>**Value**  <br/>  <br/>It's hard to find something that grows consistently at several percent a week,<br/>but if you do you may have found something surprisingly valuable. If we<br/>project forward we see why.  <br/>  <br/><br/>A company that grows at 1% a week will grow 1.7x a year, whereas a company<br/>that grows at 5% a week will grow 12.6x. A company making $1000 a month (a<br/>typical number early in YC) and growing at 1% a week will 4 years later be<br/>making $7900 a month, which is less than a good programmer makes in salary in<br/>Silicon Valley. A startup that grows at 5% a week will in 4 years be making<br/>$25 million a month. [10]  <br/>  <br/>Our ancestors must rarely have encountered cases of exponential growth,<br/>because our intutitions are no guide here. What happens to fast growing<br/>startups tends to surprise even the founders.  <br/>  <br/>Small variations in growth rate produce qualitatively different outcomes.<br/>That's why there's a separate word for startups, and why startups do things<br/>that ordinary companies don't, like raising money and getting acquired. And,<br/>strangely enough, it's also why they fail so frequently.  <br/>  <br/>Considering how valuable a successful startup can become, anyone familiar with<br/>the concept of expected value would be surprised if the failure rate weren't<br/>high. If a successful startup could make a founder $100 million, then even if<br/>the chance of succeeding were only 1%, the expected value of starting one<br/>would be $1 million. And the probability of a group of sufficiently smart and<br/>determined founders succeeding on that scale might be significantly over 1%.<br/>For the right people — e.g. the young Bill Gates — the probability might be<br/>20% or even 50%. So it's not surprising that so many want to take a shot at<br/>it. In an efficient market, the number of failed startups should be<br/>proportionate to the size of the successes. And since the latter is huge the<br/>former should be too. [11]  <br/>  <br/>What this means is that at any given time, the great majority of startups will<br/>be working on something that's never going to go anywhere, and yet glorifying<br/>their doomed efforts with the grandiose title of "startup."  <br/>  <br/>This doesn't bother me. It's the same with other high-beta vocations, like<br/>being an actor or a novelist. I've long since gotten used to it. But it seems<br/>to bother a lot of people, particularly those who've started ordinary<br/>businesses. Many are annoyed that these so-called startups get all the<br/>attention, when hardly any of them will amount to anything.  <br/>  <br/>If they stepped back and looked at the whole picture they might be less<br/>indignant. The mistake they're making is that by basing their opinions on<br/>anecdotal evidence they're implicitly judging by the median rather than the<br/>average. If you judge by the median startup, the whole concept of a startup<br/>seems like a fraud. You have to invent a bubble to explain why founders want<br/>to start them or investors want to fund them. But it's a mistake to use the<br/>median in a domain with so much variation. If you look at the average outcome<br/>rather than the median, you can understand why investors like them, and why,<br/>if they aren't median people, it's a rational choice for founders to start<br/>them.  <br/>  <br/>**Deals**  <br/>  <br/>Why do investors like startups so much? Why are they so hot to invest in<br/>photo-sharing apps, rather than solid money-making businesses? Not only for<br/>the obvious reason.  <br/>  <br/>The test of any investment is the ratio of return to risk. Startups pass that<br/>test because although they're appallingly risky, the returns when they do<br/>succeed are so high. But that's not the only reason investors like startups.<br/>An ordinary slower-growing business might have just as good a ratio of return<br/>to risk, if both were lower. So why are VCs interested only in high-growth<br/>companies? The reason is that they get paid by getting their capital back,<br/>ideally after the startup IPOs, or failing that when it's acquired.  <br/>  <br/>The other way to get returns from an investment is in the form of dividends.<br/>Why isn't there a parallel VC industry that invests in ordinary companies in<br/>return for a percentage of their profits? Because it's too easy for people who<br/>control a private company to funnel its revenues to themselves (e.g. by buying<br/>overpriced components from a supplier they control) while making it look like<br/>the company is making little profit. Anyone who invested in private companies<br/>in return for dividends would have to pay close attention to their books.  <br/>  <br/>The reason VCs like to invest in startups is not simply the returns, but also<br/>because such investments are so easy to oversee. The founders can't enrich<br/>themselves without also enriching the investors. [12]  <br/>  <br/>Why do founders want to take the VCs' money? Growth, again. The constraint<br/>between good ideas and growth operates in both directions. It's not merely<br/>that you need a scalable idea to grow. If you have such an idea and don't grow<br/>fast enough, competitors will. Growing too slowly is particularly dangerous in<br/>a business with network effects, which the best startups usually have to some<br/>degree.  <br/>  <br/>Almost every company needs some amount of funding to get started. But startups<br/>often raise money even when they are or could be profitable. It might seem<br/>foolish to sell stock in a profitable company for less than you think it will<br/>later be worth, but it's no more foolish than buying insurance. Fundamentally<br/>that's how the most successful startups view fundraising. They could grow the<br/>company on its own revenues, but the extra money and help supplied by VCs will<br/>let them grow even faster. Raising money lets you _choose_ your growth rate.  <br/>  <br/>Money to grow faster is always at the command of the most successful startups,<br/>because the VCs need them more than they need the VCs. A profitable startup<br/>could if it wanted just grow on its own revenues. Growing slower might be<br/>slightly dangerous, but chances are it wouldn't kill them. Whereas VCs need to<br/>invest in startups, and in particular the most successful startups, or they'll<br/>be out of business. Which means that any sufficiently promising startup will<br/>be offered money on terms they'd be crazy to refuse. And yet because of the<br/>scale of the successes in the startup business, VCs can still make money from<br/>such investments. You'd have to be crazy to believe your company was going to<br/>become as valuable as a high growth rate can make it, but some do.  <br/>  <br/>Pretty much every successful startup will get acquisition offers too. Why?<br/>What is it about startups that makes other companies want to buy them? [13]  <br/>  <br/>Fundamentally the same thing that makes everyone else want the stock of<br/>successful startups: a rapidly growing company is valuable. It's a good thing<br/>eBay bought Paypal, for example, because Paypal is now responsible for 43% of<br/>their sales and probably more of their growth.  <br/>  <br/>But acquirers have an additional reason to want startups. A rapidly growing<br/>company is not merely valuable, but dangerous. If it keeps expanding, it might<br/>expand into the acquirer's own territory. Most product acquisitions have some<br/>component of fear. Even if an acquirer isn't threatened by the startup itself,<br/>they might be alarmed at the thought of what a competitor could do with it.<br/>And because startups are in this sense doubly valuable to acquirers, acquirers<br/>will often pay more than an ordinary investor would. [14]  <br/>  <br/>**Understand**  <br/>  <br/>The combination of founders, investors, and acquirers forms a natural<br/>ecosystem. It works so well that those who don't understand it are driven to<br/>invent conspiracy theories to explain how neatly things sometimes turn out.<br/>Just as our ancestors did to explain the apparently too neat workings of the<br/>natural world. But there is no secret cabal making it all work.  <br/>  <br/>If you start from the mistaken assumption that Instagram was worthless, you<br/>have to invent a secret boss to force Mark Zuckerberg to buy it. To anyone who<br/>knows Mark Zuckerberg, that is the reductio ad absurdum of the initial<br/>assumption. The reason he bought Instagram was that it was valuable and<br/>dangerous, and what made it so was growth.  <br/>  <br/>If you want to understand startups, understand growth. Growth drives<br/>everything in this world. Growth is why startups usually work on technology —<br/>because ideas for fast growing companies are so rare that the best way to find<br/>new ones is to discover those recently made viable by change, and technology<br/>is the best source of rapid change. Growth is why it's a rational choice<br/>economically for so many founders to try starting a startup: growth makes the<br/>successful companies so valuable that the expected value is high even though<br/>the risk is too. Growth is why VCs want to invest in startups: not just<br/>because the returns are high but also because generating returns from capital<br/>gains is easier to manage than generating returns from dividends. Growth<br/>explains why the most successful startups take VC money even if they don't<br/>need to: it lets them choose their growth rate. And growth explains why<br/>successful startups almost invariably get acquisition offers. To acquirers a<br/>fast-growing company is not merely valuable but dangerous too.  <br/>  <br/>It's not just that if you want to succeed in some domain, you have to<br/>understand the forces driving it. Understanding growth is what starting a<br/>startup _consists_ of. What you're really doing (and to the dismay of some<br/>observers, all you're really doing) when you start a startup is committing to<br/>solve a harder type of problem than ordinary businesses do. You're committing<br/>to search for one of the rare ideas that generates rapid growth. Because these<br/>ideas are so valuable, finding one is hard. The startup is the embodiment of<br/>your discoveries so far. Starting a startup is thus very much like deciding to<br/>be a research scientist: you're not committing to solve any specific problem;<br/>you don't know for sure which problems are soluble; but you're committing to<br/>try to discover something no one knew before. A startup founder is in effect<br/>an economic research scientist. Most don't discover anything that remarkable,<br/>but some discover relativity.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] Strictly speaking it's not lots of customers you need but a big market,<br/>meaning a high product of number of customers times how much they'll pay. But<br/>it's dangerous to have too few customers even if they pay a lot, or the power<br/>that individual customers have over you could turn you into a de facto<br/>consulting firm. So whatever market you're in, you'll usually do best to err<br/>on the side of making the broadest type of product for it.  <br/>  <br/>[2] One year at Startup School David Heinemeier Hansson encouraged programmers<br/>who wanted to start businesses to use a restaurant as a model. What he meant,<br/>I believe, is that it's fine to start software companies constrained in (a) in<br/>the same way a restaurant is constrained in (b). I agree. Most people should<br/>not try to start startups.  <br/>  <br/>[3] That sort of stepping back is one of the things we focus on at Y<br/>Combinator. It's common for founders to have discovered something intuitively<br/>without understanding all its implications. That's probably true of the<br/>biggest discoveries in any field.  <br/>  <br/>[4] I got it wrong in "How to Make Wealth" when I said that a startup was a<br/>small company that takes on a hard technical problem. That is the most common<br/>recipe but not the only one.  <br/>  <br/>[5] In principle companies aren't limited by the size of the markets they<br/>serve, because they could just expand into new markets. But there seem to be<br/>limits on the ability of big companies to do that. Which means the slowdown<br/>that comes from bumping up against the limits of one's markets is ultimately<br/>just another way in which internal limits are expressed.  <br/>  <br/>It may be that some of these limits could be overcome by changing the shape of<br/>the organization — specifically by sharding it.  <br/>  <br/>[6] This is, obviously, only for startups that have already launched or can<br/>launch during YC. A startup building a new database will probably not do that.<br/>On the other hand, launching something small and then using growth rate as<br/>evolutionary pressure is such a valuable technique that any company that could<br/>start this way probably should.  <br/>  <br/>[7] If the startup is taking the Facebook/Twitter route and building something<br/>they hope will be very popular but from which they don't yet have a definite<br/>plan to make money, the growth rate has to be higher, even though it's a proxy<br/>for revenue growth, because such companies need huge numbers of users to<br/>succeed at all.  <br/>  <br/>Beware too of the edge case where something spreads rapidly but the churn is<br/>high as well, so that you have good net growth till you run through all the<br/>potential users, at which point it suddenly stops.  <br/>  <br/>[8] Within YC when we say it's ipso facto right to do whatever gets you<br/>growth, it's implicit that this excludes trickery like buying users for more<br/>than their lifetime value, counting users as active when they're really not,<br/>bleeding out invites at a regularly increasing rate to manufacture a perfect<br/>growth curve, etc. Even if you were able to fool investors with such tricks,<br/>you'd ultimately be hurting yourself, because you're throwing off your own<br/>compass.  <br/>  <br/>[9] Which is why it's such a dangerous mistake to believe that successful<br/>startups are simply the embodiment of some brilliant initial idea. What you're<br/>looking for initially is not so much a great idea as an idea that could evolve<br/>into a great one. The danger is that promising ideas are not merely blurry<br/>versions of great ones. They're often different in kind, because the early<br/>adopters you evolve the idea upon have different needs from the rest of the<br/>market. For example, the idea that evolves into Facebook isn't merely a subset<br/>of Facebook; the idea that evolves into Facebook is a site for Harvard<br/>undergrads.  <br/>  <br/>[10] What if a company grew at 1.7x a year for a really long time? Could it<br/>not grow just as big as any successful startup? In principle yes, of course.<br/>If our hypothetical company making $1000 a month grew at 1% a week for 19<br/>years, it would grow as big as a company growing at 5% a week for 4 years. But<br/>while such trajectories may be common in, say, real estate development, you<br/>don't see them much in the technology business. In technology, companies that<br/>grow slowly tend not to grow as big.  <br/>  <br/>[11] Any expected value calculation varies from person to person depending on<br/>their utility function for money. I.e. the first million is worth more to most<br/>people than subsequent millions. How much more depends on the person. For<br/>founders who are younger or more ambitious the utility function is flatter.<br/>Which is probably part of the reason the founders of the most successful<br/>startups of all tend to be on the young side.  <br/>  <br/>[12] More precisely, this is the case in the biggest winners, which is where<br/>all the returns come from. A startup founder could pull the same trick of<br/>enriching himself at the company's expense by selling them overpriced<br/>components. But it wouldn't be worth it for the founders of Google to do that.<br/>Only founders of failing startups would even be tempted, but those are<br/>writeoffs from the VCs' point of view anyway.  <br/>  <br/>[13] Acquisitions fall into two categories: those where the acquirer wants the<br/>business, and those where the acquirer just wants the employees. The latter<br/>type is sometimes called an HR acquisition. Though nominally acquisitions and<br/>sometimes on a scale that has a significant effect on the expected value<br/>calculation for potential founders, HR acquisitions are viewed by acquirers as<br/>more akin to hiring bonuses.  <br/>  <br/>[14] I once explained this to some founders who had recently arrived from<br/>Russia. They found it novel that if you threatened a company they'd pay a<br/>premium for you. "In Russia they just kill you," they said, and they were only<br/>partly joking. Economically, the fact that established companies can't simply<br/>eliminate new competitors may be one of the most valuable aspects of the rule<br/>of law. And so to the extent we see incumbents suppressing competitors via<br/>regulations or patent suits, we should worry, not because it's a departure<br/>from the rule of law per se but from what the rule of law is aiming at.  <br/>  <br/>**Thanks** to Sam Altman, Marc Andreessen, Paul Buchheit, Patrick Collison,<br/>Jessica Livingston, Geoff Ralston, and Harj Taggar for reading drafts of this.  <br/>  <br/><br/>Arabic Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>July 2006  <br/>  <br/>When I was in high school I spent a lot of time imitating bad writers. What we<br/>studied in English classes was mostly fiction, so I assumed that was the<br/>highest form of writing. Mistake number one. The stories that seemed to be<br/>most admired were ones in which people suffered in complicated ways. Anything<br/>funny or gripping was ipso facto suspect, unless it was old enough to be hard<br/>to understand, like Shakespeare or Chaucer. Mistake number two. The ideal<br/>medium seemed the short story, which I've since learned had quite a brief<br/>life, roughly coincident with the peak of magazine publishing. But since their<br/>size made them perfect for use in high school classes, we read a lot of them,<br/>which gave us the impression the short story was flourishing. Mistake number<br/>three. And because they were so short, nothing really had to happen; you could<br/>just show a randomly truncated slice of life, and that was considered<br/>advanced. Mistake number four. The result was that I wrote a lot of stories in<br/>which nothing happened except that someone was unhappy in a way that seemed<br/>deep.  <br/>  <br/>For most of college I was a philosophy major. I was very impressed by the<br/>papers published in philosophy journals. They were so beautifully typeset, and<br/>their tone was just captivating—alternately casual and buffer-overflowingly<br/>technical. A fellow would be walking along a street and suddenly modality qua<br/>modality would spring upon him. I didn't ever quite understand these papers,<br/>but I figured I'd get around to that later, when I had time to reread them<br/>more closely. In the meantime I tried my best to imitate them. This was, I can<br/>now see, a doomed undertaking, because they weren't really saying anything. No<br/>philosopher ever refuted another, for example, because no one said anything<br/>definite enough to refute. Needless to say, my imitations didn't say anything<br/>either.  <br/>  <br/>In grad school I was still wasting time imitating the wrong things. There was<br/>then a fashionable type of program called an expert system, at the core of<br/>which was something called an inference engine. I looked at what these things<br/>did and thought "I could write that in a thousand lines of code." And yet<br/>eminent professors were writing books about them, and startups were selling<br/>them for a year's salary a copy. What an opportunity, I thought; these<br/>impressive things seem easy to me; I must be pretty sharp. Wrong. It was<br/>simply a fad. The books the professors wrote about expert systems are now<br/>ignored. They were not even on a _path_ to anything interesting. And the<br/>customers paying so much for them were largely the same government agencies<br/>that paid thousands for screwdrivers and toilet seats.  <br/>  <br/>How do you avoid copying the wrong things? Copy only what you genuinely like.<br/>That would have saved me in all three cases. I didn't enjoy the short stories<br/>we had to read in English classes; I didn't learn anything from philosophy<br/>papers; I didn't use expert systems myself. I believed these things were good<br/>because they were admired.  <br/>  <br/>It can be hard to separate the things you like from the things you're<br/>impressed with. One trick is to ignore presentation. Whenever I see a painting<br/>impressively hung in a museum, I ask myself: how much would I pay for this if<br/>I found it at a garage sale, dirty and frameless, and with no idea who painted<br/>it? If you walk around a museum trying this experiment, you'll find you get<br/>some truly startling results. Don't ignore this data point just because it's<br/>an outlier.  <br/>  <br/>Another way to figure out what you like is to look at what you enjoy as guilty<br/>pleasures. Many things people like, especially if they're young and ambitious,<br/>they like largely for the feeling of virtue in liking them. 99% of people<br/>reading _Ulysses_ are thinking "I'm reading _Ulysses_ " as they do it. A<br/>guilty pleasure is at least a pure one. What do you read when you don't feel<br/>up to being virtuous? What kind of book do you read and feel sad that there's<br/>only half of it left, instead of being impressed that you're half way through?<br/>That's what you really like.  <br/>  <br/>Even when you find genuinely good things to copy, there's another pitfall to<br/>be avoided. Be careful to copy what makes them good, rather than their flaws.<br/>It's easy to be drawn into imitating flaws, because they're easier to see, and<br/>of course easier to copy too. For example, most painters in the eighteenth and<br/>nineteenth centuries used brownish colors. They were imitating the great<br/>painters of the Renaissance, whose paintings by that time were brown with<br/>dirt. Those paintings have since been cleaned, revealing brilliant colors;<br/>their imitators are of course still brown.  <br/>  <br/>It was painting, incidentally, that cured me of copying the wrong things.<br/>Halfway through grad school I decided I wanted to try being a painter, and the<br/>art world was so manifestly corrupt that it snapped the leash of credulity.<br/>These people made philosophy professors seem as scrupulous as mathematicians.<br/>It was so clearly a choice of doing good work xor being an insider that I was<br/>forced to see the distinction. It's there to some degree in almost every<br/>field, but I had till then managed to avoid facing it.  <br/>  <br/>That was one of the most valuable things I learned from painting: you have to<br/>figure out for yourself what's good. You can't trust authorities. They'll lie<br/>to you on this one.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>Comment on this essay.  <br/>  <br/>  <br/><br/>Chinese Translation  <br/>  <br/><br/>Romanian Translation  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>January 2006  <br/>  <br/>To do something well you have to like it. That idea is not exactly novel.<br/>We've got it down to four words: "Do what you love." But it's not enough just<br/>to tell people that. Doing what you love is complicated.  <br/>  <br/>The very idea is foreign to what most of us learn as kids. When I was a kid,<br/>it seemed as if work and fun were opposites by definition. Life had two<br/>states: some of the time adults were making you do things, and that was called<br/>work; the rest of the time you could do what you wanted, and that was called<br/>playing. Occasionally the things adults made you do were fun, just as,<br/>occasionally, playing wasn't—for example, if you fell and hurt yourself. But<br/>except for these few anomalous cases, work was pretty much defined as not-fun.  <br/>  <br/>And it did not seem to be an accident. School, it was implied, was tedious<br/>_because_ it was preparation for grownup work.  <br/>  <br/>The world then was divided into two groups, grownups and kids. Grownups, like<br/>some kind of cursed race, had to work. Kids didn't, but they did have to go to<br/>school, which was a dilute version of work meant to prepare us for the real<br/>thing. Much as we disliked school, the grownups all agreed that grownup work<br/>was worse, and that we had it easy.  <br/>  <br/>Teachers in particular all seemed to believe implicitly that work was not fun.<br/>Which is not surprising: work wasn't fun for most of them. Why did we have to<br/>memorize state capitals instead of playing dodgeball? For the same reason they<br/>had to watch over a bunch of kids instead of lying on a beach. You couldn't<br/>just do what you wanted.  <br/>  <br/>I'm not saying we should let little kids do whatever they want. They may have<br/>to be made to work on certain things. But if we make kids work on dull stuff,<br/>it might be wise to tell them that tediousness is not the defining quality of<br/>work, and indeed that the reason they have to work on dull stuff now is so<br/>they can work on more interesting stuff later. [1]  <br/>  <br/>Once, when I was about 9 or 10, my father told me I could be whatever I wanted<br/>when I grew up, so long as I enjoyed it. I remember that precisely because it<br/>seemed so anomalous. It was like being told to use dry water. Whatever I<br/>thought he meant, I didn't think he meant work could _literally_ be fun—fun<br/>like playing. It took me years to grasp that.  <br/>  <br/> **Jobs**  <br/>  <br/>By high school, the prospect of an actual job was on the horizon. Adults would<br/>sometimes come to speak to us about their work, or we would go to see them at<br/>work. It was always understood that they enjoyed what they did. In retrospect<br/>I think one may have: the private jet pilot. But I don't think the bank<br/>manager really did.  <br/>  <br/>The main reason they all acted as if they enjoyed their work was presumably<br/>the upper-middle class convention that you're supposed to. It would not merely<br/>be bad for your career to say that you despised your job, but a social faux-<br/>pas.  <br/>  <br/>Why is it conventional to pretend to like what you do? The first sentence of<br/>this essay explains that. If you have to like something to do it well, then<br/>the most successful people will all like what they do. That's where the upper-<br/>middle class tradition comes from. Just as houses all over America are full of<br/>chairs that are, without the owners even knowing it, nth-degree imitations of<br/>chairs designed 250 years ago for French kings, conventional attitudes about<br/>work are, without the owners even knowing it, nth-degree imitations of the<br/>attitudes of people who've done great things.  <br/>  <br/>What a recipe for alienation. By the time they reach an age to think about<br/>what they'd like to do, most kids have been thoroughly misled about the idea<br/>of loving one's work. School has trained them to regard work as an unpleasant<br/>duty. Having a job is said to be even more onerous than schoolwork. And yet<br/>all the adults claim to like what they do. You can't blame kids for thinking<br/>"I am not like these people; I am not suited to this world."  <br/>  <br/>Actually they've been told three lies: the stuff they've been taught to regard<br/>as work in school is not real work; grownup work is not (necessarily) worse<br/>than schoolwork; and many of the adults around them are lying when they say<br/>they like what they do.  <br/>  <br/>The most dangerous liars can be the kids' own parents. If you take a boring<br/>job to give your family a high standard of living, as so many people do, you<br/>risk infecting your kids with the idea that work is boring. [2] Maybe it would<br/>be better for kids in this one case if parents were not so unselfish. A parent<br/>who set an example of loving their work might help their kids more than an<br/>expensive house. [3]  <br/>  <br/>It was not till I was in college that the idea of work finally broke free from<br/>the idea of making a living. Then the important question became not how to<br/>make money, but what to work on. Ideally these coincided, but some spectacular<br/>boundary cases (like Einstein in the patent office) proved they weren't<br/>identical.  <br/>  <br/>The definition of work was now to make some original contribution to the<br/>world, and in the process not to starve. But after the habit of so many years<br/>my idea of work still included a large component of pain. Work still seemed to<br/>require discipline, because only hard problems yielded grand results, and hard<br/>problems couldn't literally be fun. Surely one had to force oneself to work on<br/>them.  <br/>  <br/>If you think something's supposed to hurt, you're less likely to notice if<br/>you're doing it wrong. That about sums up my experience of graduate school.  <br/>  <br/> **Bounds**  <br/>  <br/> _How much_ are you supposed to like what you do? Unless you know that, you<br/>don't know when to stop searching. And if, like most people, you underestimate<br/>it, you'll tend to stop searching too early. You'll end up doing something<br/>chosen for you by your parents, or the desire to make money, or prestige—or<br/>sheer inertia.  <br/>  <br/>Here's an upper bound: Do what you love doesn't mean, do what you would like<br/>to do most _this second_. Even Einstein probably had moments when he wanted to<br/>have a cup of coffee, but told himself he ought to finish what he was working<br/>on first.  <br/>  <br/>It used to perplex me when I read about people who liked what they did so much<br/>that there was nothing they'd rather do. There didn't seem to be any sort of<br/>work I liked _that_ much. If I had a choice of (a) spending the next hour<br/>working on something or (b) be teleported to Rome and spend the next hour<br/>wandering about, was there any sort of work I'd prefer? Honestly, no.  <br/>  <br/>But the fact is, almost anyone would rather, at any given moment, float about<br/>in the Carribbean, or have sex, or eat some delicious food, than work on hard<br/>problems. The rule about doing what you love assumes a certain length of time.<br/>It doesn't mean, do what will make you happiest this second, but what will<br/>make you happiest over some longer period, like a week or a month.  <br/>  <br/>Unproductive pleasures pall eventually. After a while you get tired of lying<br/>on the beach. If you want to stay happy, you have to do something.  <br/>  <br/>As a lower bound, you have to like your work more than any unproductive<br/>pleasure. You have to like what you do enough that the concept of "spare time"<br/>seems mistaken. Which is not to say you have to spend all your time working.<br/>You can only work so much before you get tired and start to screw up. Then you<br/>want to do something else—even something mindless. But you don't regard this<br/>time as the prize and the time you spend working as the pain you endure to<br/>earn it.  <br/>  <br/>I put the lower bound there for practical reasons. If your work is not your<br/>favorite thing to do, you'll have terrible problems with procrastination.<br/>You'll have to force yourself to work, and when you resort to that the results<br/>are distinctly inferior.  <br/>  <br/>To be happy I think you have to be doing something you not only enjoy, but<br/>admire. You have to be able to say, at the end, wow, that's pretty cool. This<br/>doesn't mean you have to make something. If you learn how to hang glide, or to<br/>speak a foreign language fluently, that will be enough to make you say, for a<br/>while at least, wow, that's pretty cool. What there has to be is a test.  <br/>  <br/>So one thing that falls just short of the standard, I think, is reading books.<br/>Except for some books in math and the hard sciences, there's no test of how<br/>well you've read a book, and that's why merely reading books doesn't quite<br/>feel like work. You have to do something with what you've read to feel<br/>productive.  <br/>  <br/>I think the best test is one Gino Lee taught me: to try to do things that<br/>would make your friends say wow. But it probably wouldn't start to work<br/>properly till about age 22, because most people haven't had a big enough<br/>sample to pick friends from before then.  <br/>  <br/> **Sirens**  <br/>  <br/>What you should not do, I think, is worry about the opinion of anyone beyond<br/>your friends. You shouldn't worry about prestige. Prestige is the opinion of<br/>the rest of the world. When you can ask the opinions of people whose judgement<br/>you respect, what does it add to consider the opinions of people you don't<br/>even know? [4]  <br/>  <br/>This is easy advice to give. It's hard to follow, especially when you're<br/>young. [5] Prestige is like a powerful magnet that warps even your beliefs<br/>about what you enjoy. It causes you to work not on what you like, but what<br/>you'd like to like.  <br/>  <br/>That's what leads people to try to write novels, for example. They like<br/>reading novels. They notice that people who write them win Nobel prizes. What<br/>could be more wonderful, they think, than to be a novelist? But liking the<br/>idea of being a novelist is not enough; you have to like the actual work of<br/>novel-writing if you're going to be good at it; you have to like making up<br/>elaborate lies.  <br/>  <br/>Prestige is just fossilized inspiration. If you do anything well enough,<br/>you'll _make_ it prestigious. Plenty of things we now consider prestigious<br/>were anything but at first. Jazz comes to mind—though almost any established<br/>art form would do. So just do what you like, and let prestige take care of<br/>itself.  <br/>  <br/>Prestige is especially dangerous to the ambitious. If you want to make<br/>ambitious people waste their time on errands, the way to do it is to bait the<br/>hook with prestige. That's the recipe for getting people to give talks, write<br/>forewords, serve on committees, be department heads, and so on. It might be a<br/>good rule simply to avoid any prestigious task. If it didn't suck, they<br/>wouldn't have had to make it prestigious.  <br/>  <br/>Similarly, if you admire two kinds of work equally, but one is more<br/>prestigious, you should probably choose the other. Your opinions about what's<br/>admirable are always going to be slightly influenced by prestige, so if the<br/>two seem equal to you, you probably have more genuine admiration for the less<br/>prestigious one.  <br/>  <br/>The other big force leading people astray is money. Money by itself is not<br/>that dangerous. When something pays well but is regarded with contempt, like<br/>telemarketing, or prostitution, or personal injury litigation, ambitious<br/>people aren't tempted by it. That kind of work ends up being done by people<br/>who are "just trying to make a living." (Tip: avoid any field whose<br/>practitioners say this.) The danger is when money is combined with prestige,<br/>as in, say, corporate law, or medicine. A comparatively safe and prosperous<br/>career with some automatic baseline prestige is dangerously tempting to<br/>someone young, who hasn't thought much about what they really like.  <br/>  <br/>The test of whether people love what they do is whether they'd do it even if<br/>they weren't paid for it—even if they had to work at another job to make a<br/>living. How many corporate lawyers would do their current work if they had to<br/>do it for free, in their spare time, and take day jobs as waiters to support<br/>themselves?  <br/>  <br/>This test is especially helpful in deciding between different kinds of<br/>academic work, because fields vary greatly in this respect. Most good<br/>mathematicians would work on math even if there were no jobs as math<br/>professors, whereas in the departments at the other end of the spectrum, the<br/>availability of teaching jobs is the driver: people would rather be English<br/>professors than work in ad agencies, and publishing papers is the way you<br/>compete for such jobs. Math would happen without math departments, but it is<br/>the existence of English majors, and therefore jobs teaching them, that calls<br/>into being all those thousands of dreary papers about gender and identity in<br/>the novels of Conrad. No one does that kind of thing for fun.  <br/>  <br/>The advice of parents will tend to err on the side of money. It seems safe to<br/>say there are more undergrads who want to be novelists and whose parents want<br/>them to be doctors than who want to be doctors and whose parents want them to<br/>be novelists. The kids think their parents are "materialistic." Not<br/>necessarily. All parents tend to be more conservative for their kids than they<br/>would for themselves, simply because, as parents, they share risks more than<br/>rewards. If your eight year old son decides to climb a tall tree, or your<br/>teenage daughter decides to date the local bad boy, you won't get a share in<br/>the excitement, but if your son falls, or your daughter gets pregnant, you'll<br/>have to deal with the consequences.  <br/>  <br/> **Discipline**  <br/>  <br/>With such powerful forces leading us astray, it's not surprising we find it so<br/>hard to discover what we like to work on. Most people are doomed in childhood<br/>by accepting the axiom that work = pain. Those who escape this are nearly all<br/>lured onto the rocks by prestige or money. How many even discover something<br/>they love to work on? A few hundred thousand, perhaps, out of billions.  <br/>  <br/>It's hard to find work you love; it must be, if so few do. So don't<br/>underestimate this task. And don't feel bad if you haven't succeeded yet. In<br/>fact, if you admit to yourself that you're discontented, you're a step ahead<br/>of most people, who are still in denial. If you're surrounded by colleagues<br/>who claim to enjoy work that you find contemptible, odds are they're lying to<br/>themselves. Not necessarily, but probably.  <br/>  <br/>Although doing great work takes less discipline than people think—because the<br/>way to do great work is to find something you like so much that you don't have<br/>to force yourself to do it— _finding_ work you love does usually require<br/>discipline. Some people are lucky enough to know what they want to do when<br/>they're 12, and just glide along as if they were on railroad tracks. But this<br/>seems the exception. More often people who do great things have careers with<br/>the trajectory of a ping-pong ball. They go to school to study A, drop out and<br/>get a job doing B, and then become famous for C after taking it up on the<br/>side.  <br/>  <br/>Sometimes jumping from one sort of work to another is a sign of energy, and<br/>sometimes it's a sign of laziness. Are you dropping out, or boldly carving a<br/>new path? You often can't tell yourself. Plenty of people who will later do<br/>great things seem to be disappointments early on, when they're trying to find<br/>their niche.  <br/>  <br/>Is there some test you can use to keep yourself honest? One is to try to do a<br/>good job at whatever you're doing, even if you don't like it. Then at least<br/>you'll know you're not using dissatisfaction as an excuse for being lazy.<br/>Perhaps more importantly, you'll get into the habit of doing things well.  <br/>  <br/>Another test you can use is: always produce. For example, if you have a day<br/>job you don't take seriously because you plan to be a novelist, are you<br/>producing? Are you writing pages of fiction, however bad? As long as you're<br/>producing, you'll know you're not merely using the hazy vision of the grand<br/>novel you plan to write one day as an opiate. The view of it will be<br/>obstructed by the all too palpably flawed one you're actually writing.  <br/>  <br/>"Always produce" is also a heuristic for finding the work you love. If you<br/>subject yourself to that constraint, it will automatically push you away from<br/>things you think you're supposed to work on, toward things you actually like.<br/>"Always produce" will discover your life's work the way water, with the aid of<br/>gravity, finds the hole in your roof.  <br/>  <br/>Of course, figuring out what you like to work on doesn't mean you get to work<br/>on it. That's a separate question. And if you're ambitious you have to keep<br/>them separate: you have to make a conscious effort to keep your ideas about<br/>what you want from being contaminated by what seems possible. [6]  <br/>  <br/>It's painful to keep them apart, because it's painful to observe the gap<br/>between them. So most people pre-emptively lower their expectations. For<br/>example, if you asked random people on the street if they'd like to be able to<br/>draw like Leonardo, you'd find most would say something like "Oh, I can't<br/>draw." This is more a statement of intention than fact; it means, I'm not<br/>going to try. Because the fact is, if you took a random person off the street<br/>and somehow got them to work as hard as they possibly could at drawing for the<br/>next twenty years, they'd get surprisingly far. But it would require a great<br/>moral effort; it would mean staring failure in the eye every day for years.<br/>And so to protect themselves people say "I can't."  <br/>  <br/>Another related line you often hear is that not everyone can do work they<br/>love—that someone has to do the unpleasant jobs. Really? How do you make them?<br/>In the US the only mechanism for forcing people to do unpleasant jobs is the<br/>draft, and that hasn't been invoked for over 30 years. All we can do is<br/>encourage people to do unpleasant work, with money and prestige.  <br/>  <br/>If there's something people still won't do, it seems as if society just has to<br/>make do without. That's what happened with domestic servants. For millennia<br/>that was the canonical example of a job "someone had to do." And yet in the<br/>mid twentieth century servants practically disappeared in rich countries, and<br/>the rich have just had to do without.  <br/>  <br/>So while there may be some things someone has to do, there's a good chance<br/>anyone saying that about any particular job is mistaken. Most unpleasant jobs<br/>would either get automated or go undone if no one were willing to do them.  <br/>  <br/> **Two Routes**  <br/>  <br/>There's another sense of "not everyone can do work they love" that's all too<br/>true, however. One has to make a living, and it's hard to get paid for doing<br/>work you love. There are two routes to that destination:<br/><br/>> The organic route: as you become more eminent, gradually to increase the<br/>> parts of your job that you like at the expense of those you don't.  <br/>>  <br/>> The two-job route: to work at things you don't like to get money to work on<br/>> things you do.<br/><br/>The organic route is more common. It happens naturally to anyone who does good<br/>work. A young architect has to take whatever work he can get, but if he does<br/>well he'll gradually be in a position to pick and choose among projects. The<br/>disadvantage of this route is that it's slow and uncertain. Even tenure is not<br/>real freedom.  <br/>  <br/>The two-job route has several variants depending on how long you work for<br/>money at a time. At one extreme is the "day job," where you work regular hours<br/>at one job to make money, and work on what you love in your spare time. At the<br/>other extreme you work at something till you make enough not to have to work<br/>for money again.  <br/>  <br/>The two-job route is less common than the organic route, because it requires a<br/>deliberate choice. It's also more dangerous. Life tends to get more expensive<br/>as you get older, so it's easy to get sucked into working longer than you<br/>expected at the money job. Worse still, anything you work on changes you. If<br/>you work too long on tedious stuff, it will rot your brain. And the best<br/>paying jobs are most dangerous, because they require your full attention.  <br/>  <br/>The advantage of the two-job route is that it lets you jump over obstacles.<br/>The landscape of possible jobs isn't flat; there are walls of varying heights<br/>between different kinds of work. [7] The trick of maximizing the parts of your<br/>job that you like can get you from architecture to product design, but not,<br/>probably, to music. If you make money doing one thing and then work on<br/>another, you have more freedom of choice.  <br/>  <br/>Which route should you take? That depends on how sure you are of what you want<br/>to do, how good you are at taking orders, how much risk you can stand, and the<br/>odds that anyone will pay (in your lifetime) for what you want to do. If<br/>you're sure of the general area you want to work in and it's something people<br/>are likely to pay you for, then you should probably take the organic route.<br/>But if you don't know what you want to work on, or don't like to take orders,<br/>you may want to take the two-job route, if you can stand the risk.  <br/>  <br/>Don't decide too soon. Kids who know early what they want to do seem<br/>impressive, as if they got the answer to some math question before the other<br/>kids. They have an answer, certainly, but odds are it's wrong.  <br/>  <br/>A friend of mine who is a quite successful doctor complains constantly about<br/>her job. When people applying to medical school ask her for advice, she wants<br/>to shake them and yell "Don't do it!" (But she never does.) How did she get<br/>into this fix? In high school she already wanted to be a doctor. And she is so<br/>ambitious and determined that she overcame every obstacle along the<br/>way—including, unfortunately, not liking it.  <br/>  <br/>Now she has a life chosen for her by a high-school kid.  <br/>  <br/>When you're young, you're given the impression that you'll get enough<br/>information to make each choice before you need to make it. But this is<br/>certainly not so with work. When you're deciding what to do, you have to<br/>operate on ridiculously incomplete information. Even in college you get little<br/>idea what various types of work are like. At best you may have a couple<br/>internships, but not all jobs offer internships, and those that do don't teach<br/>you much more about the work than being a batboy teaches you about playing<br/>baseball.  <br/>  <br/>In the design of lives, as in the design of most other things, you get better<br/>results if you use flexible media. So unless you're fairly sure what you want<br/>to do, your best bet may be to choose a type of work that could turn into<br/>either an organic or two-job career. That was probably part of the reason I<br/>chose computers. You can be a professor, or make a lot of money, or morph it<br/>into any number of other kinds of work.  <br/>  <br/>It's also wise, early on, to seek jobs that let you do many different things,<br/>so you can learn faster what various kinds of work are like. Conversely, the<br/>extreme version of the two-job route is dangerous because it teaches you so<br/>little about what you like. If you work hard at being a bond trader for ten<br/>years, thinking that you'll quit and write novels when you have enough money,<br/>what happens when you quit and then discover that you don't actually like<br/>writing novels?  <br/>  <br/>Most people would say, I'd take that problem. Give me a million dollars and<br/>I'll figure out what to do. But it's harder than it looks. Constraints give<br/>your life shape. Remove them and most people have no idea what to do: look at<br/>what happens to those who win lotteries or inherit money. Much as everyone<br/>thinks they want financial security, the happiest people are not those who<br/>have it, but those who like what they do. So a plan that promises freedom at<br/>the expense of knowing what to do with it may not be as good as it seems.  <br/>  <br/>Whichever route you take, expect a struggle. Finding work you love is very<br/>difficult. Most people fail. Even if you succeed, it's rare to be free to work<br/>on what you want till your thirties or forties. But if you have the<br/>destination in sight you'll be more likely to arrive at it. If you know you<br/>can love work, you're in the home stretch, and if you know what work you love,<br/>you're practically there.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Currently we do the opposite: when we make kids do boring work, like<br/>arithmetic drills, instead of admitting frankly that it's boring, we try to<br/>disguise it with superficial decorations.  <br/>  <br/>[2] One father told me about a related phenomenon: he found himself concealing<br/>from his family how much he liked his work. When he wanted to go to work on a<br/>saturday, he found it easier to say that it was because he "had to" for some<br/>reason, rather than admitting he preferred to work than stay home with them.  <br/>  <br/>[3] Something similar happens with suburbs. Parents move to suburbs to raise<br/>their kids in a safe environment, but suburbs are so dull and artificial that<br/>by the time they're fifteen the kids are convinced the whole world is boring.  <br/>  <br/>[4] I'm not saying friends should be the only audience for your work. The more<br/>people you can help, the better. But friends should be your compass.  <br/>  <br/>[5] Donald Hall said young would-be poets were mistaken to be so obsessed with<br/>being published. But you can imagine what it would do for a 24 year old to get<br/>a poem published in _The New Yorker_. Now to people he meets at parties he's a<br/>real poet. Actually he's no better or worse than he was before, but to a<br/>clueless audience like that, the approval of an official authority makes all<br/>the difference. So it's a harder problem than Hall realizes. The reason the<br/>young care so much about prestige is that the people they want to impress are<br/>not very discerning.  <br/>  <br/>[6] This is isomorphic to the principle that you should prevent your beliefs<br/>about how things are from being contaminated by how you wish they were. Most<br/>people let them mix pretty promiscuously. The continuing popularity of<br/>religion is the most visible index of that.  <br/>  <br/>[7] A more accurate metaphor would be to say that the graph of jobs is not<br/>very well connected.  <br/>  <br/> **Thanks** to Trevor Blackwell, Dan Friedman, Sarah Harlin, Jessica<br/>Livingston, Jackie McDonough, Robert Morris, Peter Norvig, David Sloo, and<br/>Aaron Swartz for reading drafts of this.  <br/>  <br/><br/>Hebrew Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Chinese Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>Slovak Translation  <br/>  <br/><br/>Italian Translation  <br/>  <br/><br/>German Translation  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>French Translation  <br/>  <br/><br/>Hungarian Translation  <br/>  <br/><br/>Portuguese Translation  <br/>  <br/><br/>Serbian Translation  <br/>  <br/><br/>Greek Translation  <br/>  <br/><br/>  <br/><br/>July 2010  <br/>  <br/>What hard liquor, cigarettes, heroin, and crack have in common is that they're<br/>all more concentrated forms of less addictive predecessors. Most if not all<br/>the things we describe as addictive are. And the scary thing is, the process<br/>that created them is accelerating.  <br/>  <br/>We wouldn't want to stop it. It's the same process that cures diseases:<br/>technological progress. Technological progress means making things do more of<br/>what we want. When the thing we want is something we want to want, we consider<br/>technological progress good. If some new technique makes solar cells x% more<br/>efficient, that seems strictly better. When progress concentrates something we<br/>don't want to want—when it transforms opium into heroin—it seems bad. But it's<br/>the same process at work. [1]  <br/>  <br/>No one doubts this process is accelerating, which means increasing numbers of<br/>things we like will be transformed into things we like too much. [2]  <br/>  <br/>As far as I know there's no word for something we like too much. The closest<br/>is the colloquial sense of "addictive." That usage has become increasingly<br/>common during my lifetime. And it's clear why: there are an increasing number<br/>of things we need it for. At the extreme end of the spectrum are crack and<br/>meth. Food has been transformed by a combination of factory farming and<br/>innovations in food processing into something with way more immediate bang for<br/>the buck, and you can see the results in any town in America. Checkers and<br/>solitaire have been replaced by World of Warcraft and FarmVille. TV has become<br/>much more engaging, and even so it can't compete with Facebook.  <br/>  <br/>The world is more addictive than it was 40 years ago. And unless the forms of<br/>technological progress that produced these things are subject to different<br/>laws than technological progress in general, the world will get more addictive<br/>in the next 40 years than it did in the last 40.  <br/>  <br/>The next 40 years will bring us some wonderful things. I don't mean to imply<br/>they're all to be avoided. Alcohol is a dangerous drug, but I'd rather live in<br/>a world with wine than one without. Most people can coexist with alcohol; but<br/>you have to be careful. More things we like will mean more things we have to<br/>be careful about.  <br/>  <br/>Most people won't, unfortunately. Which means that as the world becomes more<br/>addictive, the two senses in which one can live a normal life will be driven<br/>ever further apart. One sense of "normal" is statistically normal: what<br/>everyone else does. The other is the sense we mean when we talk about the<br/>normal operating range of a piece of machinery: what works best.  <br/>  <br/>These two senses are already quite far apart. Already someone trying to live<br/>well would seem eccentrically abstemious in most of the US. That phenomenon is<br/>only going to become more pronounced. You can probably take it as a rule of<br/>thumb from now on that if people don't think you're weird, you're living<br/>badly.  <br/>  <br/>Societies eventually develop antibodies to addictive new things. I've seen<br/>that happen with cigarettes. When cigarettes first appeared, they spread the<br/>way an infectious disease spreads through a previously isolated population.<br/>Smoking rapidly became a (statistically) normal thing. There were ashtrays<br/>everywhere. We had ashtrays in our house when I was a kid, even though neither<br/>of my parents smoked. You had to for guests.  <br/>  <br/>As knowledge spread about the dangers of smoking, customs changed. In the last<br/>20 years, smoking has been transformed from something that seemed totally<br/>normal into a rather seedy habit: from something movie stars did in publicity<br/>shots to something small huddles of addicts do outside the doors of office<br/>buildings. A lot of the change was due to legislation, of course, but the<br/>legislation couldn't have happened if customs hadn't already changed.  <br/>  <br/>It took a while though—on the order of 100 years. And unless the rate at which<br/>social antibodies evolve can increase to match the accelerating rate at which<br/>technological progress throws off new addictions, we'll be increasingly unable<br/>to rely on customs to protect us. [3] Unless we want to be canaries in the<br/>coal mine of each new addiction—the people whose sad example becomes a lesson<br/>to future generations—we'll have to figure out for ourselves what to avoid and<br/>how. It will actually become a reasonable strategy (or a more reasonable<br/>strategy) to suspect everything new.  <br/>  <br/>In fact, even that won't be enough. We'll have to worry not just about new<br/>things, but also about existing things becoming more addictive. That's what<br/>bit me. I've avoided most addictions, but the Internet got me because it<br/>became addictive while I was using it. [4]  <br/>  <br/>Most people I know have problems with Internet addiction. We're all trying to<br/>figure out our own customs for getting free of it. That's why I don't have an<br/>iPhone, for example; the last thing I want is for the Internet to follow me<br/>out into the world. [5] My latest trick is taking long hikes. I used to think<br/>running was a better form of exercise than hiking because it took less time.<br/>Now the slowness of hiking seems an advantage, because the longer I spend on<br/>the trail, the longer I have to think without interruption.  <br/>  <br/>Sounds pretty eccentric, doesn't it? It always will when you're trying to<br/>solve problems where there are no customs yet to guide you. Maybe I can't<br/>plead Occam's razor; maybe I'm simply eccentric. But if I'm right about the<br/>acceleration of addictiveness, then this kind of lonely squirming to avoid it<br/>will increasingly be the fate of anyone who wants to get things done. We'll<br/>increasingly be defined by what we say no to.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] Could you restrict technological progress to areas where you wanted it?<br/>Only in a limited way, without becoming a police state. And even then your<br/>restrictions would have undesirable side effects. "Good" and "bad"<br/>technological progress aren't sharply differentiated, so you'd find you<br/>couldn't slow the latter without also slowing the former. And in any case, as<br/>Prohibition and the "war on drugs" show, bans often do more harm than good.  <br/>  <br/>[2] Technology has always been accelerating. By Paleolithic standards,<br/>technology evolved at a blistering pace in the Neolithic period.  <br/>  <br/>[3] Unless we mass produce social customs. I suspect the recent resurgence of<br/>evangelical Christianity in the US is partly a reaction to drugs. In<br/>desperation people reach for the sledgehammer; if their kids won't listen to<br/>them, maybe they'll listen to God. But that solution has broader consequences<br/>than just getting kids to say no to drugs. You end up saying no to science as<br/>well.  <br/>  <br/>I worry we may be heading for a future in which only a few people plot their<br/>own itinerary through no-land, while everyone else books a package tour. Or<br/>worse still, has one booked for them by the government.  <br/>  <br/>[4] People commonly use the word "procrastination" to describe what they do on<br/>the Internet. It seems to me too mild to describe what's happening as merely<br/>not-doing-work. We don't call it procrastination when someone gets drunk<br/>instead of working.  <br/>  <br/>[5] Several people have told me they like the iPad because it lets them bring<br/>the Internet into situations where a laptop would be too conspicuous. In other<br/>words, it's a hip flask. (This is true of the iPhone too, of course, but this<br/>advantage isn't as obvious because it reads as a phone, and everyone's used to<br/>those.)  <br/>  <br/> **Thanks** to Sam Altman, Patrick Collison, Jessica Livingston, and Robert<br/>Morris for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>February 2003  <br/>  <br/>When we were in junior high school, my friend Rich and I made a map of the<br/>school lunch tables according to popularity. This was easy to do, because kids<br/>only ate lunch with others of about the same popularity. We graded them from A<br/>to E. A tables were full of football players and cheerleaders and so on. E<br/>tables contained the kids with mild cases of Down's Syndrome, what in the<br/>language of the time we called "retards."  <br/>  <br/>We sat at a D table, as low as you could get without looking physically<br/>different. We were not being especially candid to grade ourselves as D. It<br/>would have taken a deliberate lie to say otherwise. Everyone in the school<br/>knew exactly how popular everyone else was, including us.  <br/>  <br/>My stock gradually rose during high school. Puberty finally arrived; I became<br/>a decent soccer player; I started a scandalous underground newspaper. So I've<br/>seen a good part of the popularity landscape.  <br/>  <br/>I know a lot of people who were nerds in school, and they all tell the same<br/>story: there is a strong correlation between being smart and being a nerd, and<br/>an even stronger inverse correlation between being a nerd and being popular.<br/>Being smart seems to _make_ you unpopular.  <br/>  <br/>Why? To someone in school now, that may seem an odd question to ask. The mere<br/>fact is so overwhelming that it may seem strange to imagine that it could be<br/>any other way. But it could. Being smart doesn't make you an outcast in<br/>elementary school. Nor does it harm you in the real world. Nor, as far as I<br/>can tell, is the problem so bad in most other countries. But in a typical<br/>American secondary school, being smart is likely to make your life difficult.<br/>Why?  <br/>  <br/>  <br/>  <br/>The key to this mystery is to rephrase the question slightly. Why don't smart<br/>kids make themselves popular? If they're so smart, why don't they figure out<br/>how popularity works and beat the system, just as they do for standardized<br/>tests?  <br/>  <br/>One argument says that this would be impossible, that the smart kids are<br/>unpopular because the other kids envy them for being smart, and nothing they<br/>could do could make them popular. I wish. If the other kids in junior high<br/>school envied me, they did a great job of concealing it. And in any case, if<br/>being smart were really an enviable quality, the girls would have broken<br/>ranks. The guys that guys envy, girls like.  <br/>  <br/>In the schools I went to, being smart just didn't matter much. Kids didn't<br/>admire it or despise it. All other things being equal, they would have<br/>preferred to be on the smart side of average rather than the dumb side, but<br/>intelligence counted far less than, say, physical appearance, charisma, or<br/>athletic ability.  <br/>  <br/>So if intelligence in itself is not a factor in popularity, why are smart kids<br/>so consistently unpopular? The answer, I think, is that they don't really want<br/>to be popular.  <br/>  <br/>If someone had told me that at the time, I would have laughed at him. Being<br/>unpopular in school makes kids miserable, some of them so miserable that they<br/>commit suicide. Telling me that I didn't want to be popular would have seemed<br/>like telling someone dying of thirst in a desert that he didn't want a glass<br/>of water. Of course I wanted to be popular.  <br/>  <br/>But in fact I didn't, not enough. There was something else I wanted more: to<br/>be smart. Not simply to do well in school, though that counted for something,<br/>but to design beautiful rockets, or to write well, or to understand how to<br/>program computers. In general, to make great things.  <br/>  <br/>At the time I never tried to separate my wants and weigh them against one<br/>another. If I had, I would have seen that being smart was more important. If<br/>someone had offered me the chance to be the most popular kid in school, but<br/>only at the price of being of average intelligence (humor me here), I wouldn't<br/>have taken it.  <br/>  <br/>Much as they suffer from their unpopularity, I don't think many nerds would.<br/>To them the thought of average intelligence is unbearable. But most kids would<br/>take that deal. For half of them, it would be a step up. Even for someone in<br/>the eightieth percentile (assuming, as everyone seemed to then, that<br/>intelligence is a scalar), who wouldn't drop thirty points in exchange for<br/>being loved and admired by everyone?  <br/>  <br/>And that, I think, is the root of the problem. Nerds serve two masters. They<br/>want to be popular, certainly, but they want even more to be smart. And<br/>popularity is not something you can do in your spare time, not in the fiercely<br/>competitive environment of an American secondary school.  <br/>  <br/>  <br/>  <br/>Alberti, arguably the archetype of the Renaissance Man, writes that "no art,<br/>however minor, demands less than total dedication if you want to excel in it."<br/>I wonder if anyone in the world works harder at anything than American school<br/>kids work at popularity. Navy SEALs and neurosurgery residents seem slackers<br/>by comparison. They occasionally take vacations; some even have hobbies. An<br/>American teenager may work at being popular every waking hour, 365 days a<br/>year.  <br/>  <br/>I don't mean to suggest they do this consciously. Some of them truly are<br/>little Machiavellis, but what I really mean here is that teenagers are always<br/>on duty as conformists.  <br/>  <br/>For example, teenage kids pay a great deal of attention to clothes. They don't<br/>consciously dress to be popular. They dress to look good. But to who? To the<br/>other kids. Other kids' opinions become their definition of right, not just<br/>for clothes, but for almost everything they do, right down to the way they<br/>walk. And so every effort they make to do things "right" is also, consciously<br/>or not, an effort to be more popular.  <br/>  <br/>Nerds don't realize this. They don't realize that it takes work to be popular.<br/>In general, people outside some very demanding field don't realize the extent<br/>to which success depends on constant (though often unconscious) effort. For<br/>example, most people seem to consider the ability to draw as some kind of<br/>innate quality, like being tall. In fact, most people who "can draw" like<br/>drawing, and have spent many hours doing it; that's why they're good at it.<br/>Likewise, popular isn't just something you are or you aren't, but something<br/>you make yourself.  <br/>  <br/>The main reason nerds are unpopular is that they have other things to think<br/>about. Their attention is drawn to books or the natural world, not fashions<br/>and parties. They're like someone trying to play soccer while balancing a<br/>glass of water on his head. Other players who can focus their whole attention<br/>on the game beat them effortlessly, and wonder why they seem so incapable.  <br/>  <br/>Even if nerds cared as much as other kids about popularity, being popular<br/>would be more work for them. The popular kids learned to be popular, and to<br/>want to be popular, the same way the nerds learned to be smart, and to want to<br/>be smart: from their parents. While the nerds were being trained to get the<br/>right answers, the popular kids were being trained to please.  <br/>  <br/>  <br/>  <br/>So far I've been finessing the relationship between smart and nerd, using them<br/>as if they were interchangeable. In fact it's only the context that makes them<br/>so. A nerd is someone who isn't socially adept enough. But "enough" depends on<br/>where you are. In a typical American school, standards for coolness are so<br/>high (or at least, so specific) that you don't have to be especially awkward<br/>to look awkward by comparison.  <br/>  <br/>Few smart kids can spare the attention that popularity requires. Unless they<br/>also happen to be good-looking, natural athletes, or siblings of popular kids,<br/>they'll tend to become nerds. And that's why smart people's lives are worst<br/>between, say, the ages of eleven and seventeen. Life at that age revolves far<br/>more around popularity than before or after.  <br/>  <br/>Before that, kids' lives are dominated by their parents, not by other kids.<br/>Kids do care what their peers think in elementary school, but this isn't their<br/>whole life, as it later becomes.  <br/>  <br/>Around the age of eleven, though, kids seem to start treating their family as<br/>a day job. They create a new world among themselves, and standing in this<br/>world is what matters, not standing in their family. Indeed, being in trouble<br/>in their family can win them points in the world they care about.  <br/>  <br/>The problem is, the world these kids create for themselves is at first a very<br/>crude one. If you leave a bunch of eleven-year-olds to their own devices, what<br/>you get is _Lord of the Flies._ Like a lot of American kids, I read this book<br/>in school. Presumably it was not a coincidence. Presumably someone wanted to<br/>point out to us that we were savages, and that we had made ourselves a cruel<br/>and stupid world. This was too subtle for me. While the book seemed entirely<br/>believable, I didn't get the additional message. I wish they had just told us<br/>outright that we were savages and our world was stupid.  <br/>  <br/>  <br/>  <br/>Nerds would find their unpopularity more bearable if it merely caused them to<br/>be ignored. Unfortunately, to be unpopular in school is to be actively<br/>persecuted.  <br/>  <br/>Why? Once again, anyone currently in school might think this a strange<br/>question to ask. How could things be any other way? But they could be. Adults<br/>don't normally persecute nerds. Why do teenage kids do it?  <br/>  <br/>Partly because teenagers are still half children, and many children are just<br/>intrinsically cruel. Some torture nerds for the same reason they pull the legs<br/>off spiders. Before you develop a conscience, torture is amusing.  <br/>  <br/>Another reason kids persecute nerds is to make themselves feel better. When<br/>you tread water, you lift yourself up by pushing water down. Likewise, in any<br/>social hierarchy, people unsure of their own position will try to emphasize it<br/>by maltreating those they think rank below. I've read that this is why poor<br/>whites in the United States are the group most hostile to blacks.  <br/>  <br/>But I think the main reason other kids persecute nerds is that it's part of<br/>the mechanism of popularity. Popularity is only partially about individual<br/>attractiveness. It's much more about alliances. To become more popular, you<br/>need to be constantly doing things that bring you close to other popular<br/>people, and nothing brings people closer than a common enemy.  <br/>  <br/>Like a politician who wants to distract voters from bad times at home, you can<br/>create an enemy if there isn't a real one. By singling out and persecuting a<br/>nerd, a group of kids from higher in the hierarchy create bonds between<br/>themselves. Attacking an outsider makes them all insiders. This is why the<br/>worst cases of bullying happen with groups. Ask any nerd: you get much worse<br/>treatment from a group of kids than from any individual bully, however<br/>sadistic.  <br/>  <br/>If it's any consolation to the nerds, it's nothing personal. The group of kids<br/>who band together to pick on you are doing the same thing, and for the same<br/>reason, as a bunch of guys who get together to go hunting. They don't actually<br/>hate you. They just need something to chase.  <br/>  <br/>Because they're at the bottom of the scale, nerds are a safe target for the<br/>entire school. If I remember correctly, the most popular kids don't persecute<br/>nerds; they don't need to stoop to such things. Most of the persecution comes<br/>from kids lower down, the nervous middle classes.  <br/>  <br/>The trouble is, there are a lot of them. The distribution of popularity is not<br/>a pyramid, but tapers at the bottom like a pear. The least popular group is<br/>quite small. (I believe we were the only D table in our cafeteria map.) So<br/>there are more people who want to pick on nerds than there are nerds.  <br/>  <br/>As well as gaining points by distancing oneself from unpopular kids, one loses<br/>points by being close to them. A woman I know says that in high school she<br/>liked nerds, but was afraid to be seen talking to them because the other girls<br/>would make fun of her. Unpopularity is a communicable disease; kids too nice<br/>to pick on nerds will still ostracize them in self-defense.  <br/>  <br/>It's no wonder, then, that smart kids tend to be unhappy in middle school and<br/>high school. Their other interests leave them little attention to spare for<br/>popularity, and since popularity resembles a zero-sum game, this in turn makes<br/>them targets for the whole school. And the strange thing is, this nightmare<br/>scenario happens without any conscious malice, merely because of the shape of<br/>the situation.  <br/>  <br/>  <br/>  <br/>For me the worst stretch was junior high, when kid culture was new and harsh,<br/>and the specialization that would later gradually separate the smarter kids<br/>had barely begun. Nearly everyone I've talked to agrees: the nadir is<br/>somewhere between eleven and fourteen.  <br/>  <br/>In our school it was eighth grade, which was ages twelve and thirteen for me.<br/>There was a brief sensation that year when one of our teachers overheard a<br/>group of girls waiting for the school bus, and was so shocked that the next<br/>day she devoted the whole class to an eloquent plea not to be so cruel to one<br/>another.  <br/>  <br/>It didn't have any noticeable effect. What struck me at the time was that she<br/>was surprised. You mean she doesn't know the kind of things they say to one<br/>another? You mean this isn't normal?  <br/>  <br/>It's important to realize that, no, the adults don't know what the kids are<br/>doing to one another. They know, in the abstract, that kids are monstrously<br/>cruel to one another, just as we know in the abstract that people get tortured<br/>in poorer countries. But, like us, they don't like to dwell on this depressing<br/>fact, and they don't see evidence of specific abuses unless they go looking<br/>for it.  <br/>  <br/>Public school teachers are in much the same position as prison wardens.<br/>Wardens' main concern is to keep the prisoners on the premises. They also need<br/>to keep them fed, and as far as possible prevent them from killing one<br/>another. Beyond that, they want to have as little to do with the prisoners as<br/>possible, so they leave them to create whatever social organization they want.<br/>From what I've read, the society that the prisoners create is warped, savage,<br/>and pervasive, and it is no fun to be at the bottom of it.  <br/>  <br/>In outline, it was the same at the schools I went to. The most important thing<br/>was to stay on the premises. While there, the authorities fed you, prevented<br/>overt violence, and made some effort to teach you something. But beyond that<br/>they didn't want to have too much to do with the kids. Like prison wardens,<br/>the teachers mostly left us to ourselves. And, like prisoners, the culture we<br/>created was barbaric.  <br/>  <br/>  <br/>  <br/>Why is the real world more hospitable to nerds? It might seem that the answer<br/>is simply that it's populated by adults, who are too mature to pick on one<br/>another. But I don't think this is true. Adults in prison certainly pick on<br/>one another. And so, apparently, do society wives; in some parts of Manhattan,<br/>life for women sounds like a continuation of high school, with all the same<br/>petty intrigues.  <br/>  <br/>I think the important thing about the real world is not that it's populated by<br/>adults, but that it's very large, and the things you do have real effects.<br/>That's what school, prison, and ladies-who-lunch all lack. The inhabitants of<br/>all those worlds are trapped in little bubbles where nothing they do can have<br/>more than a local effect. Naturally these societies degenerate into savagery.<br/>They have no function for their form to follow.  <br/>  <br/>When the things you do have real effects, it's no longer enough just to be<br/>pleasing. It starts to be important to get the right answers, and that's where<br/>nerds show to advantage. Bill Gates will of course come to mind. Though<br/>notoriously lacking in social skills, he gets the right answers, at least as<br/>measured in revenue.  <br/>  <br/>The other thing that's different about the real world is that it's much<br/>larger. In a large enough pool, even the smallest minorities can achieve a<br/>critical mass if they clump together. Out in the real world, nerds collect in<br/>certain places and form their own societies where intelligence is the most<br/>important thing. Sometimes the current even starts to flow in the other<br/>direction: sometimes, particularly in university math and science departments,<br/>nerds deliberately exaggerate their awkwardness in order to seem smarter. John<br/>Nash so admired Norbert Wiener that he adopted his habit of touching the wall<br/>as he walked down a corridor.  <br/>  <br/>  <br/>  <br/>As a thirteen-year-old kid, I didn't have much more experience of the world<br/>than what I saw immediately around me. The warped little world we lived in<br/>was, I thought, _the world._ The world seemed cruel and boring, and I'm not<br/>sure which was worse.  <br/>  <br/>Because I didn't fit into this world, I thought that something must be wrong<br/>with me. I didn't realize that the reason we nerds didn't fit in was that in<br/>some ways we were a step ahead. We were already thinking about the kind of<br/>things that matter in the real world, instead of spending all our time playing<br/>an exacting but mostly pointless game like the others.  <br/>  <br/>We were a bit like an adult would be if he were thrust back into middle<br/>school. He wouldn't know the right clothes to wear, the right music to like,<br/>the right slang to use. He'd seem to the kids a complete alien. The thing is,<br/>he'd know enough not to care what they thought. We had no such confidence.  <br/>  <br/>A lot of people seem to think it's good for smart kids to be thrown together<br/>with "normal" kids at this stage of their lives. Perhaps. But in at least some<br/>cases the reason the nerds don't fit in really is that everyone else is crazy.<br/>I remember sitting in the audience at a "pep rally" at my high school,<br/>watching as the cheerleaders threw an effigy of an opposing player into the<br/>audience to be torn to pieces. I felt like an explorer witnessing some bizarre<br/>tribal ritual.  <br/>  <br/>  <br/>  <br/>If I could go back and give my thirteen year old self some advice, the main<br/>thing I'd tell him would be to stick his head up and look around. I didn't<br/>really grasp it at the time, but the whole world we lived in was as fake as a<br/>Twinkie. Not just school, but the entire town. Why do people move to suburbia?<br/>To have kids! So no wonder it seemed boring and sterile. The whole place was a<br/>giant nursery, an artificial town created explicitly for the purpose of<br/>breeding children.  <br/>  <br/>Where I grew up, it felt as if there was nowhere to go, and nothing to do.<br/>This was no accident. Suburbs are deliberately designed to exclude the outside<br/>world, because it contains things that could endanger children.  <br/>  <br/>And as for the schools, they were just holding pens within this fake world.<br/>Officially the purpose of schools is to teach kids. In fact their primary<br/>purpose is to keep kids locked up in one place for a big chunk of the day so<br/>adults can get things done. And I have no problem with this: in a specialized<br/>industrial society, it would be a disaster to have kids running around loose.  <br/>  <br/>What bothers me is not that the kids are kept in prisons, but that (a) they<br/>aren't told about it, and (b) the prisons are run mostly by the inmates. Kids<br/>are sent off to spend six years memorizing meaningless facts in a world ruled<br/>by a caste of giants who run after an oblong brown ball, as if this were the<br/>most natural thing in the world. And if they balk at this surreal cocktail,<br/>they're called misfits.  <br/>  <br/>  <br/>  <br/>Life in this twisted world is stressful for the kids. And not just for the<br/>nerds. Like any war, it's damaging even to the winners.  <br/>  <br/>Adults can't avoid seeing that teenage kids are tormented. So why don't they<br/>do something about it? Because they blame it on puberty. The reason kids are<br/>so unhappy, adults tell themselves, is that monstrous new chemicals,<br/>_hormones_ , are now coursing through their bloodstream and messing up<br/>everything. There's nothing wrong with the system; it's just inevitable that<br/>kids will be miserable at that age.  <br/>  <br/>This idea is so pervasive that even the kids believe it, which probably<br/>doesn't help. Someone who thinks his feet naturally hurt is not going to stop<br/>to consider the possibility that he is wearing the wrong size shoes.  <br/>  <br/>I'm suspicious of this theory that thirteen-year-old kids are intrinsically<br/>messed up. If it's physiological, it should be universal. Are Mongol nomads<br/>all nihilists at thirteen? I've read a lot of history, and I have not seen a<br/>single reference to this supposedly universal fact before the twentieth<br/>century. Teenage apprentices in the Renaissance seem to have been cheerful and<br/>eager. They got in fights and played tricks on one another of course<br/>(Michelangelo had his nose broken by a bully), but they weren't crazy.  <br/>  <br/>As far as I can tell, the concept of the hormone-crazed teenager is coeval<br/>with suburbia. I don't think this is a coincidence. I think teenagers are<br/>driven crazy by the life they're made to lead. Teenage apprentices in the<br/>Renaissance were working dogs. Teenagers now are neurotic lapdogs. Their<br/>craziness is the craziness of the idle everywhere.  <br/>  <br/>  <br/>  <br/>When I was in school, suicide was a constant topic among the smarter kids. No<br/>one I knew did it, but several planned to, and some may have tried. Mostly<br/>this was just a pose. Like other teenagers, we loved the dramatic, and suicide<br/>seemed very dramatic. But partly it was because our lives were at times<br/>genuinely miserable.  <br/>  <br/>Bullying was only part of the problem. Another problem, and possibly an even<br/>worse one, was that we never had anything real to work on. Humans like to<br/>work; in most of the world, your work is your identity. And all the work we<br/>did was pointless, or seemed so at the time.  <br/>  <br/>At best it was practice for real work we might do far in the future, so far<br/>that we didn't even know at the time what we were practicing for. More often<br/>it was just an arbitrary series of hoops to jump through, words without<br/>content designed mainly for testability. (The three main causes of the Civil<br/>War were.... Test: List the three main causes of the Civil War.)  <br/>  <br/>And there was no way to opt out. The adults had agreed among themselves that<br/>this was to be the route to college. The only way to escape this empty life<br/>was to submit to it.  <br/>  <br/>  <br/>  <br/>Teenage kids used to have a more active role in society. In pre-industrial<br/>times, they were all apprentices of one sort or another, whether in shops or<br/>on farms or even on warships. They weren't left to create their own societies.<br/>They were junior members of adult societies.  <br/>  <br/>Teenagers seem to have respected adults more then, because the adults were the<br/>visible experts in the skills they were trying to learn. Now most kids have<br/>little idea what their parents do in their distant offices, and see no<br/>connection (indeed, there is precious little) between schoolwork and the work<br/>they'll do as adults.  <br/>  <br/>And if teenagers respected adults more, adults also had more use for<br/>teenagers. After a couple years' training, an apprentice could be a real help.<br/>Even the newest apprentice could be made to carry messages or sweep the<br/>workshop.  <br/>  <br/>Now adults have no immediate use for teenagers. They would be in the way in an<br/>office. So they drop them off at school on their way to work, much as they<br/>might drop the dog off at a kennel if they were going away for the weekend.  <br/>  <br/>What happened? We're up against a hard one here. The cause of this problem is<br/>the same as the cause of so many present ills: specialization. As jobs become<br/>more specialized, we have to train longer for them. Kids in pre-industrial<br/>times started working at about 14 at the latest; kids on farms, where most<br/>people lived, began far earlier. Now kids who go to college don't start<br/>working full-time till 21 or 22. With some degrees, like MDs and PhDs, you may<br/>not finish your training till 30.  <br/>  <br/>Teenagers now are useless, except as cheap labor in industries like fast food,<br/>which evolved to exploit precisely this fact. In almost any other kind of<br/>work, they'd be a net loss. But they're also too young to be left<br/>unsupervised. Someone has to watch over them, and the most efficient way to do<br/>this is to collect them together in one place. Then a few adults can watch all<br/>of them.  <br/>  <br/>If you stop there, what you're describing is literally a prison, albeit a<br/>part-time one. The problem is, many schools practically do stop there. The<br/>stated purpose of schools is to educate the kids. But there is no external<br/>pressure to do this well. And so most schools do such a bad job of teaching<br/>that the kids don't really take it seriously-- not even the smart kids. Much<br/>of the time we were all, students and teachers both, just going through the<br/>motions.  <br/>  <br/>In my high school French class we were supposed to read Hugo's _Les<br/>Miserables._ I don't think any of us knew French well enough to make our way<br/>through this enormous book. Like the rest of the class, I just skimmed the<br/>Cliff's Notes. When we were given a test on the book, I noticed that the<br/>questions sounded odd. They were full of long words that our teacher wouldn't<br/>have used. Where had these questions come from? From the Cliff's Notes, it<br/>turned out. The teacher was using them too. We were all just pretending.  <br/>  <br/>There are certainly great public school teachers. The energy and imagination<br/>of my fourth grade teacher, Mr. Mihalko, made that year something his students<br/>still talk about, thirty years later. But teachers like him were individuals<br/>swimming upstream. They couldn't fix the system.  <br/>  <br/>  <br/>  <br/>In almost any group of people you'll find hierarchy. When groups of adults<br/>form in the real world, it's generally for some common purpose, and the<br/>leaders end up being those who are best at it. The problem with most schools<br/>is, they have no purpose. But hierarchy there must be. And so the kids make<br/>one out of nothing.  <br/>  <br/>We have a phrase to describe what happens when rankings have to be created<br/>without any meaningful criteria. We say that the situation _degenerates into a<br/>popularity contest._ And that's exactly what happens in most American schools.<br/>Instead of depending on some real test, one's rank depends mostly on one's<br/>ability to increase one's rank. It's like the court of Louis XIV. There is no<br/>external opponent, so the kids become one another's opponents.  <br/>  <br/>When there is some real external test of skill, it isn't painful to be at the<br/>bottom of the hierarchy. A rookie on a football team doesn't resent the skill<br/>of the veteran; he hopes to be like him one day and is happy to have the<br/>chance to learn from him. The veteran may in turn feel a sense of _noblesse<br/>oblige_. And most importantly, their status depends on how well they do<br/>against opponents, not on whether they can push the other down.  <br/>  <br/>Court hierarchies are another thing entirely. This type of society debases<br/>anyone who enters it. There is neither admiration at the bottom, nor _noblesse<br/>oblige_ at the top. It's kill or be killed.  <br/>  <br/>This is the sort of society that gets created in American secondary schools.<br/>And it happens because these schools have no real purpose beyond keeping the<br/>kids all in one place for a certain number of hours each day. What I didn't<br/>realize at the time, and in fact didn't realize till very recently, is that<br/>the twin horrors of school life, the cruelty and the boredom, both have the<br/>same cause.  <br/>  <br/>  <br/>  <br/>The mediocrity of American public schools has worse consequences than just<br/>making kids unhappy for six years. It breeds a rebelliousness that actively<br/>drives kids away from the things they're supposed to be learning.  <br/>  <br/>Like many nerds, probably, it was years after high school before I could bring<br/>myself to read anything we'd been assigned then. And I lost more than books. I<br/>mistrusted words like "character" and "integrity" because they had been so<br/>debased by adults. As they were used then, these words all seemed to mean the<br/>same thing: obedience. The kids who got praised for these qualities tended to<br/>be at best dull-witted prize bulls, and at worst facile schmoozers. If that<br/>was what character and integrity were, I wanted no part of them.  <br/>  <br/>The word I most misunderstood was "tact." As used by adults, it seemed to mean<br/>keeping your mouth shut. I assumed it was derived from the same root as<br/>"tacit" and "taciturn," and that it literally meant being quiet. I vowed that<br/>I would never be tactful; they were never going to shut me up. In fact, it's<br/>derived from the same root as "tactile," and what it means is to have a deft<br/>touch. Tactful is the opposite of clumsy. I don't think I learned this until<br/>college.  <br/>  <br/>  <br/>  <br/>Nerds aren't the only losers in the popularity rat race. Nerds are unpopular<br/>because they're distracted. There are other kids who deliberately opt out<br/>because they're so disgusted with the whole process.  <br/>  <br/>Teenage kids, even rebels, don't like to be alone, so when kids opt out of the<br/>system, they tend to do it as a group. At the schools I went to, the focus of<br/>rebellion was drug use, specifically marijuana. The kids in this tribe wore<br/>black concert t-shirts and were called "freaks."  <br/>  <br/>Freaks and nerds were allies, and there was a good deal of overlap between<br/>them. Freaks were on the whole smarter than other kids, though never studying<br/>(or at least never appearing to) was an important tribal value. I was more in<br/>the nerd camp, but I was friends with a lot of freaks.  <br/>  <br/>They used drugs, at least at first, for the social bonds they created. It was<br/>something to do together, and because the drugs were illegal, it was a shared<br/>badge of rebellion.  <br/>  <br/>I'm not claiming that bad schools are the whole reason kids get into trouble<br/>with drugs. After a while, drugs have their own momentum. No doubt some of the<br/>freaks ultimately used drugs to escape from other problems-- trouble at home,<br/>for example. But, in my school at least, the reason most kids _started_ using<br/>drugs was rebellion. Fourteen-year-olds didn't start smoking pot because<br/>they'd heard it would help them forget their problems. They started because<br/>they wanted to join a different tribe.  <br/>  <br/>Misrule breeds rebellion; this is not a new idea. And yet the authorities<br/>still for the most part act as if drugs were themselves the cause of the<br/>problem.  <br/>  <br/>  <br/>  <br/>The real problem is the emptiness of school life. We won't see solutions till<br/>adults realize that. The adults who may realize it first are the ones who were<br/>themselves nerds in school. Do you want your kids to be as unhappy in eighth<br/>grade as you were? I wouldn't. Well, then, is there anything we can do to fix<br/>things? Almost certainly. There is nothing inevitable about the current<br/>system. It has come about mostly by default.  <br/>  <br/>Adults, though, are busy. Showing up for school plays is one thing. Taking on<br/>the educational bureaucracy is another. Perhaps a few will have the energy to<br/>try to change things. I suspect the hardest part is realizing that you can.  <br/>  <br/>Nerds still in school should not hold their breath. Maybe one day a heavily<br/>armed force of adults will show up in helicopters to rescue you, but they<br/>probably won't be coming this month. Any immediate improvement in nerds' lives<br/>is probably going to have to come from the nerds themselves.  <br/>  <br/>Merely understanding the situation they're in should make it less painful.<br/>Nerds aren't losers. They're just playing a different game, and a game much<br/>closer to the one played in the real world. Adults know this. It's hard to<br/>find successful adults now who don't claim to have been nerds in high school.  <br/>  <br/>It's important for nerds to realize, too, that school is not life. School is a<br/>strange, artificial thing, half sterile and half feral. It's all-encompassing,<br/>like life, but it isn't the real thing. It's only temporary, and if you look,<br/>you can see beyond it even while you're still in it.  <br/>  <br/>If life seems awful to kids, it's neither because hormones are turning you all<br/>into monsters (as your parents believe), nor because life actually is awful<br/>(as you believe). It's because the adults, who no longer have any economic use<br/>for you, have abandoned you to spend years cooped up together with nothing<br/>real to do. _Any_ society of that type is awful to live in. You don't have to<br/>look any further to explain why teenage kids are unhappy.  <br/>  <br/>I've said some harsh things in this essay, but really the thesis is an<br/>optimistic one-- that several problems we take for granted are in fact not<br/>insoluble after all. Teenage kids are not inherently unhappy monsters. That<br/>should be encouraging news to kids and adults both.  <br/>  <br/>  <br/>  <br/>**Thanks** to Sarah Harlin, Trevor Blackwell, Robert Morris, Eric Raymond, and<br/>Jackie Weicker for reading drafts of this essay, and Maria Daniels for<br/>scanning photos.  <br/>  <br/>  <br/><br/>Re: Why Nerds are Unpopular  <br/>  <br/><br/>Gateway High School, 1981  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>French Translation  <br/>  <br/><br/>My War With Brian  <br/>  <br/><br/>Buttons  <br/>  <br/><br/>Portuguese Translation  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>November 2008  <br/>  <br/>One of the differences between big companies and startups is that big<br/>companies tend to have developed procedures to protect themselves against<br/>mistakes. A startup walks like a toddler, bashing into things and falling over<br/>all the time. A big company is more deliberate.  <br/>  <br/>The gradual accumulation of checks in an organization is a kind of learning,<br/>based on disasters that have happened to it or others like it. After giving a<br/>contract to a supplier who goes bankrupt and fails to deliver, for example, a<br/>company might require all suppliers to prove they're solvent before submitting<br/>bids.  <br/>  <br/>As companies grow they invariably get more such checks, either in response to<br/>disasters they've suffered, or (probably more often) by hiring people from<br/>bigger companies who bring with them customs for protecting against new types<br/>of disasters.  <br/>  <br/>It's natural for organizations to learn from mistakes. The problem is, people<br/>who propose new checks almost never consider that the check itself has a cost.  <br/>  <br/> _Every check has a cost._ For example, consider the case of making suppliers<br/>verify their solvency. Surely that's mere prudence? But in fact it could have<br/>substantial costs. There's obviously the direct cost in time of the people on<br/>both sides who supply and check proofs of the supplier's solvency. But the<br/>real costs are the ones you never hear about: the company that would be the<br/>best supplier, but doesn't bid because they can't spare the effort to get<br/>verified. Or the company that would be the best supplier, but falls just short<br/>of the threshold for solvency—which will of course have been set on the high<br/>side, since there is no apparent cost of increasing it.  <br/>  <br/>Whenever someone in an organization proposes to add a new check, they should<br/>have to explain not just the benefit but the cost. No matter how bad a job<br/>they did of analyzing it, this meta-check would at least remind everyone there<br/>had to _be_ a cost, and send them looking for it.  <br/>  <br/>If companies started doing that, they'd find some surprises. Joel Spolsky<br/>recently spoke at Y Combinator about selling software to corporate customers.<br/>He said that in most companies software costing up to about $1000 could be<br/>bought by individual managers without any additional approvals. Above that<br/>threshold, software purchases generally had to be approved by a committee. But<br/>babysitting this process was so expensive for software vendors that it didn't<br/>make sense to charge less than $50,000. Which means if you're making something<br/>you might otherwise have charged $5000 for, you have to sell it for $50,000<br/>instead.  <br/>  <br/>The purpose of the committee is presumably to ensure that the company doesn't<br/>waste money. And yet the result is that the company pays 10 times as much.  <br/>  <br/>Checks on purchases will always be expensive, because the harder it is to sell<br/>something to you, the more it has to cost. And not merely linearly, either. If<br/>you're hard enough to sell to, the people who are best at making things don't<br/>want to bother. The only people who will sell to you are companies that<br/>specialize in selling to you. Then you've sunk to a whole new level of<br/>inefficiency. Market mechanisms no longer protect you, because the good<br/>suppliers are no longer in the market.  <br/>  <br/>Such things happen constantly to the biggest organizations of all,<br/>governments. But checks instituted by governments can cause much worse<br/>problems than merely overpaying. Checks instituted by governments can cripple<br/>a country's whole economy. Up till about 1400, China was richer and more<br/>technologically advanced than Europe. One reason Europe pulled ahead was that<br/>the Chinese government restricted long trading voyages. So it was left to the<br/>Europeans to explore and eventually to dominate the rest of the world,<br/>including China.  <br/>  <br/>In more recent times, Sarbanes-Oxley has practically destroyed the US IPO<br/>market. That wasn't the intention of the legislators who wrote it. They just<br/>wanted to add a few more checks on public companies. But they forgot to<br/>consider the cost. They forgot that companies about to go public are usually<br/>rather stretched, and that the weight of a few extra checks that might be easy<br/>for General Electric to bear are enough to prevent younger companies from<br/>being public at all.  <br/>  <br/>Once you start to think about the cost of checks, you can start to ask other<br/>interesting questions. Is the cost increasing or decreasing? Is it higher in<br/>some areas than others? Where does it increase discontinuously? If large<br/>organizations started to ask questions like that, they'd learn some<br/>frightening things.  <br/>  <br/>I think the cost of checks may actually be increasing. The reason is that<br/>software plays an increasingly important role in companies, and the people who<br/>write software are particularly harmed by checks.  <br/>  <br/>Programmers are unlike many types of workers in that the best ones actually<br/>prefer to work hard. This doesn't seem to be the case in most types of work.<br/>When I worked in fast food, we didn't prefer the busy times. And when I used<br/>to mow lawns, I definitely didn't prefer it when the grass was long after a<br/>week of rain.  <br/>  <br/>Programmers, though, like it better when they write more code. Or more<br/>precisely, when they release more code. Programmers like to make a difference.<br/>Good ones, anyway.  <br/>  <br/>For good programmers, one of the best things about working for a startup is<br/>that there are few checks on releases. In true startups, there are no external<br/>checks at all. If you have an idea for a new feature in the morning, you can<br/>write it and push it to the production servers before lunch. And when you can<br/>do that, you have more ideas.  <br/>  <br/>At big companies, software has to go through various approvals before it can<br/>be launched. And the cost of doing this can be enormous—in fact,<br/>discontinuous. I was talking recently to a group of three programmers whose<br/>startup had been acquired a few years before by a big company. When they'd<br/>been independent, they could release changes instantly. Now, they said, the<br/>absolute fastest they could get code released on the production servers was<br/>two weeks.  <br/>  <br/>This didn't merely make them less productive. It made them hate working for<br/>the acquirer.  <br/>  <br/>Here's a sign of how much programmers like to be able to work hard: these guys<br/>would have _paid_ to be able to release code immediately, the way they used<br/>to. I asked them if they'd trade 10% of the acquisition price for the ability<br/>to release code immediately, and all three instantly said yes. Then I asked<br/>what was the maximum percentage of the acquisition price they'd trade for it.<br/>They said they didn't want to think about it, because they didn't want to know<br/>how high they'd go, but I got the impression it might be as much as half.  <br/>  <br/>They'd have sacrificed hundreds of thousands of dollars, perhaps millions,<br/>just to be able to deliver more software to users. And you know what? It would<br/>have been perfectly safe to let them. In fact, the acquirer would have been<br/>better off; not only wouldn't these guys have broken anything, they'd have<br/>gotten a lot more done. So the acquirer is in fact getting worse performance<br/>at greater cost. Just like the committee approving software purchases.  <br/>  <br/>And just as the greatest danger of being hard to sell to is not that you<br/>overpay but that the best suppliers won't even sell to you, the greatest<br/>danger of applying too many checks to your programmers is not that you'll make<br/>them unproductive, but that good programmers won't even want to work for you.  <br/>  <br/>Steve Jobs's famous maxim "artists ship" works both ways. Artists aren't<br/>merely capable of shipping. They insist on it. So if you don't let people<br/>ship, you won't have any artists.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>April 2008  <br/>  <br/> _(This essay is derived from a talk at the 2008 Startup School.)_  <br/>  <br/>About a month after we started Y Combinator we came up with the phrase that<br/>became our motto: Make something people want. We've learned a lot since then,<br/>but if I were choosing now that's still the one I'd pick.  <br/>  <br/>Another thing we tell founders is not to worry too much about the business<br/>model, at least at first. Not because making money is unimportant, but because<br/>it's so much easier than building something great.  <br/>  <br/>A couple weeks ago I realized that if you put those two ideas together, you<br/>get something surprising. Make something people want. Don't worry too much<br/>about making money. What you've got is a description of a charity.  <br/>  <br/>When you get an unexpected result like this, it could either be a bug or a new<br/>discovery. Either businesses aren't supposed to be like charities, and we've<br/>proven by reductio ad absurdum that one or both of the principles we began<br/>with is false. Or we have a new idea.  <br/>  <br/>I suspect it's the latter, because as soon as this thought occurred to me, a<br/>whole bunch of other things fell into place.  <br/>  <br/> **Examples**  <br/>  <br/>For example, Craigslist. It's not a charity, but they run it like one. And<br/>they're astoundingly successful. When you scan down the list of most popular<br/>web sites, the number of employees at Craigslist looks like a misprint. Their<br/>revenues aren't as high as they could be, but most startups would be happy to<br/>trade places with them.  <br/>  <br/>In Patrick O'Brian's novels, his captains always try to get upwind of their<br/>opponents. If you're upwind, you decide when and if to engage the other ship.<br/>Craigslist is effectively upwind of enormous revenues. They'd face some<br/>challenges if they wanted to make more, but not the sort you face when you're<br/>tacking upwind, trying to force a crappy product on ambivalent users by<br/>spending ten times as much on sales as on development. [1]  <br/>  <br/>I'm not saying startups should aim to end up like Craigslist. They're a<br/>product of unusual circumstances. But they're a good model for the early<br/>phases.  <br/>  <br/>Google looked a lot like a charity in the beginning. They didn't have ads for<br/>over a year. At year 1, Google was indistinguishable from a nonprofit. If a<br/>nonprofit or government organization had started a project to index the web,<br/>Google at year 1 is the limit of what they'd have produced.  <br/>  <br/>Back when I was working on spam filters I thought it would be a good idea to<br/>have a web-based email service with good spam filtering. I wasn't thinking of<br/>it as a company. I just wanted to keep people from getting spammed. But as I<br/>thought more about this project, I realized it would probably have to be a<br/>company. It would cost something to run, and it would be a pain to fund with<br/>grants and donations.  <br/>  <br/>That was a surprising realization. Companies often claim to be benevolent, but<br/>it was surprising to realize there were purely benevolent projects that had to<br/>be embodied as companies to work.  <br/>  <br/>I didn't want to start another company, so I didn't do it. But if someone had,<br/>they'd probably be quite rich now. There was a window of about two years when<br/>spam was increasing rapidly but all the big email services had terrible<br/>filters. If someone had launched a new, spam-free mail service, users would<br/>have flocked to it.  <br/>  <br/>Notice the pattern here? From either direction we get to the same spot. If you<br/>start from successful startups, you find they often behaved like nonprofits.<br/>And if you start from ideas for nonprofits, you find they'd often make good<br/>startups.  <br/>  <br/> **Power**  <br/>  <br/>How wide is this territory? Would all good nonprofits be good companies?<br/>Possibly not. What makes Google so valuable is that their users have money. If<br/>you make people with money love you, you can probably get some of it. But<br/>could you also base a successful startup on behaving like a nonprofit to<br/>people who don't have money? Could you, for example, grow a successful startup<br/>out of curing an unfashionable but deadly disease like malaria?  <br/>  <br/>I'm not sure, but I suspect that if you pushed this idea, you'd be surprised<br/>how far it would go. For example, people who apply to Y Combinator don't<br/>generally have much money, and yet we can profit by helping them, because with<br/>our help they could make money. Maybe the situation is similar with malaria.<br/>Maybe an organization that helped lift its weight off a country could benefit<br/>from the resulting growth.  <br/>  <br/>I'm not proposing this is a serious idea. I don't know anything about malaria.<br/>But I've been kicking ideas around long enough to know when I come across a<br/>powerful one.  <br/>  <br/>One way to guess how far an idea extends is to ask yourself at what point<br/>you'd bet against it. The thought of betting against benevolence is alarming<br/>in the same way as saying that something is technically impossible. You're<br/>just asking to be made a fool of, because these are such powerful forces. [2]  <br/>  <br/>For example, initially I thought maybe this principle only applied to Internet<br/>startups. Obviously it worked for Google, but what about Microsoft? Surely<br/>Microsoft isn't benevolent? But when I think back to the beginning, they were.<br/>Compared to IBM they were like Robin Hood. When IBM introduced the PC, they<br/>thought they were going to make money selling hardware at high prices. But by<br/>gaining control of the PC standard, Microsoft opened up the market to any<br/>manufacturer. Hardware prices plummeted, and lots of people got to have<br/>computers who couldn't otherwise have afforded them. It's the sort of thing<br/>you'd expect Google to do.  <br/>  <br/>Microsoft isn't so benevolent now. Now when one thinks of what Microsoft does<br/>to users, all the verbs that come to mind begin with F. [3] And yet it doesn't<br/>seem to pay. Their stock price has been flat for years. Back when they were<br/>Robin Hood, their stock price rose like Google's. Could there be a connection?  <br/>  <br/>You can see how there would be. When you're small, you can't bully customers,<br/>so you have to charm them. Whereas when you're big you can maltreat them at<br/>will, and you tend to, because it's easier than satisfying them. You grow big<br/>by being nice, but you can stay big by being mean.  <br/>  <br/>You get away with it till the underlying conditions change, and then all your<br/>victims escape. So "Don't be evil" may be the most valuable thing Paul<br/>Buchheit made for Google, because it may turn out to be an elixir of corporate<br/>youth. I'm sure they find it constraining, but think how valuable it will be<br/>if it saves them from lapsing into the fatal laziness that afflicted Microsoft<br/>and IBM.  <br/>  <br/>The curious thing is, this elixir is freely available to any other company.<br/>Anyone can adopt "Don't be evil." The catch is that people will hold you to<br/>it. So I don't think you're going to see record labels or tobacco companies<br/>using this discovery.  <br/>  <br/> **Morale**  <br/>  <br/>There's a lot of external evidence that benevolence works. But how does it<br/>work? One advantage of investing in a large number of startups is that you get<br/>a lot of data about how they work. From what we've seen, being good seems to<br/>help startups in three ways: it improves their morale, it makes other people<br/>want to help them, and above all, it helps them be decisive.  <br/>  <br/>Morale is tremendously important to a startup—so important that morale alone<br/>is almost enough to determine success. Startups are often described as<br/>emotional roller-coasters. One minute you're going to take over the world, and<br/>the next you're doomed. The problem with feeling you're doomed is not just<br/>that it makes you unhappy, but that it makes you _stop working_. So the<br/>downhills of the roller-coaster are more of a self fulfilling prophecy than<br/>the uphills. If feeling you're going to succeed makes you work harder, that<br/>probably improves your chances of succeeding, but if feeling you're going to<br/>fail makes you stop working, that practically guarantees you'll fail.  <br/>  <br/>Here's where benevolence comes in. If you feel you're really helping people,<br/>you'll keep working even when it seems like your startup is doomed. Most of us<br/>have some amount of natural benevolence. The mere fact that someone needs you<br/>makes you want to help them. So if you start the kind of startup where users<br/>come back each day, you've basically built yourself a giant tamagotchi. You've<br/>made something you need to take care of.  <br/>  <br/>Blogger is a famous example of a startup that went through really low lows and<br/>survived. At one point they ran out of money and everyone left. Evan Williams<br/>came in to work the next day, and there was no one but him. What kept him<br/>going? Partly that users needed him. He was hosting thousands of people's<br/>blogs. He couldn't just let the site die.  <br/>  <br/>There are many advantages of launching quickly, but the most important may be<br/>that once you have users, the tamagotchi effect kicks in. Once you have users<br/>to take care of, you're forced to figure out what will make them happy, and<br/>that's actually very valuable information.  <br/>  <br/>The added confidence that comes from trying to help people can also help you<br/>with investors. One of the founders of Chatterous told me recently that he and<br/>his cofounder had decided that this service was something the world needed, so<br/>they were going to keep working on it no matter what, even if they had to move<br/>back to Canada and live in their parents' basements.  <br/>  <br/>Once they realized this, they stopped caring so much what investors thought<br/>about them. They still met with them, but they weren't going to die if they<br/>didn't get their money. And you know what? The investors got a lot more<br/>interested. They could sense that the Chatterouses were going to do this<br/>startup with or without them.  <br/>  <br/>If you're really committed and your startup is cheap to run, you become very<br/>hard to kill. And practically all startups, even the most successful, come<br/>close to death at some point. So if doing good for people gives you a sense of<br/>mission that makes you harder to kill, that alone more than compensates for<br/>whatever you lose by not choosing a more selfish project.  <br/>  <br/> **Help**  <br/>  <br/>Another advantage of being good is that it makes other people want to help<br/>you. This too seems to be an inborn trait in humans.  <br/>  <br/>One of the startups we've funded, Octopart, is currently locked in a classic<br/>battle of good versus evil. They're a search site for industrial components. A<br/>lot of people need to search for components, and before Octopart there was no<br/>good way to do it. That, it turned out, was no coincidence.  <br/>  <br/>Octopart built the right way to search for components. Users like it and<br/>they've been growing rapidly. And yet for most of Octopart's life, the biggest<br/>distributor, Digi-Key, has been trying to force them take their prices off the<br/>site. Octopart is sending them customers for free, and yet Digi-Key is trying<br/>to make that traffic stop. Why? Because their current business model depends<br/>on overcharging people who have incomplete information about prices. They<br/>don't want search to work.  <br/>  <br/>The Octoparts are the nicest guys in the world. They dropped out of the PhD<br/>program in physics at Berkeley to do this. They just wanted to fix a problem<br/>they encountered in their research. Imagine how much time you could save the<br/>world's engineers if they could do searches online. So when I hear that a big,<br/>evil company is trying to stop them in order to keep search broken, it makes<br/>me really want to help them. It makes me spend more time on the Octoparts than<br/>I do with most of the other startups we've funded. It just made me spend<br/>several minutes telling you how great they are. Why? Because they're good guys<br/>and they're trying to help the world.  <br/>  <br/>If you're benevolent, people will rally around you: investors, customers,<br/>other companies, and potential employees. In the long term the most important<br/>may be the potential employees. I think everyone knows now that good hackers<br/>are much better than mediocre ones. If you can attract the best hackers to<br/>work for you, as Google has, you have a big advantage. And the very best<br/>hackers tend to be idealistic. They're not desperate for a job. They can work<br/>wherever they want. So most want to work on things that will make the world<br/>better.  <br/>  <br/> **Compass**  <br/>  <br/>But the most important advantage of being good is that it acts as a compass.<br/>One of the hardest parts of doing a startup is that you have so many choices.<br/>There are just two or three of you, and a thousand things you could do. How do<br/>you decide?  <br/>  <br/>Here's the answer: Do whatever's best for your users. You can hold onto this<br/>like a rope in a hurricane, and it will save you if anything can. Follow it<br/>and it will take you through everything you need to do.  <br/>  <br/>It's even the answer to questions that seem unrelated, like how to convince<br/>investors to give you money. If you're a good salesman, you could try to just<br/>talk them into it. But the more reliable route is to convince them through<br/>your users: if you make something users love enough to tell their friends, you<br/>grow exponentially, and that will convince any investor.  <br/>  <br/>Being good is a particularly useful strategy for making decisions in complex<br/>situations because it's stateless. It's like telling the truth. The trouble<br/>with lying is that you have to remember everything you've said in the past to<br/>make sure you don't contradict yourself. If you tell the truth you don't have<br/>to remember anything, and that's a really useful property in domains where<br/>things happen fast.  <br/>  <br/>For example, Y Combinator has now invested in 80 startups, 57 of which are<br/>still alive. (The rest have died or merged or been acquired.) When you're<br/>trying to advise 57 startups, it turns out you have to have a stateless<br/>algorithm. You can't have ulterior motives when you have 57 things going on at<br/>once, because you can't remember them. So our rule is just to do whatever's<br/>best for the founders. Not because we're particularly benevolent, but because<br/>it's the only algorithm that works on that scale.  <br/>  <br/>When you write something telling people to be good, you seem to be claiming to<br/>be good yourself. So I want to say explicitly that I am not a particularly<br/>good person. When I was a kid I was firmly in the camp of bad. The way adults<br/>used the word good, it seemed to be synonymous with quiet, so I grew up very<br/>suspicious of it.  <br/>  <br/>You know how there are some people whose names come up in conversation and<br/>everyone says "He's _such_ a great guy?" People never say that about me. The<br/>best I get is "he means well." I am not claiming to be good. At best I speak<br/>good as a second language.  <br/>  <br/>So I'm not suggesting you be good in the usual sanctimonious way. I'm<br/>suggesting it because it works. It will work not just as a statement of<br/>"values," but as a guide to strategy, and even a design spec for software.<br/>Don't just not be evil. Be good.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] Fifty years ago it would have seemed shocking for a public company not to<br/>pay dividends. Now many tech companies don't. The markets seem to have figured<br/>out how to value potential dividends. Maybe that isn't the last step in this<br/>evolution. Maybe markets will eventually get comfortable with potential<br/>earnings. (VCs already are, and at least some of them consistently make<br/>money.)  <br/>  <br/>I realize this sounds like the stuff one used to hear about the "new economy"<br/>during the Bubble. Believe me, I was not drinking that kool-aid at the time.<br/>But I'm convinced there were some good ideas buried in Bubble thinking. For<br/>example, it's ok to focus on growth instead of profits—but only if the growth<br/>is genuine. You can't be buying users; that's a pyramid scheme. But a company<br/>with rapid, genuine growth is valuable, and eventually markets learn how to<br/>value valuable things.  <br/>  <br/>[2] The idea of starting a company with benevolent aims is currently<br/>undervalued, because the kind of people who currently make that their explicit<br/>goal don't usually do a very good job.  <br/>  <br/>It's one of the standard career paths of trustafarians to start some vaguely<br/>benevolent business. The problem with most of them is that they either have a<br/>bogus political agenda or are feebly executed. The trustafarians' ancestors<br/>didn't get rich by preserving their traditional culture; maybe people in<br/>Bolivia don't want to either. And starting an organic farm, though it's at<br/>least straightforwardly benevolent, doesn't help people on the scale that<br/>Google does.  <br/>  <br/>Most explicitly benevolent projects don't hold themselves sufficiently<br/>accountable. They act as if having good intentions were enough to guarantee<br/>good effects.  <br/>  <br/>[3] Users dislike their new operating system so much that they're starting<br/>petitions to save the old one. And the old one was nothing special. The<br/>hackers within Microsoft must know in their hearts that if the company really<br/>cared about users they'd just advise them to switch to OSX.  <br/>  <br/> **Thanks** to Trevor Blackwell, Paul Buchheit, Jessica Livingston, and Robert<br/>Morris for reading drafts of this.  <br/>  <br/>  <br/>  <br/>  <br/><br/>Russian Translation  <br/><br/>German Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>1993<br/><br/>_(This essay is from the introduction to_On Lisp. _The red text explains the<br/>origins ofArc's name.)_  <br/>  <br/>It's a long-standing principle of programming style that the functional<br/>elements of a program should not be too large. If some component of a program<br/>grows beyond the stage where it's readily comprehensible, it becomes a mass of<br/>complexity which conceals errors as easily as a big city conceals fugitives.<br/>Such software will be hard to read, hard to test, and hard to debug.  <br/>  <br/>In accordance with this principle, a large program must be divided into<br/>pieces, and the larger the program, the more it must be divided. How do you<br/>divide a program? The traditional approach is called _top-down design:_ you<br/>say "the purpose of the program is to do these seven things, so I divide it<br/>into seven major subroutines. The first subroutine has to do these four<br/>things, so it in turn will have four of its own subroutines," and so on. This<br/>process continues until the whole program has the right level of granularity--<br/>each part large enough to do something substantial, but small enough to be<br/>understood as a single unit.  <br/>  <br/>Experienced Lisp programmers divide up their programs differently. As well as<br/>top-down design, they follow a principle which could be called _bottom-up<br/>design_ \-- changing the language to suit the problem. In Lisp, you don't just<br/>write your program down toward the language, you also build the language up<br/>toward your program. As you're writing a program you may think "I wish Lisp<br/>had such-and-such an operator." So you go and write it. Afterward you realize<br/>that using the new operator would simplify the design of another part of the<br/>program, and so on. Language and program evolve together. Like the border<br/>between two warring states, the boundary between language and program is drawn<br/>and redrawn, until eventually it comes to rest along the mountains and rivers,<br/>the natural frontiers of your problem. In the end your program will look as if<br/>the language had been designed for it. And when language and program fit one<br/>another well, you end up with code which is clear, small, and efficient.  <br/>  <br/>It's worth emphasizing that bottom-up design doesn't mean just writing the<br/>same program in a different order. When you work bottom-up, you usually end up<br/>with a different program. Instead of a single, monolithic program, you will<br/>get a larger language with more abstract operators, and a smaller program<br/>written in it. Instead of a lintel, you'll get an arch.  <br/>  <br/>In typical code, once you abstract out the parts which are merely bookkeeping,<br/>what's left is much shorter; the higher you build up the language, the less<br/>distance you will have to travel from the top down to it. This brings several<br/>advantages:  <br/>  <br/><br/>  1. By making the language do more of the work, bottom-up design yields programs which are smaller and more agile. A shorter program doesn't have to be divided into so many components, and fewer components means programs which are easier to read or modify. Fewer components also means fewer connections between components, and thus less chance for errors there. As industrial designers strive to reduce the number of moving parts in a machine, experienced Lisp programmers use bottom-up design to reduce the size and complexity of their programs.  <br/>  <br/><br/>  2. Bottom-up design promotes code re-use. When you write two or more programs, many of the utilities you wrote for the first program will also be useful in the succeeding ones. Once you've acquired a large substrate of utilities, writing a new program can take only a fraction of the effort it would require if you had to start with raw Lisp.  <br/>  <br/><br/>  3. Bottom-up design makes programs easier to read.  An instance of this type of abstraction asks the reader to understand a general-purpose operator; an instance of functional abstraction asks the reader to understand a special-purpose subroutine. [1]  <br/>  <br/><br/>  4. Because it causes you always to be on the lookout for patterns in your code, working bottom-up helps to clarify your ideas about the design of your program. If two distant components of a program are similar in form, you'll be led to notice the similarity and perhaps to redesign the program in a simpler way. <br/><br/>Bottom-up design is possible to a certain degree in languages other than Lisp.<br/>Whenever you see library functions, bottom-up design is happening. However,<br/>Lisp gives you much broader powers in this department, and augmenting the<br/>language plays a proportionately larger role in Lisp style-- so much so that<br/>Lisp is not just a different language, but a whole different way of<br/>programming.  <br/>  <br/>It's true that this style of development is better suited to programs which<br/>can be written by small groups. However, at the same time, it extends the<br/>limits of what can be done by a small group. In _The Mythical Man-Month_ ,<br/>Frederick Brooks proposed that the productivity of a group of programmers does<br/>not grow linearly with its size. As the size of the group increases, the<br/>productivity of individual programmers goes down. The experience of Lisp<br/>programming suggests a more cheerful way to phrase this law: as the size of<br/>the group decreases, the productivity of individual programmers goes up. A<br/>small group wins, relatively speaking, simply because it's smaller. When a<br/>small group also takes advantage of the techniques that Lisp makes possible,<br/>it can win outright.  <br/>  <br/>  <br/>  <br/> **New:** Download On Lisp for Free.  <br/>  <br/>  <br/>  <br/><br/>* * *<br/><br/>  <br/>  <br/>[1] "But no one can read the program without understanding all your new<br/>utilities." To see why such statements are usually mistaken, see Section 4.8.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>January 2016  <br/>  <br/>One advantage of being old is that you can see change happen in your lifetime.<br/>A lot of the change I've seen is fragmentation. US politics is much more<br/>polarized than it used to be. Culturally we have ever less common ground. The<br/>creative class flocks to a handful of happy cities, abandoning the rest. And<br/>increasing economic inequality means the spread between rich and poor is<br/>growing too. I'd like to propose a hypothesis: that all these trends are<br/>instances of the same phenomenon. And moreover, that the cause is not some<br/>force that's pulling us apart, but rather the erosion of forces that had been<br/>pushing us together.  <br/>  <br/>Worse still, for those who worry about these trends, the forces that were<br/>pushing us together were an anomaly, a one-time combination of circumstances<br/>that's unlikely to be repeated — and indeed, that we would not want to repeat.  <br/>  <br/>The two forces were war (above all World War II), and the rise of large<br/>corporations.  <br/>  <br/>The effects of World War II were both economic and social. Economically, it<br/>decreased variation in income. Like all modern armed forces, America's were<br/>socialist economically. From each according to his ability, to each according<br/>to his need. More or less. Higher ranking members of the military got more (as<br/>higher ranking members of socialist societies always do), but what they got<br/>was fixed according to their rank. And the flattening effect wasn't limited to<br/>those under arms, because the US economy was conscripted too. Between 1942 and<br/>1945 all wages were set by the National War Labor Board. Like the military,<br/>they defaulted to flatness. And this national standardization of wages was so<br/>pervasive that its effects could still be seen years after the war ended. [1]  <br/>  <br/>Business owners weren't supposed to be making money either. FDR said "not a<br/>single war millionaire" would be permitted. To ensure that, any increase in a<br/>company's profits over prewar levels was taxed at 85%. And when what was left<br/>after corporate taxes reached individuals, it was taxed again at a marginal<br/>rate of 93%. [2]  <br/>  <br/>Socially too the war tended to decrease variation. Over 16 million men and<br/>women from all sorts of different backgrounds were brought together in a way<br/>of life that was literally uniform. Service rates for men born in the early<br/>1920s approached 80%. And working toward a common goal, often under stress,<br/>brought them still closer together.  <br/>  <br/>Though strictly speaking World War II lasted less than 4 years for the US, its<br/>effects lasted longer. Wars make central governments more powerful, and World<br/>War II was an extreme case of this. In the US, as in all the other Allied<br/>countries, the federal government was slow to give up the new powers it had<br/>acquired. Indeed, in some respects the war didn't end in 1945; the enemy just<br/>switched to the Soviet Union. In tax rates, federal power, defense spending,<br/>conscription, and nationalism, the decades after the war looked more like<br/>wartime than prewar peacetime. [3] And the social effects lasted too. The kid<br/>pulled into the army from behind a mule team in West Virginia didn't simply go<br/>back to the farm afterward. Something else was waiting for him, something that<br/>looked a lot like the army.  <br/>  <br/>If total war was the big political story of the 20th century, the big economic<br/>story was the rise of a new kind of company. And this too tended to produce<br/>both social and economic cohesion. [4]  <br/>  <br/>The 20th century was the century of the big, national corporation. General<br/>Electric, General Foods, General Motors. Developments in finance,<br/>communications, transportation, and manufacturing enabled a new type of<br/>company whose goal was above all scale. Version 1 of this world was low-res: a<br/>Duplo world of a few giant companies dominating each big market. [5]  <br/>  <br/>The late 19th and early 20th centuries had been a time of consolidation, led<br/>especially by J. P. Morgan. Thousands of companies run by their founders were<br/>merged into a couple hundred giant ones run by professional managers.<br/>Economies of scale ruled the day. It seemed to people at the time that this<br/>was the final state of things. John D. Rockefeller said in 1880<br/><br/>> The day of combination is here to stay. Individualism has gone, never to<br/>> return.<br/><br/>He turned out to be mistaken, but he seemed right for the next hundred years.  <br/>  <br/>The consolidation that began in the late 19th century continued for most of<br/>the 20th. By the end of World War II, as Michael Lind writes, "the major<br/>sectors of the economy were either organized as government-backed cartels or<br/>dominated by a few oligopolistic corporations."  <br/>  <br/>For consumers this new world meant the same choices everywhere, but only a few<br/>of them. When I grew up there were only 2 or 3 of most things, and since they<br/>were all aiming at the middle of the market there wasn't much to differentiate<br/>them.  <br/>  <br/>One of the most important instances of this phenomenon was in TV. Here there<br/>were 3 choices: NBC, CBS, and ABC. Plus public TV for eggheads and communists.<br/>The programs that the 3 networks offered were indistinguishable. In fact, here<br/>there was a triple pressure toward the center. If one show did try something<br/>daring, local affiliates in conservative markets would make them stop. Plus<br/>since TVs were expensive, whole families watched the same shows together, so<br/>they had to be suitable for everyone.  <br/>  <br/>And not only did everyone get the same thing, they got it at the same time.<br/>It's difficult to imagine now, but every night tens of millions of families<br/>would sit down together in front of their TV set watching the same show, at<br/>the same time, as their next door neighbors. What happens now with the Super<br/>Bowl used to happen every night. We were literally in sync. [6]  <br/>  <br/>In a way mid-century TV culture was good. The view it gave of the world was<br/>like you'd find in a children's book, and it probably had something of the<br/>effect that (parents hope) children's books have in making people behave<br/>better. But, like children's books, TV was also misleading. Dangerously<br/>misleading, for adults. In his autobiography, Robert MacNeil talks of seeing<br/>gruesome images that had just come in from Vietnam and thinking, we can't show<br/>these to families while they're having dinner.  <br/>  <br/>I know how pervasive the common culture was, because I tried to opt out of it,<br/>and it was practically impossible to find alternatives. When I was 13 I<br/>realized, more from internal evidence than any outside source, that the ideas<br/>we were being fed on TV were crap, and I stopped watching it. [7] But it<br/>wasn't just TV. It seemed like everything around me was crap. The politicians<br/>all saying the same things, the consumer brands making almost identical<br/>products with different labels stuck on to indicate how prestigious they were<br/>meant to be, the balloon-frame houses with fake "colonial" skins, the cars<br/>with several feet of gratuitous metal on each end that started to fall apart<br/>after a couple years, the "red delicious" apples that were red but only<br/>nominally<br/><br/>Too Many Elite American Men Are Obsessed With Work and Wealth  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>April 2004  <br/>  <br/>To the popular press, "hacker" means someone who breaks into computers. Among<br/>programmers it means a good programmer. But the two meanings are connected. To<br/>programmers, "hacker" connotes mastery in the most literal sense: someone who<br/>can make a computer do what he wants—whether the computer wants to or not.  <br/>  <br/>To add to the confusion, the noun "hack" also has two senses. It can be either<br/>a compliment or an insult. It's called a hack when you do something in an ugly<br/>way. But when you do something so clever that you somehow beat the system,<br/>that's also called a hack. The word is used more often in the former than the<br/>latter sense, probably because ugly solutions are more common than brilliant<br/>ones.  <br/>  <br/>Believe it or not, the two senses of "hack" are also connected. Ugly and<br/>imaginative solutions have something in common: they both break the rules. And<br/>there is a gradual continuum between rule breaking that's merely ugly (using<br/>duct tape to attach something to your bike) and rule breaking that is<br/>brilliantly imaginative (discarding Euclidean space).  <br/>  <br/>Hacking predates computers. When he was working on the Manhattan Project,<br/>Richard Feynman used to amuse himself by breaking into safes containing secret<br/>documents. This tradition continues today. When we were in grad school, a<br/>hacker friend of mine who spent too much time around MIT had his own lock<br/>picking kit. (He now runs a hedge fund, a not unrelated enterprise.)  <br/>  <br/>It is sometimes hard to explain to authorities why one would want to do such<br/>things. Another friend of mine once got in trouble with the government for<br/>breaking into computers. This had only recently been declared a crime, and the<br/>FBI found that their usual investigative technique didn't work. Police<br/>investigation apparently begins with a motive. The usual motives are few:<br/>drugs, money, sex, revenge. Intellectual curiosity was not one of the motives<br/>on the FBI's list. Indeed, the whole concept seemed foreign to them.  <br/>  <br/>Those in authority tend to be annoyed by hackers' general attitude of<br/>disobedience. But that disobedience is a byproduct of the qualities that make<br/>them good programmers. They may laugh at the CEO when he talks in generic<br/>corporate newspeech, but they also laugh at someone who tells them a certain<br/>problem can't be solved. Suppress one, and you suppress the other.  <br/>  <br/>This attitude is sometimes affected. Sometimes young programmers notice the<br/>eccentricities of eminent hackers and decide to adopt some of their own in<br/>order to seem smarter. The fake version is not merely annoying; the prickly<br/>attitude of these posers can actually slow the process of innovation.  <br/>  <br/>But even factoring in their annoying eccentricities, the disobedient attitude<br/>of hackers is a net win. I wish its advantages were better understood.  <br/>  <br/>For example, I suspect people in Hollywood are simply mystified by hackers'<br/>attitudes toward copyrights. They are a perennial topic of heated discussion<br/>on Slashdot. But why should people who program computers be so concerned about<br/>copyrights, of all things?  <br/>  <br/>Partly because some companies use _mechanisms_ to prevent copying. Show any<br/>hacker a lock and his first thought is how to pick it. But there is a deeper<br/>reason that hackers are alarmed by measures like copyrights and patents. They<br/>see increasingly aggressive measures to protect "intellectual property" as a<br/>threat to the intellectual freedom they need to do their job. And they are<br/>right.  <br/>  <br/>It is by poking about inside current technology that hackers get ideas for the<br/>next generation. No thanks, intellectual homeowners may say, we don't need any<br/>outside help. But they're wrong. The next generation of computer technology<br/>has often—perhaps more often than not—been developed by outsiders.  <br/>  <br/>In 1977 there was no doubt some group within IBM developing what they expected<br/>to be the next generation of business computer. They were mistaken. The next<br/>generation of business computer was being developed on entirely different<br/>lines by two long-haired guys called Steve in a garage in Los Altos. At about<br/>the same time, the powers that be were cooperating to develop the official<br/>next generation operating system, Multics. But two guys who thought Multics<br/>excessively complex went off and wrote their own. They gave it a name that was<br/>a joking reference to Multics: Unix.  <br/>  <br/>The latest intellectual property laws impose unprecedented restrictions on the<br/>sort of poking around that leads to new ideas. In the past, a competitor might<br/>use patents to prevent you from selling a copy of something they made, but<br/>they couldn't prevent you from taking one apart to see how it worked. The<br/>latest laws make this a crime. How are we to develop new technology if we<br/>can't study current technology to figure out how to improve it?  <br/>  <br/>Ironically, hackers have brought this on themselves. Computers are responsible<br/>for the problem. The control systems inside machines used to be physical:<br/>gears and levers and cams. Increasingly, the brains (and thus the value) of<br/>products is in software. And by this I mean software in the general sense:<br/>i.e. data. A song on an LP is physically stamped into the plastic. A song on<br/>an iPod's disk is merely stored on it.  <br/>  <br/>Data is by definition easy to copy. And the Internet makes copies easy to<br/>distribute. So it is no wonder companies are afraid. But, as so often happens,<br/>fear has clouded their judgement. The government has responded with draconian<br/>laws to protect intellectual property. They probably mean well. But they may<br/>not realize that such laws will do more harm than good.  <br/>  <br/>Why are programmers so violently opposed to these laws? If I were a<br/>legislator, I'd be interested in this mystery—for the same reason that, if I<br/>were a farmer and suddenly heard a lot of squawking coming from my hen house<br/>one night, I'd want to go out and investigate. Hackers are not stupid, and<br/>unanimity is very rare in this world. So if they're all squawking, perhaps<br/>there is something amiss.  <br/>  <br/>Could it be that such laws, though intended to protect America, will actually<br/>harm it? Think about it. There is something very _American_ about Feynman<br/>breaking into safes during the Manhattan Project. It's hard to imagine the<br/>authorities having a sense of humor about such things over in Germany at that<br/>time. Maybe it's not a coincidence.  <br/>  <br/>Hackers are unruly. That is the essence of hacking. And it is also the essence<br/>of Americanness. It is no accident that Silicon Valley is in America, and not<br/>France, or Germany, or England, or Japan. In those countries, people color<br/>inside the lines.  <br/>  <br/>I lived for a while in Florence. But after I'd been there a few months I<br/>realized that what I'd been unconsciously hoping to find there was back in the<br/>place I'd just left. The reason Florence is famous is that in 1450, it was New<br/>York. In 1450 it was filled with the kind of turbulent and ambitious people<br/>you find now in America. (So I went back to America.)  <br/>  <br/>It is greatly to America's advantage that it is a congenial atmosphere for the<br/>right sort of unruliness—that it is a home not just for the smart, but for<br/>smart-alecks. And hackers are invariably smart-alecks. If we had a national<br/>holiday, it would be April 1st. It says a great deal about our work that we<br/>use the same word for a brilliant or a horribly cheesy solution. When we cook<br/>one up we're not always 100% sure which kind it is. But as long as it has the<br/>right sort of wrongness, that's a promising sign. It's odd that people think<br/>of programming as precise and methodical. _Computers_ are precise and<br/>methodical. Hacking is something you do with a gleeful laugh.  <br/>  <br/>In our world some of the most characteristic solutions are not far removed<br/>from practical jokes. IBM was no doubt rather surprised by the consequences of<br/>the licensing deal for DOS, just as the hypothetical "adversary" must be when<br/>Michael Rabin solves a problem by redefining it as one that's easier to solve.  <br/>  <br/>Smart-alecks have to develop a keen sense of how much they can get away with.<br/>And lately hackers have sensed a change in the atmosphere. Lately hackerliness<br/>seems rather frowned upon.  <br/>  <br/>To hackers the recent contraction in civil liberties seems especially ominous.<br/>That must also mystify outsiders. Why should we care especially about civil<br/>liberties? Why programmers, more than dentists or salesmen or landscapers?  <br/>  <br/>Let me put the case in terms a government official would appreciate. Civil<br/>liberties are not just an ornament, or a quaint American tradition. Civil<br/>liberties make countries rich. If you made a graph of GNP per capita vs. civil<br/>liberties, you'd notice a definite trend. Could civil liberties really be a<br/>cause, rather than just an effect? I think so. I think a society in which<br/>people can do and say what they want will also tend to be one in which the<br/>most efficient solutions win, rather than those sponsored by the most<br/>influential people. Authoritarian countries become corrupt; corrupt countries<br/>become poor; and poor countries are weak. It seems to me there is a Laffer<br/>curve for government power, just as for tax revenues. At least, it seems<br/>likely enough that it would be stupid to try the experiment and find out.<br/>Unlike high tax rates, you can't repeal totalitarianism if it turns out to be<br/>a mistake.  <br/>  <br/>This is why hackers worry. The government spying on people doesn't literally<br/>make programmers write worse code. It just leads eventually to a world in<br/>which bad ideas win. And because this is so important to hackers, they're<br/>especially sensitive to it. They can sense totalitarianism approaching from a<br/>distance, as animals can sense an approaching thunderstorm.  <br/>  <br/>It would be ironic if, as hackers fear, recent measures intended to protect<br/>national security and intellectual property turned out to be a missile aimed<br/>right at what makes America successful. But it would not be the first time<br/>that measures taken in an atmosphere of panic had the opposite of the intended<br/>effect.  <br/>  <br/>There is such a thing as Americanness. There's nothing like living abroad to<br/>teach you that. And if you want to know whether something will nurture or<br/>squash this quality, it would be hard to find a better focus group than<br/>hackers, because they come closest of any group I know to embodying it.<br/>Closer, probably, than the men running our government, who for all their talk<br/>of patriotism remind me more of Richelieu or Mazarin than Thomas Jefferson or<br/>George Washington.  <br/>  <br/>When you read what the founding fathers had to say for themselves, they sound<br/>more like hackers. "The spirit of resistance to government," Jefferson wrote,<br/>"is so valuable on certain occasions, that I wish it always to be kept alive."  <br/>  <br/>Imagine an American president saying that today. Like the remarks of an<br/>outspoken old grandmother, the sayings of the founding fathers have<br/>embarrassed generations of their less confident successors. They remind us<br/>where we come from. They remind us that it is the people who break rules that<br/>are the source of America's wealth and power.  <br/>  <br/>Those in a position to impose rules naturally want them to be obeyed. But be<br/>careful what you ask for. You might get it.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Thanks** to Ken Anderson, Trevor Blackwell, Daniel Giffin, Sarah Harlin,<br/>Shiro Kawai, Jessica Livingston, Matz, Jackie McDonough, Robert Morris, Eric<br/>Raymond, Guido van Rossum, David Weinberger, and Steven Wolfram for reading<br/>drafts of this essay.  <br/>  <br/>(The image shows Steves Jobs and Wozniak with a "blue box." Photo by Margret<br/>Wozniak. Reproduced by permission of Steve Wozniak.)  <br/>  <br/>  <br/><br/>Portuguese Translation  <br/>  <br/><br/>Hebrew Translation  <br/>  <br/><br/>Romanian Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>December 2014  <br/>  <br/>Many startups go through a point a few months before they die where although<br/>they have a significant amount of money in the bank, they're also losing a lot<br/>each month, and revenue growth is either nonexistent or mediocre. The company<br/>has, say, 6 months of runway. Or to put it more brutally, 6 months before<br/>they're out of business. They expect to avoid that by raising more from<br/>investors. [1]  <br/>  <br/>That last sentence is the fatal one.  <br/>  <br/>There may be nothing founders are so prone to delude themselves about as how<br/>interested investors will be in giving them additional funding. It's hard to<br/>convince investors the first time too, but founders expect that. What bites<br/>them the second time is a confluence of three forces:<br/><br/>  1. The company is spending more now than it did the first time it raised money.  <br/>  <br/><br/>  2. Investors have much higher standards for companies that have already raised money.  <br/>  <br/><br/>  3. The company is now starting to read as a failure. The first time it raised money, it was neither a success nor a failure; it was too early to ask. Now it's possible to ask that question, and the default answer is failure, because at this point that is the default outcome. <br/><br/>I'm going to call the situation I described in the first paragraph "the fatal<br/>pinch." I try to resist coining phrases, but making up a name for this<br/>situation may snap founders into realizing when they're in it.  <br/>  <br/>One of the things that makes the fatal pinch so dangerous is that it's self-<br/>reinforcing. Founders overestimate their chances of raising more money, and so<br/>are slack about reaching profitability, which further decreases their chances<br/>of raising money.  <br/>  <br/>Now that you know about the fatal pinch, how do you avoid it? Y Combinator<br/>tells founders who raise money to act as if it's the last they'll ever get.<br/>Because the self-reinforcing nature of this situation works the other way too:<br/>the less you need further investment, the easier it is to get.  <br/>  <br/>What do you do if you're already in the fatal pinch? The first step is to re-<br/>evaluate the probability of raising more money. I will now, by an amazing feat<br/>of clairvoyance, do this for you: the probability is zero. [2]  <br/>  <br/>Three options remain: you can shut down the company, you can increase how much<br/>you make, and you can decrease how much you spend.  <br/>  <br/>You should shut down the company if you're certain it will fail no matter what<br/>you do. Then at least you can give back the money you have left, and save<br/>yourself however many months you would have spent riding it down.  <br/>  <br/>Companies rarely _have_ to fail though. What I'm really doing here is giving<br/>you the option of admitting you've already given up.  <br/>  <br/>If you don't want to shut down the company, that leaves increasing revenues<br/>and decreasing expenses. In most startups, expenses = people, and decreasing<br/>expenses = firing people. [3] Deciding to fire people is usually hard, but<br/>there's one case in which it shouldn't be: when there are people you already<br/>know you should fire but you're in denial about it. If so, now's the time.  <br/>  <br/>If that makes you profitable, or will enable you to make it to profitability<br/>on the money you have left, you've avoided the immediate danger.  <br/>  <br/>Otherwise you have three options: you either have to fire good people, get<br/>some or all of the employees to take less salary for a while, or increase<br/>revenues.  <br/>  <br/>Getting people to take less salary is a weak solution that will only work when<br/>the problem isn't too bad. If your current trajectory won't quite get you to<br/>profitability but you can get over the threshold by cutting salaries a little,<br/>you might be able to make the case to everyone for doing it. Otherwise you're<br/>probably just postponing the problem, and that will be obvious to the people<br/>whose salaries you're proposing to cut. [4]  <br/>  <br/>Which leaves two options, firing good people and making more money. While<br/>trying to balance them, keep in mind the eventual goal: to be a successful<br/>product company in the sense of having a single thing lots of people use.  <br/>  <br/>You should lean more toward firing people if the source of your trouble is<br/>overhiring. If you went out and hired 15 people before you even knew what you<br/>were building, you've created a broken company. You need to figure out what<br/>you're building, and it will probably be easier to do that with a handful of<br/>people than 15. Plus those 15 people might not even be the ones you need for<br/>whatever you end up building. So the solution may be to shrink and then figure<br/>out what direction to grow in. After all, you're not doing those 15 people any<br/>favors if you fly the company into ground with them aboard. They'll all lose<br/>their jobs eventually, along with all the time they expended on this doomed<br/>company.  <br/>  <br/>Whereas if you only have a handful of people, it may be better to focus on<br/>trying to make more money. It may seem facile to suggest a startup make more<br/>money, as if that could be done for the asking. Usually a startup is already<br/>trying as hard as it can to sell whatever it sells. What I'm suggesting here<br/>is not so much to try harder to make money but to try to make money in a<br/>different way. For example, if you have only one person selling while the rest<br/>are writing code, consider having everyone work on selling. What good will<br/>more code do you when you're out of business? If you have to write code to<br/>close a certain deal, go ahead; that follows from everyone working on selling.<br/>But only work on whatever will get you the most revenue the soonest.  <br/>  <br/>Another way to make money differently is to sell different things, and in<br/>particular to do more consultingish work. I say consultingish because there is<br/>a long slippery slope from making products to pure consulting, and you don't<br/>have to go far down it before you start to offer something really attractive<br/>to customers. Although your product may not be very appealing yet, if you're a<br/>startup your programmers will often be way better than the ones your customers<br/>have. Or you may have expertise in some new field they don't understand. So if<br/>you change your sales conversations just a little from "do you want to buy our<br/>product?" to "what do you need that you'd pay a lot for?" you may find it's<br/>suddenly a lot easier to extract money from customers.  <br/>  <br/>Be ruthlessly mercenary when you start doing this, though. You're trying to<br/>save your company from death here, so make customers pay a lot, quickly. And<br/>to the extent you can, try to avoid the worst pitfalls of consulting. The<br/>ideal thing might be if you built a precisely defined derivative version of<br/>your product for the customer, and it was otherwise a straight product sale.<br/>You keep the IP and no billing by the hour.  <br/>  <br/>In the best case, this consultingish work may not be just something you do to<br/>survive, but may turn out to be the thing-that-doesn't-scale that defines your<br/>company. Don't expect it to be, but as you dive into individual users' needs,<br/>keep your eyes open for narrow openings that have wide vistas beyond.  <br/>  <br/>There is usually so much demand for custom work that unless you're really<br/>incompetent there has to be some point down the slope of consulting at which<br/>you can survive. But I didn't use the term slippery slope by accident;<br/>customers' insatiable demand for custom work will always be pushing you toward<br/>the bottom. So while you'll probably survive, the problem now becomes to<br/>survive with the least damage and distraction.  <br/>  <br/>The good news is, plenty of successful startups have passed through near-death<br/>experiences and gone on to flourish. You just have to realize in time that<br/>you're near death. And if you're in the fatal pinch, you are.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] There are a handful of companies that can't reasonably expect to make<br/>money for the first year or two, because what they're building takes so long.<br/>For these companies substitute "progress" for "revenue growth." You're not one<br/>of these companies unless your initial investors agreed in advance that you<br/>were. And frankly even these companies wish they weren't, because the<br/>illiquidity of "progress" puts them at the mercy of investors.  <br/>  <br/>[2] There's a variant of the fatal pinch where your existing investors help<br/>you along by promising to invest more. Or rather, where you read them as<br/>promising to invest more, while they think they're just mentioning the<br/>possibility. The way to solve this problem, if you have 8 months of runway or<br/>less, is to try to get the money right now. Then you'll either get the money,<br/>in which case (immediate) problem solved, or at least prevent your investors<br/>from helping you to remain in denial about your fundraising prospects.  <br/>  <br/>[3] Obviously, if you have significant expenses other than salaries that you<br/>can eliminate, do it now.  <br/>  <br/>[4] Unless of course the source of the problem is that you're paying<br/>yourselves high salaries. If by cutting the founders' salaries to the minimum<br/>you need, you can make it to profitability, you should. But it's a bad sign if<br/>you needed to read this to realize that.  <br/>  <br/>**Thanks** to Sam Altman, Paul Buchheit, Jessica Livingston, and Geoff Ralston<br/>for reading drafts of this.  <br/>  <br/><br/>Arabic Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>January 2003  <br/>  <br/> _(This article is derived from a keynote talk at the fall 2002 meeting of<br/>NEPLS.)_  <br/>  <br/>Visitors to this country are often surprised to find that Americans like to<br/>begin a conversation by asking "what do you do?" I've never liked this<br/>question. I've rarely had a neat answer to it. But I think I have finally<br/>solved the problem. Now, when someone asks me what I do, I look them straight<br/>in the eye and say "I'm designing a new dialect of Lisp." I recommend this<br/>answer to anyone who doesn't like being asked what they do. The conversation<br/>will turn immediately to other topics.  <br/>  <br/>I don't consider myself to be doing research on programming languages. I'm<br/>just designing one, in the same way that someone might design a building or a<br/>chair or a new typeface. I'm not trying to discover anything new. I just want<br/>to make a language that will be good to program in. In some ways, this<br/>assumption makes life a lot easier.  <br/>  <br/>The difference between design and research seems to be a question of new<br/>versus good. Design doesn't have to be new, but it has to be good. Research<br/>doesn't have to be good, but it has to be new. I think these two paths<br/>converge at the top: the best design surpasses its predecessors by using new<br/>ideas, and the best research solves problems that are not only new, but<br/>actually worth solving. So ultimately we're aiming for the same destination,<br/>just approaching it from different directions.  <br/>  <br/>What I'm going to talk about today is what your target looks like from the<br/>back. What do you do differently when you treat programming languages as a<br/>design problem instead of a research topic?  <br/>  <br/>  <br/>  <br/>The biggest difference is that you focus more on the user. Design begins by<br/>asking, who is this for and what do they need from it? A good architect, for<br/>example, does not begin by creating a design that he then imposes on the<br/>users, but by studying the intended users and figuring out what they need.  <br/>  <br/>Notice I said "what they need," not "what they want." I don't mean to give the<br/>impression that working as a designer means working as a sort of short-order<br/>cook, making whatever the client tells you to. This varies from field to field<br/>in the arts, but I don't think there is any field in which the best work is<br/>done by the people who just make exactly what the customers tell them to.  <br/>  <br/>The customer _is_ always right in the sense that the measure of good design is<br/>how well it works for the user. If you make a novel that bores everyone, or a<br/>chair that's horribly uncomfortable to sit in, then you've done a bad job,<br/>period. It's no defense to say that the novel or the chair is designed<br/>according to the most advanced theoretical principles.  <br/>  <br/>And yet, making what works for the user doesn't mean simply making what the<br/>user tells you to. Users don't know what all the choices are, and are often<br/>mistaken about what they really want.  <br/>  <br/>The answer to the paradox, I think, is that you have to design for the user,<br/>but you have to design what the user needs, not simply what he says he wants.<br/>It's much like being a doctor. You can't just treat a patient's symptoms. When<br/>a patient tells you his symptoms, you have to figure out what's actually wrong<br/>with him, and treat that.  <br/>  <br/>This focus on the user is a kind of axiom from which most of the practice of<br/>good design can be derived, and around which most design issues center.  <br/>  <br/>  <br/>  <br/>If good design must do what the user needs, who is the user? When I say that<br/>design must be for users, I don't mean to imply that good design aims at some<br/>kind of lowest common denominator. You can pick any group of users you want.<br/>If you're designing a tool, for example, you can design it for anyone from<br/>beginners to experts, and what's good design for one group might be bad for<br/>another. The point is, you have to pick some group of users. I don't think you<br/>can even talk about good or bad design except with reference to some intended<br/>user.  <br/>  <br/>You're most likely to get good design if the intended users include the<br/>designer himself. When you design something for a group that doesn't include<br/>you, it tends to be for people you consider to be less sophisticated than you,<br/>not more sophisticated.  <br/>  <br/>That's a problem, because looking down on the user, however benevolently,<br/>seems inevitably to corrupt the designer. I suspect that very few housing<br/>projects in the US were designed by architects who expected to live in them.<br/>You can see the same thing in programming languages. C, Lisp, and Smalltalk<br/>were created for their own designers to use. Cobol, Ada, and Java, were<br/>created for other people to use.  <br/>  <br/>If you think you're designing something for idiots, the odds are that you're<br/>not designing something good, even for idiots.  <br/>  <br/>  <br/>  <br/>Even if you're designing something for the most sophisticated users, though,<br/>you're still designing for humans. It's different in research. In math you<br/>don't choose abstractions because they're easy for humans to understand; you<br/>choose whichever make the proof shorter. I think this is true for the sciences<br/>generally. Scientific ideas are not meant to be ergonomic.  <br/>  <br/>Over in the arts, things are very different. Design is all about people. The<br/>human body is a strange thing, but when you're designing a chair, that's what<br/>you're designing for, and there's no way around it. All the arts have to<br/>pander to the interests and limitations of humans. In painting, for example,<br/>all other things being equal a painting with people in it will be more<br/>interesting than one without. It is not merely an accident of history that the<br/>great paintings of the Renaissance are all full of people. If they hadn't<br/>been, painting as a medium wouldn't have the prestige that it does.  <br/>  <br/>Like it or not, programming languages are also for people, and I suspect the<br/>human brain is just as lumpy and idiosyncratic as the human body. Some ideas<br/>are easy for people to grasp and some aren't. For example, we seem to have a<br/>very limited capacity for dealing with detail. It's this fact that makes<br/>programing languages a good idea in the first place; if we could handle the<br/>detail, we could just program in machine language.  <br/>  <br/>Remember, too, that languages are not primarily a form for finished programs,<br/>but something that programs have to be developed in. Anyone in the arts could<br/>tell you that you might want different mediums for the two situations. Marble,<br/>for example, is a nice, durable medium for finished ideas, but a hopelessly<br/>inflexible one for developing new ideas.  <br/>  <br/>A program, like a proof, is a pruned version of a tree that in the past has<br/>had false starts branching off all over it. So the test of a language is not<br/>simply how clean the finished program looks in it, but how clean the path to<br/>the finished program was. A design choice that gives you elegant finished<br/>programs may not give you an elegant design process. For example, I've written<br/>a few macro-defining macros full of nested backquotes that look now like<br/>little gems, but writing them took hours of the ugliest trial and error, and<br/>frankly, I'm still not entirely sure they're correct.  <br/>  <br/>We often act as if the test of a language were how good finished programs look<br/>in it. It seems so convincing when you see the same program written in two<br/>languages, and one version is much shorter. When you approach the problem from<br/>the direction of the arts, you're less likely to depend on this sort of test.<br/>You don't want to end up with a programming language like marble.  <br/>  <br/>For example, it is a huge win in developing software to have an interactive<br/>toplevel, what in Lisp is called a read-eval-print loop. And when you have one<br/>this has real effects on the design of the language. It would not work well<br/>for a language where you have to declare variables before using them, for<br/>example. When you're just typing expressions into the toplevel, you want to be<br/>able to set x to some value and then start doing things to x. You don't want<br/>to have to declare the type of x first. You may dispute either of the<br/>premises, but if a language has to have a toplevel to be convenient, and<br/>mandatory type declarations are incompatible with a toplevel, then no language<br/>that makes type declarations mandatory could be convenient to program in.  <br/>  <br/>  <br/>  <br/>In practice, to get good design you have to get close, and stay close, to your<br/>users. You have to calibrate your ideas on actual users constantly, especially<br/>in the beginning. One of the reasons Jane Austen's novels are so good is that<br/>she read them out loud to her family. That's why she never sinks into self-<br/>indulgently arty descriptions of landscapes, or pretentious philosophizing.<br/>(The philosophy's there, but it's woven into the story instead of being pasted<br/>onto it like a label.) If you open an average "literary" novel and imagine<br/>reading it out loud to your friends as something you'd written, you'll feel<br/>all too keenly what an imposition that kind of thing is upon the reader.  <br/>  <br/>In the software world, this idea is known as Worse is Better. Actually, there<br/>are several ideas mixed together in the concept of Worse is Better, which is<br/>why people are still arguing about whether worse is actually better or not.<br/>But one of the main ideas in that mix is that if you're building something<br/>new, you should get a prototype in front of users as soon as possible.  <br/>  <br/>The alternative approach might be called the Hail Mary strategy. Instead of<br/>getting a prototype out quickly and gradually refining it, you try to create<br/>the complete, finished, product in one long touchdown pass. As far as I know,<br/>this is a recipe for disaster. Countless startups destroyed themselves this<br/>way during the Internet bubble. I've never heard of a case where it worked.  <br/>  <br/>What people outside the software world may not realize is that Worse is Better<br/>is found throughout the arts. In drawing, for example, the idea was discovered<br/>during the Renaissance. Now almost every drawing teacher will tell you that<br/>the right way to get an accurate drawing is not to work your way slowly around<br/>the contour of an object, because errors will accumulate and you'll find at<br/>the end that the lines don't meet. Instead you should draw a few quick lines<br/>in roughly the right place, and then gradually refine this initial sketch.  <br/>  <br/>In most fields, prototypes have traditionally been made out of different<br/>materials. Typefaces to be cut in metal were initially designed with a brush<br/>on paper. Statues to be cast in bronze were modelled in wax. Patterns to be<br/>embroidered on tapestries were drawn on paper with ink wash. Buildings to be<br/>constructed from stone were tested on a smaller scale in wood.  <br/>  <br/>What made oil paint so exciting, when it first became popular in the fifteenth<br/>century, was that you could actually make the finished work _from_ the<br/>prototype. You could make a preliminary drawing if you wanted to, but you<br/>weren't held to it; you could work out all the details, and even make major<br/>changes, as you finished the painting.  <br/>  <br/>You can do this in software too. A prototype doesn't have to be just a model;<br/>you can refine it into the finished product. I think you should always do this<br/>when you can. It lets you take advantage of new insights you have along the<br/>way. But perhaps even more important, it's good for morale.  <br/>  <br/>  <br/>  <br/>Morale is key in design. I'm surprised people don't talk more about it. One of<br/>my first drawing teachers told me: if you're bored when you're drawing<br/>something, the drawing will look boring. For example, suppose you have to draw<br/>a building, and you decide to draw each brick individually. You can do this if<br/>you want, but if you get bored halfway through and start making the bricks<br/>mechanically instead of observing each one, the drawing will look worse than<br/>if you had merely suggested the bricks.  <br/>  <br/>Building something by gradually refining a prototype is good for morale<br/>because it keeps you engaged. In software, my rule is: always have working<br/>code. If you're writing something that you'll be able to test in an hour, then<br/>you have the prospect of an immediate reward to motivate you. The same is true<br/>in the arts, and particularly in oil painting. Most painters start with a<br/>blurry sketch and gradually refine it. If you work this way, then in principle<br/>you never have to end the day with something that actually looks unfinished.<br/>Indeed, there is even a saying among painters: "A painting is never finished,<br/>you just stop working on it." This idea will be familiar to anyone who has<br/>worked on software.  <br/>  <br/>Morale is another reason that it's hard to design something for an<br/>unsophisticated user. It's hard to stay interested in something you don't like<br/>yourself. To make something good, you have to be thinking, "wow, this is<br/>really great," not "what a piece of shit; those fools will love it."  <br/>  <br/>Design means making things for humans. But it's not just the user who's human.<br/>The designer is human too.  <br/>  <br/>  <br/>  <br/>Notice all this time I've been talking about "the designer." Design usually<br/>has to be under the control of a single person to be any good. And yet it<br/>seems to be possible for several people to collaborate on a research project.<br/>This seems to me one of the most interesting differences between research and<br/>design.  <br/>  <br/>There have been famous instances of collaboration in the arts, but most of<br/>them seem to have been cases of molecular bonding rather than nuclear fusion.<br/>In an opera it's common for one person to write the libretto and another to<br/>write the music. And during the Renaissance, journeymen from northern Europe<br/>were often employed to do the landscapes in the backgrounds of Italian<br/>paintings. But these aren't true collaborations. They're more like examples of<br/>Robert Frost's "good fences make good neighbors." You can stick instances of<br/>good design together, but within each individual project, one person has to be<br/>in control.  <br/>  <br/>I'm not saying that good design requires that one person think of everything.<br/>There's nothing more valuable than the advice of someone whose judgement you<br/>trust. But after the talking is done, the decision about what to do has to<br/>rest with one person.  <br/>  <br/>Why is it that research can be done by collaborators and design can't? This is<br/>an interesting question. I don't know the answer. Perhaps, if design and<br/>research converge, the best research is also good design, and in fact can't be<br/>done by collaborators. A lot of the most famous scientists seem to have worked<br/>alone. But I don't know enough to say whether there is a pattern here. It<br/>could be simply that many famous scientists worked when collaboration was less<br/>common.  <br/>  <br/>Whatever the story is in the sciences, true collaboration seems to be<br/>vanishingly rare in the arts. Design by committee is a synonym for bad design.<br/>Why is that so? Is there some way to beat this limitation?  <br/>  <br/>I'm inclined to think there isn't-- that good design requires a dictator. One<br/>reason is that good design has to be all of a piece. Design is not just for<br/>humans, but for individual humans. If a design represents an idea that fits in<br/>one person's head, then the idea will fit in the user's head too.  <br/>  <br/>  <br/>  <br/> **Related:**  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Taste for Makers  <br/>  <br/><br/>Romanian Translation  <br/>  <br/><br/>Spanish Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>May 2008  <br/>  <br/>Great cities attract ambitious people. You can sense it when you walk around<br/>one. In a hundred subtle ways, the city sends you a message: you could do<br/>more; you should try harder.  <br/>  <br/>The surprising thing is how different these messages can be. New York tells<br/>you, above all: you should make more money. There are other messages too, of<br/>course. You should be hipper. You should be better looking. But the clearest<br/>message is that you should be richer.  <br/>  <br/>What I like about Boston (or rather Cambridge) is that the message there is:<br/>you should be smarter. You really should get around to reading all those books<br/>you've been meaning to.  <br/>  <br/>When you ask what message a city sends, you sometimes get surprising answers.<br/>As much as they respect brains in Silicon Valley, the message the Valley sends<br/>is: you should be more powerful.  <br/>  <br/>That's not quite the same message New York sends. Power matters in New York<br/>too of course, but New York is pretty impressed by a billion dollars even if<br/>you merely inherited it. In Silicon Valley no one would care except a few real<br/>estate agents. What matters in Silicon Valley is how much effect you have on<br/>the world. The reason people there care about Larry and Sergey is not their<br/>wealth but the fact that they control Google, which affects practically<br/>everyone.  <br/>  <br/>_____  <br/>  <br/>How much does it matter what message a city sends? Empirically, the answer<br/>seems to be: a lot. You might think that if you had enough strength of mind to<br/>do great things, you'd be able to transcend your environment. Where you live<br/>should make at most a couple percent difference. But if you look at the<br/>historical evidence, it seems to matter more than that. Most people who did<br/>great things were clumped together in a few places where that sort of thing<br/>was done at the time.  <br/>  <br/>You can see how powerful cities are from something I wrote about earlier: the<br/>case of the Milanese Leonardo. Practically every fifteenth century Italian<br/>painter you've heard of was from Florence, even though Milan was just as big.<br/>People in Florence weren't genetically different, so you have to assume there<br/>was someone born in Milan with as much natural ability as Leonardo. What<br/>happened to him?  <br/>  <br/>If even someone with the same natural ability as Leonardo couldn't beat the<br/>force of environment, do you suppose you can?  <br/>  <br/>I don't. I'm fairly stubborn, but I wouldn't try to fight this force. I'd<br/>rather use it. So I've thought a lot about where to live.  <br/>  <br/>I'd always imagined Berkeley would be the ideal place—that it would basically<br/>be Cambridge with good weather. But when I finally tried living there a couple<br/>years ago, it turned out not to be. The message Berkeley sends is: you should<br/>live better. Life in Berkeley is very civilized. It's probably the place in<br/>America where someone from Northern Europe would feel most at home. But it's<br/>not humming with ambition.  <br/>  <br/>In retrospect it shouldn't have been surprising that a place so pleasant would<br/>attract people interested above all in quality of life. Cambridge with good<br/>weather, it turns out, is not Cambridge. The people you find in Cambridge are<br/>not there by accident. You have to make sacrifices to live there. It's<br/>expensive and somewhat grubby, and the weather's often bad. So the kind of<br/>people you find in Cambridge are the kind of people who want to live where the<br/>smartest people are, even if that means living in an expensive, grubby place<br/>with bad weather.  <br/>  <br/>As of this writing, Cambridge seems to be the intellectual capital of the<br/>world. I realize that seems a preposterous claim. What makes it true is that<br/>it's more preposterous to claim about anywhere else. American universities<br/>currently seem to be the best, judging from the flow of ambitious students.<br/>And what US city has a stronger claim? New York? A fair number of smart<br/>people, but diluted by a much larger number of neanderthals in suits. The Bay<br/>Area has a lot of smart people too, but again, diluted; there are two great<br/>universities, but they're far apart. Harvard and MIT are practically adjacent<br/>by West Coast standards, and they're surrounded by about 20 other colleges and<br/>universities. [1]  <br/>  <br/>Cambridge as a result feels like a town whose main industry is ideas, while<br/>New York's is finance and Silicon Valley's is startups.  <br/>  <br/>_____  <br/>  <br/>When you talk about cities in the sense we are, what you're really talking<br/>about is collections of people. For a long time cities were the only large<br/>collections of people, so you could use the two ideas interchangeably. But we<br/>can see how much things are changing from the examples I've mentioned. New<br/>York is a classic great city. But Cambridge is just part of a city, and<br/>Silicon Valley is not even that. (San Jose is not, as it sometimes claims, the<br/>capital of Silicon Valley. It's just 178 square miles at one end of it.)  <br/>  <br/>Maybe the Internet will change things further. Maybe one day the most<br/>important community you belong to will be a virtual one, and it won't matter<br/>where you live physically. But I wouldn't bet on it. The physical world is<br/>very high bandwidth, and some of the ways cities send you messages are quite<br/>subtle.  <br/>  <br/>One of the exhilarating things about coming back to Cambridge every spring is<br/>walking through the streets at dusk, when you can see into the houses. When<br/>you walk through Palo Alto in the evening, you see nothing but the blue glow<br/>of TVs. In Cambridge you see shelves full of promising-looking books. Palo<br/>Alto was probably much like Cambridge in 1960, but you'd never guess now that<br/>there was a university nearby. Now it's just one of the richer neighborhoods<br/>in Silicon Valley. [2]  <br/>  <br/>A city speaks to you mostly by accident—in things you see through windows, in<br/>conversations you overhear. It's not something you have to seek out, but<br/>something you can't turn off. One of the occupational hazards of living in<br/>Cambridge is overhearing the conversations of people who use interrogative<br/>intonation in declarative sentences. But on average I'll take Cambridge<br/>conversations over New York or Silicon Valley ones.  <br/>  <br/>A friend who moved to Silicon Valley in the late 90s said the worst thing<br/>about living there was the low quality of the eavesdropping. At the time I<br/>thought she was being deliberately eccentric. Sure, it can be interesting to<br/>eavesdrop on people, but is good quality eavesdropping so important that it<br/>would affect where you chose to live? Now I understand what she meant. The<br/>conversations you overhear tell you what sort of people you're among.  <br/>  <br/>_____  <br/>  <br/>No matter how determined you are, it's hard not to be influenced by the people<br/>around you. It's not so much that you do whatever a city expects of you, but<br/>that you get discouraged when no one around you cares about the same things<br/>you do.  <br/>  <br/>There's an imbalance between encouragement and discouragement like that<br/>between gaining and losing money. Most people overvalue negative amounts of<br/>money: they'll work much harder to avoid losing a dollar than to gain one.<br/>Similarly, although there are plenty of people strong enough to resist doing<br/>something just because that's what one is supposed to do where they happen to<br/>be, there are few strong enough to keep working on something no one around<br/>them cares about.  <br/>  <br/>Because ambitions are to some extent incompatible and admiration is a zero-sum<br/>game, each city tends to focus on one type of ambition. The reason Cambridge<br/>is the intellectual capital is not just that there's a concentration of smart<br/>people there, but that there's nothing _else_ people there care about more.<br/>Professors in New York and the Bay area are second class citizens—till they<br/>start hedge funds or startups respectively.  <br/>  <br/>This suggests an answer to a question people in New York have wondered about<br/>since the Bubble: whether New York could grow into a startup hub to rival<br/>Silicon Valley. One reason that's unlikely is that someone starting a startup<br/>in New York would feel like a second class citizen. [3] There's already<br/>something else people in New York admire more.  <br/>  <br/>In the long term, that could be a bad thing for New York. The power of an<br/>important new technology does eventually convert to money. So by caring more<br/>about money and less about power than Silicon Valley, New York is recognizing<br/>the same thing, but slower. [4] And in fact it has been losing to Silicon<br/>Valley at its own game: the ratio of New York to California residents in the<br/>Forbes 400 has decreased from 1.45 (81:56) when the list was first published<br/>in 1982 to .83 (73:88) in 2007.  <br/>  <br/>_____  <br/>  <br/>Not all cities send a message. Only those that are centers for some type of<br/>ambition do. And it can be hard to tell exactly what message a city sends<br/>without living there. I understand the messages of New York, Cambridge, and<br/>Silicon Valley because I've lived for several years in each of them. DC and LA<br/>seem to send messages too, but I haven't spent long enough in either to say<br/>for sure what they are.  <br/>  <br/>The big thing in LA seems to be fame. There's an A List of people who are most<br/>in demand right now, and what's most admired is to be on it, or friends with<br/>those who are. Beneath that, the message is much like New York's, though<br/>perhaps with more emphasis on physical attractiveness.  <br/>  <br/>In DC the message seems to be that the most important thing is who you know.<br/>You want to be an insider. In practice this seems to work much as in LA.<br/>There's an A List and you want to be on it or close to those who are. The only<br/>difference is how the A List is selected. And even that is not that different.  <br/>  <br/>At the moment, San Francisco's message seems to be the same as Berkeley's: you<br/>should live better. But this will change if enough startups choose SF over the<br/>Valley. During the Bubble that was a predictor of failure—a self-indulgent<br/>choice, like buying expensive office furniture. Even now I'm suspicious when<br/>startups choose SF. But if enough good ones do, it stops being a self-<br/>indulgent choice, because the center of gravity of Silicon Valley will shift<br/>there.  <br/>  <br/>I haven't found anything like Cambridge for intellectual ambition. Oxford and<br/>Cambridge (England) feel like Ithaca or Hanover: the message is there, but not<br/>as strong.  <br/>  <br/>Paris was once a great intellectual center. If you went there in 1300, it<br/>might have sent the message Cambridge does now. But I tried living there for a<br/>bit last year, and the ambitions of the inhabitants are not intellectual ones.<br/>The message Paris sends now is: do things with style. I liked that, actually.<br/>Paris is the only city I've lived in where people genuinely cared about art.<br/>In America only a few rich people buy original art, and even the more<br/>sophisticated ones rarely get past judging it by the brand name of the artist.<br/>But looking through windows at dusk in Paris you can see that people there<br/>actually care what paintings look like. Visually, Paris has the best<br/>eavesdropping I know. [5]  <br/>  <br/>There's one more message I've heard from cities: in London you can still<br/>(barely) hear the message that one should be more aristocratic. If you listen<br/>for it you can also hear it in Paris, New York, and Boston. But this message<br/>is everywhere very faint. It would have been strong 100 years ago, but now I<br/>probably wouldn't have picked it up at all if I hadn't deliberately tuned in<br/>to that wavelength to see if there was any signal left.  <br/>  <br/>_____  <br/>  <br/>So far the complete list of messages I've picked up from cities is: wealth,<br/>style, hipness, physical attractiveness, fame, political power, economic<br/>power, intelligence, social class, and quality of life.  <br/>  <br/>My immediate reaction to this list is that it makes me slightly queasy. I'd<br/>always considered ambition a good thing, but I realize now that was because<br/>I'd always implicitly understood it to mean ambition in the areas I cared<br/>about. When you list everything ambitious people are ambitious about, it's not<br/>so pretty.  <br/>  <br/>On closer examination I see a couple things on the list that are surprising in<br/>the light of history. For example, physical attractiveness wouldn't have been<br/>there 100 years ago (though it might have been 2400 years ago). It has always<br/>mattered for women, but in the late twentieth century it seems to have started<br/>to matter for men as well. I'm not sure why—probably some combination of the<br/>increasing power of women, the increasing influence of actors as models, and<br/>the fact that so many people work in offices now: you can't show off by<br/>wearing clothes too fancy to wear in a factory, so you have to show off with<br/>your body instead.  <br/>  <br/>Hipness is another thing you wouldn't have seen on the list 100 years ago. Or<br/>wouldn't you? What it means is to know what's what. So maybe it has simply<br/>replaced the component of social class that consisted of being "au fait." That<br/>could explain why hipness seems particularly admired in London: it's version 2<br/>of the traditional English delight in obscure codes that only insiders<br/>understand.  <br/>  <br/>Economic power would have been on the list 100 years ago, but what we mean by<br/>it is changing. It used to mean the control of vast human and material<br/>resources. But increasingly it means the ability to direct the course of<br/>technology, and some of the people in a position to do that are not even<br/>rich—leaders of important open source projects, for example. The Captains of<br/>Industry of times past had laboratories full of clever people cooking up new<br/>technologies for them. The new breed are themselves those people.  <br/>  <br/>As this force gets more attention, another is dropping off the list: social<br/>class. I think the two changes are related. Economic power, wealth, and social<br/>class are just names for the same thing at different stages in its life:<br/>economic power converts to wealth, and wealth to social class. So the focus of<br/>admiration is simply shifting upstream.  <br/>  <br/>_____  <br/>  <br/>Does anyone who wants to do great work have to live in a great city? No; all<br/>great cities inspire some sort of ambition, but they aren't the only places<br/>that do. For some kinds of work, all you need is a handful of talented<br/>colleagues.  <br/>  <br/>What cities provide is an audience, and a funnel for peers. These aren't so<br/>critical in something like math or physics, where no audience matters except<br/>your peers, and judging ability is sufficiently straightforward that hiring<br/>and admissions committees can do it reliably. In a field like math or physics<br/>all you need is a department with the right colleagues in it. It could be<br/>anywhere—in Los Alamos, New Mexico, for example.  <br/>  <br/>It's in fields like the arts or writing or technology that the larger<br/>environment matters. In these the best practitioners aren't conveniently<br/>collected in a few top university departments and research labs—partly because<br/>talent is harder to judge, and partly because people pay for these things, so<br/>one doesn't need to rely on teaching or research funding to support oneself.<br/>It's in these more chaotic fields that it helps most to be in a great city:<br/>you need the encouragement of feeling that people around you care about the<br/>kind of work you do, and since you have to find peers for yourself, you need<br/>the much larger intake mechanism of a great city.  <br/>  <br/>You don't have to live in a great city your whole life to benefit from it. The<br/>critical years seem to be the early and middle ones of your career. Clearly<br/>you don't have to grow up in a great city. Nor does it seem to matter if you<br/>go to college in one. To most college students a world of a few thousand<br/>people seems big enough. Plus in college you don't yet have to face the<br/>hardest kind of work—discovering new problems to solve.  <br/>  <br/>It's when you move on to the next and much harder step that it helps most to<br/>be in a place where you can find peers and encouragement. You seem to be able<br/>to leave, if you want, once you've found both. The Impressionists show the<br/>typical pattern: they were born all over France (Pissarro was born in the<br/>Carribbean) and died all over France, but what defined them were the years<br/>they spent together in Paris.  <br/>  <br/>_____  <br/>  <br/>Unless you're sure what you want to do and where the leading center for it is,<br/>your best bet is probably to try living in several places when you're young.<br/>You can never tell what message a city sends till you live there, or even<br/>whether it still sends one. Often your information will be wrong: I tried<br/>living in Florence when I was 25, thinking it would be an art center, but it<br/>turned out I was 450 years too late.  <br/>  <br/>Even when a city is still a live center of ambition, you won't know for sure<br/>whether its message will resonate with you till you hear it. When I moved to<br/>New York, I was very excited at first. It's an exciting place. So it took me<br/>quite a while to realize I just wasn't like the people there. I kept searching<br/>for the Cambridge of New York. It turned out it was way, way uptown: an hour<br/>uptown by air.  <br/>  <br/>Some people know at 16 what sort of work they're going to do, but in most<br/>ambitious kids, ambition seems to precede anything specific to be ambitious<br/>about. They know they want to do something great. They just haven't decided<br/>yet whether they're going to be a rock star or a brain surgeon. There's<br/>nothing wrong with that. But it means if you have this most common type of<br/>ambition, you'll probably have to figure out where to live by trial and error.<br/>You'll probably have to find the city where you feel at home to know what sort<br/>of ambition you have.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Notes**  <br/>  <br/>[1] This is one of the advantages of not having the universities in your<br/>country controlled by the government. When governments decide how to allocate<br/>resources, political deal-making causes things to be spread out<br/>geographically. No central goverment would put its two best universities in<br/>the same town, unless it was the capital (which would cause other problems).<br/>But scholars seem to like to cluster together as much as people in any other<br/>field, and when given the freedom to they derive the same advantages from it.  <br/>  <br/>[2] There are still a few old professors in Palo Alto, but one by one they die<br/>and their houses are transformed by developers into McMansions and sold to VPs<br/>of Bus Dev.  <br/>  <br/>[3] How many times have you read about startup founders who continued to live<br/>inexpensively as their companies took off? Who continued to dress in jeans and<br/>t-shirts, to drive the old car they had in grad school, and so on? If you did<br/>that in New York, people would treat you like shit. If you walk into a fancy<br/>restaurant in San Francisco wearing a jeans and a t-shirt, they're nice to<br/>you; who knows who you might be? Not in New York.  <br/>  <br/>One sign of a city's potential as a technology center is the number of<br/>restaurants that still require jackets for men. According to Zagat's there are<br/>none in San Francisco, LA, Boston, or Seattle, 4 in DC, 6 in Chicago, 8 in<br/>London, 13 in New York, and 20 in Paris.  <br/>  <br/>(Zagat's lists the Ritz Carlton Dining Room in SF as requiring jackets but I<br/>couldn't believe it, so I called to check and in fact they don't. Apparently<br/>there's only one restaurant left on the entire West Coast that still requires<br/>jackets: The French Laundry in Napa Valley.)  <br/>  <br/>[4] Ideas are one step upstream from economic power, so it's conceivable that<br/>intellectual centers like Cambridge will one day have an edge over Silicon<br/>Valley like the one the Valley has over New York.  <br/>  <br/>This seems unlikely at the moment; if anything Boston is falling further and<br/>further behind. The only reason I even mention the possibility is that the<br/>path from ideas to startups has recently been getting smoother. It's a lot<br/>easier now for a couple of hackers with no business experience to start a<br/>startup than it was 10 years ago. If you extrapolate another 20 years, maybe<br/>the balance of power will start to shift back. I wouldn't bet on it, but I<br/>wouldn't bet against it either.  <br/>  <br/>[5] If Paris is where people care most about art, why is New York the center<br/>of gravity of the art business? Because in the twentieth century, art as brand<br/>split apart from art as stuff. New York is where the richest buyers are, but<br/>all they demand from art is brand, and since you can base brand on anything<br/>with a sufficiently identifiable style, you may as well use the local stuff.  <br/>  <br/>  <br/>  <br/> **Thanks** to Trevor Blackwell, Sarah Harlin, Jessica Livingston, Jackie<br/>McDonough, Robert Morris, and David Sloo for reading drafts of this.  <br/>  <br/><br/>Italian Translation  <br/><br/>Portuguese Translation  <br/><br/>Chinese Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>March 2009  <br/>  <br/>About twenty years ago people noticed computers and TV were on a collision<br/>course and started to speculate about what they'd produce when they converged.<br/>We now know the answer: computers. It's clear now that even by using the word<br/>"convergence" we were giving TV too much credit. This won't be convergence so<br/>much as replacement. People may still watch things they call "TV shows," but<br/>they'll watch them mostly on computers.  <br/>  <br/>What decided the contest for computers? Four forces, three of which one could<br/>have predicted, and one that would have been harder to.  <br/>  <br/>One predictable cause of victory is that the Internet is an open platform.<br/>Anyone can build whatever they want on it, and the market picks the winners.<br/>So innovation happens at hacker speeds instead of big company speeds.  <br/>  <br/>The second is Moore's Law, which has worked its usual magic on Internet<br/>bandwidth. [1]  <br/>  <br/>The third reason computers won is piracy. Users prefer it not just because<br/>it's free, but because it's more convenient. Bittorrent and YouTube have<br/>already trained a new generation of viewers that the place to watch shows is<br/>on a computer screen. [2]  <br/>  <br/>The somewhat more surprising force was one specific type of innovation: social<br/>applications. The average teenage kid has a pretty much infinite capacity for<br/>talking to their friends. But they can't physically be with them all the time.<br/>When I was in high school the solution was the telephone. Now it's social<br/>networks, multiplayer games, and various messaging applications. The way you<br/>reach them all is through a computer. [3] Which means every teenage kid (a)<br/>wants a computer with an Internet connection, (b) has an incentive to figure<br/>out how to use it, and (c) spends countless hours in front of it.  <br/>  <br/>This was the most powerful force of all. This was what made everyone want<br/>computers. Nerds got computers because they liked them. Then gamers got them<br/>to play games on. But it was connecting to other people that got everyone<br/>else: that's what made even grandmas and 14 year old girls want computers.  <br/>  <br/>After decades of running an IV drip right into their audience, people in the<br/>entertainment business had understandably come to think of them as rather<br/>passive. They thought they'd be able to dictate the way shows reached<br/>audiences. But they underestimated the force of their desire to connect with<br/>one another.  <br/>  <br/>Facebook killed TV. That is wildly oversimplified, of course, but probably as<br/>close to the truth as you can get in three words.  <br/>  <br/>___  <br/>  <br/>The TV networks already seem, grudgingly, to see where things are going, and<br/>have responded by putting their stuff, grudgingly, online. But they're still<br/>dragging their heels. They still seem to wish people would watch shows on TV<br/>instead, just as newspapers that put their stories online still seem to wish<br/>people would wait till the next morning and read them printed on paper. They<br/>should both just face the fact that the Internet is the primary medium.  <br/>  <br/>They'd be in a better position if they'd done that earlier. When a new medium<br/>arises that's powerful enough to make incumbents nervous, then it's probably<br/>powerful enough to win, and the best thing they can do is jump in immediately.  <br/>  <br/>Whether they like it or not, big changes are coming, because the Internet<br/>dissolves the two cornerstones of broadcast media: synchronicity and locality.<br/>On the Internet, you don't have to send everyone the same signal, and you<br/>don't have to send it to them from a local source. People will watch what they<br/>want when they want it, and group themselves according to whatever shared<br/>interest they feel most strongly. Maybe their strongest shared interest will<br/>be their physical location, but I'm guessing not. Which means local TV is<br/>probably dead. It was an artifact of limitations imposed by old technology. If<br/>someone were creating an Internet-based TV company from scratch now, they<br/>might have some plan for shows aimed at specific regions, but it wouldn't be a<br/>top priority.  <br/>  <br/>Synchronicity and locality are tied together. TV network affiliates care<br/>what's on at 10 because that delivers viewers for local news at 11. This<br/>connection adds more brittleness than strength, however: people don't watch<br/>what's on at 10 because they want to watch the news afterward.  <br/>  <br/>TV networks will fight these trends, because they don't have sufficient<br/>flexibility to adapt to them. They're hemmed in by local affiliates in much<br/>the same way car companies are hemmed in by dealers and unions. Inevitably,<br/>the people running the networks will take the easy route and try to keep the<br/>old model running for a couple more years, just as the record labels have<br/>done.  <br/>  <br/>A recent article in the _Wall Street Journal_ described how TV networks were<br/>trying to add more live shows, partly as a way to make viewers watch TV<br/>synchronously instead of watching recorded shows when it suited them. Instead<br/>of delivering what viewers want, they're trying to force them to change their<br/>habits to suit the networks' obsolete business model. That never works unless<br/>you have a monopoly or cartel to enforce it, and even then it only works<br/>temporarily.  <br/>  <br/>The other reason networks like live shows is that they're cheaper to produce.<br/>There they have the right idea, but they haven't followed it to its<br/>conclusion. Live content can be way cheaper than networks realize, and the way<br/>to take advantage of dramatic decreases in cost is to increase volume. The<br/>networks are prevented from seeing this whole line of reasoning because they<br/>still think of themselves as being in the broadcast business—as sending one<br/>signal to everyone. [4]  <br/>  <br/>___  <br/>  <br/>Now would be a good time to start any company that competes with TV networks.<br/>That's what a lot of Internet startups are, though they may not have had this<br/>as an explicit goal. People only have so many leisure hours a day, and TV is<br/>premised on such long sessions (unlike Google, which prides itself on sending<br/>users on their way quickly) that anything that takes up their time is<br/>competing with it. But in addition to such indirect competitors, I think TV<br/>companies will increasingly face direct ones.  <br/>  <br/>Even in cable TV, the long tail was lopped off prematurely by the threshold<br/>you had to get over to start a new channel. It will be longer on the Internet,<br/>and there will be more mobility within it. In this new world, the existing<br/>players will only have the advantages any big company has in its market.  <br/>  <br/>That will change the balance of power between the networks and the people who<br/>produce shows. The networks used to be gatekeepers. They distributed your<br/>work, and sold advertising on it. Now the people who produce a show can<br/>distribute it themselves. The main value networks supply now is ad sales.<br/>Which will tend to put them in the position of service providers rather than<br/>publishers.  <br/>  <br/>Shows will change even more. On the Internet there's no reason to keep their<br/>current format, or even the fact that they have a single format. Indeed, the<br/>more interesting sort of convergence that's coming is between shows and games.<br/>But on the question of what sort of entertainment gets distributed on the<br/>Internet in 20 years, I wouldn't dare to make any predictions, except that<br/>things will change a lot. We'll get whatever the most imaginative people can<br/>cook up. That's why the Internet won.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] Thanks to Trevor Blackwell for this point. He adds: "I remember the eyes<br/>of phone companies gleaming in the early 90s when they talked about<br/>convergence. They thought most programming would be on demand, and they would<br/>implement it and make a lot of money. It didn't work out. They assumed that<br/>their local network infrastructure would be critical to do video on-demand,<br/>because you couldn't possibly stream it from a few data centers over the<br/>internet. At the time (1992) the entire cross-country Internet bandwidth<br/>wasn't enough for one video stream. But wide-area bandwidth increased more<br/>than they expected and they were beaten by iTunes and Hulu."  <br/>  <br/>[2] Copyright owners tend to focus on the aspect they see of piracy, which is<br/>the lost revenue. They therefore think what drives users to do it is the<br/>desire to get something for free. But iTunes shows that people will pay for<br/>stuff online, if you make it easy. A significant component of piracy is simply<br/>that it offers a better user experience.  <br/>  <br/>[3] Or a phone that is actually a computer. I'm not making any predictions<br/>about the size of the device that will replace TV, just that it will have a<br/>browser and get data via the Internet.  <br/>  <br/>[4] Emmett Shear writes: "I'd argue the long tail for sports may be even<br/>larger than the long tail for other kinds of content. Anyone can broadcast a<br/>high school football game that will be interesting to 10,000 people or so,<br/>even if the quality of production is not so good."  <br/>  <br/>**Thanks** to Sam Altman, Trevor Blackwell, Nancy Cook, Michael Seibel. Emmett<br/>Shear, and Fred Wilson for reading drafts of this.  <br/>  <br/><br/>Japanese Translation  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>January 2012  <br/>  <br/>There are great startup ideas lying around unexploited right under our noses.<br/>One reason we don't see them is a phenomenon I call _schlep blindness_. Schlep<br/>was originally a Yiddish word but has passed into general use in the US. It<br/>means a tedious, unpleasant task.  <br/>  <br/>No one likes schleps, but hackers especially dislike them. Most hackers who<br/>start startups wish they could do it by just writing some clever software,<br/>putting it on a server somewhere, and watching the money roll in—without ever<br/>having to talk to users, or negotiate with other companies, or deal with other<br/>people's broken code. Maybe that's possible, but I haven't seen it.  <br/>  <br/>One of the many things we do at Y Combinator is teach hackers about the<br/>inevitability of schleps. No, you can't start a startup by just writing code.<br/>I remember going through this realization myself. There was a point in 1995<br/>when I was still trying to convince myself I could start a company by just<br/>writing code. But I soon learned from experience that schleps are not merely<br/>inevitable, but pretty much what business consists of. A company is defined by<br/>the schleps it will undertake. And schleps should be dealt with the same way<br/>you'd deal with a cold swimming pool: just jump in. Which is not to say you<br/>should seek out unpleasant work per se, but that you should never shrink from<br/>it if it's on the path to something great.  <br/>  <br/>The most dangerous thing about our dislike of schleps is that much of it is<br/>unconscious. Your unconscious won't even let you see ideas that involve<br/>painful schleps. That's schlep blindness.  <br/>  <br/>The phenomenon isn't limited to startups. Most people don't consciously decide<br/>not to be in as good physical shape as Olympic athletes, for example. Their<br/>unconscious mind decides for them, shrinking from the work involved.  <br/>  <br/>The most striking example I know of schlep blindness is Stripe, or rather<br/>Stripe's idea. For over a decade, every hacker who'd ever had to process<br/>payments online knew how painful the experience was. Thousands of people must<br/>have known about this problem. And yet when they started startups, they<br/>decided to build recipe sites, or aggregators for local events. Why? Why work<br/>on problems few care much about and no one will pay for, when you could fix<br/>one of the most important components of the world's infrastructure? Because<br/>schlep blindness prevented people from even considering the idea of fixing<br/>payments.  <br/>  <br/>Probably no one who applied to Y Combinator to work on a recipe site began by<br/>asking "should we fix payments, or build a recipe site?" and chose the recipe<br/>site. Though the idea of fixing payments was right there in plain sight, they<br/>never saw it, because their unconscious mind shrank from the complications<br/>involved. You'd have to make deals with banks. How do you do that? Plus you're<br/>moving money, so you're going to have to deal with fraud, and people trying to<br/>break into your servers. Plus there are probably all sorts of regulations to<br/>comply with. It's a lot more intimidating to start a startup like this than a<br/>recipe site.  <br/>  <br/>That scariness makes ambitious ideas doubly valuable. In addition to their<br/>intrinsic value, they're like undervalued stocks in the sense that there's<br/>less demand for them among founders. If you pick an ambitious idea, you'll<br/>have less competition, because everyone else will have been frightened off by<br/>the challenges involved. (This is also true of starting a startup generally.)  <br/>  <br/>How do you overcome schlep blindness? Frankly, the most valuable antidote to<br/>schlep blindness is probably ignorance. Most successful founders would<br/>probably say that if they'd known when they were starting their company about<br/>the obstacles they'd have to overcome, they might never have started it. Maybe<br/>that's one reason the most successful startups of all so often have young<br/>founders.  <br/>  <br/>In practice the founders grow with the problems. But no one seems able to<br/>foresee that, not even older, more experienced founders. So the reason younger<br/>founders have an advantage is that they make two mistakes that cancel each<br/>other out. They don't know how much they can grow, but they also don't know<br/>how much they'll need to. Older founders only make the first mistake.  <br/>  <br/>Ignorance can't solve everything though. Some ideas so obviously entail<br/>alarming schleps that anyone can see them. How do you see ideas like that? The<br/>trick I recommend is to take yourself out of the picture. Instead of asking<br/>"what problem should I solve?" ask "what problem do I wish someone else would<br/>solve for me?" If someone who had to process payments before Stripe had tried<br/>asking that, Stripe would have been one of the first things they wished for.  <br/>  <br/>It's too late now to be Stripe, but there's plenty still broken in the world,<br/>if you know how to see it.  <br/>  <br/>  <br/>  <br/>  <br/>  <br/> **Thanks** to Sam Altman, Paul Buchheit, Patrick Collison, Aaron Iba, Jessica<br/>Livingston, Emmett Shear, and Harj Taggar for reading drafts of this.  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/><br/><br/>October 2005  <br/>  <br/> _(This essay is derived from a talk at the 2005Startup School.)_  <br/>  <br/>How do you get good ideas for startups? That's probably the number one<br/>question people ask me.  <br/>  <br/>I'd like to reply with another question: why do people think it's hard to come<br/>up with ideas for startups?  <br/>  <br/>That might seem a stupid thing to ask. Why do they _think_ it's hard? If<br/>people can't do it, then it _is_ hard, at least for them. Right?  <br/>  <br/>Well, maybe not. What people usually say is not that they can't think of<br/>ideas, but that they don't have any. That's not quite the same thing. It could<br/>be the reason they don't have any is that they haven't tried to generate them.  <br/>  <br/>I think this is often the case. I think people believe that coming up with<br/>ideas for startups is very hard-- that it _must_ be very hard-- and so they<br/>don't try do to it. They assume ideas are like miracles: they either pop into<br/>your head or they don't.  <br/>  <br/>I also have a theory about why people think this. They overvalue ideas. They<br/>think creating a startup is just a matter of implementing some fabulous<br/>initial idea. And since a successful startup is worth millions of dollars, a<br/>good idea is therefore a million dollar idea.  <br/>  <br/>If coming up with an idea for a startup equals coming up with a million dollar<br/>idea, then of course it's going to seem hard. Too hard to bother trying. Our<br/>instincts tell us something so valuable would not be just lying around for<br/>anyone to discover.  <br/>  <br/>Actually, startup ideas are not million dollar ideas, and here's an experiment<br/>you can try to prove it: just try to sell one. Nothing evolves faster than<br/>markets. The fact that there's no market for startup ideas suggests there's no<br/>demand. Which means, in the narrow sense of the word, that startup ideas are<br/>worthless.  <br/>  <br/> **Questions**  <br/>  <br/>The fact is, most startups end up nothing like the initial idea. It would be<br/>closer to the truth to say the main value of your initial idea is that, in the<br/>process of discovering it's broken, you'll come up with your real idea.  <br/>  <br/>The initial idea is just a starting point-- not a blueprint, but a question.<br/>It might help if they were expressed that way. Instead of saying that your<br/>idea is to make a collaborative, web-based spreadsheet, say: could one make a<br/>collaborative, web-based spreadsheet? A few grammatical tweaks, and a woefully<br/>incomplete idea becomes a promising question to explore.  <br/>  <br/>There's a real difference, because an assertion provokes objections in a way a<br/>question doesn't. If you say: I'm going to build a web-based spreadsheet, then<br/>critics-- the most dangerous of which are in your own head-- will immediately<br/>reply that you'd be competing with Microsoft, that you couldn't give people<br/>the kind of UI they expect, that users wouldn't want to have their data on<br/>your servers, and so on.  <br/>  <br/>A question doesn't seem so challenging. It becomes: let's try making a web-<br/>based spreadsheet and see how far we get. And everyone knows that if you tried<br/>this you'd be able to make _something_ useful. Maybe what you'd end up with<br/>wouldn't even be a spreadsheet. Maybe it would be some kind of new spreasheet-<br/>like collaboration tool that doesn't even have a name yet. You wouldn't have<br/>thought of something like that except by implementing your way toward it.  <br/>  <br/>Treating a startup idea as a question changes what you're looking for. If an<br/>idea is a blueprint, it has to be right. But if it's a question, it can be<br/>wrong, so long as it's wrong in a way that leads to more ideas.  <br/>  <br/>One valuable way for an idea to be wrong is to be only a partial solution.<br/>When someone's working on a problem that seems too big, I always ask: is there<br/>some way to bite off some subset of the problem, then gradually expand from<br/>there? That will generally work unless you get trapped on a local maximum,<br/>like 1980s-style AI, or C.  <br/>  <br/> **Upwind**  <br/>  <br/>So far, we've reduced the problem from thinking of a million dollar idea to<br/>thinking of a mistaken question. That doesn't seem so hard, does it?  <br/>  <br/>To generate such questions you need two things: to be familiar with promising<br/>new technologies, and to have the right kind of friends. New technologies are<br/>the ingredients startup ideas are made of, and conversations with friends are<br/>the kitchen they're cooked in.  <br/>  <br/>Universities have both, and that's why so many startups grow out of them.<br/>They're filled with new technologies, because they're trying to produce<br/>research, and only things that are new count as research. And they're full of<br/>exactly the right kind of people to have ideas with: the other students, who<br/>will be not only smart but elastic-minded to a fault.  <br/>  <br/>The opposite extreme would be a well-paying but boring job at a big company.<br/>Big companies are biased against new technologies, and the people you'd meet<br/>there would be wrong too.  <br/>  <br/>In an essay I wrote for high school students, I said a good rule of thumb was<br/>to stay upwind-- to work on things that maximize your future options. The<br/>principle applies for adults too, though perhaps it has to be modified to:<br/>stay upwind for as long as you can, then cash in the potential energy you've<br/>accumulated when you need to pay for kids.  <br/>  <br/>I don't think people consciously realize this, but one reason downwind jobs<br/>like churning out Java for a bank pay so well is precisely that they are<br/>downwind. The market price for that kind of work is higher because it gives<br/>you fewer options for the future. A job that lets you work on exciting new<br/>stuff will tend to pay less, because part of the compensation is in the form<br/>of the new skills you'll learn.  <br/>  <br/>Grad school is the other end of the spectrum from a coding job at a big<br/>company: the pay's low but you spend most of your time working on new stuff.<br/>And of course, it's called "school," which makes that clear to everyone,<br/>though in fact all jobs are some percentage school.  <br/>  <br/>The right environment for having startup ideas need not be a university per<br/>se. It just has to be a situation with a large percentage of school.  <br/>  <br/>It's obvious why you want exposure to new technology, but why do you need<br/>other people? Can't you just think of new ideas yourself? The empirical answer<br/>is: no. Even Einstein needed people to bounce ideas off. Ideas get developed<br/>in the process of explaining them to the right kind of person. You need that<br/>resistance, just as a carver needs the resistance of the wood.  <br/>  <br/>This is one reason Y Combinator has a rule against investing in startups with<br/>only one founder. Practically every successful company has at least two. And<br/>because startup founders work under great pressure, it's critical they be<br/>friends.  <br/>  <br/>I didn't realize it till I was writing this, but that may help explain why<br/>there are so few female startup founders. I read on the Internet (so it must<br/>be true) that only 1.7% of VC-backed startups are founded by women. The<br/>percentage of female hackers is small, but not that small. So why the<br/>discrepancy?  <br/>  <br/>When you realize that successful startups tend to have multiple founders who<br/>were already friends, a possible explanation emerges. People's best friends<br/>are likely to be of the same sex, and if one group is a minority in some<br/>population, _pairs_ of them will be a minority squared. [1]  <br/>  <br/> **Doodling**  <br/>  <br/>What these groups of co-founders do together is more complicated than just<br/>sitting down and trying to think of ideas. I suspect the most productive setup<br/>is a kind of together-alone-together sandwich. Together you talk about some<br/>hard problem, probably getting nowhere. Then, the next morning, one of you has<br/>an idea in the shower about how to solve it. He runs eagerly to to tell the<br/>others, and together they work out the kinks.  <br/>  <br/>What happens in that shower? It seems to me that ideas just pop into my head.<br/>But can we say more than that?  <br/>  <br/>Taking a shower is like a form of meditation. You're alert, but there's<br/>nothing to distract you. It's in a situation like this, where your mind is<br/>free to roam, that it bumps into new ideas.  <br/>  <br/>What happens when your mind wanders? It may be like doodling. Most people have<br/>characteristic ways of doodling. This habit is unconscious, but not random: I<br/>found my doodles changed after I started studying painting. I started to make<br/>the kind of gestures I'd make if I were drawing from life. They were atoms of<br/>drawing, but arranged randomly. [2]  <br/>  <br/>Perhaps letting your mind wander is like doodling with ideas. You have certain<br/>mental gestures you've learned in your work, and when you're not paying<br/>attention, you keep making these same gestures, but somewhat randomly. In<br/>effect, you call the same functions on random arguments. That's what a<br/>metaphor is: a function applied to an argument of the wrong type.  <br/>  <br/>Conveniently, as I was writing this, my mind wandered: would it be useful to<br/>have metaphors in a programming language? I don't know; I don't have time to<br/>think about this. But it's convenient because this is an example of what I<br/>mean by habits of mind. I spend a lot of time thinking about language design,<br/>and my habit of always asking "would x be useful in a programming language"<br/>just got invoked.  <br/>  <br/>If new ideas arise like doodles, this would explain why you have to work at<br/>something for a while before you have any. It's not just that you can't judge<br/>ideas till you're an expert in a field. You won't even generate ideas, because<br/>you won't have any habits of mind to invoke.  <br/>  <br/>Of course the habits of mind you invoke on some field don't have to be derived<br/>from working in that field. In fact, it's often better if they're not. You're<br/>not just looking for good ideas, but for good _new_ ideas, and you have a<br/>better chance of generating those if you combine stuff from distant fields. As<br/>hackers, one of our habits of mind is to ask, could one open-source x? For<br/>example, what if you made an open-source operating system? A fine idea, but<br/>not very novel. Whereas if you ask, could you make an open-source play? you<br/>might be onto something.  <br/>  <br/>Are some kinds of work better sources of habits of mind than others? I suspect<br/>harder fields may be better sources, because to attack hard problems you need<br/>powerful solvents. I find math is a good source of metaphors-- good enough<br/>that it's worth studying just for that. Related fields are also good sources,<br/>especially when they're related in unexpected ways. Everyone knows computer<br/>science and electrical engineering are related, but precisely because everyone<br/>knows it, importing ideas from one to the other doesn't yield great profits.<br/>It's like importing something from Wisconsin to Michigan. Whereas (I claim)<br/>hacking and painting are also related, in the sense that hackers and painters<br/>are both makers, and this source of new ideas is practically virgin territory.  <br/>  <br/> **Problems**  <br/>  <br/>In theory you could stick together ideas at random and see what you came up<br/>with. What if you built a peer-to-peer dating site? Would it be useful to have<br/>an automatic book? Could you turn theorems into a commodity? When you assemble<br/>ideas at random like this, they may not be just stupid, but semantically ill-<br/>formed. What would it even mean to make theorems a commodity? You got me. I<br/>didn't think of that idea, just its name.  <br/>  <br/>You might come up with something useful this way, but I never have. It's like<br/>knowing a fabulous sculpture is hidden inside a block of marble, and all you<br/>have to do is remove the marble that isn't part of it. It's an encouraging<br/>thought, because it reminds you there is an answer, but it's not much use in<br/>practice because the search space is too big.  <br/>  <br/>I find that to have good ideas I need to be working on some problem. You can't<br/>start with randomness. You have to start with a problem, then let your mind<br/>wander just far enough for new ideas to form.  <br/>  <br/>In a way, it's harder to see problems than their solutions. Most people prefer<br/>to remain in denial about problems. It's obvious why: problems are irritating.<br/>They're problems! Imagine if people in 1700 saw their lives the way we'd see<br/>them. It would have been unbearable. This denial is such a powerful force<br/>that, even when presented with possible solutions, people often prefer to<br/>believe they wouldn't work.  <br/>  <br/>I saw this phenomenon when I worked on spam filters. In 2002, most people<br/>preferred to ignore spam, and most of those who didn't preferred to believe<br/>the heuristic filters then available were the best you could do.  <br/>  <br/>I found spam intolerable, and I felt it had to be possible to recognize it<br/>statistically. And it turns out that was all you needed to solve the problem.<br/>The algorithm I used was ridiculously simple. Anyone who'd really tried to<br/>solve the problem would have found it. It was just that no one had really<br/>tried to solve the problem. [3]  <br/>  <br/>Let me repeat that recipe: finding the problem intolerable and feeling it must<br/>be possible to solve it. Simple as it seems, that's the recipe for a lot of<br/>startup ideas.  <br/>  <br/> **Wealth**  <br/>  <br/>So far most of what I've said applies to ideas in general. What's special<br/>about startup ideas? Startup ideas are ideas for companies, and companies have<br/>to make money. And the way to make money is to make something people want.  <br/>  <br/>Wealth is what people want. I don't mean that as some kind of philosophical<br/>statement; I mean it as a tautology.  <br/>  <br/>So an idea for a startup is an idea for something people want. Wouldn't any<br/>good idea be something people want? Unfortunately not. I think new theorems<br/>are a fine thing to create, but there is no great demand for them. Whereas<br/>there appears to be great demand for celebrity gossip magazines. Wealth is<br/>defined democratically. Good ideas and valuable ideas are not quite the same<br/>thing; the difference is individual tastes.  <br/>  <br/>But valuable ideas are very close to good ideas, especially in technology. I<br/>think they're so close that you can get away with working as if the goal were<br/>to discover good ideas, so long as, in the final stage, you stop and ask: will<br/>people actually pay for this? Only a few ideas are likely to make it that far<br/>and then get shot down; RPN calculators might be one example.  <br/>  <br/>One way to make something people want is to look at stuff people use now<br/>that's broken. Dating sites are a prime example. They have millions of users,<br/>so they must be promising something people want. And yet they work horribly.<br/>Just ask anyone who uses them. It's as if they used the worse-is-better<br/>approach but stopped after the first stage and handed the thing over to<br/>marketers.  <br/>  <br/>Of course, the most obvious breakage in the average computer user's life is<br/>Windows itself. But this is a special case: you can't defeat a monopoly by a<br/>frontal attack. Windows can and will be overthrown, but not by giving people a<br/>better desktop OS. The way to kill it is to redefine the problem as a superset<br/>of the current one. The problem is not, what operating system should people<br/>use on desktop computers? but how should people use applications? There are<br/>answers to that question that don't even involve desktop computers.  <br/>  <br/>Everyone thinks Google is going to solve this problem, but it is a very subtle<br/>one, so subtle that a company as big as Google might well get it wrong. I<br/>think the odds are better than 50-50 that the Windows killer-- or more<br/>accurately, Windows transcender-- will come from some little startup.  <br/>  <br/>Another classic way to make something people want is to take a luxury and make<br/>it into a commmodity. People must want something if they pay a lot for it. And<br/>it is a very rare product that can't be made dramatically cheaper if you try.  <br/>  <br/>This was Henry Ford's plan. He made cars, which had been a luxury item, into a<br/>commodity. But the idea is much older than Henry Ford. Water mills transformed<br/>mechanical power from a luxury into a commodity, and they were used in the<br/>Roman empire. Arguably pastoralism transformed a luxury into a commodity.  <br/>  <br/>When you make something cheaper you can sell more of them. But if you make<br/>something dramatically cheaper you often get qualitative changes, because<br/>people start to use it in different ways. For example, once computers get so<br/>cheap that most people can have one of their own, you can use them as<br/>communication devices.  <br/>  <br/>Often to make something dramatically cheaper you have to redefine the problem.<br/>The Model T didn't have all the features previous cars did. It only came in<br/>black, for example. But it solved the problem people cared most about, which<br/>was getting from place to place.  <br/>  <br/>One of the most useful mental habits I know I learned from Michael Rabin: that<br/>the best way to solve a problem is often to redefine it. A lot of people use<br/>this technique without being consciously aware of it, but Rabin was<br/>spectacularly explicit. You need a big prime number? Those are pretty<br/>expensive. How about if I give you a big number that only has a 10 to the<br/>minus 100 chance of not being prime? Would that do? Well, probably; I mean,<br/>that's probably smaller than the chance that I'm imagining all this anyway.  <br/>  <br/>Redefining the problem is a particularly juicy heuristic when you have<br/>competitors, because it's so hard for rigid-minded people to follow. You can<br/>work in plain sight and they don't realize the danger. Don't worry about us.<br/>We're just working on search. Do one thing and do it well, that's our motto.  <br/>  <br/>Making things cheaper is actually a subset of a more general technique: making<br/>things easier. For a long time it was most of making things easier, but now<br/>that the things we build are so complicated, there's another rapidly growing<br/>subset: making things easier to _use_.  <br/>  <br/>This is an area where there's great room for improvement. What you want to be<br/>able to say about technology is: it just works. How often do you say that now?  <br/>  <br/>Simplicity takes effort-- genius, even. The average programmer seems to<br/>produce UI designs that are almost willfully bad. I was trying to use the<br/>stove at my mother's house a couple weeks ago. It was a new one, and instead<br/>of physical knobs it had buttons and an LED display. I tried pressing some<br/>buttons I thought would cause it to get hot, and you know what it said? "Err."<br/>Not even "Error." "Err." You can't just say "Err" to the user of a _stove_.<br/>You should design the UI so that errors are impossible. And the boneheads who<br/>designed this stove even had an example of such a UI to work from: the old<br/>one. You turn one knob to set the temperature and another to set the timer.<br/>What was wrong with that? It just worked.  <br/>  <br/>It seems that, for the average engineer, more options just means more rope to<br/>hang yourself. So if you want to start a startup, you can take almost any<br/>existing technology produced by a big company, and assume you could build<br/>something way easier to use.  <br/>  <br/> **Design for Exit**  <br/>  <br/>Success for a startup approximately equals getting bought. You need some kind<br/>of exit strategy, because you can't get the smartest people to work for you<br/>without giving them options likely to be worth something. Which means you<br/>either have to get bought or go public, and the number of startups that go<br/>public is very small.  <br/>  <br/>If success probably means getting bought, should you make that a conscious<br/>goal? The old answer was no: you were supposed to pretend that you wanted to<br/>create a giant, public company, and act surprised when someone made you an<br/>offer. Really, you want to buy us? Well, I suppose we'd consider it, for the<br/>right price.  <br/>  <br/>I think things are changing. If 98% of the time success means getting bought,<br/>why not be open about it? If 98% of the time you're doing product development<br/>on spec for some big company, why not think of that as your task? One<br/>advantage of this approach is that it gives you another source of ideas: look<br/>at big companies, think what they should be doing, and do it yourself. Even if<br/>they already know it, you'll probably be done faster.  <br/>  <br/>Just be sure to make something multiple acquirers will want. Don't fix<br/>Windows, because the only potential acquirer is Microsoft, and when there's<br/>only one acquirer, they don't have to hurry. They can take their time and copy<br/>you instead of buying you. If you want to get market price, work on something<br/>where there's competition.  <br/>  <br/>If an increasing number of startups are created to do product development on<br/>spec, it will be a natural counterweight to monopolies. Once some type of<br/>technology is captured by a monopoly, it will only evolve at big company rates<br/>instead of startup rates, whereas alternatives will evolve with especial<br/>speed. A free market interprets monopoly as damage and routes around it.  <br/>  <br/> **The Woz Route**  <br/>  <br/>The most productive way to generate startup ideas is also the most unlikely-<br/>sounding: by accident. If you look at how famous startups got started, a lot<br/>of them weren't initially supposed to be startups. Lotus began with a program<br/>Mitch Kapor wrote for a friend. Apple got started because Steve Wozniak wanted<br/>to build microcomputers, and his employer, Hewlett-Packard, wouldn't let him<br/>do it at work. Yahoo began as David Filo's personal collection of links.  <br/>  <br/>This is not the only way to start startups. You can sit down and consciously<br/>come up with an idea for a company; we did. But measured in total market cap,<br/>the build-stuff-for-yourself model might be more fruitful. It certainly has to<br/>be the most fun way to come up with startup ideas. And since a startup ought<br/>to have multiple founders who were already friends before they decided to<br/>start a company, the rather surprising conclusion is that the best way to<br/>generate startup ideas is to do what hackers do for fun: cook up amusing hacks<br/>with your friends.  <br/>  <br/>It seems like it violates some kind of conservation law, but there it is: the<br/>best way to get a "million dollar idea" is just to do what hackers enjoy doing<br/>anyway.  <br/>  <br/>  <br/>  <br/>**Notes**  <br/>  <br/>[1] This phenomenon may account for a number of discrepancies currently blamed<br/>on various forbidden isms. Never attribute to malice what can be explained by<br/>math.  <br/>  <br/>[2] A lot of classic abstract expressionism is doodling of this type: artists<br/>trained to paint from life using the same gestures but without using them to<br/>represent anything. This explains why such paintings are (slightly) more<br/>interesting than random marks would be.  <br/>  <br/>[3] Bill Yerazunis had solved the problem, but he got there by another path.<br/>He made a general-purpose file classifier so good that it also worked for<br/>spam.  <br/>  <br/><br/>One Specific Idea  <br/>  <br/><br/>Romanian Translation  <br/>  <br/><br/>Japanese Translation  <br/>  <br/><br/>Traditional Chinese Translation  <br/>  <br/><br/>Russian Translation  <br/>  <br/><br/>  <br/>  <br/><br/>* * *<br/><br/>